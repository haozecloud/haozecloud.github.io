[{"path":"/2023/09/28/Linux配置文件/mac/ruby-install/","content":"安装 Ruby安装 rvm下载安装 rvm 先安装好 RVM RVM 是一个便捷的多版本 Ruby 环境的管理和切换工具 官网：https://rvm.io/ 在终端控制台命令： $ curl -sSL https://get.rvm.io | bash -s stable 之后按回车键 截止到目前 最新的版本是 1.29.9 如下所示： 12345678910111213141516171819202122:~ admin$ curl -sSL https://get.rvm.io | bash -s stableDownloading https://github.com/rvm/rvm/archive/1.29.1.tar.gzDownloading https://github.com/rvm/rvm/releases/download/1.29.1/1.29.1.tar.gz.ascFound PGP signature at: &#x27;https://github.com/rvm/rvm/releases/download/1.29.1/1.29.1.tar.gz.asc&#x27;,but no GPG software exists to validate it, skipping.Installing RVM to /Users/admin/.rvm/ Adding rvm PATH line to /Users/admin/.profile /Users/admin/.mkshrc /Users/admin/.bashrc /Users/admin/.zshrc. Adding rvm loading line to /Users/admin/.profile /Users/admin/.bash_profile /Users/admin/.zlogin.Installation of RVM in /Users/admin/.rvm/ is almost complete: * To start using RVM you need to run `source /Users/admin/.rvm/scripts/rvm` in all your open shell windows, in rare cases you need to reopen all shell windows.# admin,## Thank you for using RVM!# We sincerely hope that RVM helps to make your life easier and more enjoyable!!!## ~Wayne, Michal &amp; team.In case of problems: https://rvm.io/help and https://twitter.com/rvm_io 等待一两分钟，成功安装好 RVM。 设置环境变量1234567891011121314# 1.2 然后，载入 RVM 环境：$ source /etc/profile.d/rvm.sh$ sudo chmod -R 777 /usr/local/rvm/archives# 1.3 修改 RVM 下载 Ruby 的源，到 Ruby China 的镜像$ echo &quot;ruby_url=https://cache.ruby-china.com/pub/ruby&quot; &gt; /usr/local/rvm/user/db$ rvm install 2.7.0 --disable-binary// 如下所示：AdmindeiMac-4:~ admin$ source ~/.rvm/scripts/rvmAdmindeiMac-4:~ admin$ echo &quot;ruby_url=https://cache.ruby-china.org/pub/ruby&quot; &gt; ~/.rvm/user/dbAdmindeiMac-4:~ admin$ rvm -vrvm 1.29.9 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io/]如果能显示版本号,则安装成功。 参考资料 MAC_Ruby 安装"},{"path":"/2023/09/28/Linux配置文件/wireshark/vim/vim_YouCompleteMe/install.sh/","content":"#vim 版本大于7.3.584 #升级vimyum install ncurses-devel perl-ExtUtils-Embed python-devel wget ftp://ftp.vim.org/pub/vim/unix/vim-7.4.tar.bz2 tar jxvf vim-7.4.tar.bz2 &amp;&amp; cd vim74.&#x2F;configure –with-features&#x3D;huge –enable-pythoninterp&#x3D;yes –with-python-config-dir&#x3D;&#x2F;usr&#x2F;lib64&#x2F;python2.6&#x2F;config&#x2F; –enable-perlinterp&#x3D;yes –enable-cscope –enable-luainterp –enable-perlinterp –enable-multibyte –prefix&#x3D;&#x2F;usr make -j4 &amp;&amp; make install #&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #升级gcc 依赖yum install gcc gcc-c++ gibc-static cloog-ppl gmp-devel islwget ftp://gcc.gnu.org/pub/gcc/infrastructure/isl-0.12.2.tar.bz2tar jxvf isl-0.12.2.tar.bz2 &amp;&amp; cd isl-0.12.2.&#x2F;configuremakemake install #获取最新gcc源码#svn checkout svn:&#x2F;&#x2F;gcc.gnu.org&#x2F;svn&#x2F;gcc&#x2F;trunk localdircd localdir&#x2F;gccmkdir build #下载gmp，mpfr，mpc源码，gcc-4.10.tgz里已经包含下载完的三个源码包，不必再次下载.&#x2F;contrib&#x2F;download_prerequisites cd build..&#x2F;configure –prefix&#x3D;&#x2F;usr –enable-languages&#x3D;c,c++ –disable-multilib make -j4#make -j选项，与cpu个数及线程数有关 make install #&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #llvm-clang #Checkout LLVM:#Change directory to where you want the llvm directory placed.mkdir &#x2F;Data&#x2F;software&#x2F;llvm-clang &amp;&amp; cd &#x2F;Data&#x2F;software&#x2F;llvm-clangsvn co http://llvm.org/svn/llvm-project/llvm/trunk llvm Checkout Clang:cd llvm&#x2F;toolssvn co http://llvm.org/svn/llvm-project/cfe/trunk clang Checkout extra Clang Tools: (optional)cd llvm&#x2F;tools&#x2F;clang&#x2F;toolssvn co http://llvm.org/svn/llvm-project/clang-tools-extra/trunk extra Checkout Compiler-RT:cd llvm&#x2F;projectssvn co http://llvm.org/svn/llvm-project/compiler-rt/trunk compiler-rtcd ..&#x2F;..&#x2F; #Build LLVM and Clang:mkdir buildcd build..&#x2F;llvm&#x2F;config –enable-optimized #会提示gcc版本过低，升级gcc方法见gcc&#x2F;install.shmake -j4make install #clang加入系统变量export PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;bin:$PATHecho “&#x2F;usr&#x2F;local&#x2F;lib” &gt;&gt; &#x2F;etc&#x2F;ld.so.confldconfig #安装clang标准库cd &#x2F;Data&#x2F;software&#x2F;llvm-clang&#x2F;llvmsvn co http://llvm.org/svn/llvm-project/libcxx/trunk libcxxcd libcxx&#x2F;lib.&#x2F;builditcp -r ..&#x2F;include&#x2F; &#x2F;usr&#x2F;include&#x2F;c++&#x2F;v1&#x2F;ln -s libc++.so.1.0 libc++.so.1ln -s libc++.so.1.0 libc++.socp libc++.so* &#x2F;usr&#x2F;lib&#x2F; cd &#x2F;Data&#x2F;software&#x2F;llvmsvn co http://llvm.org/svn/llvm-project/libcxxabi/trunk libcxxabicd libcxxabi&#x2F;lib.&#x2F;builditcp -r ..&#x2F;include&#x2F; &#x2F;usr&#x2F;include&#x2F;c++&#x2F;v1&#x2F;ln -s libc++abi.so.1.0 libc++abi.so.1ln -s libc++abi.so.1.0 libc++abi.socp libc++abi.so* &#x2F;usr&#x2F;lib&#x2F; #&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 安装vundel，vim插件管理器git clone https://github.com/gmarik/vundle.git ~&#x2F;.vim&#x2F;bundle&#x2F;vundle 使用vundel安装YouCompleteMe在.vimrc中添加如下内容：“”””””””””””””””””””””””””””””“ Vunble“”””””””””””””””””””””””””””””filetype off “ required!set rtp+&#x3D;~&#x2F;.vim&#x2F;bundle&#x2F;vundle&#x2F;call vundle#rc() “ let Vundle manage VundleBundle ‘gmarik&#x2F;vundle’ “ YouCompleteMe reposBundle ‘Valloric&#x2F;YouCompleteMe’ filetype plugin indent on “ required! 执行命令 vim +BundleInstall +qall来安装YouCompleteMe编译YouCompleteMecd ~mkdir ycm_buildcd ycm_buildcmake -G “Unix Makefiles” . &#x2F;.vim&#x2F;bundle&#x2F;YouCompleteMe&#x2F;cppcmake -G “Unix Makefiles” -DPATH_TO_LLVM_ROOT&#x3D;&#x2F;usr&#x2F; . ~&#x2F;.vim&#x2F;bundle&#x2F;YouCompleteMe&#x2F;cppmake ycm_coremake ycm_support_libs#make 结果是在&#x2F;.vim&#x2F;bundel&#x2F;YouCompletMe&#x2F;python目录下生成libclang.so、ycm_core.so、ycm_client_support.so #安装 YouCompleteMecd ~&#x2F;.vim&#x2F;bundle&#x2F;YouCompleteMe .&#x2F;install.sh –clang-completer –system-libclang"},{"path":"/2023/09/28/Linux配置文件/wireshark/readme/","content":"底行模式下:1,4 m 6 #把1-4行移动到第6行之后[含1，4]:1,4 co 6 #把1-4行复制到第6行之后[含1，4]:1,4 d #删除1-4行[含1，4] :g&#x2F;^&#x2F;m 0 #倒序文件行:g&#x2F;^$&#x2F;d #vi中删除空行:g&#x2F;^&#x2F;+1 d #删除偶数行 也可以用normal命令 :%normal jdd:g&#x2F;^&#x2F;d|m. #删除奇数行 :!ls #执行外部命令:r !ls #将外部命令的执行结果写入到vim中 编辑模式下 读取光标处的字符串，并且移动光标到它再次出现的地方。 和上面的类似，但是是往反方向寻找。c 行内删除cc 删除整行并进入输入模式cw 删除 zz 把当前置于屏幕中间，对应上下命令zt，zb fx 移动光标到当前行的下一个 x 处。使用 ; 来重复上一个 f 命令。tx 和上面的命令类似，但是是移动到 x 的左边一个位置。 编辑多个文件，vim -Oo file1 file2 #垂直分屏或水平分屏同已vim中多个文件间的复制粘贴可以使用v选择要复制的区域使用寄存器“f3Y #复制3整行到寄存器f中 ”fp #将寄存器f中的内容粘贴到光标所在行之下，大写P则为粘贴到所在行之上 快速删除全部内容gg # 定位到文件首行dG # 快速删除全部内容"},{"path":"/2023/09/28/Linux配置文件/tcp-wrappers/readme/","content":"#匹配顺序hosts.allow,匹配成功则放行，不再匹配hosts.deny，反之才会去匹配hosts.deny，若二者冲突则以hosts.deny为准 以下内容摘自博客：http://wordpress.facesoho.com/server/linux-tcp_wrappers.html简单介绍一下tcp-wrapers一. 首先检查某种服务是否受tcp_wrappers 管理ldd which sshd grep | libwrap如果有这个链接，说面某个服务接受tcp_wrappers管理二. 与tcp_wrappers相关的文件有&#x2F;etc&#x2F;hosts.allow&#x2F;etc&#x2F;hosts.deny三. 工作原理 当有请求从远程到达本机的时候首先检查&#x2F;etc&#x2F;hosts.allow如有匹配的，就默认允许访问,跳过 &#x2F;etc&#x2F;hosts.deny这个文件没有匹配的,就去匹配&#x2F;etc&#x2F;hosts.deny 文件,如果有匹配的，那么就拒绝这个访问 如果在这两个文件中，都没有匹配到，默认是允许访问的四. 这两个文件格式服务列表 ：地址列表 ：选项A. 服务列表格式：如果有多个服务，那么就用逗号隔开B. 地址列表格式： 标准IP地址：例如：192.168.0.254，192.168.0.56如果多于一个用，隔开 主机名称：例如：www.baidu.com，　.example.con匹配整个域 利用掩码：192.168.0.0&#x2F;255.255.255.0指定整个网段 网络名称：例如 @mynetworkC. 选项：主要有allow 和 deny 这两个选项D. 其它的特定格式ALL ：指代所有主机LOCAL ：指代本地主机KNOWN ：能够解析的UNKNOWN ：不能解析的PARANOID ： 五. 扩展选项：spawn : 执行某个命令 [spawn原意是产卵]vsftpd : spawn echo “login attempt from %c”to %s” | mail –s warning roottwist : 中断命令的执行：vsftpd : twist echo “login attempt from %c to %s ” | mail –s waring root 六. 一个例子在&#x2F;etc&#x2F;hosts.allow文件中指定下面的内容vsftpd: 192.168.0.in.telnetd, protmap: 192.168.0.8在&#x2F;etc&#x2F;hosts.deny中指定一下文件ALL: .cracker.org EXCEPT trusted.cracker.orgvsftpd,protmap: ALLsshd: 192.168.0. EXCEPT 192.168.0.4 TCP 封包先经过IP过滤机制IP Filtering [Linux 提供的第一层保护] 可以将不想要的来源IP(经由 TCP 封包的 Head 资料)先当掉,如果通过了，再去通过TCP_wrappers过滤,如果上面两个都通过了,再根据每个服务访问控制设定 来决定客户机能得到的权限和信息. TCP_wrappers防火墙主要涉及到两个文件&#x2F;etc&#x2F;hosts.allow&#x2F;etc&#x2F;hosts.deny这两个文件被整合在xinetd中. 需要安装tcp_wrappers套件,因为这两个文件是tcp_wrappers的设定文件,构成了一个基础的防火墙,tcp_wrappers设定tcp封装的包是否可以进入&#x2F;etc&#x2F;hosts.allow和&#x2F;etc&#x2F;hosts.deny,如果一个服务是受到 xinetd 或 TCP_Wrappers 的控制时，那么该服务就会受限于 hosts.allow 与 hosts.deny 的管理, 先判断某个服务是否可以使用tcp_wrappers防火墙.vsftpd . telnet .sendmail、sshd、tcpd、xinetd、gdm、portmap都可以使用。很多服务在&#x2F;etc&#x2F;xined.d&#x2F;目录中,可以对服务进行规则的设置.查看一个服务是否可以用tcp_wraper控制:#ldd which servername 返回信息中有很多lib开头的链接文件[库文件],说明此服务受TCP_Wrapper规则控制. 先看#cat &#x2F;etc&#x2F;xinetd.conf |less,如果enable和disable都为yes,那就以拒绝优先. only_from #定义只有指定的主机可以访问该服务.no_access #定义指定的主机不能访问该服务. only_from和no_access 定义的主机有包含的关系时,以小范围的为主,比如在only_from中1.1.1.0网段主机可以访问在no_access中1.1.0.0主机不能访问这时而不是拒绝优先,而是以only_from为准. cps #定义限制连接进来的主机数目.per_source #定义一台主机最大连接数目,通常和cps混用.instance #定义最大连接数目,这个数目是指不同的主机连接进来的数目,而不是同一台主机连接进来的数目..bind #定义指定监听的IP地址(后只跟IP地址,而不是网卡的名字.)baner #定义欢迎信息,后面指定一个文件路径.此文件内容可自己定义..socket_type &#x3D; stream #定义使用tcp协议..single_threaded #定义单线程multi_threaded #定义多线程 以ftp服务和telnet为例,机器名不只在&#x2F;etc&#x2F;sysconfig&#x2F;network中定义,还存在于&#x2F;etc&#x2F;hosts,这两个文件中的机器名必须一致,否则即使开启了telnet,也无法telnet成功 服务器IP:192.168.0.195先安装一个xinetd包,然后安装ftp包和telnet包.[root@station195 Server]# rpm -ivh xinetd-2.3.14-10.el5.i386.rpm[root@station195 Server]# rpm -ivh vsftpd-2.0.5-16.el5.i386.rpm[root@station195 Server]# rpm -ivh telnet-0.17-39.el5.i386.rpm[root@station195 Server]# rpm -ivh telnet-server-0.17-39.el5.i386.rpm编辑&#x2F;etc&#x2F;xinetd.d&#x2F;telnet将disable &#x3D; yes改为disable &#x3D; no(启动telnet,默认不会开启.)[root@station195 Server]# service xinetd restart[root@station195 Server]# chkconfig xinetd on编辑hosts.allow文件,写入一行vsftpd:192.168.0.0&#x2F;255.255.255.0 EXCEPT 192.168.0.192再编辑&#x2F;etc&#x2F;hosts.deny文件,加入一行vsftpd:ALL,然后执行此命令[root@station195 ~]# chkconfig –level 35 vsftpd on[root@station195 ~]# service vsftpd restart 可以让登录服务器时的消息发给服务器,用spawn命令.编辑hosts.allow文件写入in.telnetd:ALL:spawn &#x2F;bin&#x2F;echo date %c %d | &#x2F;bin&#x2F;mail -s “somebody access our ftp.” root意思是:当有主机访问服务器时,向管理员发封邮件内容是somebody access our ftp .%c提取客户机的信息%d是守护进程的名字.当客户机telnet服务器后,服务器向自己发邮件,我们可以在服务器上使用mail命令查看内容 From &#x6d;&#121;&#97;&#x63;&#x63;&#111;&#117;&#x6e;&#116;&#x40;&#x65;&#x78;&#97;&#x6d;&#112;&#x6c;&#101;&#x2e;&#x63;&#x6f;&#x6d; Thu Feb 25 14:35:47 2010Date: Thu, 25 Feb 2010 14:35:47 +0800From: myaccount &#109;&#121;&#x61;&#99;&#99;&#x6f;&#x75;&#x6e;&#116;&#64;&#x65;&#120;&#97;&#109;&#112;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109;To: &#109;&#x79;&#x61;&#x63;&#x63;&#111;&#117;&#110;&#x74;&#x40;&#101;&#x78;&#97;&#x6d;&#112;&#108;&#101;&#x2e;&#x63;&#111;&#109;Subject: somebody access our telnet.Thu Feb 25 14:35:47 CST 2010 192.168.0.192 in.telnetd 还可以给对方造成一种假象,提示对方输入用户名和密码,输入都正确,但是进不去. 下面就要用到twist命令[中文是 曲解]ftp为例:编辑hosts.allow文件添加命令语句：vsftpd:ALL:twist &#x2F;bin&#x2F;echo ” welcome to server.” 访问FTP时就会提示输入用户名和密码,即使输正确了.但是进不去的.还可以返回给客户一句话,比方说在hosts.allow中写入vsftpd:ALL:twist &#x2F;bin&#x2F;echo date “connection refused by %s.”访问ftp时,直接会退出来,返回的信息.C:&gt;ftp 192.168.0.195Connected to 192.168.0.195.Thu Feb 25 15:15:41 CST 2010 connection refused by &#x76;&#115;&#x66;&#x74;&#112;&#x64;&#64;&#x31;&#57;&#50;&#x2e;&#x31;&#54;&#56;&#x2e;&#x30;&#x2e;&#x31;&#x39;&#53;.Connection closed by remote host. 也可以将spawn和twist命令一起用.在hosts.allow中插入一句话vsftpd:ALL:spawn &#x2F;bin&#x2F;echo date %c to %s denied. &gt;&gt;&#x2F;var&#x2F;log&#x2F;tcpwrapper.log:twist &#x2F;bin&#x2F;echo “attempt log to %s failed.”当登录服务器时会将返回信息定向到tcpwrapper.log中..Thu Feb 25 15:32:44 CST 2010 192.168.0.200 to &#x76;&#115;&#x66;&#x74;&#x70;&#x64;&#64;&#x31;&#57;&#50;&#x2e;&#49;&#54;&#56;&#46;&#x30;&#x2e;&#49;&#57;&#x35; denied.C:&gt;ftp 192.168.0.195Connected to 192.168.0.195.attempt log to &#118;&#115;&#x66;&#x74;&#x70;&#x64;&#x40;&#49;&#57;&#50;&#x2e;&#49;&#54;&#56;&#46;&#x30;&#x2e;&#49;&#x39;&#x35; failed.Connection closed by remote host. 还可以定义欢迎信息banners"},{"path":"/2023/09/28/Linux配置文件/wireshark/swatch/sshauth.pl/","content":"#!&#x2F;usr&#x2F;bin&#x2F;perl -w############################################################################### File: sshauth.plPurpose: To interface with psad to block IP addresses that commit failedlogin attempts against SSHD. This script was written for thebook “Linux Firewalls: Attack Detection and Response withiptables, psad, and fwsnort”.Copyright (C) 2006-2007 Michael Rash (&#109;&#x62;&#114;&#x40;&#99;&#105;&#x70;&#x68;&#101;&#114;&#x64;&#x79;&#110;&#101;&#x2e;&#x6f;&#114;&#x67;)License (GNU Public License):This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program; if not, write to the Free SoftwareFoundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307USA############################################################################## $Id: index.html 2980 2011-01-09 15:27:41Z mbr $use IO::Socket;use IO::Handle;use strict; #&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; config &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;my $auth_failed_threshold &#x3D; 2;my $auth_failed_regex &#x3D; ‘sshd.Authentication\\sfailure.*?((?:[0-2]?\\d{1,2}.){3}[0-2]?\\d{1,2})’;my $sockfile &#x3D; ‘&#x2F;var&#x2F;run&#x2F;psad&#x2F;auto_ipt.sock’;my $sleep_interval &#x3D; 5; ### seconds#&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; end config &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; cache previously seen IP addresses and associated failed logincountsmy %ip_cache &#x3D; (); open the psad domain socket for writingmy $psad_sock &#x3D; IO::Socket::UNIX-&gt;new($sockfile) or die “[*] Could not acquire psad domain “, “socket $sockfile: $!”; my $file &#x3D; $ARGV[0] or die “$0 “; open the log fileopen F, $file or die “[*] Could not open $file: $!”;my $skip_first_loop &#x3D; 0;for (;;) { unless ($skip_first_loop) { seek F,0,2; ### seek to the end of the file $skip_first_loop &#x3D; 1; } my @messages &#x3D; ; for my $msg (@messages) { if ($msg &#x3D;~ m|$auth_failed_regex|) { $ip_cache{$1}++; } } for my $src (keys %ip_cache) { ### block the IP if the threshold is exceeded if ($ip_cache{$src} % $auth_failed_threshold &#x3D;&#x3D; 0) { print $psad_sock “add $src ”; } } F-&gt;clearerr(); ### be ready for new data sleep $sleep_interval;}close F;close $psad_sock;exit 0;"},{"path":"/2023/09/28/Linux配置文件/somecommands/uniq/","content":"uniq -c��–count ��ÿ���Ա���ʾ�����ظ����ֵĴ����� -d��–repeated ����ʾ�����ظ����ֵ���(һ��)�� -f&lt;��λ&gt;��–skip-fields&#x3D;&lt;��λ&gt; ���ԱȽ�ָ������λ�� -s&lt;�ַ�λ��&gt;��–skip-chars&#x3D;&lt;�ַ�λ��&gt; ���ԱȽ�ָ�����ַ��� -u��–unique ����ʾ��һ�ε����С� -w&lt;�ַ�λ��&gt;��–check-chars&#x3D;&lt;�ַ�λ��&gt; ָ��Ҫ�Ƚϵ��ַ��� –help ��ʾ������ –version ��ʾ�汾��Ϣ�� #####ע��uniq������”�����ظ�����”���У�û������������ʹ���ֶ��Ҳ����Ϊ�ظ���������ȥ�ص�ʱ��һ����sort����ʹ��,��sort���򣬱�֤�ظ������������֣�Ȼ��ʹ��uniq��ʾ�����ظ���һ�����ﵽȥ��Ч�� [root@stu100 ~]# cat test ����boy took bat home ����boy took bat home ����girl took bat home ����dog brought hat home ����dog brought hat home ����dog brought hat home ������test�ļ������ݣ����Կ������е������ظ��� ����[root@stu100 ~]# uniq test ����boy took bat home ����girl took bat home ����dog brought hat home ����uniq������κβ���������ʾ�����ظ�����һ��,ע�������”�����ظ�”������������uniq���������ظ� ����[root@stu100 ~]# uniq -c test ����2 boy took bat home ����1 girl took bat home ����3 dog brought hat home ����-c ������ʾ�ļ���ÿ���������ֵĴ����� ����[root@stu100 ~]# uniq -d test ����boy took bat home ����dog brought hat home ����-dѡ�����ʾ�ļ��������ظ����ֵ��У���ÿ�������ظ�����ֻ��ʾһ�Ρ� ����[root@stu100 ~]# uniq -u test ����girl took bat home ����-uѡ����ʾ�ļ���û���������ֵ��С� ����[root@stu100 ~]# uniq -f 2 -s 2 test ����boy took bat home ��������ÿ�е�ǰ2���ֶΣ����Եڶ����հ��ַ��͵������ֶε����ַ������at home ����[root@stu100 ~]# uniq -f 1 test ����boy took bat home ����dog brought hat home ��������ÿ�еĵ�һ���ֶΣ�����boy ��girl��ͷ���п������������ظ�����"},{"path":"/2023/09/28/Linux配置文件/somecommands/tee/","content":"1 echo “hello world” | tee tee.txt �������������׼�������Ļ����ͬʱд���ļ�tee.txt 2 tee -a ׷�ӣ��������ļ�ԭ�������� echo “1234” | tee -a tee.txt 3 tee- ������ظ������� echo “12345” |tee -������1234512345 echo “12345” |tee - - &#x2F;&#x2F;ע��-��tee֮�估-��-֮�䶼�пո�������123451234512345 echo “12345” |tee - - -������12345123451234512345"},{"path":"/2023/09/28/Linux配置文件/somecommands/strace/","content":"�����Ի���ϵͳ���û���ϵͳ������������ ������ͨ�������ƶ�ϵͳ���õĴ��������ѵ�ʱ���Լ��ɹ���ʧ�ܵĴ���������ϵͳ���õ�ʹ�� ������׷�ٷ��͸����̵��ź�(signal) ������ͨ������id(pid)�ż��뵽�����������еĽ����� �е�ʱ���㷢���֣�����������޸������ļ���Ӧ�ó���û�а������˼·ȥ���У�����ʲôԭ��һ��ǳ�Ե����׺��ӵĿ����ǣ�Ӧ�ó�������ʱ��ȡ������ΪҪ��ȡ�������ļ����𣿿���������� strace php 2&gt;&amp;1 | grep php.ini strace -e open php 2&gt;&amp;1 | grep php.ini #����ͨ��-e������ָ��ֻ׷�����ǹ��ĵ�ϵͳ���� stace -e open ,access 2&gt;&amp;1 | grep your-filename#������û�ж�ȡ������ļ�����ȡ�Ľ����ʲô������û��Ȩ��?�ļ������ڣ� strace -p PID #���̴˿�����ʲô strace -T ���û��ѵ�ʱ�� strace -t ���÷�����ʱ�� strace -c -p PID ���̵�ʱ�䶼���������ˣ�"},{"path":"/2023/09/28/Linux配置文件/somecommands/sort/","content":"sort sort ʹ��˫�������ָ��� s&#x3D;’,,’sort -t $’s’ -k 2 filename ps -e -o’user,uid,pid,comm,args,pcpu,rss,vsz,stime’|sort -nrk7|head #�ڴ�ռ��ǰʮ �����κ�ѡ��������ĸ��˳�������˳��ASCII��ֵ�����У�Ĭ������ sort -u ȥ���ظ��� sort -r ������� sort -o ���������ļ������Ŀ�������ԭ�ļ� sort -n ����ֵ���� sort -t -k ,�趨���������ָ�����н������� sort -M ���·����� sort -m -t “ “ -k 4 -o log_all log1 log2 log3 ����־�ϲ� sort -b ����ÿ��ǰ������пհ��ַ����ӵ�һ���ɼ��ַ���ʼ�Ƚ� [ FStart [ .CStart ] ] [ Modifier ] [ , [ FEnd [ .CEnd ] ][ Modifier ] ] ����﷨��ʽ���Ա����еĶ��ţ�����������Ϊ���󲿷֣�Start���ֺ�End���֡� �ȸ������һ��˼�룬�Ǿ��ǡ�������趨End���֣���ô����ΪEnd���趨Ϊ��β��������������Ҫ�ģ��������㲻���������� Start����Ҳ����������ɣ����е�Modifier���־�������֮ǰ˵��������n��r��ѡ��֡������ص�˵˵Start���ֵ�FStart��C.Start�� C.StartҲ�ǿ���ʡ�Եģ�ʡ�ԵĻ��ͱ�ʾ�ӱ���Ŀ�ͷ���ֿ�ʼ��֮ǰ�����е�-k 2��-k 3����ʡ����C.Start������ඡ� FStart.CStart������FStart���Ǳ�ʾʹ�õ��򣬶�CStart���ʾ��FStart���дӵڼ����ַ���ʼ�㡰�������ַ����� ͬ������End�����У�������趨FEnd.CEnd�������ʡ��.CEnd�����ʾ��β������β��������������һ���ַ������ߣ�����㽫CEnd�趨Ϊ0(��)��Ҳ�Ǳ�ʾ��β������β���� 7 ͻ�����룬�ӹ�˾Ӣ�����Ƶĵڶ�����ĸ��ʼ�������� $ sort -t �� �� -k 1.2 facebook.txtbaidu 100 5000sohu 100 4500google 110 5000guge 50 3000 ��������ʹ����-k 1.2����ͱ�ʾ�Ե�һ����ĵڶ����ַ���ʼ����������һ���ַ�Ϊֹ���ַ�������������ᷢ��baidu��Ϊ�ڶ�����ĸ��a�����а��ס�sohu��google�ڶ����ַ�����o����sohu��h��google��oǰ�棬�������߷ֱ����ڵڶ��͵�����gugeֻ�����ӵ����ˡ� 8 ��ͻ�����룬��ֻ��Թ�˾Ӣ�����Ƶĵڶ�����ĸ�������������ͬ�İ���Ա�����ʽ��н������� $ sort -t �� �� -k 1.2,1.2 -k 3,3nr facebook.txtbaidu 100 5000google 110 5000sohu 100 4500guge 50 3000 ����ֻ�Եڶ�����ĸ����������������ʹ����-k 1.2,1.2�ı�ʾ��ʽ����ʾ���ǡ�ֻ���Եڶ�����ĸ�������򡣣�������ʡ���ʹ��-k 1.2��ô���У�������Ȼ���У���Ϊ��ʡ����End���֣������ζ���㽫�Դӵڶ�����ĸ�𵽱������һ���ַ�Ϊֹ���ַ����������򣩡�����Ա�����ʽ�����������Ҳʹ����-k 3,3��������׼ȷ�ı�������ʾ���ǡ�ֻ���Ա������������Ϊ�����ʡ���˺����3���ͱ�������ǡ��Ե�3����ʼ�����һ����λ�õ����ݽ��������ˡ� 9 ��modifier���ֻ������õ���Щѡ� �����õ�b��d��f��i��n �� r�� ����n��r��϶��Ѿ�����Ϥ�ˡ� b��ʾ���Ա����ǩ���հ׷��š� d��ʾ�Ա������ֵ�˳�����򣨼���ֻ���ǿհ׺���ĸ���� f��ʾ�Ա�����Դ�Сд�������� i��ʾ���ԡ����ɴ�ӡ�ַ�����ֻ��Կɴ�ӡ�ַ��������򡣣���ЩASCII���ǲ��ɴ�ӡ�ַ�������\\a�Ǳ�����\\b���˸� �ǻ��У�\\r�ǻس��ȵȣ� 10 ˼��˼������-k��-u����ʹ�õ����ӣ� $ cat facebook.txtgoogle 110 5000baidu 100 5000guge 50 3000sohu 100 4500 ������ԭʼ��facebook.txt�ļ��� $ sort -n -k 2 facebook.txtguge 50 3000baidu 100 5000sohu 100 4500google 110 5000 $ sort -n -k 2 -u facebook.txtguge 50 3000baidu 100 5000google 110 5000 ���趨�Թ�˾Ա���������ֵ����Ȼ���-u��sohuһ�оͱ�ɾ���ˣ�ԭ��-uֻʶ����-k�趨���򣬷�����ͬ���ͽ�������ͬ���ж�ɾ���� $ sort -k 1 -u facebook.txtbaidu 100 5000google 110 5000guge 50 3000sohu 100 4500 $ sort -k 1.1,1.1 -u facebook.txtbaidu 100 5000google 110 5000sohu 100 4500 �������Ҳͬ������ͷ�ַ���g��guge��û���������ѡ� $ sort -n -k 2 -k 3 -u facebook.txtguge 50 3000sohu 100 4500baidu 100 5000google 110 5000 �ף����������������������ȼ�������£�ʹ��-u��û��ɾ���κ��С�ԭ��-u�ǻ�Ȩ������-kѡ�������ͬ�ĲŻ�ɾ����ֻҪ������һ����ͬ����������ɾ����:)�����ţ�������Լ���һ��sina 100 4500���Կ��� 11 ���������� $ sort -n -k 2.2,3.1 facebook.txtguge 50 3000baidu 100 5000sohu 100 4500google 110 5000 �Եڶ�����ĵڶ����ַ���ʼ����������ĵ�һ���ַ������Ĳ��ֽ������� ��һ�У�����ȡ0 3���ڶ�����ȡ00 5����������ȡ00 4����������ȡ10 5�� ����Ϊsort��Ϊ0С��00С��000С��0000��. ���0 3�϶����ڵ�һ����10 5�϶��������һ������Ϊʲô00 5ȴ��00 4ǰ���أ���������Լ���ʵ��˼��һ�¡��� �𰸽�����ԭ����������趨�Ǹ����󡱣�sortֻ��Ƚϵڶ�����ĵڶ����ַ����ڶ���������һ���ַ��Ĳ��֣�������ѵ�������Ŀ�ͷ�ַ�����ȽϷ�Χ��������00��00��ͬʱ��sort�ͻ��Զ��Ƚϵ�һ����ȥ�ˡ���Ȼbaidu��sohuǰ���ˡ���һ����������֤ʵ�� $ sort -n -k 2.2,3.1 -k 1,1r facebook.txtguge 50 3000sohu 100 4500baidu 100 5000google 110 5000"},{"path":"/2023/09/28/Linux配置文件/somecommands/seq/","content":"for i in $(seq 10|tac) do echo -ne “\\aThe system will reboot after $i seconds…\\r” sleep 1 done -w 同宽输出，不足的用0补齐，以输出的位数最多的数为准 -s 指定分割符，默认为回车 seq -s “ “ 2 7 2 3 4 5 6 7 -f 指定打印格式% 后面指定数字的位数 默认是”%g”,“%3g”那么数字位数是3，不足部分用空格补齐#sed -f”%03g” 9 11 这样的话数字位数不足部分用0补齐% 前面指定字符串seq -f “str%03g” 9 11str009str010str011 seq -f %05g 2 7000020000300004000050000600007"},{"path":"/2023/09/28/Linux配置文件/somecommands/sar/","content":"sar sar -u CPU��Ϣ sar -q ���г��ȼ�ϵͳ���� sar -r �ڴ漰��������ʹ��״�� sar -b I&#x2F;O������ sar -d ����ʹ��״�� sar -B �ڴ��ҳ��� sar -W �ڴ潻��״�� sar -n DEV ����״�� sar -n EDEV ��������ͳ������ sar -n SOCK �׽�����Ϣ"},{"path":"/2023/09/28/Linux配置文件/somecommands/read/","content":"read���� read -a sd #��sd��������Դ�read -a sd [Enter] ww aa zz [Enter] echo ${sd[1]} &#x3D;&#x3D;&#x3D;&gt;wwread -d e -a sd #-d�����������ñ�ʶ���Ա�ʶ���������Ĭ�����������read -a sd�س���Ȼ������һ�����ݻس�֮������ͽ����ˣ�����-d�������س�֮�󻹻�����ȴ����룬֪�����ٴ�����-d����ŵ��Ǹ��ַ�������Ż������ &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; read -n 3 #������������ַ�������ָ������ʱ��������Զ��˳� read -p #����ǰ���ӡ��ʾ���� read -p “Please input your nanme” #��Ļ�ϻ����Please input your nanme,Ȼ�󵯳��ȴ�������� read -p “You can input 3 words” -n 3 #���������ַ����Զ��˳� &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;read -e sd #-e����������������ʱ����ʹ��tab��ȫ read -e sd &#x2F;usr&#x2F;local&#x2F;src&#x2F;&#x2F;data&#x2F;www&#x2F;web&#x2F; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; read -s ��Ļ�ϲ�����ʾ��������� &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #!&#x2F;bin&#x2F;bash count&#x3D;1 &#x2F;&#x2F;��ֵ��䣬���ӿո� while read line &#x2F;&#x2F;cat ����������Ϊread���������,read������ֵ����line�� do echo “Line $count:$line” count&#x3D;$[$count + 1] &#x2F;&#x2F;ע���������еĿո� &#x2F;&#x2F;count&#x3D;$(($count+1)) &#x2F;&#x2F;let “count +&#x3D; 1”done &lt; test echo “finish” exit 0"},{"path":"/2023/09/28/Linux配置文件/somecommands/pdflush/","content":"pdflush cat &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;nr_pdflush_threads #�鿴�ж��ٸ�pdflush���� pdflush����Ϊ��&#x2F;proc&#x2F;sys&#x2F;vm�µĲ������� &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;dirty_writeback_centisecs #����pdflush�����ڣ���λ���룬Ҳ���ǰٷ�֮һ�롣Ĭ��ֵΪ500. pdflush�����Ѻ󣬰�˳���ȡ���²����� &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;dirty_expire_centiseconds #�������ݵĹ���ʱ�䣬Ĭ��3000��Ҳ����30�� &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;dirty_background_ratio #�������ڻ�������ֵ,�ٷֱȣ���Memfreee+Cached-Mapped��ֵΪ׼��Ĭ��10 ���²���Ҳ��Ӱ��pdflush &#x2F;prco&#x2F;sys&#x2F;vm&#x2F;dirty_ratio (default 40) #���ڴ�����ٷֱȣ�ϵͳ����ӵ�е������ҳ������������������ֵ������pdflushд��Ӳ�̡����cache��������pdflush����ô����ϵͳ��40%��ʱ������I&#x2F;Oƿ�������е�I&#x2F;O��Ҫ�ȴ�cache��pdflush��Ӳ�̺�������¿�ʼ�� �����и߶�д�������ϵͳdirty_background_ratio: ��Ҫ���������������Ҫ�ѻ�������Ķ�����һ���Ӵ�����д��Ӳ�̣��������ֵ��dirty_ratio�� �ڶ����������� ����д���Ǽ�Ъ�ģ���ÿ������������ܴ����ǼӴ�������� ����д��ǳ�Ƶ�������Ǽ�С�������������Է�ɢѹ�������ʹ��̸��� 1.ͨ�����ĸ����������Կ������������ڴ���ռ�ö�����д������ļ�ϵͳ�� dirty_background_ratio 2.���������ڴ��������Դ��ڶ೤ʱ�䣬�������ʱ���д����̣� dirty_expire_centisecs 3.�����������ڴ��е���������ռ�ڴ���������д����̣� dirty_ratio 4.pdflush�ں��߳�ִ�е�Ƶ�ʡ� dirty_writeback_centisecs"},{"path":"/2023/09/28/Linux配置文件/somecommands/nl/","content":"#文件添加行号nl [options] filesfiles是nl需要为其添加行号的文本文件路径名，如果有多个文件，则nl会把多个文件合在一起编号，并输出到标准输出上 选项-b 指定行号指定的方式，主要有两种： -b a 表示不论是否为空行，也同样列出行号（类似cat -n） -b t 如果有空行，空的那一行不要列出行号（默认方式） -n 列出行号表示的方法，主要有三种： -n ln 行号在屏幕最左边显示 -n rn 行号在自己栏位的最右边显示，且不加0 -n rz 行号在自己栏位的最右边显示，且加0 -w 设置行号栏占用的位数"},{"path":"/2023/09/28/Linux配置文件/somecommands/nc/","content":"netcat,网络工具中的瑞士军刀命令1nc -z -v -n 10.10.38.57 21-25 解释可以运行在TCP或者UDP模式，默认是TCP，-u参数调整为udp.z 参数告诉netcat使用0 IO,连接成功后立即关闭连接，不进行数据交换v 参数指使用冗余选项(译者注：即详细输出)n 参数告诉netcat 不要使用DNS反向查询IP地址的域名 这个命令会打印21到25所有开放的端口.Banner是一个连接的服务发送回的文本信息.当试图鉴别漏洞或者服务的类型和版本的时候,Banner信息是非常有用的.但是，并不是所有的服务都会发送banner。一旦发现开放的端口,可以容易的使用netcat连接服务抓取他们的banner。 命令2nc -v 172.31.100.7 21netcat 命令会连接开放端口21并且打印运行在这个端口上服务的banner信息。 命令3nc -l 2020 服务器模式，在本机的2020端口启动了一个tcp服务器（listen）命令 4nc 10.10.38.xx 2020 连接到nc服务器，这时候不管输入什么都会出现在服务端的屏幕上命令5#server 端：nc -l 2020 &lt; file.txt #client 端nc 10.10.38.xx 2020 &gt; file1.txt 这里创建了一个服务器在A上并且重定向netcat的输入为文件file.txt，那么当任何成功连接到该端口，netcat会发送file的文件内容。在客户端重定向输出到file1.txt，当B连接到A，A发送文件内容，B保存文件内容到file.txt.也可以相反的方法使用,如下： #server端nc -l 2020 &gt; file1.txt client端nc 10.10.38.xx 2020 &lt; file.txt 命令6Servertar -cvf – dir_name | nc -l 1567 Clientnc -n 172.31.100.7 1567 | tar -xvf - 这里在A服务器上，我们创建一个tar归档包并且通过-在控制台重定向它，然后使用管道，重定向给netcat，netcat可以通过网络发送它。在客户端我们下载该压缩包通过netcat 管道然后打开文件。如果想要节省带宽传输压缩包，我们可以使用bzip2或者其他工具压缩。 servertar -cvf – dir_name| bzip2 -z | nc -l 1567 #Clientnc -n 172.31.100.7 1567 | bzip2 -d |tar -xvf - 命令7 指定源地址 假设你的机器有多个地址，希望明确指定使用哪个地址用于外部数据通讯。我们可以在netcat中使用-s选项指定ip地址。 #server$nc -u -l 1567 &lt; file.txt #client$nc -u 172.31.100.7 1567 -s 172.31.100.5 &gt; file.txt"},{"path":"/2023/09/28/Linux配置文件/somecommands/mknod/","content":"���ǵ�linux����ϵͳ���ⲿ�豸������̡����̵ȣ���ͨ�Ŷ���ͨ���豸�ļ����еģ�Ӧ�ó�����Դ򿪡��رա���д��Щ�豸�ļ����Ӷ����豸���ж�д�����ֲ��������д��ͨ���ļ�һ��easy��linuxΪ��ͬ������豸�ļ��ṩ����ͬ�Ľӿڣ�����read(),write(),open(),close()�� ������ϵͳ���豸ͨ��֮ǰ��ϵͳ����Ҫ����һ���豸�ļ�������豸�ļ������/devĿ¼�¡���ʵϵͳĬ������¾��Ѿ������˺ܶ��豸�ļ�������ʱ��������Ҫ�Լ��ֶ��½�һЩ�豸�ļ������ʱ��ͻ��õ���mkdir, mknod��������� mknod �ı�׼��ʽΪ: mknod DEVNAME &#123;b | c&#125; MAJOR MINOR 1��DEVNAME��Ҫ�������豸�ļ���������뽫�豸�ļ�����һ���ض����ļ����£�����Ҫ����mkdir��devĿ¼���½�һ��Ŀ¼�� 2�� b��c �ֱ��ʾ���豸���ַ��豸�� b��ʾϵͳ�ӿ��豸�ж�ȡ���ݵ�ʱ��ֱ�Ӵ��ڴ��buffer�ж�ȡ���ݣ������������̣� c��ʾ�ַ��豸�ļ����豸�������ݵ�ʱ�������ַ�����ʽ���ͣ�һ�δ���һ���ַ��������ӡ�����ն˶������ַ�����ʽ�������ݣ� 3��MAJOR��MINOR�ֱ��ʾ���豸�źʹ��豸�ţ� Ϊ�˹����豸��ϵͳΪÿ���豸����һ����ţ�һ���豸�������豸�źʹ��豸����ɡ����豸�ű�ʾĳһ������豸�����豸����������ͬһ���͵��豸��linux����ϵͳ��Ϊ�豸�ļ���ŷ�����32λ�޷�������������ǰ12λ�����豸�ţ���20λΪ���豸�ţ���������ϵͳ�����豸�ļ�ʱ���豸�Ų��ó���4095�����豸�Ų��ó���2^20 -1�� . ���棬���ǾͿ�����mknod�����������豸�ļ��ˡ� mkdir -p /dev/cobing mknod /dev/cobing/mydev1 c 128 512"},{"path":"/2023/09/28/Linux配置文件/somecommands/ldd/","content":"#���ȣ��ⲻ��һ����ִ�г��򣬶���һ��shell�ű� ��ʾ��֮���������ϵ"},{"path":"/2023/09/28/Linux配置文件/somecommands/join/","content":"#根据关键字合并数据文件 cat file12014-04\tA\t10.10.10.101\t82014-04\tA\t10.10.10.111\t82014-04\tA\t10.10.10.112\t82014-04\tA\t10.10.10.113\t82014-04\tA\t10.10.10.115\t82014-04\tc\t10.10.10.116\t82014-04 b 10.10.10.114 8 cat file22014-04 c 10.10.10.116 83.612014-04\tA 10.10.10.101\t83.992014-04 A 10.10.10.113 94.232014-04\tA 10.10.10.111\t86.772014-04\tb 10.10.10.114\t88.722014-04\tA 10.10.10.115\t84.962014-04 A 10.10.10.112 86.84 要求得到文件file3，其内容为： 2014-04\tA\t10.10.10.101\t8 83.992014-04\tA\t10.10.10.111\t8 86.772014-04\tA\t10.10.10.112\t8 86.842014-04\tA\t10.10.10.113\t8 94.232014-04\tA\t10.10.10.115\t8 84.962014-04\tc\t10.10.10.116\t8 83.612014-04 b 10.10.10.114 8 88.72 操作过程： sort -k 3 file1 &gt; file1.tmpsort -k 3 file2 &gt; file2.tmp join -j 3 -o 1.1 -o 1.2 -o 1.3 -o 1.4 -o 2.4 file1.tmp file2.tmp &gt; file3"},{"path":"/2023/09/28/Linux配置文件/somecommands/history/","content":"export HISTFILESIZE&#x3D;10000000export PROMPT_COMMAND&#x3D;”history -a”export HISTTIMEFORMAT&#x3D;”%Y-%m-%d_%H:%M:%S whoami “export HISTIGNORE&#x3D;”pwd:ls:ll:ls -al:”export HISTCONTROL&#x3D;”ignoredups”"},{"path":"/2023/09/28/Linux配置文件/somecommands/grub-crypt/","content":"���Եõ����ܺ���û����룬��Ҳ���ǵõ�shadow�ļ�����û����봮��Ĭ��ʹ��sha512���ܷ�ʽ"},{"path":"/2023/09/28/Linux配置文件/somecommands/find/","content":"#��ǰĿ¼�²���awstats����Ŀ¼֮���������Ϊlog���ļ���-a��ʡ�ԣ�-print��ʡ��find .&#x2F; -path ‘.&#x2F;awstats*’ -a -prune -o -name “log“ -print #�ų�����Ŀ¼find .&#x2F; ( -path ‘.&#x2F;dir0*’ -o -path ‘.&#x2F;dir1*’ ) -a prune -o -name *.txt -print -a �����ȼ�����-o,����ʹ��С�����޸���Ĭ�����ȼ�"},{"path":"/2023/09/28/Linux配置文件/somecommands/dmidecode/","content":"#查看服务器型号、序列号dmidecode|grep “System Information” -A9|grep -E “Manufacturer|Product|Serial” #查看内存的插槽数,已经使用多少插槽.每条内存多大dmidecode|grep -A5 “Memory Device”|grep Size|grep -v Range #查看内存的频率 dmidecode|grep -A16 “Memory Device”|grep ‘Speed’"},{"path":"/2023/09/28/Linux配置文件/somecommands/dig/","content":"dns��ѯ���ߣ���������nslookup ��Domain Information Groper�� yum install bind-utils dig @nameserver www.baidu.com Aʹ��ָ����nameserver��ѯwww.baidu.com��A��¼��A������AAAA/PTR/MX/ANY�ȣ�AΪĬ��ֵ�� dig -f domainlist -c IN -t A -f�������Ǵ�һ���ļ���ȡ����Ȼ��������ѯ���ļ�����Ҫ��ÿ��һ������ -c��������ָ��Э������ IN&#x2F;CH&#x2F;HS,Ĭ��IN dig -q ��ʾҪ��ѯ������ dig -x �����ѯ dig +tcp ʹ��tcp��ʽ��ѯ dig +trace ����digȫ���� dig +nocmd ʡ��dig�汾��Ϣ dig +short ������� dig +nocomment ʡ��ע����Ϣ dig +nostat ʡ������ͳ����Ϣ"},{"path":"/2023/09/28/Linux配置文件/somecommands/cut/","content":"cut cut t ‘:’ -b(�ֽ�) &#x2F;-c���ַ��� &#x2F;-f���ֶΣ� N ֻ�е�N��N- �ӵ�N���βN-M �ӵ�N���M���M��-M �ӿ�ʼ����M���M�� �ӿ�ʼ������"},{"path":"/2023/09/28/Linux配置文件/somecommands/column/","content":"column,��ʽ����� df -h | column -t column -s ‘|’ -t filename -s Ĭ���Կո�Ϊ�ָ���������ָ��Ϊ|"},{"path":"/2023/09/28/Linux配置文件/wireshark/sersync/web_server/rsyncd.secrets/","content":"rsync_user:123456"},{"path":"/2023/09/28/Linux配置文件/wireshark/sersync/web_server/rsyncd.motd/","content":"###################################################### Welcome to rsyncd server######################################################"},{"path":"/2023/09/28/Linux配置文件/wireshark/sersync/web_server/rsyncd.conf/","content":"Minimal configuration file for rsync daemonSee rsync(1) and rsyncd.conf(5) man pages for helpThis line is required by the &#x2F;etc&#x2F;init.d&#x2F;rsyncd scriptpid file &#x3D; &#x2F;var&#x2F;run&#x2F;rsyncd.pidport &#x3D; 873uid &#x3D; wwwgid &#x3D; wwwuse chroot &#x3D; noread only &#x3D; no #limit access to private LANshosts allow &#x3D; 10.10.67.40max connections &#x3D; 5motd file &#x3D; &#x2F;etc&#x2F;rsyncd&#x2F;rsyncd.motd #This will give you a separate log filelog file &#x3D; &#x2F;var&#x2F;log&#x2F;rsync.log #This will log every file transferred - up to 85,000+ per user, per sync#transfer logging &#x3D; yes log format &#x3D; %t %a %m %f %bsyslog facility &#x3D; local3timeout &#x3D; 300 [web40]path &#x3D; &#x2F;home&#x2F;shidg&#x2F;wwwlist&#x3D;yesignore errorsauth users &#x3D; rsync_usersecrets file &#x3D; &#x2F;etc&#x2F;rsyncd&#x2F;rsyncd.secretscomment &#x3D; code on web40"},{"path":"/2023/09/28/Linux配置文件/wireshark/samba/smb.conf/","content":"[global]workgroup &#x3D; WORKGROUPserver string &#x3D; Samba Server Version %vnetbios name &#x3D; FileServer ; interfaces &#x3D; lo eth0 192.168.12.2&#x2F;24 192.168.13.2&#x2F;24allow hosts &#x3D; 10.0.8. 172.169.128.; deny hosts &#x3D; 192.168.100.0&#x2F;24 ————————— Logging Options —————————–log file &#x3D; &#x2F;var&#x2F;log&#x2F;samba&#x2F;%m.log max 50KB per log file, then rotatemax log size &#x3D; 50 security &#x3D; user &#x2F;&#x2F;认证模式为Usermap to guest &#x3D; bad user &#x2F;&#x2F;这个很关键，实现匿名无须交互输入用户名和密码guest account &#x3D; nobody &#x2F;&#x2F;匿名用户映射为nobody用户,系统中要有nobody用户encrypt passwords &#x3D; yes &#x2F;&#x2F;用户的密码加密smb passwd file &#x3D; &#x2F;etc&#x2F;samba&#x2F;smbpasswd [public]comment &#x3D; publicpath&#x3D; &#x2F;data&#x2F;pub&#x2F;publicbrowseable &#x3D; yes &#x2F;&#x2F;可以被浏览，就是在网络邻居中能看到共享名guest ok &#x3D; yes &#x2F;&#x2F;允许匿名访问，这个也需要设置，否则匿名无法访问admin users &#x3D;writable &#x3D; yesprintable &#x3D; nocreate mask &#x3D; 0644directory mask &#x3D; 0755[project]comment &#x3D; projectpath&#x3D; &#x2F;data&#x2F;pub&#x2F;projectbrowseable &#x3D; yespublic &#x3D; noguest ok &#x3D; nowrite list &#x3D; @trainforce user &#x3D; root &#x2F;&#x2F;强制制定建立的文件的属主printable &#x3D; nocreate mask &#x3D; 0644directory mask &#x3D; 0755"},{"path":"/2023/09/28/Linux配置文件/wireshark/postfix/postfix/","content":"#检查配置文件postfix check &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;#启动&#x2F;关闭&#x2F;重加载postfix start|stop|relaod#除对inet_interfaces参数做修改之外，都不必重启postfix服务，使用reload即可。 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;#postfix多长时间扫描一次等待队列，默认1000秒quene_run_delay &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #一封邮件最多有多少收件人，默认1000smtpd_recipient_limit #单封邮件的大小,默认10MBmessage_size_limit &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;#同一客户端连续出错，postfix自动延迟响应时间，出错达到一定次数后断开连接smtpd_error_sleep_time &#x3D; 1ssmtpd_soft_error_limit &#x3D; 10smtpd_hard_error_limit &#x3D; 20#每次客户端出错之后，Postfix延迟1秒钟，连续10次之后，开始延长每次的延迟时间，第十一次等待11秒，第十二次等待12秒……，到达20次自动断开 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #伪装主机名称masquetade_domains &#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #投递地址发生变化。 relocated_maps &#x3D; hash:&#x2F;etc&#x2F;postfix&#x2F;relocated #比如原来的&#107;&#x64;&#101;&#110;&#116;&#x40;&#x65;&#x78;&#97;&#x6d;&#46;&#x63;&#111;&#109;邮箱已经不存在，更改为&#107;&#x64;&#101;&#x6e;&#116;&#64;&#110;&#101;&#119;&#x65;&#x78;&#97;&#x6d;&#46;&#x6e;&#101;&#x74;,则可通过在relocated查询表中写入这样的内容： &#107;&#x64;&#101;&#110;&#x74;&#x40;&#101;&#120;&#97;&#109;&#46;&#99;&#x6f;&#109; &#x6b;&#100;&#x65;&#x6e;&#116;&#x40;&#x6e;&#x65;&#119;&#101;&#x78;&#x61;&#109;&#x2e;&#110;&#x65;&#x74; postmap &#x2F;etc&#x2F;postfix&#x2F;relocated postfix reload #这样，当用户再试图发邮件给&#x6b;&#100;&#x65;&#110;&#x74;&#64;&#101;&#x78;&#x61;&#109;&#46;&#99;&#x6f;&#x6d;的时候，postfix会拒收，并告诉发件人新的邮件地址#另外，如果relocated里的内容是网域名称，则代表整个网域已经搬迁，如 @jiayeah.com jiayeah.net 这样Postfix会拒收所有发到jiayeah.com的邮件，并告诉发件人应该把邮件发到jiayeah.net &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #postfix默认是拒收不明用户的邮件的（就是在系统账户、别名表、查询表中都找不到这个用户名），如果想收取不明用户的邮件，可以这样设置：local_recipient_maps &#x3D;luser_relay &#x3D; support #local_recipient_maps参数设为空，（默认值是unix密码文件和别名表）support是一个有效的用户，那么所有的不明用户的邮件都会转到support的邮箱里。 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;#postfix队列管理程序qmgr可以使用的磁盘空间，默认值为0,即可以无限使用，可视情况设置适当上限queue_minfree &#x3D; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #邮件列表管理 #显示邮件列表 postqueue -p 显示内容包括标识符（Queue ID）大小 到达时间 寄件人地址 收件人地址如果Queue ID栏加注一个星号，代表邮件是在活动列队，加注感叹号是在保留列队，无任何符号是在等待列队 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;#删除队列中的邮件 postsuper -d [Queue ID] postsuper -d ALL &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #将邮件放进或者移出保留队列 postsuper -h [Queue ID] postsuper -H [Queue ID] &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;#对邮件重新排队，也就是让邮件重新走一遍投递流程，以成功发送 postsuper -r [Queue ID]postsuper -r ALL #查看队列文件的内容postcat -q [Queue ID] #清空邮件。指的是让postfix立刻投递滞留在队列里的邮件的操作。前提是能确定邮件一定能成功投递，否则最好不要使用这个功能 postqueue -f #清空寄到特定站点的邮件，使用-s参数，并且收信站点要在fast_flush_domains参数之中postqueue -s example.com #example.com一定要要包含在fast_flush_domains参数之中fast_flush_domains &#x3D; $relay_domains example.com #虚拟网域 #独立网域+虚拟账户virtual_mailbox_domains virtual_mainbox_base virtual_mailbox_maps #独立网域+系统账户，邮件最终还是放到系统账户的邮箱内virttual_alias_domains virtual_alias_maps"},{"path":"/2023/09/28/Linux配置文件/wireshark/postfix/postfix-vda-v13-2.10.0.patch/","content":"diff -uNr postfix-2.10.0.orig&#x2F;README_FILES&#x2F;VDA_README postfix-2.10.0&#x2F;README_FILES&#x2F;VDA_README— postfix-2.10.0.orig&#x2F;README_FILES&#x2F;VDA_README\t1970-01-01 01:00:00.000000000 +0100+++ postfix-2.10.0&#x2F;README_FILES&#x2F;VDA_README\t2013-06-07 13:21:22.837143270 +0200@@ -0,0 +1,10 @@+Postfix VDA patch for maildir++ quota support by+ Anderson Nadal &#x61;&#x6e;&#x64;&#x65;&#x72;&#x6e;&#97;&#x64;&#97;&#108;&#x40;&#103;&#109;&#x61;&#x69;&#108;&#x2e;&#99;&#x6f;&#109;+ Tomas Macek &#109;&#97;&#99;&#x61;&#x30;&#50;&#64;&#97;&#x74;&#x6c;&#97;&#115;&#x2e;&#x63;&#122;+ Lucca Longinotti++See VDA patch official website http://vda.sf.net for instructions+howto patch the Postfix’s sourcetree and configure the options+provided by this patch.++diff -uNr postfix-2.10.0.orig&#x2F;src&#x2F;global&#x2F;mail_params.h postfix-2.10.0&#x2F;src&#x2F;global&#x2F;mail_params.h— postfix-2.10.0.orig&#x2F;src&#x2F;global&#x2F;mail_params.h\t2013-02-03 19:22:21.000000000 +0100+++ postfix-2.10.0&#x2F;src&#x2F;global&#x2F;mail_params.h\t2013-06-07 13:21:22.838143270 +0200@@ -2367,6 +2367,54 @@ #define DEF_VIRT_GID_MAPS “” extern char *var_virt_gid_maps;+#define VAR_VIRT_MAILBOX_LIMIT_MAPS “virtual_mailbox_limit_maps”+#define DEF_VIRT_MAILBOX_LIMIT_MAPS “”+extern char *var_virt_mailbox_limit_maps;++#define VAR_VIRT_MAILBOX_LIMIT_INBOX “virtual_mailbox_limit_inbox”+#define DEF_VIRT_MAILBOX_LIMIT_INBOX 0+extern bool var_virt_mailbox_limit_inbox;++#define VAR_VIRT_MAILBOX_LIMIT_OVERRIDE “virtual_mailbox_limit_override”+#define DEF_VIRT_MAILBOX_LIMIT_OVERRIDE 0+extern bool var_virt_mailbox_limit_override;++#define VAR_VIRT_MAILDIR_EXTENDED “virtual_maildir_extended”+#define DEF_VIRT_MAILDIR_EXTENDED 0+extern bool var_virt_maildir_extended;++#define VAR_VIRT_OVERQUOTA_BOUNCE “virtual_overquota_bounce”+#define DEF_VIRT_OVERQUOTA_BOUNCE 0+extern bool var_virt_overquota_bounce;++#define VAR_VIRT_MAILDIR_LIMIT_MESSAGE “virtual_maildir_limit_message”+#define DEF_VIRT_MAILDIR_LIMIT_MESSAGE “Sorry, the user’s maildir has overdrawn his diskspace quota, please try again later.”+extern char *var_virt_maildir_limit_message;++#define VAR_VIRT_MAILDIR_LIMIT_MESSAGE_MAPS “virtual_maildir_limit_message_maps”+#define DEF_VIRT_MAILDIR_LIMIT_MESSAGE_MAPS “”+extern char *var_virt_maildir_limit_message_maps;++#define VAR_VIRT_MAILDIR_SUFFIX “virtual_maildir_suffix”+#define DEF_VIRT_MAILDIR_SUFFIX “”+extern char *var_virt_maildir_suffix;++#define VAR_VIRT_TRASH_COUNT “virtual_trash_count”+#define DEF_VIRT_TRASH_COUNT 0+extern bool var_virt_trash_count;++#define VAR_VIRT_TRASH_NAME “virtual_trash_name”+#define DEF_VIRT_TRASH_NAME “.Trash”+extern char *var_virt_trash_name;++#define VAR_VIRT_MAILDIR_FILTER “virtual_maildir_filter”+#define DEF_VIRT_MAILDIR_FILTER 0+extern bool var_virt_maildir_filter;++#define VAR_VIRT_MAILDIR_FILTER_MAPS “virtual_maildir_filter_maps”+#define DEF_VIRT_MAILDIR_FILTER_MAPS “”+extern char var_virt_maildir_filter_maps;+ #define VAR_VIRT_MINUID “virtual_minimum_uid” #define DEF_VIRT_MINUID 100 extern int var_virt_minimum_uid;diff -uNr postfix-2.10.0.orig&#x2F;src&#x2F;util&#x2F;file_limit.c postfix-2.10.0&#x2F;src&#x2F;util&#x2F;file_limit.c— postfix-2.10.0.orig&#x2F;src&#x2F;util&#x2F;file_limit.c\t2003-10-22 20:48:36.000000000 +0200+++ postfix-2.10.0&#x2F;src&#x2F;util&#x2F;file_limit.c\t2013-06-07 13:21:22.839143270 +0200@@ -85,7 +85,11 @@ #else struct rlimit rlim;- rlim.rlim_cur &#x3D; rlim.rlim_max &#x3D; limit;+ &#x2F; rlim_max can only be changed by root. &#x2F;+ if (getrlimit(RLIMIT_FSIZE, &amp;rlim) &lt; 0)+ msg_fatal(“getrlimit: %m”);+ rlim.rlim_cur &#x3D; limit;+ if (setrlimit(RLIMIT_FSIZE, &amp;rlim) &lt; 0) msg_fatal(“setrlimit: %m”); #ifdef SIGXFSZdiff -uNr postfix-2.10.0.orig&#x2F;src&#x2F;virtual&#x2F;mailbox.c postfix-2.10.0&#x2F;src&#x2F;virtual&#x2F;mailbox.c— postfix-2.10.0.orig&#x2F;src&#x2F;virtual&#x2F;mailbox.c\t2011-12-24 03:13:32.000000000 +0100+++ postfix-2.10.0&#x2F;src&#x2F;virtual&#x2F;mailbox.c\t2013-06-07 13:23:03.044139705 +0200@@ -52,6 +52,7 @@ #include &lt;mymalloc.h&gt; #include &lt;stringops.h&gt; #include &lt;set_eugid.h&gt;+#include &lt;iostuff.h&gt; &#x2F; Global library. &#x2F;@@ -70,6 +71,70 @@ #define YES\t1 #define NO\t0+&#x2F; change_mailbox_limit - change limit for mailbox file *&#x2F;+static int change_mailbox_limit(LOCAL_STATE state, USER_ATTR usr_attr)+{+ char *myname &#x3D; “change_mailbox_limit”;+ const char limit_res;+ long n &#x3D; 0;+ int status &#x3D; NO;++ &#x2F;+ * Look up the virtual mailbox limit size for this user.+ * Fall back to virtual_mailbox_limit in case lookup failed.+ * If virtual mailbox limit size is negative, fall back to virtual_mailbox_limit.+ * If it’s 0, set the mailbox limit to 0, which means unlimited.+ * If it’s more than 0 (positive int), check if the value is smaller than the maximum message size,+ * if it is and the virtual mailbox limit can’t be overridden, fall back to virtual_mailbox_limit and+ * warn the user, else use the value directly as the mailbox limit.+ *&#x2F;+ if (*var_virt_mailbox_limit_maps !&#x3D; 0 &amp;&amp; (limit_res &#x3D; mail_addr_find(virtual_mailbox_limit_maps, state.msg_attr.user, (char **) NULL)) !&#x3D; 0) {+ n &#x3D; atol(limit_res);+ if (n &gt; 0) {+ if ((n &lt; var_message_limit) &amp;&amp; (!var_virt_mailbox_limit_override)) {+ set_file_limit(var_virt_mailbox_limit);+ status &#x3D; NO;++ msg_warn(“%s: recipient %s - virtual mailbox limit is “+ “smaller than %s in %s - falling back to %s”,+ myname,+ state.msg_attr.user,+ VAR_MESSAGE_LIMIT,+ virtual_mailbox_limit_maps-&gt;title,+ VAR_VIRT_MAILBOX_LIMIT);+ }+ else {+ set_file_limit((off_t) n);+ status &#x3D; YES;++ if (msg_verbose)+ msg_info(“%s: set virtual mailbox limit size for %s to %ld”,+ myname, usr_attr.mailbox, n);+ }+ }+ else if (n &#x3D;&#x3D; 0) {+ set_file_limit(OFF_T_MAX);+ status &#x3D; YES;++ if (msg_verbose)+ msg_info(“%s: set virtual mailbox limit size for %s to %ld”,+ myname, usr_attr.mailbox, OFF_T_MAX);+ }+ else {+ &#x2F;* Invalid limit size (negative). Use default virtual_mailbox_limit. &#x2F;+ set_file_limit(var_virt_mailbox_limit);+ status &#x3D; NO;+ }+ }+ else {+ &#x2F; There is no limit in the maps. Use default virtual_mailbox_limit. &#x2F;+ set_file_limit(var_virt_mailbox_limit);+ status &#x3D; NO;+ }++ return(status);+}+ &#x2F; deliver_mailbox_file - deliver to recipient mailbox &#x2F; static int deliver_mailbox_file(LOCAL_STATE state, USER_ATTR usr_attr)@@ -80,7 +145,6 @@ int mail_copy_status; int deliver_status; int copy_flags;- long end; struct stat st; &#x2F;@@ -132,7 +196,7 @@ msg_warn(“specify &quot;%s &#x3D; no&quot; to ignore mailbox ownership mismatch”, VAR_STRICT_MBOX_OWNER); } else {- end &#x3D; vstream_fseek(mp-&gt;fp, (off_t) 0, SEEK_END);+ vstream_fseek(mp-&gt;fp, (off_t) 0, SEEK_END); mail_copy_status &#x3D; mail_copy(COPY_ATTR(state.msg_attr), mp-&gt;fp, copy_flags, “ ”, why); }@@ -213,62 +277,72 @@ * Look up the mailbox owner rights. Defer in case of trouble. *&#x2F; uid_res &#x3D; mail_addr_find(virtual_uid_maps, state.msg_attr.user,- IGNORE_EXTENSION);- if (uid_res &#x3D;&#x3D; 0) {-\tmsg_warn(“recipient %s: not found in %s”,- state.msg_attr.user, virtual_uid_maps-&gt;title);-\tdsb_simple(why, “4.3.5”, “mail system configuration error”);-\t*statusp &#x3D; defer_append(BOUNCE_FLAGS(state.request),- BOUNCE_ATTR(state.msg_attr));-\tRETURN(YES);+ IGNORE_EXTENSION);++ if ((uid_res &#x3D; mail_addr_find(virtual_uid_maps, state.msg_attr.user, (char **) 0)) &#x3D;&#x3D; 0) {+ if ((uid_res &#x3D; maps_find(virtual_uid_maps, strchr(state.msg_attr.user, ‘@’), DICT_FLAG_FIXED)) &#x3D;&#x3D; 0) {+ msg_warn(“recipient %s: not found in %s”, state.msg_attr.user, virtual_uid_maps-&gt;title);+ dsb_simple(why, “4.3.5”, “mail system configuration error”);+ *statusp &#x3D; defer_append(BOUNCE_FLAGS(state.request), BOUNCE_ATTR(state.msg_attr));+ RETURN(YES);+ } }+ if ((n &#x3D; atol(uid_res)) &lt; var_virt_minimum_uid) {-\tmsg_warn(“recipient %s: bad uid %s in %s”,- state.msg_attr.user, uid_res, virtual_uid_maps-&gt;title);-\tdsb_simple(why, “4.3.5”, “mail system configuration error”);-\t*statusp &#x3D; defer_append(BOUNCE_FLAGS(state.request),- BOUNCE_ATTR(state.msg_attr));-\tRETURN(YES);+ msg_warn(“recipient %s: bad uid %s in %s”, state.msg_attr.user, uid_res, virtual_uid_maps-&gt;title);+ dsb_simple(why, “4.3.5”, “mail system configuration error”);+ statusp &#x3D; defer_append(BOUNCE_FLAGS(state.request), BOUNCE_ATTR(state.msg_attr));+ RETURN(YES); }+ usr_attr.uid &#x3D; (uid_t) n; &#x2F; * Look up the mailbox group rights. Defer in case of trouble. *&#x2F; gid_res &#x3D; mail_addr_find(virtual_gid_maps, state.msg_attr.user,- IGNORE_EXTENSION);- if (gid_res &#x3D;&#x3D; 0) {-\tmsg_warn(“recipient %s: not found in %s”,- state.msg_attr.user, virtual_gid_maps-&gt;title);-\tdsb_simple(why, “4.3.5”, “mail system configuration error”);-\t*statusp &#x3D; defer_append(BOUNCE_FLAGS(state.request),- BOUNCE_ATTR(state.msg_attr));-\tRETURN(YES);+ IGNORE_EXTENSION);++ if ((gid_res &#x3D; mail_addr_find(virtual_gid_maps, state.msg_attr.user, (char **) 0)) &#x3D;&#x3D; 0) {+ if ((gid_res &#x3D; maps_find(virtual_gid_maps, strchr(state.msg_attr.user, ‘@’), DICT_FLAG_FIXED)) &#x3D;&#x3D; 0) {+ msg_warn(“recipient %s: not found in %s”, state.msg_attr.user, virtual_gid_maps-&gt;title);+ dsb_simple(why, “4.3.5”, “mail system configuration error”);+ *statusp &#x3D; defer_append(BOUNCE_FLAGS(state.request), BOUNCE_ATTR(state.msg_attr));+ RETURN(YES);+ } }+ if ((n &#x3D; atol(gid_res)) &lt;&#x3D; 0) {-\tmsg_warn(“recipient %s: bad gid %s in %s”,- state.msg_attr.user, gid_res, virtual_gid_maps-&gt;title);-\tdsb_simple(why, “4.3.5”, “mail system configuration error”);-\t*statusp &#x3D; defer_append(BOUNCE_FLAGS(state.request),- BOUNCE_ATTR(state.msg_attr));-\tRETURN(YES);+ msg_warn(“recipient %s: bad gid %s in %s”, state.msg_attr.user, gid_res, virtual_gid_maps-&gt;title);+ dsb_simple(why, “4.3.5”, “mail system configuration error”);+ statusp &#x3D; defer_append(BOUNCE_FLAGS(state.request), BOUNCE_ATTR(state.msg_attr));+ RETURN(YES); }+ usr_attr.gid &#x3D; (gid_t) n; if (msg_verbose)-\tmsg_info(“%s[%d]: set user_attr: %s, uid &#x3D; %u, gid &#x3D; %u”,- myname, state.level, usr_attr.mailbox,- (unsigned) usr_attr.uid, (unsigned) usr_attr.gid);+ msg_info(“%s[%d]: set user_attr: %s, uid &#x3D; %u, gid &#x3D; %u”,+ myname, state.level, usr_attr.mailbox,+ (unsigned) usr_attr.uid, (unsigned) usr_attr.gid); &#x2F; * Deliver to mailbox or to maildir. *&#x2F; #define LAST_CHAR(s) (s[strlen(s) - 1])- if (LAST_CHAR(usr_attr.mailbox) &#x3D;&#x3D; ‘&#x2F;‘)-\t*statusp &#x3D; deliver_maildir(state, usr_attr);- else-\t*statusp &#x3D; deliver_mailbox_file(state, usr_attr);+ if (LAST_CHAR(usr_attr.mailbox) &#x3D;&#x3D; ‘&#x2F;‘) {+ statusp &#x3D; deliver_maildir(state, usr_attr);+ }+ else {+ int changed_limit;++ changed_limit &#x3D; change_mailbox_limit(state, usr_attr);+ statusp &#x3D; deliver_mailbox_file(state, usr_attr);++ if (changed_limit)+ set_file_limit(var_virt_mailbox_limit);+ } &#x2F; * Cleanup.diff -uNr postfix-2.10.0.orig&#x2F;src&#x2F;virtual&#x2F;maildir.c postfix-2.10.0&#x2F;src&#x2F;virtual&#x2F;maildir.c— postfix-2.10.0.orig&#x2F;src&#x2F;virtual&#x2F;maildir.c\t2012-01-25 01:41:08.000000000 +0100+++ postfix-2.10.0&#x2F;src&#x2F;virtual&#x2F;maildir.c\t2013-06-07 13:21:22.840143270 +0200@@ -64,28 +64,420 @@ #include &lt;mbox_open.h&gt; #include &lt;dsn_util.h&gt;+&#x2F; Patch library. &#x2F;++#include &lt;sys&#x2F;types.h&gt; &#x2F; opendir(3), stat(2) &#x2F;+#include &lt;sys&#x2F;stat.h&gt; &#x2F; stat(2) &#x2F;+#include &lt;dirent.h&gt; &#x2F; opendir(3) &#x2F;+#include &lt;unistd.h&gt; &#x2F; stat(2) &#x2F;+#include &lt;stdlib.h&gt; &#x2F; atol(3) &#x2F;+#include &lt;string.h&gt; &#x2F; strrchr(3) &#x2F;+#include &lt;vstring_vstream.h&gt;+#include &lt;dict.h&gt;+#include &lt;dict_regexp.h&gt;+#include &lt;ctype.h&gt;+#include &lt;stdio.h&gt;+#include &lt;sys_defs.h&gt;+#include &lt;mail_addr_find.h&gt;+ &#x2F; Application-specific. &#x2F; #include “virtual.h”-&#x2F; deliver_maildir - delivery to maildir-style mailbox &#x2F;+&#x2F; Maildirsize maximal size. &#x2F;++#define SIZEFILE_MAX 5120++&#x2F;+ * Chris Stratford &#x63;&#x68;&#x72;&#x69;&#115;&#x73;&#64;&#x70;&#105;&#x70;&#x65;&#x78;&#x2e;&#x6e;&#x65;&#x74;+ * Read the maildirsize file to get quota info.+ *+ * Arguments:+ * dirname: the maildir+ * countptr: number of messages+ *+ * Returns the size of all mails as read from maildirsize,+ * zero if it couldn’t read the file.+ *&#x2F;+static long read_maildirsize(char *filename, long *sumptr, long *countptr)+{+ char *myname &#x3D; “read_maildirsize”;+ struct stat statbuf;+ VSTREAM *sizefile;+ char *p;+ int len, first;+ long sum &#x3D; 0, count &#x3D; 0, ret_value &#x3D; -1;++ if (msg_verbose)+\tmsg_info(“%s: we will use sizefile &#x3D; ‘%s’”, myname, filename);+\t+ sizefile &#x3D; vstream_fopen(filename, O_RDONLY, 0);+ if (!sizefile) {+\tif (msg_verbose)+ msg_info(“%s: cannot open %s: %m (maybe file does not exist)”, myname, filename);+\t+\treturn -1;+ } else if (stat(filename, &amp;statbuf) &lt; 0 || statbuf.st_size &gt; SIZEFILE_MAX) {+ if (sizefile) {+ vstream_fclose(sizefile);+ unlink(filename);+ }++ if (msg_verbose)+ msg_info(“%s: stat() returned &lt; 0 or filesize &gt; SIZEFILE_MAX (filename &#x3D; %s, filesize &#x3D; %ld)”, myname, filename, statbuf.st_size);++ return -1;+ }++ VSTRING *sizebuf &#x3D; vstring_alloc(SIZEFILE_MAX);+ len &#x3D; vstream_fread(sizefile, STR(sizebuf), SIZEFILE_MAX);++ p &#x3D; STR(sizebuf);+ *(p + len) &#x3D; ‘\\0’;+ first &#x3D; 1;++ while (*p) {+ long n &#x3D; 0, c &#x3D; 0;+ char *q &#x3D; p;++ while (*p) {+ if (p++ &#x3D;&#x3D; ‘ ’) {+ p[-1] &#x3D; 0;+ break;+ }+ }++ if (first) {+ first &#x3D; 0;+ continue;+ }++ if (sscanf(q, “%ld %ld”, &amp;n, &amp;c) &#x3D;&#x3D; 2) {+ sum +&#x3D; n;+ count +&#x3D; c;+ &#x2F; if (msg_verbose)+ msg_info(“%s: we read line ‘%s’, totals: sum &#x3D; %ld, count &#x3D; %ld”, myname, q, sum, count); *&#x2F;+ }+ else {+ vstream_fclose(sizefile);+ unlink(filename);+ msg_warn(“%s: invalid line ‘%s’ found in %s, removing maildirsize file”, myname, q, filename);+ vstring_free(sizebuf);++ return -1;+ }+ }++ *countptr &#x3D; count;+ *sumptr &#x3D; sum;++ if (sum &lt; 0 || count &lt; 0 || (sum &#x3D;&#x3D; 0 &amp;&amp; count !&#x3D; 0) || (sum !&#x3D; 0 &amp;&amp; count &#x3D;&#x3D; 0)) {+\tif (msg_verbose) {+ msg_info(“%s: we will return -1 and unlink %s, because file count or sum is &lt;&#x3D; 0 (sum &#x3D; %ld, count &#x3D; %ld)”, myname, filename, sum, count);+\t}+\t+\tunlink(filename);+\tret_value &#x3D; -1;+ } else {+\tif (msg_verbose)+ msg_info(“%s: we will return Maildir size &#x3D; %ld, count &#x3D; %ld”, myname, *sumptr, *countptr);++\tret_value &#x3D; sum;\t+ }++ vstream_fclose(sizefile);+ vstring_free(sizebuf);++ return ret_value;+}++&#x2F;*+ * Gives the size of the file according to the Maildir++ extension+ * present in the filename (code taken from courier-imap).+ *+ * Arguments:+ * n: filename+ *+ * Returns the size given in “,S&#x3D;“ in the filename,+ * zero if it cannot find “,S&#x3D;“ in the filename.+ *&#x2F;+static long maildir_parsequota(const char *n)+{+ const char *o;+ int yes &#x3D; 0;++ if ((o &#x3D; strrchr(n, ‘&#x2F;‘)) &#x3D;&#x3D; 0)+ o &#x3D; n;++ for (; *o; o++) {+ if (*o &#x3D;&#x3D; ‘:’)+ break;+ }++ for (; o &gt;&#x3D; n; –o) {+ if (*o &#x3D;&#x3D; ‘&#x2F;‘)+ break;++ if (*o &#x3D;&#x3D; ‘,’ &amp;&amp; o[1] &#x3D;&#x3D; ‘S’ &amp;&amp; o[2] &#x3D;&#x3D; ‘&#x3D;’) {+ yes &#x3D; 1;+ o +&#x3D; 3;+ break;+ }+ }++ if (yes) {+ long s &#x3D; 0;++ while (*o &gt;&#x3D; ‘0’ &amp;&amp; *o &lt;&#x3D; ‘9’)+ s &#x3D; s*10 + (*o++ - ‘0’);++ return s;+ }++ return 0;+}++&#x2F;*+ * Computes quota usage for a directory (taken from exim).+ *+ * This function is called to determine the exact quota usage of a virtual+ * maildir box. To achieve maximum possible speed while doing this, it takes+ * advantage of the maildirsize file and the Maildir++ extensions to filenames,+ * when applicable and configured to be used. In all other cases it simply+ * stats all the files as needed to get the size information.+ *+ * Arguments:+ * dirname: the name of the directory+ * countptr: where to add the file count (because this function recurses)+ *+ * Returns the sum of the sizes of all measurable files,+ * zero if the directory could not be opened.+ *&#x2F;+static long check_dir_size(char *dirname, long *countptr)+{+ char *myname &#x3D; “check_dir_size”;+ DIR *dir;+ long sum &#x3D; 0;+ struct dirent *ent;+ struct stat statbuf;++ dir &#x3D; opendir(dirname);+ if (dir &#x3D;&#x3D; NULL) {+ if (make_dirs(dirname, 0700) &#x3D;&#x3D; 0) { &#x2F;* Try to create the dirs. *&#x2F;+ dir &#x3D; opendir(dirname); &#x2F;* Reopen the dir. *&#x2F;+ if (dir &#x3D;&#x3D; NULL) {+ msg_warn(“%s: cannot reopen directory: %s”, myname, dirname);+ return 0;+ }+ }+ else {+ msg_warn(“%s: cannot open directory: %s”, myname, dirname);+ return 0;+ }+ }++ while ((ent &#x3D; readdir(dir)) !&#x3D; NULL) {+ char *name &#x3D; ent-&gt;d_name;+ long tmpsum &#x3D; 0;+ VSTRING buffer;++\t&#x2F; do not count dot a double-dot dirs &#x2F;+ if (strcmp(name, “.”) &#x3D;&#x3D; 0 || strcmp(name, “..”) &#x3D;&#x3D; 0)+ continue;+ &#x2F; do not count if this is the trash subdir and if we should NOT count it &#x2F;+\telse if (var_virt_trash_count &#x3D;&#x3D; 0 &amp;&amp; strcmp(name, var_virt_trash_name) &#x3D;&#x3D; 0)+ continue;++ &#x2F;+ * Here comes the real logic behind this function.+ * Optimized to be the most efficient possible,+ * depending on the settings given.+ * See above for a more detailed description.+ *&#x2F;+ if (var_virt_mailbox_limit_inbox) {+ if (var_virt_maildir_extended &amp;&amp; (tmpsum &#x3D; maildir_parsequota(name))) {+ sum +&#x3D; tmpsum;+ (countptr)++;+ }+ else {+ buffer &#x3D; vstring_alloc(1024);+ vstring_sprintf(buffer, “%s&#x2F;%s”, dirname, name);++ if (stat(STR(buffer), &amp;statbuf) &lt; 0) {+ vstring_free(buffer);+ continue;+ }+ if ((statbuf.st_mode &amp; S_IFREG) !&#x3D; 0) {+ sum +&#x3D; (long) statbuf.st_size;+ (*countptr)++;+ }++ vstring_free(buffer);+ }+ }+ else {+ buffer &#x3D; vstring_alloc(1024);+ vstring_sprintf(buffer, “%s&#x2F;%s”, dirname, name);++ if (stat(STR(buffer), &amp;statbuf) &lt; 0) {+ vstring_free(buffer);+ continue;+ }+ if ((statbuf.st_mode &amp; S_IFREG) !&#x3D; 0) {+ if (strcmp(dirname + strlen(dirname) - 3, “new”) &#x3D;&#x3D; 0 || strcmp(dirname + strlen(dirname) - 3, “cur”) &#x3D;&#x3D; 0 || strcmp(dirname + strlen(dirname) - 3, “tmp”) &#x3D;&#x3D; 0) {+ sum +&#x3D; (long) statbuf.st_size;+ (*countptr)++;+ }+ }+ else if ((statbuf.st_mode &amp; S_IFDIR) !&#x3D; 0) {+ sum +&#x3D; check_dir_size(STR(buffer), countptr);+ }++ vstring_free(buffer);+ }+ }+ closedir(dir);-int deliver_maildir(LOCAL_STATE state, USER_ATTR usr_attr)+ if (msg_verbose)+ msg_info(“%s: full scan done: dir&#x3D;%s sum&#x3D;%ld count&#x3D;%ld”, myname, dirname, sum, *countptr);++ return sum;+}++&#x2F;* Cut all occurrences of pattern from string. *&#x2F;+static char *strcut(char *str, const char *pat)+{+ char *ptr, *loc, *ret;+ ret &#x3D; str;+ loc &#x3D; str;++ &#x2F;* No match, return original string. *&#x2F;+ if (!strstr(loc, pat))+ return(str);++ while (*loc &amp;&amp; (ptr &#x3D; strstr(loc, pat))) {+ while (loc &lt; ptr)+ *str++ &#x3D; *loc++;+ loc +&#x3D; strlen(pat);+ }++ while (*loc)+ *str++ &#x3D; *loc++;++ *str &#x3D; 0;++ return(ret);+}++&#x2F;* Check if maildirfilter file is up-to-date compared to SQL, (re)write it if not. *&#x2F;+static long sql2file(char *filename, char *user)+{+ char *myname &#x3D; “sql2file”;+ char *filter_sqlres;+ char filter_fileres[128];+ long sqlmtime &#x3D; 0, filemtime &#x3D; 0, retval &#x3D; 0;+ int filterfile, size_sqlres, i;+ struct stat statbuf;++ if (*var_virt_maildir_filter_maps !&#x3D; 0) {+ filter_sqlres &#x3D; (char *) mymalloc(16000);+ filter_sqlres &#x3D; (char *) mail_addr_find(virtual_maildir_filter_maps, user, (char **) 0);++ if (filter_sqlres) {+ strcut(filter_sqlres, “\\r”);+ if (filter_sqlres[0] &#x3D;&#x3D; ‘#’ &amp;&amp; filter_sqlres[1] &#x3D;&#x3D; ‘ ‘ &amp;&amp; filter_sqlres[2] &#x3D;&#x3D; ‘M’) {+ size_sqlres &#x3D; strlen(filter_sqlres);++ for (i &#x3D; 4; i &lt;&#x3D; size_sqlres; i++) {+ if(filter_sqlres[i] &#x3D;&#x3D; ‘&#x2F;‘ &amp;&amp; filter_sqlres[i+1] &#x3D;&#x3D; ‘^’) {+ filter_sqlres[i-1] &#x3D; ‘ ’;+ }+ }++ filter_sqlres[(size_sqlres+1)] &#x3D; ‘\\0’;++ sqlmtime &#x3D; atol(filter_sqlres+3);+ retval &#x3D; sqlmtime;++ filterfile &#x3D; open(filename, O_RDONLY, 0);+ if (filterfile) {+ read(filterfile, (void *) filter_fileres, 127);+ close(filterfile);++ filemtime &#x3D; atol(filter_fileres+3);+ }++ if (msg_verbose)+ msg_info(“%s: filter data: sql_size&#x3D;%li sql_mtime&#x3D;%ld file_mtime&#x3D;%ld”, myname, strlen(filter_sqlres), sqlmtime, filemtime);+ }+ if (sqlmtime !&#x3D; filemtime &amp;&amp; sqlmtime !&#x3D; 0) {+ if ((filterfile &#x3D; open(filename, O_WRONLY | O_CREAT | O_TRUNC, 0640))) {+ if (msg_verbose)+ msg_info(“%s: updating filter file: %s”, myname, filename);+ write(filterfile, filter_sqlres, strlen(filter_sqlres));+ close(filterfile);+ }+ else {+ msg_warn(“%s: can’t create filter file: %s”, myname, filename);+ retval &#x3D; 0;+ }+ }+ }+ }+ else {+ if (stat(filename, &amp;statbuf) &#x3D;&#x3D; 0)+ retval &#x3D; (long) statbuf.st_mtime;+ if (msg_verbose)+ msg_info(“%s: processing filter file: file_mtime&#x3D;%ld”, myname, retval);+ }++ return retval;+}++&#x2F;* deliver_maildir - delivery to maildir-style mailbox *&#x2F;+int deliver_maildir(LOCAL_STATE state, USER_ATTR usr_attr) { const char *myname &#x3D; “deliver_maildir”;- char *newdir;- char *tmpdir;- char *curdir;- char *tmpfile;- char *newfile;+ char *newdir;+ char *tmpdir;+ char *curdir;+ char *newfile;+ char *tmpfile; DSN_BUF *why &#x3D; state.msg_attr.why; VSTRING *buf; VSTREAM *dst;- int mail_copy_status;- int deliver_status;- int copy_flags;- struct stat st;- struct timeval starttime;+ int mail_copy_status;+ int deliver_status;+ int copy_flags;+ struct stat st;+ struct timeval starttime;++ &#x2F;* Maildir Quota. *&#x2F;+ const char *limit_res; &#x2F;* Limit from map. *&#x2F;+ char *sizefilename &#x3D; (char *) 0; &#x2F;* Maildirsize file name. *&#x2F;+ VSTRING *filequota; &#x2F;* Quota setting from the maildirsize file. *&#x2F;+ VSTREAM *sizefile; &#x2F;* Maildirsize file handle. *&#x2F;+ long n &#x3D; 0; &#x2F;* Limit in long integer format. *&#x2F;+ long saved_count &#x3D; 0; &#x2F;* The total number of files. *&#x2F;+ long saved_size &#x3D; 0; &#x2F;* The total quota of all files. *&#x2F;+ struct stat mail_stat; &#x2F;* To check the size of the mail to be written. *&#x2F;+ struct stat sizefile_stat; &#x2F;* To check the size of the maildirsize file. *&#x2F;+ time_t tm; &#x2F;* To check the age of the maildirsize file. *&#x2F;++ &#x2F;* Maildir Filters. *&#x2F;+ const char *value, *cmd_text; &#x2F;* Filter values. *&#x2F;+ char *filtername;+ char *header;+ char *bkpnewfile;+ char *mdffilename &#x3D; (char *) 0; &#x2F;* Maildirfolder file name. *&#x2F;+ VSTRING *fltstr;+ VSTREAM *tmpfilter;+ VSTREAM *mdffile; &#x2F;* Maildirfolder file handle. *&#x2F;+ DICT *FILTERS;+ long sqlmtime; &#x2F;* Latest modification time from sql2file(). *&#x2F;+ int cmd_len;+ int read_mds &#x3D; -1; &#x2F;* read_maildirsize() returned value *&#x2F;+ struct stat mdffile_stat; &#x2F;* To check if the maildirfolder file exists. *&#x2F; GETTIMEOFDAY(&amp;starttime);@@ -94,15 +486,14 @@ *&#x2F; state.level++; if (msg_verbose)-\tMSG_LOG_STATE(myname, state);+ MSG_LOG_STATE(myname, state); &#x2F;* * Don’t deliver trace-only requests. *&#x2F; if (DEL_REQ_TRACE_ONLY(state.request-&gt;flags)) {-\tdsb_simple(why, “2.0.0”, “delivers to maildir”);-\treturn (sent(BOUNCE_FLAGS(state.request),- SENT_ATTR(state.msg_attr)));+ dsb_simple(why, “2.0.0”, “delivers to maildir”);+ return (sent(BOUNCE_FLAGS(state.request), SENT_ATTR(state.msg_attr))); } &#x2F;@@ -110,18 +501,116 @@ * attribute to reflect the final recipient. &#x2F; if (vstream_fseek(state.msg_attr.fp, state.msg_attr.offset, SEEK_SET) &lt; 0)-\tmsg_fatal(“seek message file %s: %m”, VSTREAM_PATH(state.msg_attr.fp));+ msg_fatal(“seek message file %s: %m”, VSTREAM_PATH(state.msg_attr.fp)); state.msg_attr.delivered &#x3D; state.msg_attr.rcpt.address; mail_copy_status &#x3D; MAIL_COPY_STAT_WRITE; buf &#x3D; vstring_alloc(100);- copy_flags &#x3D; MAIL_COPY_TOFILE | MAIL_COPY_RETURN_PATH-\t| MAIL_COPY_DELIVERED | MAIL_COPY_ORIG_RCPT;+ copy_flags &#x3D; MAIL_COPY_TOFILE | MAIL_COPY_RETURN_PATH | MAIL_COPY_DELIVERED | MAIL_COPY_ORIG_RCPT;- newdir &#x3D; concatenate(usr_attr.mailbox, “new&#x2F;“, (char *) 0);- tmpdir &#x3D; concatenate(usr_attr.mailbox, “tmp&#x2F;“, (char *) 0);- curdir &#x3D; concatenate(usr_attr.mailbox, “cur&#x2F;“, (char *) 0);+ &#x2F;*+ * Concatenate the maildir suffix (if set).+ *&#x2F;+ if (*var_virt_maildir_suffix &#x3D;&#x3D; 0) {+ newdir &#x3D; concatenate(usr_attr.mailbox, “new&#x2F;“, (char *) 0);+ tmpdir &#x3D; concatenate(usr_attr.mailbox, “tmp&#x2F;“, (char *) 0);+ curdir &#x3D; concatenate(usr_attr.mailbox, “cur&#x2F;“, (char *) 0);+ }+ else {+ newdir &#x3D; concatenate(usr_attr.mailbox, var_virt_maildir_suffix, (char *) 0);+ tmpdir &#x3D; concatenate(usr_attr.mailbox, var_virt_maildir_suffix, (char *) 0);+ curdir &#x3D; concatenate(usr_attr.mailbox, var_virt_maildir_suffix, (char *) 0);+ newdir &#x3D; concatenate(newdir, “new&#x2F;“, (char *) 0);+ tmpdir &#x3D; concatenate(tmpdir, “tmp&#x2F;“, (char *) 0);+ curdir &#x3D; concatenate(curdir, “cur&#x2F;“, (char *) 0);+ }+ &#x2F;* get the sizefilename, no matter if we use var_virt_maildir_extended *&#x2F;+ if (*var_virt_maildir_suffix &#x3D;&#x3D; 0) {+ sizefilename &#x3D; concatenate(usr_attr.mailbox, “maildirsize”, (char *) 0);+ } else {+ sizefilename &#x3D; concatenate(usr_attr.mailbox, var_virt_maildir_suffix, (char *) 0);+ sizefilename &#x3D; concatenate(sizefilename, “maildirsize”, (char *) 0);+ }++ &#x2F;*+ * Look up the virtual maildir limit size for this user.+ * Fall back to virtual_mailbox_limit in case lookup failed.+ * If virtual maildir limit size is negative, fall back to virtual_mailbox_limit.+ * If it’s 0, set the mailbox limit to 0, which means unlimited.+ * If it’s more than 0 (positive int), check if the value is smaller than the maximum message size,+ * if it is and the virtual maildir limit can’t be overridden, fall back to virtual_mailbox_limit and+ * warn the user, else use the value directly as the maildir limit.+ *&#x2F;+ if (*var_virt_mailbox_limit_maps !&#x3D; 0 &amp;&amp; (limit_res &#x3D; mail_addr_find(virtual_mailbox_limit_maps, state.msg_attr.user, (char **) NULL)) !&#x3D; 0) {+ n &#x3D; atol(limit_res);+ if (n &gt; 0) {+ if ((n &lt; var_message_limit) &amp;&amp; (!var_virt_mailbox_limit_override)) {+ n &#x3D; var_virt_mailbox_limit;++ msg_warn(“%s: recipient %s - virtual maildir limit is smaller than %s in %s - falling back to %s”,+ myname, state.msg_attr.user, VAR_MESSAGE_LIMIT, virtual_mailbox_limit_maps-&gt;title,+ VAR_VIRT_MAILBOX_LIMIT);+ }+ else {+ if (msg_verbose)+ msg_info(“%s: set virtual maildir limit size for %s to %ld”,+ myname, usr_attr.mailbox, n);+ }+ }+ else if (n &#x3D;&#x3D; 0) {+ if (msg_verbose)+ msg_info(“%s: set virtual maildir limit size for %s to %ld”,+ myname, usr_attr.mailbox, n);+ }+ else {+ if (msg_verbose)+ msg_info(“%s: quota is negative (%ld), using default virtual_mailbox_limit (%ld)”,+ myname, n, var_virt_mailbox_limit);+ &#x2F; Invalid limit size (negative). Use default virtual_mailbox_limit. &#x2F;+ n &#x3D; var_virt_mailbox_limit;+ }+ }+ else {+\tif (msg_verbose)+ msg_info(“%s: no limit found in the maps, using default virtual_mailbox_limit (%ld)”,+ myname, var_virt_mailbox_limit);+ &#x2F; There is no limit in the maps. Use default virtual_mailbox_limit. &#x2F;+ n &#x3D; var_virt_mailbox_limit;+ }++ &#x2F; If there should is a quota on maildir generaly, check it before delivering the mail &#x2F;+ if (n !&#x3D; 0) {+ set_eugid(usr_attr.uid, usr_attr.gid);+\t&#x2F; try to read the quota from maildirsize file. Returned values by read_maildirsize:+\tx &lt; 0 &#x3D; something failed+\tx &gt;&#x3D; 0 &#x3D; reading successfully finished - sum si returned, so sum size of Maildir was 0 or more &#x2F;+ if (!var_virt_mailbox_limit_inbox &amp;&amp; var_virt_maildir_extended &amp;&amp; (read_mds &#x3D; read_maildirsize(sizefilename, &amp;saved_size, &amp;saved_count)) &gt;&#x3D; 0) {+ if (msg_verbose)+ msg_info(“%s: maildirsize used&#x3D;%s sum&#x3D;%ld count&#x3D;%ld”, myname, sizefilename, saved_size, saved_count);+\t} else {+ if (msg_verbose)+ msg_info(“%s: We will recount the quota (var_virt_mailbox_limit &#x3D; %ld, var_virt_maildir_extended &#x3D; %d, read_maildirsize &#x3D; %d)”,+ myname, var_virt_mailbox_limit, var_virt_maildir_extended, read_mds);++ &#x2F; sanity &#x2F;+ saved_size &#x3D; 0;+ saved_count &#x3D; 0;+\t+ if (var_virt_mailbox_limit_inbox) {+ &#x2F; Check Inbox only (new, cur and tmp dirs). &#x2F;+ saved_size &#x3D; check_dir_size(newdir, &amp;saved_count);+ saved_size +&#x3D; check_dir_size(curdir, &amp;saved_count);+ saved_size +&#x3D; check_dir_size(tmpdir, &amp;saved_count);+ } else {+ &#x2F; Check all boxes. &#x2F;+ saved_size &#x3D; check_dir_size(usr_attr.mailbox, &amp;saved_count);+ }++ set_eugid(var_owner_uid, var_owner_gid);+ } + }+ &#x2F; * Create and write the file as the recipient, so that file quota work. * Create any missing directories on the fly. The file name is chosen@@ -175,46 +664,288 @@ * […] *&#x2F; set_eugid(usr_attr.uid, usr_attr.gid);- vstring_sprintf(buf, “%lu.P%d.%s”,- (unsigned long) starttime.tv_sec, var_pid, get_hostname());+ vstring_sprintf(buf, “%lu.P%d.%s”, (unsigned long) starttime.tv_sec, var_pid, get_hostname()); tmpfile &#x3D; concatenate(tmpdir, STR(buf), (char *) 0); newfile &#x3D; 0;+ bkpnewfile &#x3D; 0; if ((dst &#x3D; vstream_fopen(tmpfile, O_WRONLY | O_CREAT | O_EXCL, 0600)) &#x3D;&#x3D; 0-\t&amp;&amp; (errno !&#x3D; ENOENT- || make_dirs(tmpdir, 0700) &lt; 0- || (dst &#x3D; vstream_fopen(tmpfile, O_WRONLY | O_CREAT | O_EXCL, 0600)) &#x3D;&#x3D; 0)) {-\tdsb_simple(why, mbox_dsn(errno, “4.2.0”),- “create maildir file %s: %m”, tmpfile);- } else if (fstat(vstream_fileno(dst), &amp;st) &lt; 0) { &#x2F;* * Coverity 200604: file descriptor leak in code that never executes. * Code replaced by msg_fatal(), as it is not worthwhile to continue * after an impossible error condition. */ msg_fatal(“fstat %s: %m”, tmpfile); } else { vstring_sprintf(buf, “%lu.V%lxI%lxM%lu.%s”, (unsigned long) starttime.tv_sec, (unsigned long) st.st_dev, (unsigned long) st.st_ino, (unsigned long) starttime.tv_usec, get_hostname()); newfile &#x3D; concatenate(newdir, STR(buf), (char *) 0); if ((mail_copy_status &#x3D; mail_copy(COPY_ATTR(state.msg_attr), dst, copy_flags, &quot; &quot;, why)) == 0) &#123; if (sane_link(tmpfile, newfile) &lt; 0 &amp;&amp; (errno != ENOENT || (make_dirs(curdir, 0700), make_dirs(newdir, 0700)) &lt; 0 || sane_link(tmpfile, newfile) &lt; 0)) &#123; dsb_simple(why, mbox_dsn(errno, &quot;4.2.0&quot;), &quot;create maildir file %s: %m&quot;, newfile); mail_copy_status = MAIL_COPY_STAT_WRITE; &#125; } if (unlink(tmpfile) &lt; 0) msg_warn(&quot;remove %s: %m&quot;, tmpfile); &amp;&amp; (errno != ENOENT || make_dirs(tmpdir, 0700) &lt; 0 || (dst = vstream_fopen(tmpfile, O_WRONLY | O_CREAT | O_EXCL, 0600)) == 0)) &#123; dsb_simple(why, mbox_dsn(errno, &quot;4.2.0&quot;), &quot;create maildir file %s: %m&quot;, tmpfile); } else if (fstat(vstream_fileno(dst), &amp;st) &lt; 0) { /* * Coverity 200604: file descriptor leak in code that never executes. * Code replaced by msg_fatal(), as it is not worthwhile to continue * after an impossible error condition. */ msg_fatal(&quot;fstat %s: %m&quot;, tmpfile); } else { vstring_sprintf(buf, &quot;%lu.V%lxI%lxM%lu.%s&quot;, (unsigned long) starttime.tv_sec, (unsigned long) st.st_dev, (unsigned long) st.st_ino, (unsigned long) starttime.tv_usec, get_hostname()); newfile = concatenate(newdir, STR(buf), (char *) 0); bkpnewfile = concatenate(STR(buf), (char *) 0); /* Will need it later, if we MOVE to other folders. */ if ((mail_copy_status = mail_copy(COPY_ATTR(state.msg_attr), dst, copy_flags, &quot; &quot;, why)) == 0) &#123; /* * Add a &quot;,S=&lt;sizeoffile&gt;&quot; to the newly written file according to the * Maildir++ specifications: http://www.inter7.com/courierimap/README.maildirquota.html * This needs a stat(2) of the tempfile and modification of the * name of the file. */ if (stat(tmpfile, &amp;mail_stat) == 0) &#123; if (n != 0) &#123; saved_size += (long) mail_stat.st_size; saved_count++; &#125; if (var_virt_maildir_extended) &#123; /* Append the size of the file to newfile. */ vstring_sprintf(buf, &quot;,S=%ld&quot;, (long) mail_stat.st_size); newfile = concatenate(newfile, STR(buf), (char *) 0); bkpnewfile = concatenate(bkpnewfile, STR(buf), (char *) 0); &#125; &#125; /* * Now we have the maildir size in saved_size, compare it to the max * quota value and eventually issue a message that we&#39;ve overdrawn it. */ if (saved_size &gt; n) &#123; mail_copy_status = MAIL_COPY_STAT_WRITE; if (((long) mail_stat.st_size &gt; n) || (var_virt_overquota_bounce)) errno = EFBIG; else errno = EDQUOT; &#125; else &#123; /* Maildirfilter code by rk@demiurg.net. */ if (var_virt_maildir_filter) &#123; if (msg_verbose) msg_info(&quot;%s: loading DICT filters&quot;, myname); +#define STREQUAL(x,y,l) (strncasecmp((x), (y), (l)) &#x3D;&#x3D; 0 &amp;&amp; (y)[l] &#x3D;&#x3D; 0) +#define MAIL_COPY_STAT_REJECT (1&lt;&lt;3)+#define MAIL_COPY_STAT_DISCARD (1&lt;&lt;4)+ /* Read filters. */ filtername = concatenate(&quot;regexp:&quot;, usr_attr.mailbox, &quot;maildirfilter&quot;, (char *) 0); sqlmtime = sql2file(strchr(filtername, &#39;/&#39;), state.msg_attr.user); /* Check if this filter is already registered as dictionary. */ if (msg_verbose) msg_info(&quot;%s: checking DICT filters for %s&quot;, myname, filtername); if ((FILTERS = dict_handle(filtername))) &#123; if (msg_verbose) msg_info(&quot;%s: DICT filter found&quot;, myname); /* * If we have mtime in our DICT structure, check it against sqlmtime * and reload the filters if they differ. */ if (FILTERS-&gt;mtime &gt; 0 &amp;&amp; sqlmtime &gt; 0 &amp;&amp; FILTERS-&gt;mtime != sqlmtime) &#123; if (msg_verbose) msg_info(&quot;%s: reloading DICT filters (dict_mtime=%ld != sql_mtime=%ld)&quot;, myname, FILTERS-&gt;mtime, sqlmtime); dict_unregister(filtername); FILTERS = dict_open(filtername, O_RDONLY, DICT_FLAG_LOCK); dict_register(filtername, FILTERS); FILTERS-&gt;mtime = sqlmtime; &#125; &#125; else &#123; if (sqlmtime &gt; 0) &#123; /* Registering filter as new dictionary. */ if (msg_verbose) msg_info(&quot;%s: loading DICT filters from %s (mtime=%ld)&quot;, myname, filtername, sqlmtime); FILTERS = dict_open(filtername, O_RDONLY, DICT_FLAG_LOCK); dict_register(filtername, FILTERS); FILTERS-&gt;mtime = sqlmtime; &#125; &#125; if (FILTERS &amp;&amp; (tmpfilter = vstream_fopen(tmpfile, O_RDONLY, 0))) &#123; fltstr = vstring_alloc(1024); header = (char *) malloc(8192); /* !!!INSECURE!!! See 7168-hack below. */ header[0] = 0; vstring_get_nonl_bound(fltstr, tmpfilter, 1023); header = concatenate(header, STR(fltstr), (char *) 0); while(!vstream_feof(tmpfilter) &amp;&amp; fltstr-&gt;vbuf.data[0] &amp;&amp; strlen(header) &lt; 7168 ) &#123; vstring_get_nonl_bound(fltstr, tmpfilter, 1023); /* Glue multiline headers, replacing leading TAB with space. */ if (msg_verbose) msg_info(&quot;%s: fltstr value: %s&quot;, myname, STR(fltstr)); if (fltstr-&gt;vbuf.data[0] == &#39; &#39; || fltstr-&gt;vbuf.data[0] == &#39;\\t&#39; ) &#123; if (fltstr-&gt;vbuf.data[0] == &#39;\\t&#39;) fltstr-&gt;vbuf.data[0] = &#39; &#39;; header = concatenate(header, STR(fltstr), (char *) 0); &#125; else &#123; header = concatenate(header, &quot; &quot;, STR(fltstr), (char *) 0); &#125; &#125; if (msg_verbose) msg_info(&quot;%s: checking filter CMD for %s&quot;, myname, filtername); /* Check whole header part with regexp maps. */ if ((value = dict_get(FILTERS, lowercase(header))) != 0) &#123; if (msg_verbose) msg_info(&quot;%s: preparing filter CMD&quot;, myname); cmd_text = value + strcspn(value, &quot; \\t&quot;); cmd_len = cmd_text - value; while (*cmd_text &amp;&amp; ISSPACE(*cmd_text)) cmd_text++; if (msg_verbose) msg_info(&quot;%s: executing filter CMD&quot;, myname); if (STREQUAL(value, &quot;REJECT&quot;, cmd_len)) &#123; if (msg_verbose) msg_info(&quot;%s: executing filter CMD REJECT&quot;, myname); mail_copy_status = MAIL_COPY_STAT_REJECT; vstring_sprintf(why-&gt;reason, &quot;%s&quot;, cmd_text); dsb_simple(why, &quot;5.0.0&quot;, &quot;User filter - REJECT&quot;); &#125; if (STREQUAL(value, &quot;DISCARD&quot;, cmd_len)) &#123; if (msg_verbose) msg_info(&quot;%s: executing filter CMD DISCARD&quot;, myname); mail_copy_status = MAIL_COPY_STAT_DISCARD; vstring_sprintf(why-&gt;reason, &quot;%s&quot;, cmd_text); dsb_simple(why, &quot;5.0.0&quot;, &quot;User filter - DISCARD&quot;); &#125; if (var_virt_maildir_extended) &#123; if (STREQUAL(value, &quot;MOVE&quot;, cmd_len)) &#123; if (msg_verbose) msg_info(&quot;%s: executing filter CMD MOVE&quot;, myname); strcut((char *) cmd_text, &quot; &quot;); strcut((char *) cmd_text, &quot;\\t&quot;); strcut((char *) cmd_text, &quot;/&quot;); strcut((char *) cmd_text, &quot;..&quot;); if (*var_virt_maildir_suffix == 0) &#123; newfile = concatenate(usr_attr.mailbox, (char *) 0); &#125; else &#123; newfile = concatenate(usr_attr.mailbox, var_virt_maildir_suffix, (char *) 0); &#125; if (cmd_text[0] != &#39;.&#39;) &#123; newfile = concatenate(newfile, &quot;.&quot;, (char *) 0); &#125; newdir = concatenate(newfile, cmd_text, &quot;/&quot;, &quot;new/&quot;, (char *) 0); tmpdir = concatenate(newfile, cmd_text, &quot;/&quot;, &quot;tmp/&quot;, (char *) 0); curdir = concatenate(newfile, cmd_text, &quot;/&quot;, &quot;cur/&quot;, (char *) 0); mdffilename = concatenate(newfile, cmd_text, &quot;/&quot;, &quot;maildirfolder&quot;, (char *) 0); newfile = concatenate(newfile, cmd_text, &quot;/&quot;, &quot;new/&quot;, bkpnewfile, (char *) 0); &#125; &#125; if (STREQUAL(value, &quot;LOG&quot;, cmd_len) || STREQUAL(value, &quot;WARN&quot;, cmd_len)) &#123; msg_warn(&quot;%s: header check warning: %s&quot;, myname, cmd_text); &#125; if (STREQUAL(value, &quot;INFO&quot;, cmd_len)) &#123; msg_info(&quot;%s: header check info: %s&quot;, myname, cmd_text); &#125; if (msg_verbose) msg_info(&quot;%s: exiting filter CMD&quot;, myname); &#125; /* End-Of-Check */ myfree(header); vstring_free(fltstr); vstream_fclose(tmpfilter); &#125; myfree(filtername); &#125; /* End-Of-Maildirfilter */ /* Deliver to curdir. */ if (mail_copy_status == 0) &#123; if (sane_link(tmpfile, newfile) &lt; 0 &amp;&amp; (errno != ENOENT || (make_dirs(curdir, 0700), make_dirs(newdir, 0700), make_dirs(tmpdir, 0700)) &lt; 0 || sane_link(tmpfile, newfile) &lt; 0)) &#123; dsb_simple(why, mbox_dsn(errno, &quot;4.2.0&quot;), &quot;create maildir file %s: %m&quot;, newfile); mail_copy_status = MAIL_COPY_STAT_WRITE; &#125; if (var_virt_maildir_extended) &#123; time(&amp;tm); /* Check if the quota in the file is the same as the current one, if not, delete the file. */ sizefile = vstream_fopen(sizefilename, O_RDONLY, 0); if (sizefile) &#123; filequota = vstring_alloc(128); vstring_get_null_bound(filequota, sizefile, 127); vstream_fclose(sizefile); if (atol(vstring_export(filequota)) != n) unlink(sizefilename); &#125; /* Open maildirsize file to append this transaction. */ sizefile = vstream_fopen(sizefilename, O_WRONLY | O_APPEND, 0640); /* If the open fails (maildirsize doesn&#39;t exist), or it&#39;s too large, or too old, overwrite it. */ if(!sizefile || (stat(sizefilename, &amp;sizefile_stat) &lt; 0) || (sizefile_stat.st_size &gt; SIZEFILE_MAX) || (sizefile_stat.st_mtime + 15*60 &lt; tm)) &#123; /* If the file exists, sizefile has been opened above, so close it first. */ if (sizefile) &#123; vstream_fclose(sizefile); sizefile = vstream_fopen(sizefilename, O_WRONLY | O_TRUNC, 0640); &#125; else &#123; sizefile = vstream_fopen(sizefilename, O_WRONLY | O_CREAT, 0640); &#125; /* If the creation worked, write to the file, otherwise just give up. */ if (sizefile) &#123; vstream_fprintf(sizefile, &quot;%ldS %ld %ld &quot;, n, saved_size, saved_count); vstream_fclose(sizefile); &#125; &#125; else &#123; /* We opened maildirsize, so let&#39;s just append this transaction and close it. */ vstream_fprintf(sizefile, &quot;%ld 1 &quot;, (long) mail_stat.st_size); vstream_fclose(sizefile); &#125; /* * 1) mdffilename != 0, so the maildirfilter code went through the MOVE to subfolder rule. * 2) stat() failed, maybe the file does not exist? Try to create it. */ if (mdffilename &amp;&amp; (stat(mdffilename, &amp;mdffile_stat) &lt; 0)) &#123; mdffile = vstream_fopen(mdffilename, O_WRONLY | O_CREAT, 0600); if (mdffile) &#123; vstream_fclose(mdffile); &#125; else &#123; msg_warn(&quot;Cannot create maildirfolder file &#39;%s&#39;: %s&quot;, mdffilename, strerror(errno)); &#125; &#125; &#125; &#125; &#125; &#125; if (unlink(tmpfile) &lt; 0) msg_warn(&quot;remove %s: %m&quot;, tmpfile); } set_eugid(var_owner_uid, var_owner_gid); @@ -224,31 +955,64 @@ * location possibly under user control. *&#x2F; if (mail_copy_status &amp; MAIL_COPY_STAT_CORRUPT) {-\tdeliver_status &#x3D; DEL_STAT_DEFER; } else if (mail_copy_status !&#x3D; 0) { if (errno &#x3D;&#x3D; EACCES) { msg_warn(&quot;maildir access problem for UID/GID=%lu/%lu: %s&quot;, (long) usr_attr.uid, (long) usr_attr.gid, STR(why-&gt;reason)); msg_warn(&quot;perhaps you need to create the maildirs in advance&quot;); } vstring_sprintf_prepend(why-&gt;reason, “maildir delivery failed: “); deliver_status &#x3D; (STR(why-&gt;status)[0] == &#39;4&#39; ? defer_append : bounce_append) (BOUNCE_FLAGS(state.request), BOUNCE_ATTR(state.msg_attr)); } else { dsb_simple(why, “2.0.0”, “delivered to maildir”); deliver_status &#x3D; sent(BOUNCE_FLAGS(state.request), SENT_ATTR(state.msg_attr)); deliver_status = DEL_STAT_DEFER; } else if (mail_copy_status !&#x3D; 0) { if (errno == EACCES) &#123; msg_warn(&quot;maildir access problem for UID/GID=%lu/%lu: %s&quot;, (long) usr_attr.uid, (long) usr_attr.gid, STR(why-&gt;reason)); msg_warn(&quot;perhaps you need to create the maildirs in advance&quot;); &#125; /* Support per-recipient bounce messages. */ const char *limit_message; int errnored = errno; /* Seems like mail_addr_find resets errno ... */ if (*var_virt_maildir_limit_message_maps != 0 &amp;&amp; (limit_message = mail_addr_find(virtual_maildir_limit_message_maps, state.msg_attr.user, (char **) NULL)) != 0) &#123; errno = errnored; if (errno == EFBIG) &#123; dsb_simple(why, &quot;5.2.2&quot;, limit_message, NULL); &#125; if (errno == EDQUOT) &#123; dsb_simple(why, &quot;4.2.2&quot;, limit_message, NULL); &#125; &#125; else &#123; errno = errnored; if (errno == EFBIG) &#123; dsb_simple(why, &quot;5.2.2&quot;, var_virt_maildir_limit_message, NULL); &#125; if (errno == EDQUOT) &#123; dsb_simple(why, &quot;4.2.2&quot;, var_virt_maildir_limit_message, NULL); &#125; &#125; vstring_sprintf_prepend(why-&gt;reason, &quot;maildir delivery failed: &quot;); deliver_status = (STR(why-&gt;status)[0] == &#39;4&#39; ? defer_append : bounce_append) (BOUNCE_FLAGS(state.request), BOUNCE_ATTR(state.msg_attr)); } else { dsb_simple(why, &quot;2.0.0&quot;, &quot;delivered to maildir&quot;); deliver_status = sent(BOUNCE_FLAGS(state.request), SENT_ATTR(state.msg_attr)); } vstring_free(buf); myfree(newdir); myfree(tmpdir); myfree(curdir); if (sizefilename) myfree(sizefilename); if (mdffilename) myfree(mdffilename); myfree(tmpfile); if (newfile) myfree(newfile); myfree(newfile); if (bkpnewfile) myfree(bkpnewfile); return (deliver_status); }diff -uNr postfix-2.10.0.orig&#x2F;src&#x2F;virtual&#x2F;virtual.c postfix-2.10.0&#x2F;src&#x2F;virtual&#x2F;virtual.c— postfix-2.10.0.orig&#x2F;src&#x2F;virtual&#x2F;virtual.c\t2011-02-19 01:46:06.000000000 +0100+++ postfix-2.10.0&#x2F;src&#x2F;virtual&#x2F;virtual.c\t2013-06-07 13:21:22.840143270 +0200@@ -335,12 +335,30 @@char var_mail_spool_dir; &#x2F; XXX dependency fix *&#x2F;bool var_strict_mbox_owner; +char *var_virt_mailbox_limit_maps;+bool var_virt_mailbox_limit_inbox;+bool var_virt_mailbox_limit_override;+bool var_virt_maildir_extended;+bool var_virt_overquota_bounce;+char *var_virt_maildir_limit_message;+char *var_virt_maildir_limit_message_maps;+char *var_virt_maildir_suffix;+bool var_virt_trash_count;+char *var_virt_trash_name;+bool var_virt_maildir_filter;+char var_virt_maildir_filter_maps;++ &#x2F; Mappings. *&#x2F; MAPS *virtual_mailbox_maps; MAPS *virtual_uid_maps; MAPS *virtual_gid_maps;+MAPS *virtual_mailbox_limit_maps;+MAPS *virtual_maildir_limit_message_maps;+MAPS *virtual_maildir_filter_maps; &#x2F;* Bit masks.@@ -450,15 +468,28 @@ *&#x2F;virtual_mailbox_maps &#x3D;maps_create(VAR_VIRT_MAILBOX_MAPS, var_virt_mailbox_maps, DICT_FLAG_LOCK | DICT_FLAG_PARANOID); DICT_FLAG_LOCK); virtual_uid_maps = maps_create(VAR_VIRT_UID_MAPS, var_virt_uid_maps, DICT_FLAG_LOCK | DICT_FLAG_PARANOID); DICT_FLAG_LOCK); virtual_gid_maps = maps_create(VAR_VIRT_GID_MAPS, var_virt_gid_maps, DICT_FLAG_LOCK | DICT_FLAG_PARANOID); DICT_FLAG_LOCK); virtual_mailbox_limit_maps &#x3D; maps_create(VAR_VIRT_MAILBOX_LIMIT_MAPS, var_virt_mailbox_limit_maps, DICT_FLAG_LOCK); virtual_maildir_limit_message_maps &#x3D; maps_create(VAR_VIRT_MAILDIR_LIMIT_MESSAGE_MAPS, var_virt_maildir_limit_message_maps, DICT_FLAG_LOCK); virtual_maildir_filter_maps &#x3D; maps_create(VAR_VIRT_MAILDIR_FILTER_MAPS, var_virt_maildir_filter_maps, DICT_FLAG_LOCK); virtual_mbox_lock_mask = mbox_lock_mask(var_virt_mailbox_lock); }@@ -510,10 +541,22 @@ VAR_VIRT_GID_MAPS, DEF_VIRT_GID_MAPS, &amp;var_virt_gid_maps, 0, 0, VAR_VIRT_MAILBOX_BASE, DEF_VIRT_MAILBOX_BASE, &amp;var_virt_mailbox_base, 1, 0, VAR_VIRT_MAILBOX_LOCK, DEF_VIRT_MAILBOX_LOCK, &amp;var_virt_mailbox_lock, 1, 0,+\tVAR_VIRT_MAILBOX_LIMIT_MAPS, DEF_VIRT_MAILBOX_LIMIT_MAPS, &amp;var_virt_mailbox_limit_maps, 0, 0,+\tVAR_VIRT_MAILDIR_LIMIT_MESSAGE, DEF_VIRT_MAILDIR_LIMIT_MESSAGE, &amp;var_virt_maildir_limit_message, 1, 0,+\tVAR_VIRT_MAILDIR_LIMIT_MESSAGE_MAPS, DEF_VIRT_MAILDIR_LIMIT_MESSAGE_MAPS, &amp;var_virt_maildir_limit_message_maps, 0, 0,+\tVAR_VIRT_MAILDIR_SUFFIX, DEF_VIRT_MAILDIR_SUFFIX, &amp;var_virt_maildir_suffix, 0, 0,+\tVAR_VIRT_TRASH_NAME, DEF_VIRT_TRASH_NAME, &amp;var_virt_trash_name, 0, 0,+\tVAR_VIRT_MAILDIR_FILTER_MAPS, DEF_VIRT_MAILDIR_FILTER_MAPS, &amp;var_virt_maildir_filter_maps, 0, 0, 0, }; static const CONFIG_BOOL_TABLE bool_table[] &#x3D; { VAR_STRICT_MBOX_OWNER, DEF_STRICT_MBOX_OWNER, &amp;var_strict_mbox_owner,+\tVAR_VIRT_MAILBOX_LIMIT_INBOX, DEF_VIRT_MAILBOX_LIMIT_INBOX, &amp;var_virt_mailbox_limit_inbox,+\tVAR_VIRT_MAILBOX_LIMIT_OVERRIDE, DEF_VIRT_MAILBOX_LIMIT_OVERRIDE, &amp;var_virt_mailbox_limit_override,+\tVAR_VIRT_MAILDIR_EXTENDED, DEF_VIRT_MAILDIR_EXTENDED, &amp;var_virt_maildir_extended,+\tVAR_VIRT_OVERQUOTA_BOUNCE, DEF_VIRT_OVERQUOTA_BOUNCE, &amp;var_virt_overquota_bounce,+\tVAR_VIRT_TRASH_COUNT, DEF_VIRT_TRASH_COUNT, &amp;var_virt_trash_count,+\tVAR_VIRT_MAILDIR_FILTER, DEF_VIRT_MAILDIR_FILTER, &amp;var_virt_maildir_filter, 0, }; @@ -530,6 +573,7 @@ MAIL_SERVER_PRE_INIT, pre_init, MAIL_SERVER_POST_INIT, post_init, MAIL_SERVER_PRE_ACCEPT, pre_accept, MAIL_SERVER_BOOL_TABLE, bool_table, MAIL_SERVER_PRIVILEGED, 0); }diff -uNr postfix-2.10.0.orig&#x2F;src&#x2F;virtual&#x2F;virtual.h postfix-2.10.0&#x2F;src&#x2F;virtual&#x2F;virtual.h— postfix-2.10.0.orig&#x2F;src&#x2F;virtual&#x2F;virtual.h\t2006-01-08 00:59:47.000000000 +0100+++ postfix-2.10.0&#x2F;src&#x2F;virtual&#x2F;virtual.h\t2013-06-07 13:21:22.841143270 +0200@@ -34,6 +34,9 @@ extern MAPS *virtual_mailbox_maps; extern MAPS *virtual_uid_maps; extern MAPS *virtual_gid_maps;+extern MAPS *virtual_mailbox_limit_maps;+extern MAPS *virtual_maildir_limit_message_maps;+extern MAPS *virtual_maildir_filter_maps; &#x2F;* User attributes: these control the privileges for delivery to external"},{"path":"/2023/09/28/Linux配置文件/wireshark/openvpn/server.conf/","content":"设置监听IP，默认是监听所有IP;local a.b.c.d 设置监听端口，必须要对应的在防火墙里面打开port 1194 设置用TCP还是UDP协议？;proto tcpproto tcp 设置创建tun的路由IP通道，还是创建tap的以太网通道路由IP容易控制，所以推荐使用它；但如果如IPX等必须使用第二层才能通过的通讯，则可以用tap方式，tap也就是以太网桥接;dev tapdev tun Windows需要给网卡一个名称，这里设置，linux不需要;dev-node MyTap 这里是重点，必须指定SSL&#x2F;TLS root certificate (ca),certificate(cert), and private key (key)ca文件是服务端和客户端都必须使用的，但不需要ca.key服务端和客户端指定各自的.crt和.key请注意路径,可以使用以配置文件开始为根的相对路径,也可以使用绝对路径请小心存放.key密钥文件ca &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;2.0&#x2F;keys&#x2F;ca.crtcert &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;2.0&#x2F;keys&#x2F;openvpn.example.com.crtkey &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;2.0&#x2F;keys&#x2F;openvpn.example.com.key This file should be kept secret指定Diffie hellman parameters.dh &#x2F;etc&#x2F;openvpn&#x2F;easy-rsa&#x2F;2.0&#x2F;keys&#x2F;dh2048.pem 配置VPN使用的网段，OpenVPN会自动提供基于该网段的DHCP服务，但不能和任何一方的局域网段重复，保证唯一server 10.8.0.0 255.255.255.0 维持一个客户端和virtual IP的对应表，以方便客户端重新连接可以获得同样的IPifconfig-pool-persist ipp.txt 配置为以太网桥模式,但需要使用系统的桥接功能这里不需要使用;server-bridge 10.8.0.4 255.255.255.0 10.8.0.50 10.8.0.100 为客户端创建对应的路由,以另其通达公司网内部服务器但记住，公司网内部服务器也需要有可用路由返回到客户端;push “route 192.168.20.0 255.255.255.0”push “route 172.24.30.0 255.255.255.0” 为特定的客户端指定IP或指定路由,该路由通常是客户端后面的内网网段,而不是服务端连接的网段ccd是&#x2F;etc&#x2F;openvpn下的目录，其中建有希望限制的客户端CommonName为文件名的文件,并通过下面的命令写入固定IP地址例如Common Name为client1,则在&#x2F;etc&#x2F;openvpn&#x2F;ccd&#x2F;client1写有：ifconfig-push 10.9.0.1 10.9.0.2;client-config-dir ccd;route 192.168.40.128 255.255.255.248 为可以对不同的客户端设置防火墙等权限可以让其自动运行对应脚本,可参考man;learn-address .&#x2F;script 若客户端希望所有的流量都通过VPN传输,则可以使用该语句其会自动改变客户端的网关为VPN服务器,推荐关闭一旦设置，请小心服务端的DHCP设置问题;push “redirect-gateway” 用OpenVPN的DHCP功能为客户端提供指定的DNS、WINS等;push “dhcp-option DNS 10.8.0.1”;push “dhcp-option WINS 10.8.0.1” 默认客户端之间是不能直接通讯的，除非把下面的语句注释掉client-to-client 如果您希望有相同Common Name的客户端都可以登陆也可以注释下面的语句,推荐每个客户端都使用不用的Common Name常用于测试;duplicate-cn 设置服务端检测的间隔和超时时间keepalive 10 120 下面是一些对安全性增强的措施For extra security beyond that providedby SSL&#x2F;TLS, create an “HMAC firewall”to help block DoS attacks and UDP port flooding.Generate with:openvpn –genkey –secret ta.keyThe server and each client must havea copy of this key.The second parameter should be 0on the server and 1 on the clients.;tls-auth ta.key 0 # This file is secret Select a cryptographic cipher.This config item must be copied tothe client config file as well.;cipher BF-CBC # Blowfish (default);cipher AES-128-CBC # AES;cipher DES-EDE3-CBC # Triple-DES 使用lzo压缩的通讯,服务端和客户端都必须配置comp-lzo 设置最大用户数;max-clients 100 让OpenVPN以nobody用户和组来运行（安全）;user nobody;group nobody The persist options will try to avoidaccessing certain resources on restartthat may no longer be accessible becauseof the privilege downgrade.persist-keypersist-tun 输出短日志,每分钟刷新一次,以显示当前的客户端status &#x2F;var&#x2F;log&#x2F;openvpn&#x2F;openvpn-status.log 缺省日志会记录在系统日志中，但也可以导向到其他地方建议调试的使用先不要设置,调试完成后再定义log &#x2F;var&#x2F;log&#x2F;openvpn&#x2F;openvpn.loglog-append &#x2F;var&#x2F;log&#x2F;openvpn&#x2F;openvpn.log 设置日志的级别0 is silent, except for fatal errors4 is reasonable for general usage5 and 6 can help to debug connection problems9 is extremely verboseverb 3 Silence repeating messages. At most 20sequential messages of the same messagecategory will be output to the log.;mute 20"},{"path":"/2023/09/28/Linux配置文件/wireshark/openvpn/client/","content":"1.下载客户端，安装：http://vpntech.googlecode.com/files/openvpn-2.1.1-gui-1.0.3-install-cn-64bit.zip2.将服务端打包文件解压，并将包内ca.crt、client1.crt、client1.key复制到安装目录的config下.3.在config下创建client.ovpn文件内容如下：定义是一个客户端client# 定义使用路由IP模式，与服务端一致;dev tapdev tun# 定义Windows下使用的网卡名称,linux不需要;dev-node MyTap# 定义使用的协议，与服务端一致;proto tcpproto tcp# 指定服务端地址和端口,可以用多行指定多台服务器# 实现负载均衡（从上往下尝试）remote 192.168.100.90 1194;remote my-server-2 1194# 若上面配置了多台服务器，让客户端随机连接;remote-random# 解析服务器域名# Keep trying indefinitely to resolve the# host name of the OpenVPN server. Very useful# on machines which are not permanently connected# to the internet such as laptops.resolv-retry infinite# 客户端不需要绑定端口# Most clients do not need to bind to# a specific local port number.nobind# 也是为了让Openvpn也nobody运行（安全）# 注意：Windows不能设置;user nobody;group nobody# Try to preserve some state across restarts.persist-keypersist-tun# 若客户端通过HTTP Proxy，在这里设置# 要使用Proxy，不能使用UDP为VPN的通讯协议;http-proxy-retry # retry on connection failures;http-proxy [proxy server] [proxy port #]# 无线网络有很多多余的头文件，设置忽略它;mute-replay-warnings# 重点，就是指定ca和客户端的证书ca ca.crtcert client1.crtkey client1.key# 如果服务端打开了PAM认证模块，客户端需要另其有效;auth-user-pass# 一些安全措施# Verify server certificate by checking# that the certicate has the nsCertType# field set to “server”. This is an# important precaution to protect against# a potential attack discussed here:# http://openvpn.net/howto.html#mitm## To use this feature, you will need to generate# your server certificates with the nsCertType# field set to “server”. The build-key-server# script in the easy-rsa folder will do this.;ns-cert-type server# If a tls-auth key is used on the server# then every client must also have the key.;tls-auth ta.key 1# Select a cryptographic cipher.# If the cipher option is used on the server# then you must also specify it here.;cipher x# 使用lzo压缩，与服务端一致comp-lzo# Set log file verbosity.verb 3# Silence repeating messages;mute 205.连接：在右下角的openvpn图标上右击，选择“Connect”,若能正常分配IP，则连接成功。"},{"path":"/2023/09/28/Linux配置文件/wireshark/openswan/ipsec.conf/","content":"&#x2F;etc&#x2F;ipsec.conf - Openswan IPsec configuration fileThis file: &#x2F;usr&#x2F;local&#x2F;share&#x2F;doc&#x2F;openswan&#x2F;ipsec.conf-sampleManual: ipsec.conf.5version\t2.0\t# conforms to second version of ipsec.conf specification basic configurationconfig setup # Do not set debug options to debug configuration issues! # plutodebug &#x2F; klipsdebug &#x3D; “all”, “none” or a combation from below: # “raw crypt parsing emitting control klips pfkey natt x509 dpd private” # eg: # plutodebug&#x3D;”control parsing” # Again: only enable plutodebug or klipsdebug when asked by a developer # # enable to get logs per-peer # plutoopts&#x3D;”–perpeerlog” # # Enable core dumps (might require system changes, like ulimit -C) # This is required for abrtd to work properly # Note: incorrect SElinux policies might prevent pluto writing the core dumpdir&#x3D;&#x2F;var&#x2F;run&#x2F;pluto&#x2F; # # NAT-TRAVERSAL support, see README.NAT-Traversal nat_traversal&#x3D;yes # exclude networks used on server side by adding %v4:!a.b.c.0&#x2F;24 # It seems that T-Mobile in the US and Rogers&#x2F;Fido in Canada are # using 25&#x2F;8 as “private” address space on their 3G network. # This range has not been announced via BGP (at least upto 2010-12-21) virtual_private&#x3D;%v4:10.10.66.0&#x2F;24,%v4:10.10.64.0&#x2F;24,%v4:10.10.203.0&#x2F;24,%v4:192.168.0.0&#x2F;16,%v4:172.16.3.0&#x2F;24,%v4:172.16.83.0&#x2F;24,%v4:25.0.0.0&#x2F;8,%v6:fd00::&#x2F;8,%v6:fe80::&#x2F;10 # OE is now off by default. Uncomment and change to on, to enable. oe&#x3D;off # which IPsec stack to use. auto will try netkey, then klips then mast protostack&#x3D;netkey # Use this to log to a file, or disable logging on embedded systems (like openwrt) #plutostderrlog&#x3D;&#x2F;dev&#x2F;null Add connections heresample VPN connectionfor more examples, see &#x2F;etc&#x2F;ipsec.d&#x2F;examples&#x2F;#conn sample# # Left security gateway, subnet behind it, nexthop toward right.# left&#x3D;10.0.0.1# leftsubnet&#x3D;172.16.0.0&#x2F;24# leftnexthop&#x3D;10.22.33.44# # Right security gateway, subnet behind it, nexthop toward left.# right&#x3D;10.12.12.1# rightsubnet&#x3D;192.168.0.0&#x2F;24# rightnexthop&#x3D;10.101.102.103# # To authorize this connection, but not actually start it,# # at startup, uncomment this.# #auto&#x3D;addconn net-net ike&#x3D;3des-md5 authby&#x3D;secret keyingtries&#x3D;0 left&#x3D;118.145.0.200 leftsubnet&#x3D;10.10.66.0&#x2F;24 leftnexthop&#x3D;%defaultroute right&#x3D;58.20.61.68 rightsubnet&#x3D;10.10.203.0&#x2F;24 rightnexthop&#x3D;%defaultroute compress&#x3D;no auto&#x3D;start"},{"path":"/2023/09/28/Linux配置文件/nginx+tomcat/install/","content":"#nginx+tomcat��α��ֿͻ��˻Ự�� tomcat sessioin���������÷�����apache+tomcat���м�¼��ͬ��������nginx+tomcat.���ַ�ʽ����tomcat����session���漰��sessionͬ�����ڼ�Ⱥ�ϴ�ʱ���ܻ����������ս ʹ��jvm_route, nginx��һ��ģ�飬����cookie�����û�����̶����䵽ͬһ���tomcat���û��ڵ�һ�η���ʱ��nginx�ͻ���cookie�д���”���”�������Ǿ��Ǻ��tomcat��jvmroute,���������û����������󶼻�����ͬһ��tomcat��ʵ�ֻỰ���֡� ##jvm_routeģ������ ��ȡ���°汾svn checkout http://nginx-upstream-jvm-route.googlecode.com/svn/trunk/ nginx-upstream-jvm-route-read-only #��װnginx����Ϊnginx����ģ�� ######https://github.com/tbje/nginx-upstream-jvm-route#########tar zxvf nginx-upstream-jvm-route.tgz tar zxvf nginx-1.4.7.tar.gz &amp;&amp; cd nginx-1.4.7 patch -p0 &lt; ..&#x2F;nginx-upstream-jvm-route&#x2F;jvm_route.patch .&#x2F;configure .&#x2F;configure –prefix&#x3D;&#x2F;Data&#x2F;app&#x2F;nginx-1.4.7 –with-pcre&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre –with-openssl&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl –with-http_sub_module –with-http_ssl_module –with-http_stub_status_module –with-http_realip_module –add-module&#x3D;&#x2F;Data&#x2F;software&#x2F;nginx-upstream-jvm-route make &amp;&amp; make install nginx.confupstream tomcat &#123; server localhost:8080 srun_id=s1; server localhost:8081 srun_id=s2; server 10.10.67.115:8080 srun_id=s3; server 10.10.67.115:8081 srun_id=s4; jvm_route $cookie_JSESSIONID|sessionid reverse; &#125; server { listen 80; server_name xy.happigo.com; access_log off; if ( $fastcgi_script_name ~ ..*/.*php ) { return 403; } location &#x2F; { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://tomcat; }} tomcat server.xml ,ֻ��Ҫ����jvmroute ~"},{"path":"/2023/09/28/Linux配置文件/wireshark/mysql/mysql_del_root.sh/","content":"#����δ�˳�mysql��������ֱ��ʹ��������������root�û� insert into user set user&#x3D;’root’,ssl_cipher&#x3D;’’,x509_issuer&#x3D;’’,x509_subject&#x3D;’’; update user set Host&#x3D;’localhost’,select_priv&#x3D;’y’, insert_priv&#x3D;’y’,update_priv&#x3D;’y’, Alter_priv&#x3D;’y’,delete_priv&#x3D;’y’,create_priv&#x3D;’y’,drop_priv&#x3D;’y’,reload_priv&#x3D;’y’,shutdown_priv&#x3D;’y’,Process_priv&#x3D;’y’,file_priv&#x3D;’y’,grant_priv&#x3D;’y’,References_priv&#x3D;’y’,index_priv&#x3D;’y’,create_user_priv&#x3D;’y’,show_db_priv&#x3D;’y’,super_priv&#x3D;’y’,create_tmp_table_priv&#x3D;’y’,Lock_tables_priv&#x3D;’y’,execute_priv&#x3D;’y’,repl_slave_priv&#x3D;’y’,repl_client_priv&#x3D;’y’,create_view_priv&#x3D;’y’,show_view_priv&#x3D;’y’,create_routine_priv&#x3D;’y’,alter_routine_priv&#x3D;’y’,create_user_priv&#x3D;’y’ where user&#x3D;’root’; #����ǰ���˳�mysql����������ɱ����ǰmysql���̣��ƹ���Ȩ������mysql�����������û���֮�������������� #killall mysqld#mysqld_safe –skip-grant-tables &amp;#&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysql"},{"path":"/2023/09/28/Linux配置文件/wireshark/mysql/mysqlsla/","content":"perl��װDBD::mysql ��DBI����ģ�� tar zxvf mysqlsla-2.03.tar.gz &amp;&amp; cd mysqlsla-2.03 perl MakeFile.PL make make install Ĭ�ϰ�װ��mysqlsla-2.03&#x2F;bin�£��ƶ���$PATH�¼��� mysqlsla –log-type slow slow.log"},{"path":"/2023/09/28/Linux配置文件/wireshark/mysql/mysql-slave.sh/","content":"mysql&gt; flush tables with readlock; show master status; slave stop; change master tomaster_host&#x3D;’192.168.48.128’,master_user&#x3D;’backup’,master_password&#x3D;’backup’,master_log_file&#x3D;’mysql-bin.000003’,master_log_pos&#x3D;1826803; slave start;1826803show slave status\\G;jfjb"},{"path":"/2023/09/28/Linux配置文件/lvs+keepalived/install.sh/","content":"CentOS-6yum install kernel-devel yum install popt popt-devel popt-static libnl libnl-devel tar zxvf ipvsadm-1.26.tar.gz &amp;&amp; cd ipvsadm-1.26 make &amp;&amp; make install ####real_server的sysctl.conf###### ##必须关闭arp解析功能##net.ipv4.conf.lo.arp_ignore &#x3D; 1net.ipv4.conf.lo.arp_announce &#x3D; 2net.ipv4.conf.all.arp_ignore &#x3D; 1net.ipv4.conf.all.arp_announce &#x3D; 2 #keepalived tar zxvf keepalived-1.2.8.tar.gz &amp;&amp; cd keepalived-1.2.8 .&#x2F;configure &amp;&amp; make &amp;&amp; make install cp &#x2F;usr&#x2F;local&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;keepalived &#x2F;etc&#x2F;init.d&#x2F; cp &#x2F;usr&#x2F;local&#x2F;etc&#x2F;sysconfig&#x2F;keepalived &#x2F;etc&#x2F;sysconfig&#x2F; mkdir &#x2F;etc&#x2F;keepalived cp &#x2F;usr&#x2F;local&#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf &#x2F;etc&#x2F;keepalived&#x2F; cp &#x2F;usr&#x2F;local&#x2F;sbin&#x2F;keepalived &#x2F;usr&#x2F;sbin&#x2F;"},{"path":"/2023/09/28/Linux配置文件/lnmp/tomcat/install.sh/","content":"#jave-jdk #http://www.oracle.com/technetwork/java/javase/downloads/index.html chmod +x jdk-6u37-linux-x64.bin .&#x2F;jdk-6u37-linux-x64.bin #安装完成后将生成jdk1.6.0_37目录 mv jdk1.6.0_37 &#x2F;usr&#x2F;local&#x2F; #修改环境变量#最好不要直接修改&#x2F;etc&#x2F;profile文件，而是通过修改用户家目录下的.bashrc文件来单独为制定用户设置环境变量 echo -ne “JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk1.6.0_37 PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin CLASSPATH&#x3D;.:JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar export JAVA_HOME PATH CLASSPATH” &gt;&gt; .bashrc #测试是否安装成功java -version #tomcat #http://mirror.olnevhost.net/pub/apache/tomcat/tomcat-7/v7.0.33/bin/apache-tomcat-7.0.33.tar.gz tar zxvf apache-tomcat-7.0.33.tar.gz mv tar zxvf apache-tomcat-7.0.33 &#x2F;usr&#x2F;local&#x2F;tomcat $tomcat_home&#x2F;bin&#x2F;startup.sh | shutdown.sh #修改tomcat根目录 $tomcat_home&#x2F;conf&#x2F;server.xml #这一句是自行添加的"},{"path":"/2023/09/28/Linux配置文件/lnmp/ZendOpcache/","content":"���Ҫ��Zend Guard Loader���棬����Ҫ�ŵ�Zend Guard Loader��ǰ�棬����������php���ٲ�����档"},{"path":"/2023/09/28/Linux配置文件/lnmp/sysctl.conf/","content":"###linux�ںˣ���������Ż�####����ip��ת��net.ipv4.ip_forward &#x3D; 0net.ipv4.conf.all.forwarding &#x3D; 0 #��ֱ�����ӵ�������з���·������net.ipv4.conf.all.rp_filter &#x3D; 1net.ipv4.conf.default.rp_filter &#x3D; 1 #���������ܺ���Դ·����Ϣ��ip��net.ipv4.conf.all.accept_source_route &#x3D; 0net.ipv4.conf.default.accept_source_route &#x3D; 0 #��TCP SYN cookies������һ���̶�Ԥ��SYN����net.ipv4.tcp_syncookies &#x3D; 1 #SYN���еĳ��ȣ��ʵ������ֵ�������ڵֵ�SYN����net.ipv4.tcp_max_syn_backlog &#x3D; 3072#SYN�����Դ������ʵ����͸�ֵ�������ڷ���SYN����net.ipv4.tcp_synack_retries &#x3D; 3net.ipv4.tcp_syn_retries &#x3D; 3 #�ر�Linux kernel��·���ض�����net.ipv4.conf.all.send_redirects &#x3D; 0net.ipv4.conf.default.send_redirects &#x3D; 0 #������ip�ض�����Ϣnet.ipv4.conf.all.accept_redirects &#x3D; 0 #ȡ����ȫ�ض���net.ipv4.conf.all.secure_redirects &#x3D; 0 #Ԥ��ICMP̽��net.ipv4.icmp_echo_ignore_broadcasts &#x3D; 1net.ipv4.icmp_ignore_bogus_error_responses &#x3D; 1 #���̿��ٻ��գ�����ϵͳ�д��ڴ���TIME_WAIT����net.ipv4.tcp_tw_recycle &#x3D; 1net.ipv4.tcp_fin_timeout &#x3D; 30 #�˿����ã�һ�㲻����#net.ipv4.tcp_tw_reuse &#x3D; 1 #��ʱ�˿ڷ�Χnet.ipv4.ip_local_port_range &#x3D; 1024 65535"},{"path":"/2023/09/28/Linux配置文件/lnmp/php.ini/","content":"[PHP] ;;;;;;;;;;;;;;;;;;;; About php.ini ;;;;;;;;;;;;;;;;;;;;; PHP’s initialization file, generally called php.ini, is responsible for; configuring many of the aspects of PHP’s behavior. ; PHP attempts to find and load this configuration from a number of locations.; The following is a summary of its search order:; 1. SAPI module specific location.; 2. The PHPRC environment variable. (As of PHP 5.2.0); 3. A number of predefined registry keys on Windows (As of PHP 5.2.0); 4. Current working directory (except CLI); 5. The web server’s directory (for SAPI modules), or directory of PHP; (otherwise in Windows); 6. The directory from the –with-config-file-path compile time option, or the; Windows directory (C:\\windows or C:\\winnt); See the PHP docs for more specific information.; http://php.net/configuration.file ; The syntax of the file is extremely simple. Whitespace and Lines; beginning with a semicolon are silently ignored (as you probably guessed).; Section headers (e.g. [Foo]) are also silently ignored, even though; they might mean something in the future. ; Directives following the section heading [PATH&#x3D;&#x2F;www&#x2F;mysite] only; apply to PHP files in the &#x2F;www&#x2F;mysite directory. Directives; following the section heading [HOST&#x3D;www.example.com] only apply to; PHP files served from www.example.com. Directives set in these; special sections cannot be overridden by user-defined INI files or; at runtime. Currently, [PATH&#x3D;] and [HOST&#x3D;] sections only work under; CGI&#x2F;FastCGI.; http://php.net/ini.sections ; Directives are specified using the following syntax:; directive &#x3D; value; Directive names are case sensitive - foo&#x3D;bar is different from FOO&#x3D;bar.; Directives are variables used to configure PHP or PHP extensions.; There is no name validation. If PHP can’t find an expected; directive because it is not set or is mistyped, a default value will be used. ; The value can be a string, a number, a PHP constant (e.g. E_ALL or M_PI), one; of the INI constants (On, Off, True, False, Yes, No and None) or an expression; (e.g. E_ALL &amp; ~E_NOTICE), a quoted string (“bar”), or a reference to a; previously set variable or directive (e.g. ${foo}) ; Expressions in the INI file are limited to bitwise operators and parentheses:; | bitwise OR; ^ bitwise XOR; &amp; bitwise AND; ~ bitwise NOT; ! boolean NOT ; Boolean flags can be turned on using the values 1, On, True or Yes.; They can be turned off using the values 0, Off, False or No. ; An empty string can be denoted by simply not writing anything after the equal; sign, or by using the None keyword: ; foo &#x3D; ; sets foo to an empty string; foo &#x3D; None ; sets foo to an empty string; foo &#x3D; “None” ; sets foo to the string ‘None’ ; If you use constants in your value, and these constants belong to a; dynamically loaded extension (either a PHP extension or a Zend extension),; you may only use these constants after the line that loads the extension. ;;;;;;;;;;;;;;;;;;;; About this file ;;;;;;;;;;;;;;;;;;;;; PHP comes packaged with two INI files. One that is recommended to be used; in production environments and one that is recommended to be used in; development environments. ; php.ini-production contains settings which hold security, performance and; best practices at its core. But please be aware, these settings may break; compatibility with older or less security conscience applications. We; recommending using the production ini in production and testing environments. ; php.ini-development is very similar to its production variant, except it’s; much more verbose when it comes to errors. We recommending using the; development version only in development environments as errors shown to; application users can inadvertently leak otherwise secure information. ;;;;;;;;;;;;;;;;;;;; Quick Reference ;;;;;;;;;;;;;;;;;;;;; The following are all the settings which are different in either the production; or development versions of the INIs with respect to PHP’s default behavior.; Please see the actual settings later in the document for more details as to why; we recommend these changes in PHP’s behavior. ; allow_call_time_pass_reference; Default Value: On; Development Value: Off; Production Value: Off ; display_errors; Default Value: On; Development Value: On; Production Value: Off ; display_startup_errors; Default Value: Off; Development Value: On; Production Value: Off ; error_reporting; Default Value: E_ALL &amp; ~E_NOTICE; Development Value: E_ALL | E_STRICT; Production Value: E_ALL &amp; ~E_DEPRECATED ; html_errors; Default Value: On; Development Value: On; Production value: Off ; log_errors; Default Value: Off; Development Value: On; Production Value: On ; magic_quotes_gpc; Default Value: On; Development Value: Off; Production Value: Off ; max_input_time; Default Value: -1 (Unlimited); Development Value: 60 (60 seconds); Production Value: 60 (60 seconds) ; output_buffering; Default Value: Off; Development Value: 4096; Production Value: 4096 ; register_argc_argv; Default Value: On; Development Value: Off; Production Value: Off ; register_long_arrays; Default Value: On; Development Value: Off; Production Value: Off ; request_order; Default Value: None; Development Value: “GP”; Production Value: “GP” ; session.bug_compat_42; Default Value: On; Development Value: On; Production Value: Off ; session.bug_compat_warn; Default Value: On; Development Value: On; Production Value: Off ; session.gc_divisor; Default Value: 100; Development Value: 1000; Production Value: 1000 ; session.hash_bits_per_character; Default Value: 4; Development Value: 5; Production Value: 5 ; short_open_tag; Default Value: On; Development Value: Off; Production Value: Off ; track_errors; Default Value: Off; Development Value: On; Production Value: Off ; url_rewriter.tags; Default Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,form&#x3D;,fieldset&#x3D;”; Development Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,input&#x3D;src,form&#x3D;fakeentry”; Production Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,input&#x3D;src,form&#x3D;fakeentry” ; variables_order; Default Value: “EGPCS”; Development Value: “GPCS”; Production Value: “GPCS” ;;;;;;;;;;;;;;;;;;;;; php.ini Options ;;;;;;;;;;;;;;;;;;;;;; Name for user-defined php.ini (.htaccess) files. Default is “.user.ini”;user_ini.filename &#x3D; “.user.ini” ; To disable this feature set this option to empty value;user_ini.filename &#x3D; ; TTL for user-defined php.ini files (time-to-live) in seconds. Default is 300 seconds (5 minutes);user_ini.cache_ttl &#x3D; 300 ;;;;;;;;;;;;;;;;;;;;; Language Options ;;;;;;;;;;;;;;;;;;;;; ; Enable the PHP scripting language engine under Apache.; http://php.net/engineengine &#x3D; On ; This directive determines whether or not PHP will recognize code between; tags as PHP source which should be processed as such. It’s been; recommended for several years that you not use the short tag “short cut” and; instead to use the full tag combination. With the wide spread use; of XML and use of these tags by other languages, the server can become easily; confused and end up parsing the wrong code in the wrong context. But because; this short cut has been a feature for such a long time, it’s currently still; supported for backwards compatibility, but we recommend you don’t use them.; Default Value: On; Development Value: Off; Production Value: Off; http://php.net/short-open-tagshort_open_tag &#x3D; On ; Allow ASP-style &lt;% %&gt; tags.; http://php.net/asp-tagsasp_tags &#x3D; Off ; The number of significant digits displayed in floating point numbers.; http://php.net/precisionprecision &#x3D; 14 ; Enforce year 2000 compliance (will cause problems with non-compliant browsers); http://php.net/y2k-compliancey2k_compliance &#x3D; On ; Output buffering is a mechanism for controlling how much output data; (excluding headers and cookies) PHP should keep internally before pushing that; data to the client. If your application’s output exceeds this setting, PHP; will send that data in chunks of roughly the size you specify.; Turning on this setting and managing its maximum buffer size can yield some; interesting side-effects depending on your application and web server.; You may be able to send headers and cookies after you’ve already sent output; through print or echo. You also may see performance benefits if your server is; emitting less packets due to buffered output versus PHP streaming the output; as it gets it. On production servers, 4096 bytes is a good setting for performance; reasons.; Note: Output buffering can also be controlled via Output Buffering Control; functions.; Possible Values:; On &#x3D; Enabled and buffer is unlimited. (Use with caution); Off &#x3D; Disabled; Integer &#x3D; Enables the buffer and sets its maximum size in bytes.; Note: This directive is hardcoded to Off for the CLI SAPI; Default Value: Off; Development Value: 4096; Production Value: 4096; http://php.net/output-bufferingoutput_buffering &#x3D; 4096 ; You can redirect all of the output of your scripts to a function. For; example, if you set output_handler to “mb_output_handler”, character; encoding will be transparently converted to the specified encoding.; Setting any output handler automatically turns on output buffering.; Note: People who wrote portable scripts should not depend on this ini; directive. Instead, explicitly set the output handler using ob_start().; Using this ini directive may cause problems unless you know what script; is doing.; Note: You cannot use both “mb_output_handler” with “ob_iconv_handler”; and you cannot use both “ob_gzhandler” and “zlib.output_compression”.; Note: output_handler must be empty if this is set ‘On’ !!!!; Instead you must use zlib.output_handler.; http://php.net/output-handler;output_handler &#x3D; ; Transparent output compression using the zlib library; Valid values for this option are ‘off’, ‘on’, or a specific buffer size; to be used for compression (default is 4KB); Note: Resulting chunk size may vary due to nature of compression. PHP; outputs chunks that are few hundreds bytes each as a result of; compression. If you prefer a larger chunk size for better; performance, enable output_buffering in addition.; Note: You need to use zlib.output_handler instead of the standard; output_handler, or otherwise the output will be corrupted.; http://php.net/zlib.output-compressionzlib.output_compression &#x3D; Off ; http://php.net/zlib.output-compression-level;zlib.output_compression_level &#x3D; -1 ; You cannot specify additional output handlers if zlib.output_compression; is activated here. This setting does the same as output_handler but in; a different order.; http://php.net/zlib.output-handler;zlib.output_handler &#x3D; ; Implicit flush tells PHP to tell the output layer to flush itself; automatically after every output block. This is equivalent to calling the; PHP function flush() after each and every call to print() or echo() and each; and every HTML block. Turning this option on has serious performance; implications and is generally recommended for debugging purposes only.; http://php.net/implicit-flush; Note: This directive is hardcoded to On for the CLI SAPIimplicit_flush &#x3D; Off ; The unserialize callback function will be called (with the undefined class’; name as parameter), if the unserializer finds an undefined class; which should be instantiated. A warning appears if the specified function is; not defined, or if the function doesn’t include&#x2F;implement the missing class.; So only set this entry, if you really want to implement such a; callback-function.unserialize_callback_func &#x3D; ; When floats &amp; doubles are serialized store serialize_precision significant; digits after the floating point. The default value ensures that when floats; are decoded with unserialize, the data will remain the same.serialize_precision &#x3D; 17 ; This directive allows you to enable and disable warnings which PHP will issue; if you pass a value by reference at function call time. Passing values by; reference at function call time is a deprecated feature which will be removed; from PHP at some point in the near future. The acceptable method for passing a; value by reference to a function is by declaring the reference in the functions; definition, not at call time. This directive does not disable this feature, it; only determines whether PHP will warn you about it or not. These warnings; should enabled in development environments only.; Default Value: On (Suppress warnings); Development Value: Off (Issue warnings); Production Value: Off (Issue warnings); http://php.net/allow-call-time-pass-referenceallow_call_time_pass_reference &#x3D; Off ; Safe Mode; http://php.net/safe-modesafe_mode &#x3D; Off ; By default, Safe Mode does a UID compare check when; opening files. If you want to relax this to a GID compare,; then turn on safe_mode_gid.; http://php.net/safe-mode-gidsafe_mode_gid &#x3D; Off ; When safe_mode is on, UID&#x2F;GID checks are bypassed when; including files from this directory and its subdirectories.; (directory must also be in include_path or full path must; be used when including); http://php.net/safe-mode-include-dirsafe_mode_include_dir &#x3D; ; When safe_mode is on, only executables located in the safe_mode_exec_dir; will be allowed to be executed via the exec family of functions.; http://php.net/safe-mode-exec-dirsafe_mode_exec_dir &#x3D; ; Setting certain environment variables may be a potential security breach.; This directive contains a comma-delimited list of prefixes. In Safe Mode,; the user may only alter environment variables whose names begin with the; prefixes supplied here. By default, users will only be able to set; environment variables that begin with PHP_ (e.g. PHP_FOO&#x3D;BAR).; Note: If this directive is empty, PHP will let the user modify ANY; environment variable!; http://php.net/safe-mode-allowed-env-varssafe_mode_allowed_env_vars &#x3D; PHP_ ; This directive contains a comma-delimited list of environment variables that; the end user won’t be able to change using putenv(). These variables will be; protected even if safe_mode_allowed_env_vars is set to allow to change them.; http://php.net/safe-mode-protected-env-varssafe_mode_protected_env_vars &#x3D; LD_LIBRARY_PATH ; open_basedir, if set, limits all file operations to the defined directory; and below. This directive makes most sense if used in a per-directory; or per-virtualhost web server configuration file. This directive is; NOT affected by whether Safe Mode is turned On or Off.; http://php.net/open-basedir;open_basedir &#x3D; ; This directive allows you to disable certain functions for security reasons.; It receives a comma-delimited list of function names. This directive is; NOT affected by whether Safe Mode is turned On or Off.; http://php.net/disable-functionsdisable_functions &#x3D; phpinfo,passthru,system,chroot,scandir,chgrp,chown,proc_open,proc_get_status,ini_alter,ini_alter,ini_restore,dl,pfsockopen,openlog,syslog,readlink,symlink,popepassthru,stream_socket_server,putenv,exec,shell_exec ; This directive allows you to disable certain classes for security reasons.; It receives a comma-delimited list of class names. This directive is; NOT affected by whether Safe Mode is turned On or Off.; http://php.net/disable-classesdisable_classes &#x3D; ; Colors for Syntax Highlighting mode. Anything that’s acceptable in; would work.; http://php.net/syntax-highlighting;highlight.string &#x3D; #DD0000;highlight.comment &#x3D; #FF9900;highlight.keyword &#x3D; #007700;highlight.bg &#x3D; #FFFFFF;highlight.default &#x3D; #0000BB;highlight.html &#x3D; #000000 ; If enabled, the request will be allowed to complete even if the user aborts; the request. Consider enabling it if executing long requests, which may end up; being interrupted by the user or a browser timing out. PHP’s default behavior; is to disable this feature.; http://php.net/ignore-user-abort;ignore_user_abort &#x3D; On ; Determines the size of the realpath cache to be used by PHP. This value should; be increased on systems where PHP opens many files to reflect the quantity of; the file operations performed.; http://php.net/realpath-cache-size;realpath_cache_size &#x3D; 16k ; Duration of time, in seconds for which to cache realpath information for a given; file or directory. For systems with rarely changing files, consider increasing this; value.; http://php.net/realpath-cache-ttl;realpath_cache_ttl &#x3D; 120 ;;;;;;;;;;;;;;;;;; Miscellaneous ;;;;;;;;;;;;;;;;;; ; Decides whether PHP may expose the fact that it is installed on the server; (e.g. by adding its signature to the Web server header). It is no security; threat in any way, but it makes it possible to determine whether you use PHP; on your server or not.; http://php.net/expose-phpexpose_php &#x3D; Off ;;;;;;;;;;;;;;;;;;;; Resource Limits ;;;;;;;;;;;;;;;;;;;; ; Maximum execution time of each script, in seconds; http://php.net/max-execution-time; Note: This directive is hardcoded to 0 for the CLI SAPImax_execution_time &#x3D; 30 ; Maximum amount of time each script may spend parsing request data. It’s a good; idea to limit this time on productions servers in order to eliminate unexpectedly; long running scripts.; Note: This directive is hardcoded to -1 for the CLI SAPI; Default Value: -1 (Unlimited); Development Value: 60 (60 seconds); Production Value: 60 (60 seconds); http://php.net/max-input-timemax_input_time &#x3D; 60 ; Maximum input variable nesting level; http://php.net/max-input-nesting-level;max_input_nesting_level &#x3D; 64 ; Maximum amount of memory a script may consume (128MB); http://php.net/memory-limitmemory_limit &#x3D; 128M ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; Error handling and logging ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; This directive informs PHP of which errors, warnings and notices you would like; it to take action for. The recommended way of setting values for this; directive is through the use of the error level constants and bitwise; operators. The error level constants are below here for convenience as well as; some common settings and their meanings.; By default, PHP is set to take action on all errors, notices and warnings EXCEPT; those related to E_NOTICE and E_STRICT, which together cover best practices and; recommended coding standards in PHP. For performance reasons, this is the; recommend error reporting setting. Your production server shouldn’t be wasting; resources complaining about best practices and coding standards. That’s what; development servers and development settings are for.; Note: The php.ini-development file has this setting as E_ALL | E_STRICT. This; means it pretty much reports everything which is exactly what you want during; development and early testing.;; Error Level Constants:; E_ALL - All errors and warnings (includes E_STRICT as of PHP 6.0.0); E_ERROR - fatal run-time errors; E_RECOVERABLE_ERROR - almost fatal run-time errors; E_WARNING - run-time warnings (non-fatal errors); E_PARSE - compile-time parse errors; E_NOTICE - run-time notices (these are warnings which often result; from a bug in your code, but it’s possible that it was; intentional (e.g., using an uninitialized variable and; relying on the fact it’s automatically initialized to an; empty string); E_STRICT - run-time notices, enable to have PHP suggest changes; to your code which will ensure the best interoperability; and forward compatibility of your code; E_CORE_ERROR - fatal errors that occur during PHP’s initial startup; E_CORE_WARNING - warnings (non-fatal errors) that occur during PHP’s; initial startup; E_COMPILE_ERROR - fatal compile-time errors; E_COMPILE_WARNING - compile-time warnings (non-fatal errors); E_USER_ERROR - user-generated error message; E_USER_WARNING - user-generated warning message; E_USER_NOTICE - user-generated notice message; E_DEPRECATED - warn about code that will not work in future versions; of PHP; E_USER_DEPRECATED - user-generated deprecation warnings;; Common Values:; E_ALL &amp; ~E_NOTICE (Show all errors, except for notices and coding standards warnings.); E_ALL &amp; ~E_NOTICE | E_STRICT (Show all errors, except for notices); E_COMPILE_ERROR|E_RECOVERABLE_ERROR|E_ERROR|E_CORE_ERROR (Show only errors); E_ALL | E_STRICT (Show all errors, warnings and notices including coding standards.); Default Value: E_ALL &amp; ~E_NOTICE; Development Value: E_ALL | E_STRICT; Production Value: E_ALL &amp; ~E_DEPRECATED; http://php.net/error-reportingerror_reporting &#x3D; E_ALL &amp; ~E_DEPRECATED ; This directive controls whether or not and where PHP will output errors,; notices and warnings too. Error output is very useful during development, but; it could be very dangerous in production environments. Depending on the code; which is triggering the error, sensitive information could potentially leak; out of your application such as database usernames and passwords or worse.; It’s recommended that errors be logged on production servers rather than; having the errors sent to STDOUT.; Possible Values:; Off &#x3D; Do not display any errors; stderr &#x3D; Display errors to STDERR (affects only CGI&#x2F;CLI binaries!); On or stdout &#x3D; Display errors to STDOUT; Default Value: On; Development Value: On; Production Value: Off; http://php.net/display-errorsdisplay_errors &#x3D; Off ; The display of errors which occur during PHP’s startup sequence are handled; separately from display_errors. PHP’s default behavior is to suppress those; errors from clients. Turning the display of startup errors on can be useful in; debugging configuration problems. But, it’s strongly recommended that you; leave this setting off on production servers.; Default Value: Off; Development Value: On; Production Value: Off; http://php.net/display-startup-errorsdisplay_startup_errors &#x3D; Off ; Besides displaying errors, PHP can also log errors to locations such as a; server-specific log, STDERR, or a location specified by the error_log; directive found below. While errors should not be displayed on productions; servers they should still be monitored and logging is a great way to do that.; Default Value: Off; Development Value: On; Production Value: On; http://php.net/log-errorslog_errors &#x3D; On ; Set maximum length of log_errors. In error_log information about the source is; added. The default is 1024 and 0 allows to not apply any maximum length at all.; http://php.net/log-errors-max-lenlog_errors_max_len &#x3D; 1024 ; Do not log repeated messages. Repeated errors must occur in same file on same; line unless ignore_repeated_source is set true.; http://php.net/ignore-repeated-errorsignore_repeated_errors &#x3D; Off ; Ignore source of message when ignoring repeated messages. When this setting; is On you will not log errors with repeated messages from different files or; source lines.; http://php.net/ignore-repeated-sourceignore_repeated_source &#x3D; Off ; If this parameter is set to Off, then memory leaks will not be shown (on; stdout or in the log). This has only effect in a debug compile, and if; error reporting includes E_WARNING in the allowed list; http://php.net/report-memleaksreport_memleaks &#x3D; On ; This setting is on by default.;report_zend_debug &#x3D; 0 ; Store the last error&#x2F;warning message in $php_errormsg (boolean). Setting this value; to On can assist in debugging and is appropriate for development servers. It should; however be disabled on production servers.; Default Value: Off; Development Value: On; Production Value: Off; http://php.net/track-errorstrack_errors &#x3D; Off ; Turn off normal error reporting and emit XML-RPC error XML; http://php.net/xmlrpc-errors;xmlrpc_errors &#x3D; 0 ; An XML-RPC faultCode;xmlrpc_error_number &#x3D; 0 ; When PHP displays or logs an error, it has the capability of inserting html; links to documentation related to that error. This directive controls whether; those HTML links appear in error messages or not. For performance and security; reasons, it’s recommended you disable this on production servers.; Note: This directive is hardcoded to Off for the CLI SAPI; Default Value: On; Development Value: On; Production value: Off; http://php.net/html-errorshtml_errors &#x3D; Off ; If html_errors is set On PHP produces clickable error messages that direct; to a page describing the error or function causing the error in detail.; You can download a copy of the PHP manual from http://php.net/docs; and change docref_root to the base URL of your local copy including the; leading ‘&#x2F;‘. You must also specify the file extension being used including; the dot. PHP’s default behavior is to leave these settings empty.; Note: Never use this feature for production boxes.; http://php.net/docref-root; Examples;docref_root &#x3D; “&#x2F;phpmanual&#x2F;“ ; http://php.net/docref-ext;docref_ext &#x3D; .html ; String to output before an error message. PHP’s default behavior is to leave; this setting blank.; http://php.net/error-prepend-string; Example:;error_prepend_string &#x3D; ““ ; String to output after an error message. PHP’s default behavior is to leave; this setting blank.; http://php.net/error-append-string; Example:;error_append_string &#x3D; ““ ; Log errors to specified file. PHP’s default behavior is to leave this value; empty.; http://php.net/error-log; Example:error_log &#x3D; &#x2F;data&#x2F;logs&#x2F;php&#x2F;php_errors.log; Log errors to syslog (Event Log on NT, not valid in Windows 95).;error_log &#x3D; syslog ;;;;;;;;;;;;;;;;;; Data Handling ;;;;;;;;;;;;;;;;;; ; The separator used in PHP generated URLs to separate arguments.; PHP’s default setting is “&amp;”.; http://php.net/arg-separator.output; Example:;arg_separator.output &#x3D; “&amp;” ; List of separator(s) used by PHP to parse input URLs into variables.; PHP’s default setting is “&amp;”.; NOTE: Every character in this directive is considered as separator!; http://php.net/arg-separator.input; Example:;arg_separator.input &#x3D; “;&amp;” ; This directive determines which super global arrays are registered when PHP; starts up. If the register_globals directive is enabled, it also determines; what order variables are populated into the global space. G,P,C,E &amp; S are; abbreviations for the following respective super globals: GET, POST, COOKIE,; ENV and SERVER. There is a performance penalty paid for the registration of; these arrays and because ENV is not as commonly used as the others, ENV is; is not recommended on productions servers. You can still get access to; the environment variables through getenv() should you need to.; Default Value: “EGPCS”; Development Value: “GPCS”; Production Value: “GPCS”;; http://php.net/variables-ordervariables_order &#x3D; “GPCS” ; This directive determines which super global data (G,P,C,E &amp; S) should; be registered into the super global array REQUEST. If so, it also determines; the order in which that data is registered. The values for this directive are; specified in the same manner as the variables_order directive, EXCEPT one.; Leaving this value empty will cause PHP to use the value set in the; variables_order directive. It does not mean it will leave the super globals; array REQUEST empty.; Default Value: None; Development Value: “GP”; Production Value: “GP”; http://php.net/request-orderrequest_order &#x3D; “GP” ; Whether or not to register the EGPCS variables as global variables. You may; want to turn this off if you don’t want to clutter your scripts’ global scope; with user data.; You should do your best to write your scripts so that they do not require; register_globals to be on; Using form variables as globals can easily lead; to possible security problems, if the code is not very well thought of.; http://php.net/register-globalsregister_globals &#x3D; Off ; Determines whether the deprecated long $HTTP_*_VARS type predefined variables; are registered by PHP or not. As they are deprecated, we obviously don’t; recommend you use them. They are on by default for compatibility reasons but; they are not recommended on production servers.; Default Value: On; Development Value: Off; Production Value: Off; http://php.net/register-long-arraysregister_long_arrays &#x3D; Off ; This directive determines whether PHP registers $argv &amp; $argc each time it; runs. $argv contains an array of all the arguments passed to PHP when a script; is invoked. $argc contains an integer representing the number of arguments; that were passed when the script was invoked. These arrays are extremely; useful when running scripts from the command line. When this directive is; enabled, registering these variables consumes CPU cycles and memory each time; a script is executed. For performance reasons, this feature should be disabled; on production servers.; Note: This directive is hardcoded to On for the CLI SAPI; Default Value: On; Development Value: Off; Production Value: Off; http://php.net/register-argc-argvregister_argc_argv &#x3D; Off ; When enabled, the SERVER and ENV variables are created when they’re first; used (Just In Time) instead of when the script starts. If these variables; are not used within a script, having this directive on will result in a; performance gain. The PHP directives register_globals, register_long_arrays,; and register_argc_argv must be disabled for this directive to have any affect.; http://php.net/auto-globals-jitauto_globals_jit &#x3D; On ; Maximum size of POST data that PHP will accept.; http://php.net/post-max-sizepost_max_size &#x3D; 8M ; Magic quotes are a preprocessing feature of PHP where PHP will attempt to; escape any character sequences in GET, POST, COOKIE and ENV data which might; otherwise corrupt data being placed in resources such as databases before; making that data available to you. Because of character encoding issues and; non-standard SQL implementations across many databases, it’s not currently; possible for this feature to be 100% accurate. PHP’s default behavior is to; enable the feature. We strongly recommend you use the escaping mechanisms; designed specifically for the database your using instead of relying on this; feature. Also note, this feature has been deprecated as of PHP 5.3.0 and is; scheduled for removal in PHP 6.; Default Value: On; Development Value: Off; Production Value: Off; http://php.net/magic-quotes-gpcmagic_quotes_gpc &#x3D; Off ; Magic quotes for runtime-generated data, e.g. data from SQL, from exec(), etc.; http://php.net/magic-quotes-runtimemagic_quotes_runtime &#x3D; Off ; Use Sybase-style magic quotes (escape ‘ with ‘’ instead of &#39;).; http://php.net/magic-quotes-sybasemagic_quotes_sybase &#x3D; Off ; Automatically add files before PHP document.; http://php.net/auto-prepend-fileauto_prepend_file &#x3D; ; Automatically add files after PHP document.; http://php.net/auto-append-fileauto_append_file &#x3D; ; By default, PHP will output a character encoding using; the Content-type: header. To disable sending of the charset, simply; set it to be empty.;; PHP’s built-in default is text&#x2F;html; http://php.net/default-mimetypedefault_mimetype &#x3D; “text&#x2F;html” ; PHP’s default character set is set to empty.; http://php.net/default-charset;default_charset &#x3D; “iso-8859-1” ; Always populate the $HTTP_RAW_POST_DATA variable. PHP’s default behavior is; to disable this feature.; http://php.net/always-populate-raw-post-data;always_populate_raw_post_data &#x3D; On ;;;;;;;;;;;;;;;;;;;;;;;;;; Paths and Directories ;;;;;;;;;;;;;;;;;;;;;;;;;; ; UNIX: “&#x2F;path1:&#x2F;path2”;include_path &#x3D; “.:&#x2F;php&#x2F;includes”;; Windows: “\\path1;\\path2”;include_path &#x3D; “.;c:\\php\\includes”;; PHP’s default setting for include_path is “.;&#x2F;path&#x2F;to&#x2F;php&#x2F;pear”; http://php.net/include-path ; The root of the PHP pages, used only if nonempty.; if PHP was not compiled with FORCE_REDIRECT, you SHOULD set doc_root; if you are running php as a CGI under any web server (other than IIS); see documentation for security issues. The alternate is to use the; cgi.force_redirect configuration below; http://php.net/doc-rootdoc_root &#x3D; ; The directory under which PHP opens the script using &#x2F;~username used only; if nonempty.; http://php.net/user-diruser_dir &#x3D; ; Directory in which the loadable extensions (modules) reside.; http://php.net/extension-dir;extension_dir &#x3D; “&#x2F;usr&#x2F;local&#x2F;php&#x2F;ext”;extension&#x3D;memcache.so; On windows:; extension_dir &#x3D; “ext” ; Whether or not to enable the dl() function. The dl() function does NOT work; properly in multithreaded servers, such as IIS or Zeus, and is automatically; disabled on them.; http://php.net/enable-dlenable_dl &#x3D; Off ; cgi.force_redirect is necessary to provide security running PHP as a CGI under; most web servers. Left undefined, PHP turns this on by default. You can; turn it off here AT YOUR OWN RISK; You CAN safely turn this off for IIS, in fact, you MUST.; http://php.net/cgi.force-redirect;cgi.force_redirect &#x3D; 1 ; if cgi.nph is enabled it will force cgi to always sent Status: 200 with; every request. PHP’s default behavior is to disable this feature.;cgi.nph &#x3D; 1 ; if cgi.force_redirect is turned on, and you are not running under Apache or Netscape; (iPlanet) web servers, you MAY need to set an environment variable name that PHP; will look for to know it is OK to continue execution. Setting this variable MAY; cause security issues, KNOW WHAT YOU ARE DOING FIRST.; http://php.net/cgi.redirect-status-env;cgi.redirect_status_env &#x3D; ; ; cgi.fix_pathinfo provides real PATH_INFO&#x2F;PATH_TRANSLATED support for CGI. PHP’s; previous behaviour was to set PATH_TRANSLATED to SCRIPT_FILENAME, and to not grok; what PATH_INFO is. For more information on PATH_INFO, see the cgi specs. Setting; this to 1 will cause PHP CGI to fix its paths to conform to the spec. A setting; of zero causes PHP to behave as before. Default is 1. You should fix your scripts; to use SCRIPT_FILENAME rather than PATH_TRANSLATED.; http://php.net/cgi.fix-pathinfocgi.fix_pathinfo&#x3D;0 ; FastCGI under IIS (on WINNT based OS) supports the ability to impersonate; security tokens of the calling client. This allows IIS to define the; security context that the request runs under. mod_fastcgi under Apache; does not currently support this feature (03&#x2F;17&#x2F;2002); Set to 1 if running under IIS. Default is zero.; http://php.net/fastcgi.impersonate;fastcgi.impersonate &#x3D; 1; ; Disable logging through FastCGI connection. PHP’s default behavior is to enable; this feature.;fastcgi.logging &#x3D; 0 ; cgi.rfc2616_headers configuration option tells PHP what type of headers to; use when sending HTTP response code. If it’s set 0 PHP sends Status: header that; is supported by Apache. When this option is set to 1 PHP will send; RFC2616 compliant header.; Default is zero.; http://php.net/cgi.rfc2616-headers;cgi.rfc2616_headers &#x3D; 0 ;;;;;;;;;;;;;;;;; File Uploads ;;;;;;;;;;;;;;;;; ; Whether to allow HTTP file uploads.; http://php.net/file-uploadsfile_uploads &#x3D; On ; Temporary directory for HTTP uploaded files (will use system default if not; specified).; http://php.net/upload-tmp-dir;upload_tmp_dir &#x3D; ; Maximum allowed size for uploaded files.; http://php.net/upload-max-filesizeupload_max_filesize &#x3D; 2M ; Maximum number of files that can be uploaded via a single requestmax_file_uploads &#x3D; 20 ;;;;;;;;;;;;;;;;;;; Fopen wrappers ;;;;;;;;;;;;;;;;;;; ; Whether to allow the treatment of URLs (like http:&#x2F;&#x2F; or ftp:&#x2F;&#x2F;) as files.; http://php.net/allow-url-fopenallow_url_fopen &#x3D; On ; Whether to allow include&#x2F;require to open URLs (like http:&#x2F;&#x2F; or ftp:&#x2F;&#x2F;) as files.; http://php.net/allow-url-includeallow_url_include &#x3D; Off ; Define the anonymous ftp password (your email address). PHP’s default setting; for this is empty.; http://php.net/from;from&#x3D;”&#x6a;&#111;&#x68;&#x6e;&#64;&#x64;&#x6f;&#x65;&#x2e;&#99;&#x6f;&#x6d;“ ; Define the User-Agent string. PHP’s default setting for this is empty.; http://php.net/user-agent;user_agent&#x3D;”PHP” ; Default timeout for socket based streams (seconds); http://php.net/default-socket-timeoutdefault_socket_timeout &#x3D; 60 ; If your scripts have to deal with files from Macintosh systems,; or you are running on a Mac and need to deal with files from; unix or win32 systems, setting this flag will cause PHP to; automatically detect the EOL character in those files so that; fgets() and file() will work regardless of the source of the file.; http://php.net/auto-detect-line-endings;auto_detect_line_endings &#x3D; Off ;;;;;;;;;;;;;;;;;;;;;;; Dynamic Extensions ;;;;;;;;;;;;;;;;;;;;;;; ; If you wish to have an extension loaded automatically, use the following; syntax:;; extension&#x3D;modulename.extension;; For example, on Windows:;; extension&#x3D;msql.dll;; … or under UNIX:;; extension&#x3D;msql.so;; … or with a path:;; extension&#x3D;&#x2F;path&#x2F;to&#x2F;extension&#x2F;msql.so;; If you only provide the name of the extension, PHP will look for it in its; default extension directory.;; Windows Extensions; Note that ODBC support is built in, so no dll is needed for it.; Note that many DLL files are located in the extensions&#x2F; (PHP 4) ext&#x2F; (PHP 5); extension folders as well as the separate PECL DLL download (PHP 5).; Be sure to appropriately set the extension_dir directive.;;extension&#x3D;php_bz2.dll;extension&#x3D;php_curl.dll;extension&#x3D;php_fileinfo.dll;extension&#x3D;php_gd2.dll;extension&#x3D;php_gettext.dll;extension&#x3D;php_gmp.dll;extension&#x3D;php_intl.dll;extension&#x3D;php_imap.dll;extension&#x3D;php_interbase.dll;extension&#x3D;php_ldap.dll;extension&#x3D;php_mbstring.dll;extension&#x3D;php_exif.dll ; Must be after mbstring as it depends on it;extension&#x3D;php_mysql.dll;extension&#x3D;php_mysqli.dll;extension&#x3D;php_oci8.dll ; Use with Oracle 10gR2 Instant Client;extension&#x3D;php_oci8_11g.dll ; Use with Oracle 11g Instant Client;extension&#x3D;php_openssl.dll;extension&#x3D;php_pdo_firebird.dll;extension&#x3D;php_pdo_mssql.dll;extension&#x3D;php_pdo_mysql.dll;extension&#x3D;php_pdo_oci.dll;extension&#x3D;php_pdo_odbc.dll;extension&#x3D;php_pdo_pgsql.dll;extension&#x3D;php_pdo_sqlite.dll;extension&#x3D;php_pgsql.dll;extension&#x3D;php_pspell.dll;extension&#x3D;php_shmop.dll ; The MIBS data available in the PHP distribution must be installed.; See http://www.php.net/manual/en/snmp.installation.php;extension&#x3D;php_snmp.dll ;extension&#x3D;php_soap.dll;extension&#x3D;php_sockets.dll;extension&#x3D;php_sqlite.dll;extension&#x3D;php_sqlite3.dll;extension&#x3D;php_sybase_ct.dll;extension&#x3D;php_tidy.dll;extension&#x3D;php_xmlrpc.dll;extension&#x3D;php_xsl.dll;extension&#x3D;php_zip.dll ;;;;;;;;;;;;;;;;;;;; Module Settings ;;;;;;;;;;;;;;;;;;;; [Date]; Defines the default timezone used by the date functions; http://php.net/date.timezonedate.timezone &#x3D; Asia&#x2F;ShangHai ; http://php.net/date.default-latitude;date.default_latitude &#x3D; 31.7667 ; http://php.net/date.default-longitude;date.default_longitude &#x3D; 35.2333 ; http://php.net/date.sunrise-zenith;date.sunrise_zenith &#x3D; 90.583333 ; http://php.net/date.sunset-zenith;date.sunset_zenith &#x3D; 90.583333 [filter]; http://php.net/filter.default;filter.default &#x3D; unsafe_raw ; http://php.net/filter.default-flags;filter.default_flags &#x3D; [iconv];iconv.input_encoding &#x3D; ISO-8859-1;iconv.internal_encoding &#x3D; ISO-8859-1;iconv.output_encoding &#x3D; ISO-8859-1 [intl];intl.default_locale &#x3D;; This directive allows you to produce PHP errors when some error; happens within intl functions. The value is the level of the error produced.; Default is 0, which does not produce any errors.;intl.error_level &#x3D; E_WARNING [sqlite]; http://php.net/sqlite.assoc-case;sqlite.assoc_case &#x3D; 0 [sqlite3];sqlite3.extension_dir &#x3D; [Pcre];PCRE library backtracking limit.; http://php.net/pcre.backtrack-limit;pcre.backtrack_limit&#x3D;100000 ;PCRE library recursion limit.;Please note that if you set this value to a high number you may consume all;the available process stack and eventually crash PHP (due to reaching the;stack size limit imposed by the Operating System).; http://php.net/pcre.recursion-limit;pcre.recursion_limit&#x3D;100000 [Pdo]; Whether to pool ODBC connections. Can be one of “strict”, “relaxed” or “off”; http://php.net/pdo-odbc.connection-pooling;pdo_odbc.connection_pooling&#x3D;strict ;pdo_odbc.db2_instance_name [Pdo_mysql]; If mysqlnd is used: Number of cache slots for the internal result set cache; http://php.net/pdo_mysql.cache_sizepdo_mysql.cache_size &#x3D; 2000 ; Default socket name for local MySQL connects. If empty, uses the built-in; MySQL defaults.; http://php.net/pdo_mysql.default-socketpdo_mysql.default_socket&#x3D; [Phar]; http://php.net/phar.readonly;phar.readonly &#x3D; On ; http://php.net/phar.require-hash;phar.require_hash &#x3D; On ;phar.cache_list &#x3D; [Syslog]; Whether or not to define the various syslog variables (e.g. $LOG_PID,; $LOG_CRON, etc.). Turning it off is a good idea performance-wise. In; runtime, you can define these variables by calling define_syslog_variables().; http://php.net/define-syslog-variablesdefine_syslog_variables &#x3D; Off [mail function]; For Win32 only.; http://php.net/smtpSMTP &#x3D; localhost; http://php.net/smtp-portsmtp_port &#x3D; 25 ; For Win32 only.; http://php.net/sendmail-from;sendmail_from &#x3D; &#x6d;&#101;&#64;&#x65;&#120;&#x61;&#x6d;&#112;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109; ; For Unix only. You may supply arguments as well (default: “sendmail -t -i”).; http://php.net/sendmail-path;sendmail_path &#x3D; ; Force the addition of the specified parameters to be passed as extra parameters; to the sendmail binary. These parameters will always replace the value of; the 5th parameter to mail(), even in safe mode.;mail.force_extra_parameters &#x3D; ; Add X-PHP-Originating-Script: that will include uid of the script followed by the filenamemail.add_x_header &#x3D; On ; The path to a log file that will log all mail() calls. Log entries include; the full path of the script, line number, To address and headers.;mail.log &#x3D; [SQL]; http://php.net/sql.safe-modesql.safe_mode &#x3D; Off [ODBC]; http://php.net/odbc.default-db;odbc.default_db &#x3D; Not yet implemented ; http://php.net/odbc.default-user;odbc.default_user &#x3D; Not yet implemented ; http://php.net/odbc.default-pw;odbc.default_pw &#x3D; Not yet implemented ; Controls the ODBC cursor model.; Default: SQL_CURSOR_STATIC (default).;odbc.default_cursortype ; Allow or prevent persistent links.; http://php.net/odbc.allow-persistentodbc.allow_persistent &#x3D; On ; Check that a connection is still valid before reuse.; http://php.net/odbc.check-persistentodbc.check_persistent &#x3D; On ; Maximum number of persistent links. -1 means no limit.; http://php.net/odbc.max-persistentodbc.max_persistent &#x3D; -1 ; Maximum number of links (persistent + non-persistent). -1 means no limit.; http://php.net/odbc.max-linksodbc.max_links &#x3D; -1 ; Handling of LONG fields. Returns number of bytes to variables. 0 means; passthru.; http://php.net/odbc.defaultlrlodbc.defaultlrl &#x3D; 4096 ; Handling of binary data. 0 means passthru, 1 return as is, 2 convert to char.; See the documentation on odbc_binmode and odbc_longreadlen for an explanation; of odbc.defaultlrl and odbc.defaultbinmode; http://php.net/odbc.defaultbinmodeodbc.defaultbinmode &#x3D; 1 ;birdstep.max_links &#x3D; -1 [Interbase]; Allow or prevent persistent links.ibase.allow_persistent &#x3D; 1 ; Maximum number of persistent links. -1 means no limit.ibase.max_persistent &#x3D; -1 ; Maximum number of links (persistent + non-persistent). -1 means no limit.ibase.max_links &#x3D; -1 ; Default database name for ibase_connect().;ibase.default_db &#x3D; ; Default username for ibase_connect().;ibase.default_user &#x3D; ; Default password for ibase_connect().;ibase.default_password &#x3D; ; Default charset for ibase_connect().;ibase.default_charset &#x3D; ; Default timestamp format.ibase.timestampformat &#x3D; “%Y-%m-%d %H:%M:%S” ; Default date format.ibase.dateformat &#x3D; “%Y-%m-%d” ; Default time format.ibase.timeformat &#x3D; “%H:%M:%S” [MySQL]; Allow accessing, from PHP’s perspective, local files with LOAD DATA statements; http://php.net/mysql.allow_local_infilemysql.allow_local_infile &#x3D; On ; Allow or prevent persistent links.; http://php.net/mysql.allow-persistentmysql.allow_persistent &#x3D; On ; If mysqlnd is used: Number of cache slots for the internal result set cache; http://php.net/mysql.cache_sizemysql.cache_size &#x3D; 2000 ; Maximum number of persistent links. -1 means no limit.; http://php.net/mysql.max-persistentmysql.max_persistent &#x3D; -1 ; Maximum number of links (persistent + non-persistent). -1 means no limit.; http://php.net/mysql.max-linksmysql.max_links &#x3D; -1 ; Default port number for mysql_connect(). If unset, mysql_connect() will use; the $MYSQL_TCP_PORT or the mysql-tcp entry in &#x2F;etc&#x2F;services or the; compile-time value defined MYSQL_PORT (in that order). Win32 will only look; at MYSQL_PORT.; http://php.net/mysql.default-portmysql.default_port &#x3D; ; Default socket name for local MySQL connects. If empty, uses the built-in; MySQL defaults.; http://php.net/mysql.default-socketmysql.default_socket &#x3D; ; Default host for mysql_connect() (doesn’t apply in safe mode).; http://php.net/mysql.default-hostmysql.default_host &#x3D; ; Default user for mysql_connect() (doesn’t apply in safe mode).; http://php.net/mysql.default-usermysql.default_user &#x3D; ; Default password for mysql_connect() (doesn’t apply in safe mode).; Note that this is generally a bad idea to store passwords in this file.; Any user with PHP access can run ‘echo get_cfg_var(“mysql.default_password”); and reveal this password! And of course, any users with read access to this; file will be able to reveal the password as well.; http://php.net/mysql.default-passwordmysql.default_password &#x3D; ; Maximum time (in seconds) for connect timeout. -1 means no limit; http://php.net/mysql.connect-timeoutmysql.connect_timeout &#x3D; 60 ; Trace mode. When trace_mode is active (&#x3D;On), warnings for table&#x2F;index scans and; SQL-Errors will be displayed.; http://php.net/mysql.trace-modemysql.trace_mode &#x3D; Off [MySQLi] ; Maximum number of persistent links. -1 means no limit.; http://php.net/mysqli.max-persistentmysqli.max_persistent &#x3D; -1 ; Allow accessing, from PHP’s perspective, local files with LOAD DATA statements; http://php.net/mysqli.allow_local_infile;mysqli.allow_local_infile &#x3D; On ; Allow or prevent persistent links.; http://php.net/mysqli.allow-persistentmysqli.allow_persistent &#x3D; On ; Maximum number of links. -1 means no limit.; http://php.net/mysqli.max-linksmysqli.max_links &#x3D; -1 ; If mysqlnd is used: Number of cache slots for the internal result set cache; http://php.net/mysqli.cache_sizemysqli.cache_size &#x3D; 2000 ; Default port number for mysqli_connect(). If unset, mysqli_connect() will use; the $MYSQL_TCP_PORT or the mysql-tcp entry in &#x2F;etc&#x2F;services or the; compile-time value defined MYSQL_PORT (in that order). Win32 will only look; at MYSQL_PORT.; http://php.net/mysqli.default-portmysqli.default_port &#x3D; 3306 ; Default socket name for local MySQL connects. If empty, uses the built-in; MySQL defaults.; http://php.net/mysqli.default-socketmysqli.default_socket &#x3D; ; Default host for mysql_connect() (doesn’t apply in safe mode).; http://php.net/mysqli.default-hostmysqli.default_host &#x3D; ; Default user for mysql_connect() (doesn’t apply in safe mode).; http://php.net/mysqli.default-usermysqli.default_user &#x3D; ; Default password for mysqli_connect() (doesn’t apply in safe mode).; Note that this is generally a bad idea to store passwords in this file.; Any user with PHP access can run ‘echo get_cfg_var(“mysqli.default_pw”); and reveal this password! And of course, any users with read access to this; file will be able to reveal the password as well.; http://php.net/mysqli.default-pwmysqli.default_pw &#x3D; ; Allow or prevent reconnectmysqli.reconnect &#x3D; Off [mysqlnd]; Enable &#x2F; Disable collection of general statstics by mysqlnd which can be; used to tune and monitor MySQL operations.; http://php.net/mysqlnd.collect_statisticsmysqlnd.collect_statistics &#x3D; On ; Enable &#x2F; Disable collection of memory usage statstics by mysqlnd which can be; used to tune and monitor MySQL operations.; http://php.net/mysqlnd.collect_memory_statisticsmysqlnd.collect_memory_statistics &#x3D; Off ; Size of a pre-allocated buffer used when sending commands to MySQL in bytes.; http://php.net/mysqlnd.net_cmd_buffer_size;mysqlnd.net_cmd_buffer_size &#x3D; 2048 ; Size of a pre-allocated buffer used for reading data sent by the server in; bytes.; http://php.net/mysqlnd.net_read_buffer_size;mysqlnd.net_read_buffer_size &#x3D; 32768 [OCI8] ; Connection: Enables privileged connections using external; credentials (OCI_SYSOPER, OCI_SYSDBA); http://php.net/oci8.privileged-connect;oci8.privileged_connect &#x3D; Off ; Connection: The maximum number of persistent OCI8 connections per; process. Using -1 means no limit.; http://php.net/oci8.max-persistent;oci8.max_persistent &#x3D; -1 ; Connection: The maximum number of seconds a process is allowed to; maintain an idle persistent connection. Using -1 means idle; persistent connections will be maintained forever.; http://php.net/oci8.persistent-timeout;oci8.persistent_timeout &#x3D; -1 ; Connection: The number of seconds that must pass before issuing a; ping during oci_pconnect() to check the connection validity. When; set to 0, each oci_pconnect() will cause a ping. Using -1 disables; pings completely.; http://php.net/oci8.ping-interval;oci8.ping_interval &#x3D; 60 ; Connection: Set this to a user chosen connection class to be used; for all pooled server requests with Oracle 11g Database Resident; Connection Pooling (DRCP). To use DRCP, this value should be set to; the same string for all web servers running the same application,; the database pool must be configured, and the connection string must; specify to use a pooled server.;oci8.connection_class &#x3D; ; High Availability: Using On lets PHP receive Fast Application; Notification (FAN) events generated when a database node fails. The; database must also be configured to post FAN events.;oci8.events &#x3D; Off ; Tuning: This option enables statement caching, and specifies how; many statements to cache. Using 0 disables statement caching.; http://php.net/oci8.statement-cache-size;oci8.statement_cache_size &#x3D; 20 ; Tuning: Enables statement prefetching and sets the default number of; rows that will be fetched automatically after statement execution.; http://php.net/oci8.default-prefetch;oci8.default_prefetch &#x3D; 100 ; Compatibility. Using On means oci_close() will not close; oci_connect() and oci_new_connect() connections.; http://php.net/oci8.old-oci-close-semantics;oci8.old_oci_close_semantics &#x3D; Off [PostgresSQL]; Allow or prevent persistent links.; http://php.net/pgsql.allow-persistentpgsql.allow_persistent &#x3D; On ; Detect broken persistent links always with pg_pconnect().; Auto reset feature requires a little overheads.; http://php.net/pgsql.auto-reset-persistentpgsql.auto_reset_persistent &#x3D; Off ; Maximum number of persistent links. -1 means no limit.; http://php.net/pgsql.max-persistentpgsql.max_persistent &#x3D; -1 ; Maximum number of links (persistent+non persistent). -1 means no limit.; http://php.net/pgsql.max-linkspgsql.max_links &#x3D; -1 ; Ignore PostgreSQL backends Notice message or not.; Notice message logging require a little overheads.; http://php.net/pgsql.ignore-noticepgsql.ignore_notice &#x3D; 0 ; Log PostgreSQL backends Notice message or not.; Unless pgsql.ignore_notice&#x3D;0, module cannot log notice message.; http://php.net/pgsql.log-noticepgsql.log_notice &#x3D; 0 [Sybase-CT]; Allow or prevent persistent links.; http://php.net/sybct.allow-persistentsybct.allow_persistent &#x3D; On ; Maximum number of persistent links. -1 means no limit.; http://php.net/sybct.max-persistentsybct.max_persistent &#x3D; -1 ; Maximum number of links (persistent + non-persistent). -1 means no limit.; http://php.net/sybct.max-linkssybct.max_links &#x3D; -1 ; Minimum server message severity to display.; http://php.net/sybct.min-server-severitysybct.min_server_severity &#x3D; 10 ; Minimum client message severity to display.; http://php.net/sybct.min-client-severitysybct.min_client_severity &#x3D; 10 ; Set per-context timeout; http://php.net/sybct.timeout;sybct.timeout&#x3D; ;sybct.packet_size ; The maximum time in seconds to wait for a connection attempt to succeed before returning failure.; Default: one minute;sybct.login_timeout&#x3D; ; The name of the host you claim to be connecting from, for display by sp_who.; Default: none;sybct.hostname&#x3D; ; Allows you to define how often deadlocks are to be retried. -1 means “forever”.; Default: 0;sybct.deadlock_retry_count&#x3D; [bcmath]; Number of decimal digits for all bcmath functions.; http://php.net/bcmath.scalebcmath.scale &#x3D; 0 [browscap]; http://php.net/browscap;browscap &#x3D; extra&#x2F;browscap.ini [Session]; Handler used to store&#x2F;retrieve data.; http://php.net/session.save-handlersession.save_handler &#x3D; files ; Argument passed to save_handler. In the case of files, this is the path; where data files are stored. Note: Windows users have to change this; variable in order to use PHP’s session functions.;; The path can be defined as:;; session.save_path &#x3D; “N;&#x2F;path”;; where N is an integer. Instead of storing all the session files in; &#x2F;path, what this will do is use subdirectories N-levels deep, and; store the session data in those directories. This is useful if you; or your OS have problems with lots of files in one directory, and is; a more efficient layout for servers that handle lots of sessions.;; NOTE 1: PHP will not create this directory structure automatically.; You can use the script in the ext&#x2F;session dir for that purpose.; NOTE 2: See the section on garbage collection below if you choose to; use subdirectories for session storage;; The file storage module creates files using mode 600 by default.; You can change that by using;; session.save_path &#x3D; “N;MODE;&#x2F;path”;; where MODE is the octal representation of the mode. Note that this; does not overwrite the process’s umask.; http://php.net/session.save-path;session.save_path &#x3D; “&#x2F;tmp” ; Whether to use cookies.; http://php.net/session.use-cookiessession.use_cookies &#x3D; 1 ; http://php.net/session.cookie-secure;session.cookie_secure &#x3D; ; This option forces PHP to fetch and use a cookie for storing and maintaining; the session id. We encourage this operation as it’s very helpful in combatting; session hijacking when not specifying and managing your own session id. It is; not the end all be all of session hijacking defense, but it’s a good start.; http://php.net/session.use-only-cookiessession.use_only_cookies &#x3D; 1 ; Name of the session (used as cookie name).; http://php.net/session.namesession.name &#x3D; PHPSESSID ; Initialize session on request startup.; http://php.net/session.auto-startsession.auto_start &#x3D; 0 ; Lifetime in seconds of cookie or, if 0, until browser is restarted.; http://php.net/session.cookie-lifetimesession.cookie_lifetime &#x3D; 0 ; The path for which the cookie is valid.; http://php.net/session.cookie-pathsession.cookie_path &#x3D; &#x2F; ; The domain for which the cookie is valid.; http://php.net/session.cookie-domainsession.cookie_domain &#x3D; ; Whether or not to add the httpOnly flag to the cookie, which makes it inaccessible to browser scripting languages such as JavaScript.; http://php.net/session.cookie-httponlysession.cookie_httponly &#x3D; ; Handler used to serialize data. php is the standard serializer of PHP.; http://php.net/session.serialize-handlersession.serialize_handler &#x3D; php ; Defines the probability that the ‘garbage collection’ process is started; on every session initialization. The probability is calculated by using; gc_probability&#x2F;gc_divisor. Where session.gc_probability is the numerator; and gc_divisor is the denominator in the equation. Setting this value to 1; when the session.gc_divisor value is 100 will give you approximately a 1% chance; the gc will run on any give request.; Default Value: 1; Development Value: 1; Production Value: 1; http://php.net/session.gc-probabilitysession.gc_probability &#x3D; 1 ; Defines the probability that the ‘garbage collection’ process is started on every; session initialization. The probability is calculated by using the following equation:; gc_probability&#x2F;gc_divisor. Where session.gc_probability is the numerator and; session.gc_divisor is the denominator in the equation. Setting this value to 1; when the session.gc_divisor value is 100 will give you approximately a 1% chance; the gc will run on any give request. Increasing this value to 1000 will give you; a 0.1% chance the gc will run on any give request. For high volume production servers,; this is a more efficient approach.; Default Value: 100; Development Value: 1000; Production Value: 1000; http://php.net/session.gc-divisorsession.gc_divisor &#x3D; 1000 ; After this number of seconds, stored data will be seen as ‘garbage’ and; cleaned up by the garbage collection process.; http://php.net/session.gc-maxlifetimesession.gc_maxlifetime &#x3D; 1440 ; NOTE: If you are using the subdirectory option for storing session files; (see session.save_path above), then garbage collection does not; happen automatically. You will need to do your own garbage; collection through a shell script, cron entry, or some other method.; For example, the following script would is the equivalent of; setting session.gc_maxlifetime to 1440 (1440 seconds &#x3D; 24 minutes):; find &#x2F;path&#x2F;to&#x2F;sessions -cmin +24 | xargs rm ; PHP 4.2 and less have an undocumented feature&#x2F;bug that allows you to; to initialize a session variable in the global scope, even when register_globals; is disabled. PHP 4.3 and later will warn you, if this feature is used.; You can disable the feature and the warning separately. At this time,; the warning is only displayed, if bug_compat_42 is enabled. This feature; introduces some serious security problems if not handled correctly. It’s; recommended that you do not use this feature on production servers. But you; should enable this on development servers and enable the warning as well. If you; do not enable the feature on development servers, you won’t be warned when it’s; used and debugging errors caused by this can be difficult to track down.; Default Value: On; Development Value: On; Production Value: Off; http://php.net/session.bug-compat-42session.bug_compat_42 &#x3D; Off ; This setting controls whether or not you are warned by PHP when initializing a; session value into the global space. session.bug_compat_42 must be enabled before; these warnings can be issued by PHP. See the directive above for more information.; Default Value: On; Development Value: On; Production Value: Off; http://php.net/session.bug-compat-warnsession.bug_compat_warn &#x3D; Off ; Check HTTP Referer to invalidate externally stored URLs containing ids.; HTTP_REFERER has to contain this substring for the session to be; considered as valid.; http://php.net/session.referer-checksession.referer_check &#x3D; ; How many bytes to read from the file.; http://php.net/session.entropy-lengthsession.entropy_length &#x3D; 0 ; Specified here to create the session id.; http://php.net/session.entropy-file; On systems that don’t have &#x2F;dev&#x2F;urandom &#x2F;dev&#x2F;arandom can be used; On windows, setting the entropy_length setting will activate the; Windows random source (using the CryptoAPI);session.entropy_file &#x3D; &#x2F;dev&#x2F;urandom ; Set to {nocache,private,public,} to determine HTTP caching aspects; or leave this empty to avoid sending anti-caching headers.; http://php.net/session.cache-limitersession.cache_limiter &#x3D; nocache ; Document expires after n minutes.; http://php.net/session.cache-expiresession.cache_expire &#x3D; 180 ; trans sid support is disabled by default.; Use of trans sid may risk your users security.; Use this option with caution.; - User may send URL contains active session ID; to other person via. email&#x2F;irc&#x2F;etc.; - URL that contains active session ID may be stored; in publically accessible computer.; - User may access your site with the same session ID; always using URL stored in browser’s history or bookmarks.; http://php.net/session.use-trans-sidsession.use_trans_sid &#x3D; 0 ; Select a hash function for use in generating session ids.; Possible Values; 0 (MD5 128 bits); 1 (SHA-1 160 bits); This option may also be set to the name of any hash function supported by; the hash extension. A list of available hashes is returned by the hash_algos(); function.; http://php.net/session.hash-functionsession.hash_function &#x3D; 0 ; Define how many bits are stored in each character when converting; the binary hash data to something readable.; Possible values:; 4 (4 bits: 0-9, a-f); 5 (5 bits: 0-9, a-v); 6 (6 bits: 0-9, a-z, A-Z, “-“, “,”); Default Value: 4; Development Value: 5; Production Value: 5; http://php.net/session.hash-bits-per-charactersession.hash_bits_per_character &#x3D; 5 ; The URL rewriter will look for URLs in a defined set of HTML tags.; form&#x2F;fieldset are special; if you include them here, the rewriter will; add a hidden field with the info which is otherwise appended; to URLs. If you want XHTML conformity, remove the form entry.; Note that all valid entries require a “&#x3D;”, even if no value follows.; Default Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,form&#x3D;,fieldset&#x3D;”; Development Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,input&#x3D;src,form&#x3D;fakeentry”; Production Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,input&#x3D;src,form&#x3D;fakeentry”; http://php.net/url-rewriter.tagsurl_rewriter.tags &#x3D; “a&#x3D;href,area&#x3D;href,frame&#x3D;src,input&#x3D;src,form&#x3D;fakeentry” [MSSQL]; Allow or prevent persistent links.mssql.allow_persistent &#x3D; On ; Maximum number of persistent links. -1 means no limit.mssql.max_persistent &#x3D; -1 ; Maximum number of links (persistent+non persistent). -1 means no limit.mssql.max_links &#x3D; -1 ; Minimum error severity to display.mssql.min_error_severity &#x3D; 10 ; Minimum message severity to display.mssql.min_message_severity &#x3D; 10 ; Compatibility mode with old versions of PHP 3.0.mssql.compatability_mode &#x3D; Off ; Connect timeout;mssql.connect_timeout &#x3D; 5 ; Query timeout;mssql.timeout &#x3D; 60 ; Valid range 0 - 2147483647. Default &#x3D; 4096.;mssql.textlimit &#x3D; 4096 ; Valid range 0 - 2147483647. Default &#x3D; 4096.;mssql.textsize &#x3D; 4096 ; Limits the number of records in each batch. 0 &#x3D; all records in one batch.;mssql.batchsize &#x3D; 0 ; Specify how datetime and datetim4 columns are returned; On &#x3D;&gt; Returns data converted to SQL server settings; Off &#x3D;&gt; Returns values as YYYY-MM-DD hh:mm:ss;mssql.datetimeconvert &#x3D; On ; Use NT authentication when connecting to the servermssql.secure_connection &#x3D; Off ; Specify max number of processes. -1 &#x3D; library default; msdlib defaults to 25; FreeTDS defaults to 4096;mssql.max_procs &#x3D; -1 ; Specify client character set.; If empty or not set the client charset from freetds.comf is used; This is only used when compiled with FreeTDS;mssql.charset &#x3D; “ISO-8859-1” [Assertion]; Assert(expr); active by default.; http://php.net/assert.active;assert.active &#x3D; On ; Issue a PHP warning for each failed assertion.; http://php.net/assert.warning;assert.warning &#x3D; On ; Don’t bail out by default.; http://php.net/assert.bail;assert.bail &#x3D; Off ; User-function to be called if an assertion fails.; http://php.net/assert.callback;assert.callback &#x3D; 0 ; Eval the expression with current error_reporting(). Set to true if you want; error_reporting(0) around the eval().; http://php.net/assert.quiet-eval;assert.quiet_eval &#x3D; 0 [COM]; path to a file containing GUIDs, IIDs or filenames of files with TypeLibs; http://php.net/com.typelib-file;com.typelib_file &#x3D; ; allow Distributed-COM calls; http://php.net/com.allow-dcom;com.allow_dcom &#x3D; true ; autoregister constants of a components typlib on com_load(); http://php.net/com.autoregister-typelib;com.autoregister_typelib &#x3D; true ; register constants casesensitive; http://php.net/com.autoregister-casesensitive;com.autoregister_casesensitive &#x3D; false ; show warnings on duplicate constant registrations; http://php.net/com.autoregister-verbose;com.autoregister_verbose &#x3D; true ; The default character set code-page to use when passing strings to and from COM objects.; Default: system ANSI code page;com.code_page&#x3D; [mbstring]; language for internal character representation.; http://php.net/mbstring.language;mbstring.language &#x3D; Japanese ; internal&#x2F;script encoding.; Some encoding cannot work as internal encoding.; (e.g. SJIS, BIG5, ISO-2022-*); http://php.net/mbstring.internal-encoding;mbstring.internal_encoding &#x3D; EUC-JP ; http input encoding.; http://php.net/mbstring.http-input;mbstring.http_input &#x3D; auto ; http output encoding. mb_output_handler must be; registered as output buffer to function; http://php.net/mbstring.http-output;mbstring.http_output &#x3D; SJIS ; enable automatic encoding translation according to; mbstring.internal_encoding setting. Input chars are; converted to internal encoding by setting this to On.; Note: Do not use automatic encoding translation for; portable libs&#x2F;applications.; http://php.net/mbstring.encoding-translation;mbstring.encoding_translation &#x3D; Off ; automatic encoding detection order.; auto means; http://php.net/mbstring.detect-order;mbstring.detect_order &#x3D; auto ; substitute_character used when character cannot be converted; one from another; http://php.net/mbstring.substitute-character;mbstring.substitute_character &#x3D; none; ; overload(replace) single byte functions by mbstring functions.; mail(), ereg(), etc are overloaded by mb_send_mail(), mb_ereg(),; etc. Possible values are 0,1,2,4 or combination of them.; For example, 7 for overload everything.; 0: No overload; 1: Overload mail() function; 2: Overload str*() functions; 4: Overload ereg*() functions; http://php.net/mbstring.func-overload;mbstring.func_overload &#x3D; 0 ; enable strict encoding detection.;mbstring.strict_detection &#x3D; Off ; This directive specifies the regex pattern of content types for which mb_output_handler(); is activated.; Default: mbstring.http_output_conv_mimetype&#x3D;^(text&#x2F;|application&#x2F;xhtml+xml);mbstring.http_output_conv_mimetype&#x3D; ; Allows to set script encoding. Only affects if PHP is compiled with –enable-zend-multibyte; Default: “”;mbstring.script_encoding&#x3D; [gd]; Tell the jpeg decode to ignore warnings and try to create; a gd image. The warning will then be displayed as notices; disabled by default; http://php.net/gd.jpeg-ignore-warning;gd.jpeg_ignore_warning &#x3D; 0 [exif]; Exif UNICODE user comments are handled as UCS-2BE&#x2F;UCS-2LE and JIS as JIS.; With mbstring support this will automatically be converted into the encoding; given by corresponding encode setting. When empty mbstring.internal_encoding; is used. For the decode settings you can distinguish between motorola and; intel byte order. A decode setting cannot be empty.; http://php.net/exif.encode-unicode;exif.encode_unicode &#x3D; ISO-8859-15 ; http://php.net/exif.decode-unicode-motorola;exif.decode_unicode_motorola &#x3D; UCS-2BE ; http://php.net/exif.decode-unicode-intel;exif.decode_unicode_intel &#x3D; UCS-2LE ; http://php.net/exif.encode-jis;exif.encode_jis &#x3D; ; http://php.net/exif.decode-jis-motorola;exif.decode_jis_motorola &#x3D; JIS ; http://php.net/exif.decode-jis-intel;exif.decode_jis_intel &#x3D; JIS [Tidy]; The path to a default tidy configuration file to use when using tidy; http://php.net/tidy.default-config;tidy.default_config &#x3D; &#x2F;usr&#x2F;local&#x2F;lib&#x2F;php&#x2F;default.tcfg ; Should tidy clean and repair output automatically?; WARNING: Do not use this option if you are generating non-html content; such as dynamic images; http://php.net/tidy.clean-outputtidy.clean_output &#x3D; Off [soap]; Enables or disables WSDL caching feature.; http://php.net/soap.wsdl-cache-enabledsoap.wsdl_cache_enabled&#x3D;1 ; Sets the directory name where SOAP extension will put cache files.; http://php.net/soap.wsdl-cache-dirsoap.wsdl_cache_dir&#x3D;”&#x2F;tmp” ; (time to live) Sets the number of second while cached file will be used; instead of original one.; http://php.net/soap.wsdl-cache-ttlsoap.wsdl_cache_ttl&#x3D;86400 ; Sets the size of the cache limit. (Max. number of WSDL files to cache)soap.wsdl_cache_limit &#x3D; 5 [sysvshm]; A default size of the shared memory segment;sysvshm.init_mem &#x3D; 10000 [ldap]; Sets the maximum number of open links or -1 for unlimited.ldap.max_links &#x3D; -1 [mcrypt]; For more information about mcrypt settings see http://php.net/mcrypt-module-open ; Directory where to load mcrypt algorithms; Default: Compiled in into libmcrypt (usually &#x2F;usr&#x2F;local&#x2F;lib&#x2F;libmcrypt);mcrypt.algorithms_dir&#x3D; ; Directory where to load mcrypt modes; Default: Compiled in into libmcrypt (usually &#x2F;usr&#x2F;local&#x2F;lib&#x2F;libmcrypt);mcrypt.modes_dir&#x3D; [dba];dba.default_handler&#x3D;; Local Variables:; tab-width: 4[opcache]zend_extension&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;opcache.soopcache.memory_consumption&#x3D;256opcache.interned_strings_buffer&#x3D;8opcache.max_accelerated_files&#x3D;4000opcache.revalidate_freq&#x3D;60opcache.fast_shutdown&#x3D;1opcache.enable_cli&#x3D;1opcache.enable&#x3D;1; End:"},{"path":"/2023/09/28/Linux配置文件/lnmp/php-fpm.conf/","content":";;;;;;;;;;;;;;;;;;;;;; FPM Configuration ;;;;;;;;;;;;;;;;;;;;;; ; All relative paths in this configuration file are relative to PHP’s install; prefix (&#x2F;usr&#x2F;local&#x2F;php). This prefix can be dynamicaly changed by using the; ‘-p’ argument from the command line. ; Include one or more files. If glob(3) exists, it is used to include a bunch of; files from a glob(3) pattern. This directive can be used everywhere in the; file.; Relative path can also be used. They will be prefixed by:; - the global prefix if it’s been set (-p arguement); - &#x2F;usr&#x2F;local&#x2F;php otherwise;include&#x3D;etc&#x2F;fpm.d&#x2F;*.conf ;;;;;;;;;;;;;;;;;;; Global Options ;;;;;;;;;;;;;;;;;;; [global]; Pid file; Note: the default prefix is &#x2F;usr&#x2F;local&#x2F;php&#x2F;var; Default Value: nonepid &#x3D; &#x2F;tmp&#x2F;php-fpm.pid ; Error log file; Note: the default prefix is &#x2F;usr&#x2F;local&#x2F;php&#x2F;var; Default Value: log&#x2F;php-fpm.logerror_log &#x3D; &#x2F;data&#x2F;logs&#x2F;php&#x2F;fpm-error.log ; Log level; Possible Values: alert, error, warning, notice, debug; Default Value: notice;log_level &#x3D; notice ; If this number of child processes exit with SIGSEGV or SIGBUS within the time; interval set by emergency_restart_interval then FPM will restart. A value; of ‘0’ means ‘Off’.; Default Value: 0;emergency_restart_threshold &#x3D; 0 ; Interval of time used by emergency_restart_interval to determine when; a graceful restart will be initiated. This can be useful to work around; accidental corruptions in an accelerator’s shared memory.; Available Units: s(econds), m(inutes), h(ours), or d(ays); Default Unit: seconds; Default Value: 0;emergency_restart_interval &#x3D; 0 ; Time limit for child processes to wait for a reaction on signals from master.; Available units: s(econds), m(inutes), h(ours), or d(ays); Default Unit: seconds; Default Value: 0;process_control_timeout &#x3D; 0 ; Send FPM to background. Set to ‘no’ to keep FPM in foreground for debugging.; Default Value: yes;daemonize &#x3D; yes ; Set open file descriptor rlimit for the master process.; Default Value: system defined valuerlimit_files &#x3D; 65535 ; Set max core size rlimit for the master process.; Possible Values: ‘unlimited’ or an integer greater or equal to 0; Default Value: system defined value;rlimit_core &#x3D; 0 ;;;;;;;;;;;;;;;;;;;;; Pool Definitions ;;;;;;;;;;;;;;;;;;;;; ; Multiple pools of child processes may be started with different listening; ports and different management options. The name of the pool will be; used in logs and stats. There is no limitation on the number of pools which; FPM can handle. Your system will tell you anyway :) ; Start a new pool named ‘www’.; the variable $pool can we used in any directive and will be replaced by the; pool name (‘www’ here)[www] ; Per pool prefix; It only applies on the following directives:; - ‘slowlog’; - ‘listen’ (unixsocket); - ‘chroot’; - ‘chdir’; - ‘php_values’; - ‘php_admin_values’; When not set, the global prefix (or &#x2F;usr&#x2F;local&#x2F;php) applies instead.; Note: This directive can also be relative to the global prefix.; Default Value: none;prefix &#x3D; &#x2F;path&#x2F;to&#x2F;pools&#x2F;$pool ; The address on which to accept FastCGI requests.; Valid syntaxes are:; ‘ip.add.re.ss:port’ - to listen on a TCP socket to a specific address on; a specific port;; ‘port’ - to listen on a TCP socket to all addresses on a; specific port;; ‘&#x2F;path&#x2F;to&#x2F;unix&#x2F;socket’ - to listen on a unix socket.; Note: This value is mandatory.listen &#x3D; &#x2F;dev&#x2F;shm&#x2F;php-cgi.sock;listen &#x3D; 127.0.0.1:9000 ; Set listen(2) backlog. A value of ‘-1’ means unlimited.; Default Value: 128 (-1 on FreeBSD and OpenBSD);listen.backlog &#x3D; -1 ; List of ipv4 addresses of FastCGI clients which are allowed to connect.; Equivalent to the FCGI_WEB_SERVER_ADDRS environment variable in the original; PHP FCGI (5.2.2+). Makes sense only with a tcp listening socket. Each address; must be separated by a comma. If this value is left blank, connections will be; accepted from any ip address.; Default Value: anylisten.allowed_clients &#x3D; 127.0.0.1 ; Set permissions for unix socket, if one is used. In Linux, read&#x2F;write; permissions must be set in order to allow connections from a web server. Many; BSD-derived systems allow connections regardless of permissions.; Default Values: user and group are set as the running user; mode is set to 0666;listen.owner &#x3D; nobody;listen.group &#x3D; nobody;listen.mode &#x3D; 0666 ; Unix user&#x2F;group of processes; Note: The user is mandatory. If the group is not set, the default user’s group; will be used.user &#x3D; wwwgroup &#x3D; www ; Choose how the process manager will control the number of child processes.; Possible Values:; static - a fixed number (pm.max_children) of child processes;; dynamic - the number of child processes are set dynamically based on the; following directives:; pm.max_children - the maximum number of children that can; be alive at the same time.; pm.start_servers - the number of children created on startup.; pm.min_spare_servers - the minimum number of children in ‘idle’; state (waiting to process). If the number; of ‘idle’ processes is less than this; number then some children will be created.; pm.max_spare_servers - the maximum number of children in ‘idle’; state (waiting to process). If the number; of ‘idle’ processes is greater than this; number then some children will be killed.; Note: This value is mandatory.pm &#x3D; dynamic ; The number of child processes to be created when pm is set to ‘static’ and the; maximum number of child processes to be created when pm is set to ‘dynamic’.; This value sets the limit on the number of simultaneous requests that will be; served. Equivalent to the ApacheMaxClients directive with mpm_prefork.; Equivalent to the PHP_FCGI_CHILDREN environment variable in the original PHP; CGI.; Note: Used when pm is set to either ‘static’ or ‘dynamic’; Note: This value is mandatory.pm.max_children &#x3D; 120 ; The number of child processes created on startup.; Note: Used only when pm is set to ‘dynamic’; Default Value: min_spare_servers + (max_spare_servers - min_spare_servers) &#x2F; 2pm.start_servers &#x3D; 15 ; The desired minimum number of idle server processes.; Note: Used only when pm is set to ‘dynamic’; Note: Mandatory when pm is set to ‘dynamic’pm.min_spare_servers &#x3D; 5 ; The desired maximum number of idle server processes.; Note: Used only when pm is set to ‘dynamic’; Note: Mandatory when pm is set to ‘dynamic’pm.max_spare_servers &#x3D; 35 ; The number of requests each child process should execute before respawning.; This can be useful to work around memory leaks in 3rd party libraries. For; endless request processing specify ‘0’. Equivalent to PHP_FCGI_MAX_REQUESTS.; Default Value: 0pm.max_requests &#x3D; 800 ; The URI to view the FPM status page. If this value is not set, no URI will be; recognized as a status page. By default, the status page shows the following; information:; accepted conn - the number of request accepted by the pool;; pool - the name of the pool;; process manager - static or dynamic;; idle processes - the number of idle processes;; active processes - the number of active processes;; total processes - the number of idle + active processes.; max children reached - number of times, the process limit has been reached,; when pm tries to start more children (works only for; pm ‘dynamic’); The values of ‘idle processes’, ‘active processes’ and ‘total processes’ are; updated each second. The value of ‘accepted conn’ is updated in real time.; Example output:; accepted conn: 12073; pool: www; process manager: static; idle processes: 35; active processes: 65; total processes: 100; max children reached: 1; By default the status page output is formatted as text&#x2F;plain. Passing either; ‘html’, ‘xml’ or ‘json’ as a query string will return the corresponding output; syntax. Example:; http://www.foo.bar/status; http://www.foo.bar/status?json; http://www.foo.bar/status?html; http://www.foo.bar/status?xml; Note: The value must start with a leading slash (&#x2F;). The value can be; anything, but it may not be a good idea to use the .php extension or it; may conflict with a real PHP file.; Default Value: not set;pm.status_path &#x3D; &#x2F;status ; The ping URI to call the monitoring page of FPM. If this value is not set, no; URI will be recognized as a ping page. This could be used to test from outside; that FPM is alive and responding, or to; - create a graph of FPM availability (rrd or such);; - remove a server from a group if it is not responding (load balancing);; - trigger alerts for the operating team (24&#x2F;7).; Note: The value must start with a leading slash (&#x2F;). The value can be; anything, but it may not be a good idea to use the .php extension or it; may conflict with a real PHP file.; Default Value: not set;ping.path &#x3D; &#x2F;ping ; This directive may be used to customize the response of a ping request. The; response is formatted as text&#x2F;plain with a 200 response code.; Default Value: pong;ping.response &#x3D; pong ; The access log file; Default: not set;access.log &#x3D; log&#x2F;$pool.access.log ; The access log format.; The following syntax is allowed; %%: the ‘%’ character; %C: %CPU used by the request; it can accept the following format:; - %{user}C for user CPU only; - %{system}C for system CPU only; - %{total}C for user + system CPU (default); %d: time taken to serve the request; it can accept the following format:; - %{seconds}d (default); - %{miliseconds}d; - %{mili}d; - %{microseconds}d; - %{micro}d; %e: an environment variable (same as $_ENV or $_SERVER); it must be associated with embraces to specify the name of the env; variable. Some exemples:; - server specifics like: %{REQUEST_METHOD}e or %{SERVER_PROTOCOL}e; - HTTP headers like: %{HTTP_HOST}e or %{HTTP_USER_AGENT}e; %f: script filename; %l: content-length of the request (for POST request only); %m: request method; %M: peak of memory allocated by PHP; it can accept the following format:; - %{bytes}M (default); - %{kilobytes}M; - %{kilo}M; - %{megabytes}M; - %{mega}M; %n: pool name; %o: ouput header; it must be associated with embraces to specify the name of the header:; - %{Content-Type}o; - %{X-Powered-By}o; - %{Transfert-Encoding}o; - ….; %p: of the child that serviced the request; %P: PID of the parent of the child that serviced the request; %q: the query string; %Q: the ‘?’ character if query string exists; %r: the request URI (without the query string, see %q and %Q); %R: remote IP address; %s: status (response code); %t: server time the request was received; it can accept a strftime(3) format:; %d&#x2F;%b&#x2F;%Y:%H:%M:%S %z (default); %T: time the log has been written (the request has finished); it can accept a strftime(3) format:; %d&#x2F;%b&#x2F;%Y:%H:%M:%S %z (default); %u: remote user;; Default: “%R - %u %t &quot;%m %r&quot; %s”;access.format &#x3D; %R - %u %t “%m %r%Q%q” %s %f %{mili}d %{kilo}M %C%% ; The timeout for serving a single request after which the worker process will; be killed. This option should be used when the ‘max_execution_time’ ini option; does not stop script execution for some reason. A value of ‘0’ means ‘off’.; Available units: s(econds)(default), m(inutes), h(ours), or d(ays); Default Value: 0;request_terminate_timeout &#x3D; 0 ; The timeout for serving a single request after which a PHP backtrace will be; dumped to the ‘slowlog’ file. A value of ‘0s’ means ‘off’.; Available units: s(econds)(default), m(inutes), h(ours), or d(ays); Default Value: 0;request_slowlog_timeout &#x3D; 0 ; The log file for slow requests; Default Value: not set; Note: slowlog is mandatory if request_slowlog_timeout is set;slowlog &#x3D; log&#x2F;$pool.log.slow ; Set open file descriptor rlimit.; Default Value: system defined valuerlimit_files &#x3D; 65535 ; Set max core size rlimit.; Possible Values: ‘unlimited’ or an integer greater or equal to 0; Default Value: system defined value;rlimit_core &#x3D; 0 ; Chroot to this directory at the start. This value must be defined as an; absolute path. When this value is not set, chroot is not used.; Note: you can prefix with ‘$prefix’ to chroot to the pool prefix or one; of its subdirectories. If the pool prefix is not set, the global prefix; will be used instead.; Note: chrooting is a great security feature and should be used whenever; possible. However, all PHP paths will be relative to the chroot; (error_log, sessions.save_path, …).; Default Value: not set;chroot &#x3D; ; Chdir to this directory at the start.; Note: relative path can be used.; Default Value: current directory or &#x2F; when chroot;chdir &#x3D; &#x2F;var&#x2F;www ; Redirect worker stdout and stderr into main error log. If not set, stdout and; stderr will be redirected to &#x2F;dev&#x2F;null according to FastCGI specs.; Note: on highloaded environement, this can cause some delay in the page; process time (several ms).; Default Value: no;catch_workers_output &#x3D; yes ; Pass environment variables like LD_LIBRARY_PATH. All $VARIABLEs are taken from; the current environment.; Default Value: clean env;env[HOSTNAME] &#x3D; $HOSTNAME;env[PATH] &#x3D; &#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;bin:&#x2F;bin;env[TMP] &#x3D; &#x2F;tmp;env[TMPDIR] &#x3D; &#x2F;tmp;env[TEMP] &#x3D; &#x2F;tmp ; Additional php.ini defines, specific to this pool of workers. These settings; overwrite the values previously defined in the php.ini. The directives are the; same as the PHP SAPI:; php_value&#x2F;php_flag - you can set classic ini defines which can; be overwritten from PHP call ‘ini_set’.; php_admin_value&#x2F;php_admin_flag - these directives won’t be overwritten by; PHP call ‘ini_set’; For php_*flag, valid values are on, off, 1, 0, true, false, yes or no. ; Defining ‘extension’ will load the corresponding shared extension from; extension_dir. Defining ‘disable_functions’ or ‘disable_classes’ will not; overwrite previously defined php.ini values, but will append the new value; instead. ; Note: path INI options can be relative and will be expanded with the prefix; (pool, global or &#x2F;usr&#x2F;local&#x2F;php) ; Default Value: nothing is defined by default except the values in php.ini and; specified at startup with the -d argument;php_admin_value[sendmail_path] &#x3D; &#x2F;usr&#x2F;sbin&#x2F;sendmail -t -i -f &#x77;&#x77;&#119;&#64;&#109;&#121;&#46;&#x64;&#x6f;&#x6d;&#x61;&#x69;&#110;&#x2e;&#x63;&#111;&#x6d;;php_flag[display_errors] &#x3D; off;php_admin_value[error_log] &#x3D; &#x2F;var&#x2F;log&#x2F;fpm-php.www.log;php_admin_flag[log_errors] &#x3D; on;php_admin_value[memory_limit] &#x3D; 32M"},{"path":"/2023/09/28/Linux配置文件/lnmp/nginx.conf/","content":"user www www;worker_processes 4;worker_rlimit_nofile 8192;#8 cpu��#worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000; #error_log logs&#x2F;error.log;#error_log logs&#x2F;error.log notice;#error_log logs&#x2F;error.log info; #pid logs&#x2F;nginx.pid; events { use epoll; worker_connections 4096;} http { include mime.types; default_type application&#x2F;octet-stream; #log_format main &#39;$remote_addr - $remote_user [$time_local] &#39; # &#39;&quot;$request&quot; - $status - $body_bytes_sent &#39; # &#39;&quot;$http_user_agent&quot; &quot;$http_referer&quot; &#39;; #access_log logs/access.log main; keepalive_timeout 65; server_names_hash_max_size 512; server_names_hash_bucket_size 128; sendfile off; tcp_nopush off; tcp_nodelay on; server_tokens off; client_header_timeout 60; client_body_timeout 60; client_max_body_size 8m; client_header_buffer_size 1k; large_client_header_buffers 4 4k; send_timeout 90; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 128k; fastcgi_buffers 8 128k; fastcgi_busy_buffers_size 256k; fastcgi_temp_file_write_size 256k; fastcgi_intercept_errors on; #����nginx��������Ϣ���͵��ͻ��ˣ�404��403�ȣ� gzip on; gzip_min_length 1024; #�������ݳ���С���趨ֵ��ѹ�� #gzip_proxied expired no-cache no-store private auth; # ���ڴӷ�������������������ѹ�� gzip_buffers 4 8k; gzip_http_version 1.1; gzip_comp_level 4; gzip_types text/plain text/css application/x-javascript text/xml application/xml application/xml+rss text/javascript; #gzip_vary on; # �������Ƿ񷵻�&quot;Vary\tAccept-Encoding&quot;����web�������ϲ��з����������squid��ʱ��ʹ������������Ա����������������ȷ���͵����ݡ� # �������� #limit_zone one $binary_remote_addr 5m; server &#123; listen 80; server_name localhost; root /data/www; index index.php index.html index.htm; if ( $fastcgi_script_name ~ \\..*\\/.*php ) &#123; return 403; &#125; #Ŀ¼���Զ����ӡ�/�� if (-d $request_filename)&#123; rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent; &#125; #charset koi8-r; #access_log logs/host.access.log main; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; #ͼƬ��js�ȷ�����#�мǲ�Ҫ�Ѹ�Ŀ¼���趨���ڵ���location�� �����Ӱ��������� location ~* \\.(gif|jpg|png|swf|flv)$ &#123; #valid_referers none blocked *.phpchina.com; #if ($invalid_referer) &#123; # return 404; #&#125; access_log off; expires 10d; &#125; # ���ش������� #location / &#123; # limit_conn one 1; #ͬһ�Ựֻ����һ������ # limit_rate 2m; #�����ٶ����� #&#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ \\.php$ &#123; fastcgi_pass unix:/dev/shm/php-cgi.sock; #fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; # deny access to .htaccess files, if Apache&#39;s document root # concurs with nginx&#39;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443; # server_name localhost; # ssl on; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_timeout 5m; # ssl_protocols SSLv2 SSLv3 TLSv1; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; }"},{"path":"/2023/09/28/Linux配置文件/lnmp/nginx-proxy-vhost.com/","content":"server { listen 80; server_name www.phpchina.com phpchina.com; if ($host !&#x3D; ‘www.phpchina.com&#39;){ rewrite ^&#x2F;(.*) http://www.phpchina.com/$1 permanent; } access_log off; if ( $fastcgi_script_name ~ ..*/.*php ) { return 403; } #目录后自动添加“/” if (-d $request_filename)&#123; rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent; &#125; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.122.110; &#125; }"},{"path":"/2023/09/28/Linux配置文件/lnmp/nginx-proxy-master.conf/","content":"user www www;worker_processes 4;worker_rlimit_nofile 65535;#error_log logs&#x2F;error.log;#error_log logs&#x2F;error.log notice;#error_log logs&#x2F;error.log info; #pid logs&#x2F;nginx.pid; events { use epoll; worker_connections 4096;} http { include mime.types; default_type application&#x2F;octet-stream; #log_format main &#39;$remote_addr - $remote_user [$time_local] &#39; # &#39;&quot;$request&quot; - $status - $body_bytes_sent &#39; # &#39;&quot;$http_user_agent&quot; &quot;$http_referer&quot; &#39;; access_log off; keepalive_timeout 65; server_names_hash_max_size 512; server_names_hash_bucket_size 128; sendfile off; tcp_nopush off; tcp_nodelay on; server_tokens off; client_header_timeout 60; client_body_timeout 60; client_max_body_size 8m; client_header_buffer_size 1k; large_client_header_buffers 4 4k; send_timeout 90; proxy_connect_timeout 90; #nginx����˷��������ӳ�ʱʱ��(�������ӳ�ʱ�� proxy_read_timeout 90; #���ӳɹ��󣬺�˷�������Ӧʱ��(�������ճ�ʱ) proxy_send_timeout 90; #��˷��������ݻش�ʱ��(�������ͳ�ʱ) proxy_buffer_size 4k; #���ô�����������nginx�������û�ͷ��Ϣ�Ļ�������С proxy_buffers 4 32k; #proxy_buffers����������ҳƽ����32k���µĻ����������� proxy_busy_buffers_size 64k; /#���ϵͳ��æ������������proxy_buffers���ٷ��Ƽ� *2 proxy_temp_file_write_size 64k; //proxy������ʱ�ļ���С gzip on; gzip_min_length 1024; gzip_buffers 4 8k; gzip_http_version 1.1; gzip_comp_level 4; gzip_types text/plain text/css application/x-javascript text/xml application/xml application/xml+rss text/javascript; upstream show_phpchina &#123; server 192.168.122.100 max_fails=2 fail_timeout=30s; &#125; upstream test_phpchina &#123; server 192.168.122.106 max_fails=2 fail_timeout=30s; &#125; server { listen 80 default; return 500; } include vhosts&#x2F;*;}"},{"path":"/2023/09/28/Linux配置文件/lnmp/nginx-mini.conf/","content":"user www www;worker_processes 1;worker_rlimit_nofile 51200;#8 cpu��#worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000; #error_log logs&#x2F;error.log;#error_log logs&#x2F;error.log notice;#error_log logs&#x2F;error.log info; #pid logs&#x2F;nginx.pid; events { use epoll; worker_connections 51200;} http { include mime.types; default_type application&#x2F;octet-stream; #log_format main &#39;$remote_addr - $remote_user [$time_local] &#39; # &#39;&quot;$request&quot; - $status - $body_bytes_sent &#39; # &#39;&quot;$http_user_agent&quot; &quot;$http_referer&quot; &#39;; #access_log logs/access.log main; keepalive_timeout 60; server_names_hash_max_size 256; server_names_hash_bucket_size 128; sendfile off; tcp_nopush off; tcp_nodelay on; server_tokens off; client_header_timeout 60; client_body_timeout 60; client_max_body_size 8m; client_header_buffer_size 4k; large_client_header_buffers 4 4k; send_timeout 90; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; fastcgi_intercept_errors on; #����nginx��������Ϣ���͵��ͻ��ˣ�404��403�ȣ� gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 2; gzip_types text/plain text/css application/x-javascript text/xml application/xml application/xml+rss text/javascript; gzip_vary on; # �������� #limit_zone one $binary_remote_addr 5m; server &#123; listen 80 default; server_name www.jiayeah.org jiayeah.org; if ($host != &#39;jiayeah.org&#39;) &#123; rewrite ^/(.*) http://jiayeah.org/$1 permanent; #return 404; &#125; root /data/www/wordpress; index index.php index.html index.htm; #charset koi8-r; #access_log logs/host.access.log main; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; #ͼƬ��js�ȷ�����#�мǲ�Ҫ�Ѹ�Ŀ¼���趨���ڵ���location�� �����Ӱ��������� location ~* \\.(gif|jpg|png|swf|flv|js|css)$ &#123; #valid_referers none blocked *.phpchina.com; #if ($invalid_referer) &#123; # return 404; #&#125; access_log off; expires 10d; &#125; # ���ش������� #location / &#123; # limit_conn one 1; #ͬһ�Ựֻ����һ������ # limit_rate 2m; #�����ٶ����� #&#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ \\.php$ &#123; fastcgi_pass unix:/dev/shm/php-cgi.sock; #fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; # deny access to .htaccess files, if Apache&#39;s document root # concurs with nginx&#39;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443; # server_name localhost; # ssl on; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_timeout 5m; # ssl_protocols SSLv2 SSLv3 TLSv1; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; }"},{"path":"/2023/09/28/Linux配置文件/lnmp/mysql_backup.sh/","content":"#!&#x2F;bin&#x2F;bash#DB_DIR&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data#Modify 2010 08 10#by shidegang BACK_DIR&#x3D;&#x2F;data&#x2F;bak&#x2F;mysql DB_LST&#x3D;&#x2F;tmp&#x2F;db.lst DATE&#x3D;date +%Y-%m-%d export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin mysql -u root -p’’ -e ‘show databases’ &gt; $DB_LST [ ! -d $BACK_DIR ] &amp;&amp; mkdir -p $BACK_DIRfor i in $(grep -vE “Database|information_schema|test” $DB_LST)do mysqldump –user&#x3D;’root’ –passwor&#x3D;’’ –default-character-set&#x3D;utf8 $i &gt; $BACK_DIR&#x2F;$i-$DATE.sql [ “$PWD” !&#x3D; “$BACK_DIR” ] &amp;&amp; cd $BACK_DIR gzip -f $BACK_DIR&#x2F;$i-$DATE.sqldone find $BACK_DIR -mtime +7 | xargs -i rm -rf {}"},{"path":"/2023/09/28/Linux配置文件/lnmp/mysql.user.sql/","content":"– MySQL dump 10.13 Distrib 5.5.27, for Linux (i686)– Host: localhost Database: mysql – Server version\t5.5.27-log &#x2F;*!40101 SET @OLD_CHARACTER_SET_CLIENT&#x3D;@@CHARACTER_SET_CLIENT &#x2F;;&#x2F;!40101 SET @OLD_CHARACTER_SET_RESULTS&#x3D;@@CHARACTER_SET_RESULTS &#x2F;;&#x2F;!40101 SET @OLD_COLLATION_CONNECTION&#x3D;@@COLLATION_CONNECTION &#x2F;;&#x2F;!40101 SET NAMES gbk &#x2F;;&#x2F;!40103 SET @OLD_TIME_ZONE&#x3D;@@TIME_ZONE &#x2F;;&#x2F;!40103 SET TIME_ZONE&#x3D;’+00:00’ &#x2F;;&#x2F;!40014 SET @OLD_UNIQUE_CHECKS&#x3D;@@UNIQUE_CHECKS, UNIQUE_CHECKS&#x3D;0 &#x2F;;&#x2F;!40014 SET @OLD_FOREIGN_KEY_CHECKS&#x3D;@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS&#x3D;0 &#x2F;;&#x2F;!40101 SET @OLD_SQL_MODE&#x3D;@@SQL_MODE, SQL_MODE&#x3D;’NO_AUTO_VALUE_ON_ZERO’ &#x2F;;&#x2F;!40111 SET @OLD_SQL_NOTES&#x3D;@@SQL_NOTES, SQL_NOTES&#x3D;0 *&#x2F;; –– Table structure for table userDROP TABLE IF EXISTS user;&#x2F;*!40101 SET @saved_cs_client &#x3D; @@character_set_client &#x2F;;&#x2F;!40101 SET character_set_client &#x3D; utf8 &#x2F;;CREATE TABLE user ( Host char(60) COLLATE utf8_bin NOT NULL DEFAULT ‘’, User char(16) COLLATE utf8_bin NOT NULL DEFAULT ‘’, Password char(41) CHARACTER SET latin1 COLLATE latin1_bin NOT NULL DEFAULT ‘’, Select_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Insert_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Update_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Delete_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Drop_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Reload_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Shutdown_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Process_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, File_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Grant_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, References_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Index_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Alter_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Show_db_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Super_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_tmp_table_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Lock_tables_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Execute_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Repl_slave_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Repl_client_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_view_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Show_view_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_routine_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Alter_routine_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_user_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Event_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Trigger_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_tablespace_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, ssl_type enum(‘’,’ANY’,’X509’,’SPECIFIED’) CHARACTER SET utf8 NOT NULL DEFAULT ‘’, ssl_cipher blob NOT NULL, x509_issuer blob NOT NULL, x509_subject blob NOT NULL, max_questions int(11) unsigned NOT NULL DEFAULT ‘0’, max_updates int(11) unsigned NOT NULL DEFAULT ‘0’, max_connections int(11) unsigned NOT NULL DEFAULT ‘0’, max_user_connections int(11) unsigned NOT NULL DEFAULT ‘0’, plugin char(64) COLLATE utf8_bin DEFAULT ‘’, authentication_string text COLLATE utf8_bin, PRIMARY KEY (Host,User)) ENGINE&#x3D;MyISAM DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;’Users and global privileges’;&#x2F;!40101 SET character_set_client &#x3D; @saved_cs_client *&#x2F;; –– Dumping data for table userLOCK TABLES user WRITE;&#x2F;*!40000 ALTER TABLE user DISABLE KEYS *&#x2F;;INSERT INTO user VALUES (‘localhost’,’root’,’897F89E43B915C47FA5769CDD90A24AF32CE733A’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’’,’’,’’,’’,0,0,0,0,’’,’’);&#x2F;!40000 ALTER TABLE user ENABLE KEYS &#x2F;;UNLOCK TABLES;&#x2F;!40103 SET TIME_ZONE&#x3D;@OLD_TIME_ZONE *&#x2F;; &#x2F;*!40101 SET SQL_MODE&#x3D;@OLD_SQL_MODE &#x2F;;&#x2F;!40014 SET FOREIGN_KEY_CHECKS&#x3D;@OLD_FOREIGN_KEY_CHECKS &#x2F;;&#x2F;!40014 SET UNIQUE_CHECKS&#x3D;@OLD_UNIQUE_CHECKS &#x2F;;&#x2F;!40101 SET CHARACTER_SET_CLIENT&#x3D;@OLD_CHARACTER_SET_CLIENT &#x2F;;&#x2F;!40101 SET CHARACTER_SET_RESULTS&#x3D;@OLD_CHARACTER_SET_RESULTS &#x2F;;&#x2F;!40101 SET COLLATION_CONNECTION&#x3D;@OLD_COLLATION_CONNECTION &#x2F;;&#x2F;!40111 SET SQL_NOTES&#x3D;@OLD_SQL_NOTES *&#x2F;; – Dump completed on 2012-09-05 5:57:21"},{"path":"/2023/09/28/Linux配置文件/lnmp/my.cnf/","content":"[client]default-character-set&#x3D;gbkport &#x3D; 3306socket &#x3D; &#x2F;tmp&#x2F;mysql.sock[mysqld]character-set-server &#x3D; gbkcollation-server &#x3D; gbk_chinese_ci#replicate-ignore-db &#x3D; mysql#replicate-ignore-db &#x3D; test#replicate-ignore-db &#x3D; information_schemauser &#x3D; mysqlport &#x3D; 3306socket &#x3D; &#x2F;tmp&#x2F;mysql.sockbasedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysqldatadir &#x3D; &#x2F;data&#x2F;mysql&#x2F;datalog-error &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql_error.logpid-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql.pidopen_files_limit &#x3D; 10240back_log &#x3D; 600max_connections &#x3D; 5000max_connect_errors &#x3D; 6000table_cache &#x3D; 614external-locking &#x3D; FALSEmax_allowed_packet &#x3D; 32Msort_buffer_size &#x3D; 1Mjoin_buffer_size &#x3D; 1Mthread_cache_size &#x3D; 300thread_concurrency &#x3D; 8query_cache_size &#x3D; 512Mquery_cache_limit &#x3D; 2Mquery_cache_min_res_unit &#x3D; 2kdefault-storage-engine &#x3D; MyISAMthread_stack &#x3D; 192Ktransaction_isolation &#x3D; READ-COMMITTEDtmp_table_size &#x3D; 246Mmax_heap_table_size &#x3D; 246Mlong_query_time &#x3D; 3log-slave-updateslog-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;binlog&#x2F;binlogbinlog_cache_size &#x3D; 4Mbinlog_format &#x3D; MIXEDmax_binlog_cache_size &#x3D; 8Mmax_binlog_size &#x3D; 1Gexpire-logs-days &#x3D; 30relay-log-index &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylogrelay-log-info-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylogrelay-log &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylogexpire_logs_days &#x3D; 30key_buffer_size &#x3D; 256Mread_buffer_size &#x3D; 1Mread_rnd_buffer_size &#x3D; 16Mbulk_insert_buffer_size &#x3D; 64Mmyisam_sort_buffer_size &#x3D; 128Mmyisam_max_sort_file_size &#x3D; 10Gmyisam_repair_threads &#x3D; 1;myisam_recover interactive_timeout &#x3D; 120wait_timeout &#x3D; 120 skip-name-resolveslave-skip-errors &#x3D; 1032,1062,126,1114,1146,1048,1396 server-id &#x3D; 1 ;innodb_additional_mem_pool_size &#x3D; 16M;innodb_buffer_pool_size &#x3D; 512M;innodb_data_file_path &#x3D; ibdata1:256M:autoextend;innodb_file_io_threads &#x3D; 4;innodb_thread_concurrency &#x3D; 8;innodb_flush_log_at_trx_commit &#x3D; 2;innodb_log_buffer_size &#x3D; 16M;innodb_log_file_size &#x3D; 128M;innodb_log_files_in_group &#x3D; 3;innodb_max_dirty_pages_pct &#x3D; 90;innodb_lock_wait_timeout &#x3D; 120;innodb_file_per_table &#x3D; 0 log-slow-queries &#x3D; &#x2F;data&#x2F;mysql&#x2F;slow.loglong_query_time &#x3D; 1log-queries-not-using-indexes [mysqldump]quickmax_allowed_packet &#x3D; 32M"},{"path":"/2023/09/28/Linux配置文件/lnmp/my-mini.cnf/","content":"[client]default-character-set&#x3D;utf8port &#x3D; 3306socket &#x3D; &#x2F;tmp&#x2F;mysql.sock[mysqld]character-set-server &#x3D; utf8collation-server &#x3D; utf8_general_ci#replicate-ignore-db &#x3D; mysql#replicate-ignore-db &#x3D; test#replicate-ignore-db &#x3D; information_schemauser &#x3D; mysqlport &#x3D; 3306socket &#x3D; &#x2F;tmp&#x2F;mysql.sockbasedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysqldatadir &#x3D; &#x2F;data&#x2F;mysql&#x2F;datalog-error &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql_error.logpid-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql.pidopen_files_limit &#x3D; 600back_log &#x3D; 20max_connections &#x3D; 50max_connect_errors &#x3D; 100external-locking &#x3D; FALSEmax_allowed_packet &#x3D; 4Msort_buffer_size &#x3D; 128Kjoin_buffer_size &#x3D; 128Kthread_cache_size &#x3D; 10thread_concurrency &#x3D; 4query_cache_size &#x3D; 0Mquery_cache_limit &#x3D; 2Mquery_cache_min_res_unit &#x3D; 2kdefault-storage-engine &#x3D; MyISAMthread_stack &#x3D; 192Ktransaction_isolation &#x3D; READ-COMMITTEDtmp_table_size &#x3D; 512Kmax_heap_table_size &#x3D; 32Mlong_query_time &#x3D; 3log-slave-updateslog-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;binlog&#x2F;binlogbinlog_cache_size &#x3D; 2Mbinlog_format &#x3D; MIXEDmax_binlog_cache_size &#x3D; 4Mmax_binlog_size &#x3D;512Mexpire-logs-days &#x3D; 7#relay-log-index &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog#relay-log-info-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog#relay-log &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylogkey_buffer_size &#x3D; 4Mread_buffer_size &#x3D; 1Mread_rnd_buffer_size &#x3D; 2Mbulk_insert_buffer_size &#x3D; 2Mmyisam_sort_buffer_size &#x3D; 4Mmyisam_max_sort_file_size &#x3D; 10Gmyisam_repair_threads &#x3D; 1;myisam_recover interactive_timeout &#x3D; 120wait_timeout &#x3D; 120 skip-name-resolveslave-skip-errors &#x3D; 1032,1062,126,1114,1146,1048,1396server-id &#x3D; 1 ;innodb_additional_mem_pool_size &#x3D; 16M;innodb_buffer_pool_size &#x3D; 512M;innodb_data_file_path &#x3D; ibdata1:256M:autoextend;innodb_file_io_threads &#x3D; 4;innodb_thread_concurrency &#x3D; 8;innodb_flush_log_at_trx_commit &#x3D; 2;innodb_log_buffer_size &#x3D; 16M;innodb_log_file_size &#x3D; 128M;innodb_log_files_in_group &#x3D; 3;innodb_max_dirty_pages_pct &#x3D; 90;innodb_lock_wait_timeout &#x3D; 120;innodb_file_per_table &#x3D; 0 slow_query_logslow_query_log_file &#x3D; &#x2F;data&#x2F;mysql&#x2F;slow.loglong_query_time &#x3D; 1log-queries-not-using-indexes [mysqldump]quickmax_allowed_packet &#x3D; 4M"},{"path":"/2023/09/28/Linux配置文件/lnmp/lnmp_64.sh/","content":"#!&#x2F;bin&#x2F;bashecho “Renew the sources for yum,please wait…”sleep 2cd &#x2F;etc&#x2F;yum.repos.d &amp;&amp; mv CentOS-Base.repo CentOS-Base.repo.bak &amp;&amp; wget http://mirrors.163.com/.help/CentOS6-Base-163.repoecho “First,Update the system,Please wait…”yum -y updateecho “Now,install dependent libraries.Please waiting…”sleep 2yum -y install gcc gcc-c++ libtool ncurses ncurses-devel openssl openssl-devel libxml2 libxml2-devel bison libXpm libXpm-devel fontconfig-devel libtiff libtiff-devel curl curl-devel readline readline-devel bzip2 bzip2-devel sqlite sqlite-devel zlib zlib-devel#ncurses openssl bison Ϊ����mysql5����#libXpm libXpm-devel fontconfig-devel libtiff libtiff-devel Ϊ��װgd��������sourcedir&#x3D;”&#x2F;usr&#x2F;local&#x2F;src&#x2F;lnmp&#x2F;“[ “$PWD” !&#x3D; “$sourcedir” ] &amp;&amp; cd $sourcedir ##########################echo “Start the installation of libiconv…”sleep 2tar zxvf libiconv-1.14.tar.gz &amp;&amp; cd libiconv-1.14 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libiconv-1.14 has been successfully installed!’ cd ..echo “Start the installation of libxslt…”sleep 2tar zxvf libxslt-1.1.28.tar.gz &amp;&amp; cd libxslt-1.1.28 || exit 1 #�����&#x2F;bin&#x2F;rm: cannot remove &#96;libtoolT��: No such file or directory ��sed -i ‘&#x2F;$RM “$cfgfile”&#x2F; s&#x2F;^&#x2F;#&#x2F;‘ configure .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libxslt-1.1.28 has been successfully installed!’ cd ..echo “Start the installation of libmcrypt…”sleep 2tar zxvf libmcrypt-2.5.8.tar.gz &amp;&amp; cd libmcrypt-2.5.8 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libmcrypt-2.5.8 has been successfully installed!’ echo “Start the installation of libltdl…”sleep 2cd libltdl &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F; –enable-ltdl-install &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libltdl has been successfully installed!’ cd ..&#x2F;..&#x2F;echo “Start the installation of mhash…”sleep 2tar jxvf mhash-0.9.9.9.tar.bz2 &amp;&amp; cd mhash-0.9.9.9 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,mhash-0.9.9.9 has been successfully installed!’ echo “&#x2F;usr&#x2F;local&#x2F;lib” &gt;&gt; &#x2F;etc&#x2F;ld.so.confldconfig cd ..echo “Start the installation of mcrypt…”sleep 2tar zxvf mcrypt-2.6.8.tar.gz &amp;&amp; cd mcrypt-2.6.8 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,mcrypt-2.6.8 has been successfully installed!’ cd ..echo “Start the installation of libevent…”sleep 2tar zxvf libevent-2.0.21-stable.tar.gz &amp;&amp; cd libevent-2.0.21-stable &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libevent-2.0.21 has been successfully installed!’ cd ..echo “Start the installation of libpng…”sleep 2tar zxvf libpng-1.6.8.tar.gz &amp;&amp; cd libpng-1.6.8 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1#ln -s &#x2F;usr&#x2F;lib&#x2F;libpng15.so.15.12.0 &#x2F;usr&#x2F;lib64&#x2F;libpng15.so.15echo ‘OK,libpng-1.6.28 has been successfully installed!’ cd ..echo “Start the installation of jpeg…”sleep 2tar zxvf jpegsrc.v9.tar.gz &amp;&amp; cd jpeg-9 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –enable-shared –enable-static &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,jpeg-v9 has been successfully installed!’ cd ..echo “Start the installation of freetype…”sleep 2tar zxvf freetype-2.4.12.tar.gz &amp;&amp; cd freetype-2.4.12 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,freetype-2.4.12 has been successfully installed!’ cd ..echo “Start the installation of gd2…”sleep 2tar jxvf libgd-2.1.0.bz2 &amp;&amp; cd gd&#x2F;2.1.0 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-zlib –with-png&#x3D;&#x2F;usr –with-jpeg&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-freetype&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype –with-tiff&#x3D;&#x2F;usr&#x2F; &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,gd-2.1.0 has been successfully installed!’ cd ..&#x2F;..&#x2F;echo “Start the installation of cmake…”sleep 2tar zxvf cmake-2.8.12.1.tar.gz &amp;&amp; cd cmake-2.8.12.1 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,cmake-2.8.12.1 has been successfully installed!’ cd ..echo “Start the installation of mysql…”sleep 2 #yum -y install ncurses ncurses-devel openssl openssl-develyum install bisontar zxvf mysql-5.6.15.tar.gz &amp;&amp; cd mysql-5.6.15 &amp;&amp; cmake . -DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F; -DMYSQL_DATADIR&#x3D;&#x2F;data&#x2F;mysql&#x2F;data -DWITH_INNOBASE_STORAGE_ENGINE&#x3D;1 -DWITH_MYISAM_STORAGE_ENGINE&#x3D;1 -DENABLED_LOCAL_INFILE&#x3D;1 -DMYSQL_TCP_PORT&#x3D;3306 -DEXTRA_CHARSETS&#x3D;all -DDEFAULT_CHARSET&#x3D;utf8 -DDEFAULT_COLLATION&#x3D;utf8_general_ci -DWITH_PARTITION_STORAGE_ENGINE&#x3D;1 -DMYSQL_UNIX_ADDR&#x3D;&#x2F;tmp&#x2F;mysql.sock -DWITH_DEBUG&#x3D;0 -DWITH_SSL&#x3D;yes -DSYSCONFDIR&#x3D;&#x2F;data&#x2F;mysql -DMYSQL_TCP_PORT&#x3D;3306 &amp;&amp; make &amp;&amp; make install || exit 1#-DWITH_MEMORY_STORAGE_ENGINE&#x3D;1 -DWITH_INNOBASE_STORAGE_ENGINE&#x3D;1 -DWITH_MYISAM_STORAGE_ENGINE&#x3D;1֧�ֵ��������ݿ����棬������Ҫ����echo ‘OK,MySQL-5.6.15 has been successfully installed!’echo “Prepare for start MySQL,Please wait….”sleep 2useradd -s &#x2F;sbin&#x2F;nologin wwwuseradd -s &#x2F;sbin&#x2F;nologin mysqlmkdir -p &#x2F;data&#x2F;mysql&#x2F;{data,binlog,relaylog}chown -R mysql:mysql &#x2F;data&#x2F;mysqltouch &#x2F;data&#x2F;mysql&#x2F;my.cnfecho -ne “[client] default-character-set&#x3D;utf8 port &#x3D; 3306 socket &#x3D; &#x2F;tmp&#x2F;mysql.sock [mysqld] character-set-server &#x3D; utf8 collation-server &#x3D; utf8_general_ci #replicate-ignore-db &#x3D; mysql #replicate-ignore-db &#x3D; test #replicate-ignore-db &#x3D; information_schema user &#x3D; mysql port &#x3D; 3306 socket &#x3D; &#x2F;tmp&#x2F;mysql.sock basedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql datadir &#x3D; &#x2F;data&#x2F;mysql&#x2F;data explicit_defaults_for_timestamp&#x3D;true log-error &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql_error.log pid-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql.pid open_files_limit &#x3D; 10240 back_log &#x3D; 600 max_connections &#x3D; 5000 max_connect_errors &#x3D; 6000 external-locking &#x3D; FALSE max_allowed_packet &#x3D; 32M sort_buffer_size &#x3D; 1M join_buffer_size &#x3D; 1M thread_cache_size &#x3D; 300 thread_concurrency &#x3D; 8 query_cache_size &#x3D; 512M query_cache_limit &#x3D; 2M query_cache_min_res_unit &#x3D; 2k default-storage-engine &#x3D; MyISAM thread_stack &#x3D; 192K transaction_isolation &#x3D; READ-COMMITTED tmp_table_size &#x3D; 246M max_heap_table_size &#x3D; 246M long_query_time &#x3D; 3 log-slave-updates log-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;binlog&#x2F;binlog binlog_cache_size &#x3D; 4M binlog_format &#x3D; MIXED max_binlog_cache_size &#x3D; 8M max_binlog_size &#x3D; 1G expire-logs-days &#x3D; 30 relay-log-index &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog relay-log-info-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog relay-log &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog expire_logs_days &#x3D; 30 key_buffer_size &#x3D; 256M read_buffer_size &#x3D; 1M read_rnd_buffer_size &#x3D; 16M bulk_insert_buffer_size &#x3D; 64M myisam_sort_buffer_size &#x3D; 128M myisam_max_sort_file_size &#x3D; 10G myisam_repair_threads &#x3D; 1 ;myisam_recover interactive_timeout &#x3D; 120 wait_timeout &#x3D; 120 skip-name-resolve slave-skip-errors &#x3D; 1032,1062,126,1114,1146,1048,1396 server-id &#x3D; 1 ;innodb_additional_mem_pool_size &#x3D; 16M ;innodb_buffer_pool_size &#x3D; 512M ;innodb_data_file_path &#x3D; ibdata1:256M:autoextend ;innodb_file_io_threads &#x3D; 4 ;innodb_thread_concurrency &#x3D; 8 ;innodb_flush_log_at_trx_commit &#x3D; 2 ;innodb_log_buffer_size &#x3D; 16M ;innodb_log_file_size &#x3D; 128M ;innodb_log_files_in_group &#x3D; 3 ;innodb_max_dirty_pages_pct &#x3D; 90 ;innodb_lock_wait_timeout &#x3D; 120 ;innodb_file_per_table &#x3D; 0 slow_query_log slow_query_log_file &#x3D; &#x2F;data&#x2F;mysql&#x2F;slow.log long_query_time &#x3D; 1 log-queries-not-using-indexes [mysqldump] quick max_allowed_packet &#x3D; 32M ” &gt;&gt; &#x2F;data&#x2F;mysql&#x2F;my.cnfln -s &#x2F;data&#x2F;mysql&#x2F;my.cnf &#x2F;etc&#x2F;my.cnfcp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysql* &#x2F;usr&#x2F;bin&#x2F; &amp;&amp; cp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;support-files&#x2F;mysql.server &#x2F;etc&#x2F;init.d&#x2F;mysqld &amp;&amp; chmod +x &#x2F;etc&#x2F;init.d&#x2F;mysqld || exit 1&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;scripts&#x2F;mysql_install_db –user&#x3D;mysql –basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysqlmysqld_safe –user&#x3D;mysql &amp;killall mysqldservice mysqld start #������mysql������¼if [ -f &#x2F;root&#x2F;.mysql_history ];thenrm -f &#x2F;root&#x2F;.mysql_history &amp;&amp; ln -s &#x2F;dev&#x2F;null &#x2F;root&#x2F;.mysql_historyfi #����MySQL root���룬����������˻�mysql -u root mysql &lt; ..&#x2F;mysql.user.sql#mysqld������chkconfig –level 3 mysqld on#PHP-5.3.16cd ..echo “Start the installation of php…”sleep 2 #Start installationtar zxvf php-5.5.8.tar.gz &amp;&amp; cd php-5.5.8 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;php5.5.8 –with-config-file-path&#x3D;&#x2F;usr&#x2F;local&#x2F;php5.5.8&#x2F;etc –with-libxml-dir –with-iconv-dir –with-png-dir –with-jpeg-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-zlib –with-gd&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-freetype-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype –with-mcrypt&#x3D;&#x2F;usr –with-mhash –enable-gd-native-ttf –with-curl –with-bz2 –enable-mysqlnd –with-mysql&#x3D;mysqlnd –with-mysqli&#x3D;mysqlnd –with-pdo-mysql&#x3D;mysqlnd –with-openssl-dir –without-pear –enable-fpm –enable-mbstring –enable-soap –enable-xml –enable-pdo –enable-ftp –enable-zip –enable-bcmath –enable-sockets –enable-opcache &amp;&amp; make &amp;&amp; make install || exit 1cp ..&#x2F;{php.ini,php-fpm.conf} &#x2F;usr&#x2F;local&#x2F;php-5.5.8&#x2F;etc&#x2F; &amp;&amp; mkdir &#x2F;usr&#x2F;local&#x2F;php-5.5.8&#x2F;extln -s &#x2F;usr&#x2F;local&#x2F;php-5.5.8 &#x2F;usr&#x2F;local&#x2F;phpif [ ! -d &#x2F;data&#x2F;logs&#x2F;php ];thenmkdir -p &#x2F;data&#x2F;logs&#x2F;php #��־���Ŀ¼fiecho ‘OK,PHP-5.5.8 has been successfully installed!’ #opensslcd ext&#x2F;opensslmv mv config0.m4 config.m4&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize.&#x2F;configure –with-openssl –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;openssl.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;extcd ..#PHP-5.2.17#cd ..#tar zxvf php-5.2.17.tar.gz &amp;&amp; cd php-5.2.17#patch -p1 &lt; ..&#x2F;php-5.2.17-fpm-0.5.14.diff &amp;&amp; .&#x2F;buildconf –force || exit 1#rm -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.6.26 &amp;&amp; cp &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.7.4 &#x2F;usr&#x2F;lib64 &amp;&amp; rm -f &#x2F;usr&#x2F;lib64&#x2F;{libxml2.so,libxml2.so.2} &amp;&amp; ln -s &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2.7.4 &#x2F;usr&#x2F;lib64&#x2F;libxml2.so &amp;&amp; ln -s &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2.7.4 &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2 &amp;&amp; ln -s &#x2F;usr&#x2F;lib&#x2F;libpng14.so.14.4.0 &#x2F;usr&#x2F;lib64&#x2F;libpng14.so.14|| exit 1#.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;php-5.2.17 –with-config-file-path&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;etc –with-libxml-dir –with-iconv-dir –with-png-dir –with-jpeg-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-zlib –with-gd&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-freetype-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype –with-mcrypt –with-mhash –enable-gd-native-ttf –with-readline –with-curl –with-bz2 –with-mysql&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql –with-mysqli&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysql_config –with-openssl-dir –enable-fpm –enable-fastcgi –enable-mbstring –enable-soap –enable-xml –enable-pdo –enable-ftp –without-safe-mode –enable-zip –enable-bcmath –enable-sockets &amp;&amp; make &amp;&amp; make install || exit 1#cp php.ini-dist &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc &amp;&amp; cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;sbin&#x2F;php-fpm &#x2F;etc&#x2F;init.d&#x2F; &amp;&amp; chmod +x &#x2F;etc&#x2F;init.d&#x2F;php-fpm &amp;&amp; mkdir &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext#echo ‘OK,PHP-5.2.17 has been successfully installed!’#sleep 2 cd ..echo “Start the installation of nginx…”sleep 2 #����ngx_cache_purgeģ��#wget http://labs.frickle.com/files/ngx_cache_purge-1.5.tar.gz &amp;&amp; tar zxvf ngx_cache_purge-1.5.tar.gz#tar zxvf pcre-8.30.tar.gz &amp;&amp; mv pcre-8.30 &#x2F;usr&#x2F;local&#x2F; &amp;&amp; tar zxvf openssl-1.0.1c.tar.gz &amp;&amp; mv openssl-1.0.1c &#x2F;usr&#x2F;local&#x2F; &amp;&amp; tar zxvf nginx-1.2.3.tar.gz &amp;&amp; cd nginx-1.2.3 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx –add-module&#x3D;..&#x2F;ngx_cache_purge-1.5 –with-pcre&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre-8.30 –with-openssl&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl-1.0.1c –with-http_sub_module –with-http_ssl_module –with-http_stub_status_module &amp;&amp; make &amp;&amp; make install || exit 1 tar jxvf pcre-8.34.tar.bz2 &amp;&amp; mv pcre-8.34 &#x2F;usr&#x2F;local&#x2F; &amp;&amp; tar zxvf openssl-1.0.1g.tar.gz &amp;&amp; mv openssl-1.0.1g&#x2F;usr&#x2F;local&#x2F; &amp;&amp; tar zxvf nginx-1.5.8.tar.gz &amp;&amp; cd nginx-1.5.8 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx –with-pcre&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre-8.34 –with-openssl&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl-1.0.1g –with-http_sub_module –with-http_ssl_module –with-http_stub_status_module –with-http_realip_module &amp;&amp; make &amp;&amp; make install || exit 1cat ..&#x2F;nginx.conf &gt; &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.confecho ‘OK,nginx-1.4.2 has been successfully installed!’ if [ ! -d &#x2F;data&#x2F;www ];thenmkdir -p &#x2F;data&#x2F;wwwfichown www:www &#x2F;data&#x2F;www &amp;&amp; touch &#x2F;data&#x2F;www&#x2F;index.php &amp;&amp; echo -ne ‘‘ &gt; &#x2F;data&#x2F;www&#x2F;index.php cd ..echo “Start install re2c…”sleep 2tar zxvf re2c-0.13.6.tar.gz &amp;&amp; cd re2c-0.13.6 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1echo “OK,re2c-0.13.5 has been successfully installed!” #cd ..#echo “Start install eaccelerator…”#sleep 2#tar jxvf eaccelerator-0.9.6.1.tar.bz2 &amp;&amp; cd eaccelerator-0.9.6.1#&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –enable-eaccelerator&#x3D;shared –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1#cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20060613&#x2F;eaccelerator.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F; &amp;&amp; mkdir &#x2F;data&#x2F;eacache#echo -ne “[eaccelerator] extension&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;eaccelerator.so&quot; eaccelerator.shm_size&#x3D;&quot;32&quot; eaccelerator.cache_dir&#x3D;&quot;&#x2F;data&#x2F;eacache&quot; eaccelerator.enable&#x3D;&quot;1&quot; eaccelerator.optimizer&#x3D;&quot;1&quot; eaccelerator.check_mtime&#x3D;&quot;1&quot; eaccelerator.debug&#x3D;&quot;0&quot; eaccelerator.filter&#x3D;&quot;&quot; eaccelerator.shm_max&#x3D;&quot;0&quot; eaccelerator.shm_ttl&#x3D;&quot;0&quot; eaccelerator.shm_prune_period&#x3D;&quot;0&quot; eaccelerator.shm_only&#x3D;&quot;0&quot; eaccelerator.compress&#x3D;&quot;1&quot; eaccelerator.compress_level&#x3D;&quot;9&quot; ” &gt;&gt; &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php.ini#echo “OK,Eaccelerator-0.9.6.1 has been successfully installed!”#sleep 2 #cd ..#echo “Start the installation of memcached…”#sleep 2#tar zxvf memcached-1.4.17.tar.gz &amp;&amp; cd memcached-1.4.17 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;memcached –with-libevent &amp;&amp; make &amp;&amp; make install || exit#echo “OK,memcached-1.4.17 has been successfully installed!”#sleep 2 #echo “Starting memcached,please wait….”#sleep 2#&#x2F;usr&#x2F;local&#x2F;memcached&#x2F;bin&#x2F;memcached -d -m 256 -u root -P &#x2F;tmp&#x2F;memcached.pid &amp;&amp; echo “OK,memcached is runing now” || exit 1#echo “&#x2F;usr&#x2F;local&#x2F;memcached&#x2F;bin&#x2F;memcached -d -m 256 -u root -P &#x2F;tmp&#x2F;memcached.pid” &gt;&gt; &#x2F;etc&#x2F;rc.d&#x2F;rc.local#sleep 2 cd ..echo “Start install memcache extension…”#���php�汾Ϊ5.2����memcacheʹ��2.2.6�汾���������汾���⵼��php�޷�����memcachģ�顣sleep 2tar zxvf memcache-3.0.8.tgz &amp;&amp; cd memcache-3.0.8 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –enable-memcache –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;memcache.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;echo “OK,Memcache-3.0.6 installed successfully!” cd ..echo “Start install pdf extension…”tar zxvf PDFlib-Lite-7.0.5p3.tar.gz &amp;&amp; cd PDFlib-Lite-7.0.5p3.tar.gz.&#x2F;configure –prefix&#x3D;&#x2F;Data&#x2F;app&#x2F;pdflib &amp;&amp; make &amp;&amp; make installcd ..tar zxvf pdflib-3.0.4.tgz &amp;&amp; cd pdflib-3.0.4.tgz${php_prefix}&#x2F;bin&#x2F;phpize.&#x2F;configure –with-php-config&#x3D;&#x2F;Data&#x2F;app&#x2F;php&#x2F;bin&#x2F;php-config –with-pdflib&#x3D;&#x2F;Data&#x2F;app&#x2F;pdflib&#x2F;make &amp;&amp; make install #cd ..#echo “Start install ImageMagick…”#sleep 2#tar zxvf ImageMagick-6.8.8-2.tar.gz &amp;&amp; cd ImageMagick-6.8.8-2&amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;imagemagick &amp;&amp; make &amp;&amp; make install || exit 1#echo “&#x2F;usr&#x2F;local&#x2F;imagemagick&#x2F;lib” &gt;&gt; &#x2F;etc&#x2F;ld.so.conf &amp;&amp; ldconfig#echo “OK,ImageMagick-6.8.8-2 has been installed successfully!”#sleep 2 #cd ..#echo “Start install imagick for php …”#tar zxvf imagick-3.1.2.tgz &amp;&amp; cd imagick-3.1.2 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –with-imagick&#x3D;&#x2F;usr&#x2F;local&#x2F;imagemagick –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1#cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20060613&#x2F;imagick.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;#echo “OK,imagick-3.1.2 for php has been installed successfully!”#sleep 2 #php5.3֮����Ҫ�ٵ�����װPDO_MYSQL#cd ..#echo “Start install PDO_MYSQL …”#tar zxvf PDO_MYSQL-1.0.2.tgz &amp;&amp; cd PDO_MYSQL-1.0.2 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config –with-pdo-mysql&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql &amp;&amp; make &amp;&amp; make install || exit 1#cp modules&#x2F;pdo_mysql.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;#echo “OK,PDO_MYSQL-1.0.2 has been installed successfully!” #cd ..#echo “Start install APC …”#tar zxvf APC-3.1.9.tgz &amp;&amp; cd APC-3.1.9#&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize#.&#x2F;configure –enable-apc –with-apc-mmap –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install#cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;apc.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;#echo -ne “[APC] extension &#x3D; &quot;apc.so&quot; apc.enabled &#x3D; 1 apc.cache_by_default &#x3D; on apc.shm_size &#x3D; 32M apc.ttl &#x3D; 600 apc.user_ttl &#x3D; 600 apc.write_lock &#x3D; on” &gt;&gt; &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php.ini#echo -ne “APC-3.1.9 has been installed successfully!”cd .. #yaf.sotar zxvf yaf-2.2.7.tgz &amp;&amp; cd yaf-2.2.7&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make installcp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;yaf.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F; #nginx&#x2F;mysql&#x2F;php auto runningecho “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf” &gt;&gt; &#x2F;etc&#x2F;rc.d&#x2F;rc.localecho “&#x2F;usr&#x2F;local&#x2F;php&#x2F;sbin&#x2F;php-fpm” &gt;&gt; &#x2F;etc&#x2F;rc.d&#x2F;rc.local #ulimitsed -i ‘$i * - nofile 65535\\ soft core 0\\ hard core 0&#39; /etc/security/limits.conf #sysctl.confcat sysctl.conf &gt;&gt; &#x2F;etc&#x2F;sysctl.conf &amp;&amp; chown root:root &#x2F;etc&#x2F;sysctl.conf &amp;&amp; chmod 0600 &#x2F;etc&#x2F;sysctl.conf #history��������ʱ��sed -i ‘&#x2F;HISTSIZE&#x2F;a HISTTIMEFORMAT&#x3D;”%Y%m%d-%H%M%S:”‘ &#x2F;etc&#x2F;profilesed -i ‘&#x2F;export&#x2F; s&#x2F;$&#x2F; HISTTIMEFORMAT&#x2F;‘ &#x2F;etc&#x2F;profile #su&#x2F;sudo#��wheel���Ա����ʹ��sused -i ‘&#x2F;required&#x2F; s&#x2F;^#&#x2F;&#x2F;‘ &#x2F;etc&#x2F;pam.d&#x2F;suecho “SU_WHEEL_ONLY yes” &gt;&gt; &#x2F;etc&#x2F;login.defs #sudo#Cmnd_Alias MANAGER &#x3D; &#x2F;sbin&#x2F;route, &#x2F;sbin&#x2F;ifconfig, &#x2F;bin&#x2F;ping, &#x2F;sbin&#x2F;iptables, &#x2F;sbin&#x2F;service, &#x2F;sbin&#x2F;chkconfig, &#x2F;bin&#x2F;chmod, &#x2F;bin&#x2F;chown, &#x2F;bin&#x2F;chgrp#User_Alias ADMINS &#x3D; #root ALL&#x3D;(ALL) ALL#ADMINS ALL&#x3D;(ALL) MANAGER #vim_editoryum -y install vim-enhancedcp &#x2F;etc&#x2F;vimrc &#x2F;root&#x2F;.vimrcecho -ne “set confirm set nobackup set noswapfile set hlsearch set incsearch set cmdheight&#x3D;2 let &amp;termencoding&#x3D;&amp;encoding set fileencodings&#x3D;utf-8,gbk set autoindent set smartindent set tabstop&#x3D;4 set shiftwidth&#x3D;4” &gt;&gt; &#x2F;root&#x2F;.vimrcsource &#x2F;root&#x2F;.vimrcsed -i “7a alias vi&#x3D;’vim’” &#x2F;root&#x2F;.bashrc. &#x2F;root&#x2F;.bashrc echo -ne “OK,That is all! Thanks ” #10���Ӻ�����echo -n “reboot system right now?[Y&#x2F;n]”read -n 1 answercase $answer inY|y) echofor i in $(seq -w 10| tac)do echo -ne “\\aThe system will reboot after $i seconds…\\r” sleep 1doneechoshutdown -r now;;N|n)echo;;esacexit 0"},{"path":"/2023/09/28/Linux配置文件/lnmp/lnmp_32.sh/","content":"#!&#x2F;bin&#x2F;bashecho “Renew the sources for yum,please wait…”sleep 2#cd &#x2F;etc&#x2F;yum.repos.d &amp;&amp; mv CentOS-Base.repo CentOS-Base.repo.bak &amp;&amp; wget http://mirrors.163.com/.help/CentOS-Base-163.repo#echo “First,Update the system,Please wait…”#yum -y updateecho “Now,install dependent libraries.Please waiting…”sleep 2yum -y install gcc gcc-c++ libtool ncurses ncurses-devel openssl openssl-devel curl curl-devel readline readline-devel bzip2 bzip2-devel fontconfig-devel sqlite sqlite-devel zlib zlib-develsourcedir&#x3D;”&#x2F;usr&#x2F;local&#x2F;src&#x2F;lnmp&#x2F;“ [ “$PWD” !&#x3D; “$sourcedir” ] &amp;&amp; cd $sourcedir echo “Start the installation of libxml2…”sleep 2tar zxvf libxml2-2.7.6.tar.gz &amp;&amp; cd libxml2-2.7.6#ע�͵�configure�ļ��е�ĳ�У������&#x2F;bin&#x2F;rm: cannot remove &#96;libtoolT��: No such file or directory ��sed -i ‘&#x2F;$RM “$cfgfile”&#x2F; s&#x2F;^&#x2F;#&#x2F;‘ configure.&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1#�±ߵĲ��������PHP�Ȱ�װ��������ʾlibxml2.so.2�汾����libxml�Ҳ������Ҳ���libpng14.so.14�����⡣if [ -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so ];thenrm -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so &amp;&amp; ln -s &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.7.6 &#x2F;usr&#x2F;lib&#x2F;libxml2.sofiif [ -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2 ];thenrm -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2 &amp;&amp; ln -s &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.7.6 &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2fiif [ -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.6.26 ];thenrm -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.6.26fi #echo ‘OK,libxml2-2.7.6 has been successfully installed!’##########################cd ..echo “Start the installation of libiconv…”sleep 2tar zxvf libiconv-1.14.tar.gz &amp;&amp; cd libiconv-1.14 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libiconv-1.14 has been successfully installed!’ cd ..echo “Start the installation of libxslt…”sleep 2tar zxvf libxslt-1.1.28.tar.gz &amp;&amp; cd libxslt-1.1.28 || exit 1#ע�͵�configure�ļ��е�ĳ�У������&#x2F;bin&#x2F;rm: cannot remove &#96;libtoolT��: No such file or directory ��sed -i ‘&#x2F;$RM “$cfgfile”&#x2F; s&#x2F;^&#x2F;#&#x2F;‘ configure.&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libxslt-1.1.26 has been successfully installed!’ cd ..echo “Start the installation of libmcrypt…”sleep 2tar zxvf libmcrypt-2.5.8.tar.gz &amp;&amp; cd libmcrypt-2.5.8 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libmcrypt-2.5.8 has been successfully installed!’ echo “Start the installation of libltdl…”sleep 2cd libltdl &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F; –enable-ltdl-install &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libltdl has been successfully installed!’ cd ..&#x2F;..&#x2F;echo “Start the installation of mhash…”sleep 2tar jxvf mhash-0.9.9.9.tar.bz2 &amp;&amp; cd mhash-0.9.9.9 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,mhash-0.9.9.9 has been successfully installed!’ echo “&#x2F;usr&#x2F;local&#x2F;lib” &gt;&gt; &#x2F;etc&#x2F;ld.so.confldconfig cd ..echo “Start the installation of mcrypt…”sleep 2tar zxvf mcrypt-2.6.8.tar.gz &amp;&amp; cd mcrypt-2.6.8 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,mcrypt-2.6.8 has been successfully installed!’ cd ..echo “Start the installation of libevent…”sleep 2tar zxvf libevent-2.0.21-stable.tar.gz &amp;&amp; cd libevent-2.0.19-stable &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libevent-2.0.21 has been successfully installed!’ cd ..echo “Start the installation of libpng…”sleep 2tar zxvf libpng-1.6.2.tar.gz &amp;&amp; cd libpng-1.6.2 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libpng-1.6.2 has been successfully installed!’ cd ..echo “Start the installation of jpeg…”sleep 2tar zxvf jpegsrc.v9.tar.gz &amp;&amp; cd jpeg-9 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –enable-shared –enable-static &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,jpeg-v9 has been successfully installed!’ cd ..echo “Start the installation of freetype…”sleep 2tar zxvf freetype-2.4.12.tar.gz &amp;&amp; cd freetype-2.4.12 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,freetype-2.4.12 has been successfully installed!’ cd ..echo “Start the installation of gd2…”sleep 2tar zxvf gd-2.0.35.tar.gz &amp;&amp; cd gd&#x2F;2.0.35 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-zlib –with-png –with-jpeg&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-freetype&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,gd-2.0.35 has been successfully installed!’ cd ..&#x2F;..&#x2F;echo “Start the installation of cmake…”sleep 2tar zxvf cmake-2.8.11.2.tar.gz &amp;&amp; cd cmake-2.8.11.2 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,cmake-2.8.11has been successfully installed!’ cd ..echo “Start the installation of mysql…”sleep 2 tar zxvf mysql-5.6.12.tar.gz &amp;&amp; cd mysql-5.6.12 &amp;&amp; cmake . -DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F; -DMYSQL_DATADIR&#x3D;&#x2F;data&#x2F;mysql&#x2F;data -DWITH_INNOBASE_STORAGE_ENGINE&#x3D;1 -DWITH_MYISAM_STORAGE_ENGINE&#x3D;1 -DWITH_MEMORY_STORAGE_ENGINE&#x3D;1 -DENABLED_LOCAL_INFILE&#x3D;1 -DMYSQL_TCP_PORT&#x3D;3306 -DEXTRA_CHARSETS&#x3D;all -DDEFAULT_CHARSET&#x3D;utf8 -DDEFAULT_COLLATION&#x3D;utf8_general_ci -DWITH_PARTITION_STORAGE_ENGINE&#x3D;1 -DMYSQL_UNIX_ADDR&#x3D;&#x2F;tmp&#x2F;mysql.sock -DWITH_DEBUG&#x3D;0 -DWITH_SSL&#x3D;yes -DSYSCONFDIR&#x3D;&#x2F;data&#x2F;mysql -DMYSQL_TCP_PORT&#x3D;3306 &amp;&amp; make &amp;&amp; make install || exit 1 echo ‘OK,MySQL-5.6.12 has been successfully installed!’ echo “Prepare for start MySQL,Please wait….”sleep 2useradd -s &#x2F;sbin&#x2F;nologin wwwuseradd -s &#x2F;sbin&#x2F;nologin mysqlmkdir -p &#x2F;data&#x2F;mysql&#x2F;{data,binlog,relaylog}chown -R mysql:mysql &#x2F;data&#x2F;mysqltouch &#x2F;data&#x2F;mysql&#x2F;my.cnfecho -ne “[client] default-character-set&#x3D;gbk port &#x3D; 3306 socket &#x3D; &#x2F;tmp&#x2F;mysql.sock [mysqld] character-set-server &#x3D; gbk collation-server &#x3D; gbk_chinese_ci #replicate-ignore-db &#x3D; mysql #replicate-ignore-db &#x3D; test #replicate-ignore-db &#x3D; information_schema user &#x3D; mysql port &#x3D; 3306 socket &#x3D; &#x2F;tmp&#x2F;mysql.sock basedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql datadir &#x3D; &#x2F;data&#x2F;mysql&#x2F;data explicit_defaults_for_timestamp&#x3D;true log-error &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql_error.log pid-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql.pid open_files_limit &#x3D; 10240 back_log &#x3D; 600 max_connections &#x3D; 5000 max_connect_errors &#x3D; 6000 table_cache &#x3D; 614 external-locking &#x3D; FALSE max_allowed_packet &#x3D; 32M sort_buffer_size &#x3D; 1M join_buffer_size &#x3D; 1M thread_cache_size &#x3D; 300 thread_concurrency &#x3D; 8 query_cache_size &#x3D; 512M query_cache_limit &#x3D; 2M query_cache_min_res_unit &#x3D; 2k default-storage-engine &#x3D; MyISAM thread_stack &#x3D; 192K transaction_isolation &#x3D; READ-COMMITTED tmp_table_size &#x3D; 246M max_heap_table_size &#x3D; 246M long_query_time &#x3D; 3 log-slave-updates log-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;binlog&#x2F;binlog binlog_cache_size &#x3D; 4M binlog_format &#x3D; MIXED max_binlog_cache_size &#x3D; 8M max_binlog_size &#x3D; 1G expire-logs-days &#x3D; 30 relay-log-index &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog relay-log-info-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog relay-log &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog expire_logs_days &#x3D; 30 key_buffer_size &#x3D; 256M read_buffer_size &#x3D; 1M read_rnd_buffer_size &#x3D; 16M bulk_insert_buffer_size &#x3D; 64M myisam_sort_buffer_size &#x3D; 128M myisam_max_sort_file_size &#x3D; 10G myisam_repair_threads &#x3D; 1 ;myisam_recover interactive_timeout &#x3D; 120 wait_timeout &#x3D; 120 skip-name-resolve slave-skip-errors &#x3D; 1032,1062,126,1114,1146,1048,1396 server-id &#x3D; 1 ;innodb_additional_mem_pool_size &#x3D; 16M ;innodb_buffer_pool_size &#x3D; 512M ;innodb_data_file_path &#x3D; ibdata1:256M:autoextend ;innodb_file_io_threads &#x3D; 4 ;innodb_thread_concurrency &#x3D; 8 ;innodb_flush_log_at_trx_commit &#x3D; 2 ;innodb_log_buffer_size &#x3D; 16M ;innodb_log_file_size &#x3D; 128M ;innodb_log_files_in_group &#x3D; 3 ;innodb_max_dirty_pages_pct &#x3D; 90 ;innodb_lock_wait_timeout &#x3D; 120 ;innodb_file_per_table &#x3D; 0 slow_query_log slow_query_log_file &#x3D; &#x2F;data&#x2F;mysql&#x2F;slow.log long_query_time &#x3D; 1 log-queries-not-using-indexes [mysqldump] quick max_allowed_packet &#x3D; 32M ” &gt;&gt; &#x2F;data&#x2F;mysql&#x2F;my.cnfln -s &#x2F;data&#x2F;mysql&#x2F;my.cnf &#x2F;etc&#x2F;my.cnfcp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysql* &#x2F;usr&#x2F;bin&#x2F; &amp;&amp; cp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;support-files&#x2F;mysql.server &#x2F;etc&#x2F;init.d&#x2F;mysqld &amp;&amp; chmod +x &#x2F;etc&#x2F;init.d&#x2F;mysqld || exit 1&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;scripts&#x2F;mysql_install_db –user&#x3D;mysql –basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysqlmysqld_safe –user&#x3D;mysql &amp;killall mysqldservice mysqld start #������mysql������¼if [ -f &#x2F;root&#x2F;.mysql_history ];thenrm -f &#x2F;root&#x2F;.mysql_history &amp;&amp; ln -s &#x2F;dev&#x2F;null &#x2F;root&#x2F;.mysql_historyfi #����MySQL root���룬����������˻�mysql -u root mysql &lt; ..&#x2F;mysql.user.sql#mysqld������chkconfig –level 3 mysqld on #PHP-5.3.16cd ..echo “Start the installation of php…”sleep 2 #Start installationtar zxvf php-5.3.16.tar.gz &amp;&amp; cd php-5.3.16 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;php –with-config-file-path&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;etc –with-libxml-dir –with-iconv-dir –with-png-dir –with-jpeg-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-zlib –with-gd&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-freetype-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype –with-mcrypt –with-mhash –enable-gd-native-ttf –with-readline –with-curl –with-bz2 –with-mysql&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql –with-mysqli&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysql_config –with-openssl-dir –without-pear –enable-fpm –enable-mbstring –enable-soap –enable-xml –enable-pdo –enable-ftp –enable-zip –enable-bcmath –enable-sockets &amp;&amp; make &amp;&amp; make install || exit 1cp ..&#x2F;{php.ini,php-fpm.conf} &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F; &amp;&amp; mkdir &#x2F;usr&#x2F;local&#x2F;php&#x2F;extif [ ! -d &#x2F;data&#x2F;logs&#x2F;php ];thenmkdir -p &#x2F;data&#x2F;logs&#x2F;php #��־���Ŀ¼fiecho ‘OK,PHP-5.3.16 has been successfully installed!’ #PHP-5.2.17#cd ..#tar zxvf php-5.2.17.tar.gz &amp;&amp; cd php-5.2.17#patch -p1 &lt; ..&#x2F;php-5.2.17-fpm-0.5.14.diff &amp;&amp; .&#x2F;buildconf –force || exit 1#rm -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.6.26 &amp;&amp; cp &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.7.4 &#x2F;usr&#x2F;lib64 &amp;&amp; rm -f &#x2F;usr&#x2F;lib64&#x2F;{libxml2.so,libxml2.so.2} &amp;&amp; ln -s &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2.7.4 &#x2F;usr&#x2F;lib64&#x2F;libxml2.so &amp;&amp; ln -s &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2.7.4 &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2 &amp;&amp; ln -s &#x2F;usr&#x2F;lib&#x2F;libpng14.so.14.4.0 &#x2F;usr&#x2F;lib64&#x2F;libpng14.so.14|| exit 1#.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;php –with-config-file-path&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;etc –with-libxml-dir –with-iconv-dir –with-png-dir –with-jpeg-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-zlib –with-gd&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-freetype-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype –with-mcrypt –with-mhash –enable-gd-native-ttf –with-readline –with-curl –with-bz2 –with-mysql&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql –with-mysqli&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysql_config –with-openssl-dir –enable-fpm –enable-fastcgi –enable-mbstring –enable-soap –enable-xml –enable-pdo –enable-ftp –enable-safe-mode –enable-zip –enable-bcmath –enable-sockets &amp;&amp; make &amp;&amp; make install || exit 1#cp php.ini-dist &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc &amp;&amp; cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;sbin&#x2F;php-fpm &#x2F;etc&#x2F;init.d&#x2F; &amp;&amp; chmod +x &#x2F;etc&#x2F;init.d&#x2F;php-fpm &amp;&amp; mkdir &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext#echo ‘OK,PHP-5.2.17 has been successfully installed!’#sleep 2 cd ..echo “Start the installation of nginx…”sleep 2 #����ngx_cache_purgeģ��#wget http://labs.frickle.com/files/ngx_cache_purge-1.5.tar.gz &amp;&amp; tar zxvf ngx_cache_purge-1.5.tar.gz#tar zxvf pcre-8.30.tar.gz &amp;&amp; mv pcre-8.30 &#x2F;usr&#x2F;local&#x2F; &amp;&amp; tar zxvf openssl-1.0.1c.tar.gz &amp;&amp; mv openssl-1.0.1c &#x2F;usr&#x2F;local&#x2F; &amp;&amp; tar zxvf nginx-1.2.3.tar.gz &amp;&amp; cd nginx-1.2.3 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx –add-module&#x3D;..&#x2F;ngx_cache_purge-1.5 –with-pcre&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre-8.30 –with-openssl&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl-1.0.1c –with-http_sub_module –with-http_ssl_module –with-http_stub_status_module &amp;&amp; make &amp;&amp; make install || exit 1 tar zxvf pcre-8.30.tar.gz &amp;&amp; mv pcre-8.30 &#x2F;usr&#x2F;local&#x2F; &amp;&amp; tar zxvf openssl-1.0.1c.tar.gz &amp;&amp; mv openssl-1.0.1c &#x2F;usr&#x2F;local&#x2F; &amp;&amp; tar zxvf nginx-1.2.3.tar.gz &amp;&amp; cd nginx-1.2.3 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx –with-pcre&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre-8.30 –with-openssl&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl-1.0.1c –with-http_sub_module –with-http_ssl_module –with-http_stub_status_module &amp;&amp; make &amp;&amp; make install || exit 1cat ..&#x2F;nginx.conf &gt; &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.confecho ‘OK,nginx-1.2.3 has been successfully installed!’ if [ ! -d &#x2F;data&#x2F;www ];thenmkdir -p &#x2F;data&#x2F;wwwfichown www:www &#x2F;data&#x2F;www &amp;&amp; touch &#x2F;data&#x2F;www&#x2F;index.php &amp;&amp; echo -ne ‘‘ &gt; &#x2F;data&#x2F;www&#x2F;index.php cd ..echo “Start install re2c…”sleep 2tar zxvf re2c-0.13.5.tar.gz &amp;&amp; cd re2c-0.13.5 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1echo “OK,re2c-0.13.5 has been successfully installed!” #cd ..#echo “Start install eaccelerator…”#sleep 2#tar jxvf eaccelerator-0.9.6.1.tar.bz2 &amp;&amp; cd eaccelerator-0.9.6.1#&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –enable-eaccelerator&#x3D;shared –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1#cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20060613&#x2F;eaccelerator.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F; &amp;&amp; mkdir &#x2F;data&#x2F;eacache#echo -ne “[eaccelerator] extension&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;eaccelerator.so&quot; eaccelerator.shm_size&#x3D;&quot;32&quot; eaccelerator.cache_dir&#x3D;&quot;&#x2F;data&#x2F;eacache&quot; eaccelerator.enable&#x3D;&quot;1&quot; eaccelerator.optimizer&#x3D;&quot;1&quot; eaccelerator.check_mtime&#x3D;&quot;1&quot; eaccelerator.debug&#x3D;&quot;0&quot; eaccelerator.filter&#x3D;&quot;&quot; eaccelerator.shm_max&#x3D;&quot;0&quot; eaccelerator.shm_ttl&#x3D;&quot;0&quot; eaccelerator.shm_prune_period&#x3D;&quot;0&quot; eaccelerator.shm_only&#x3D;&quot;0&quot; eaccelerator.compress&#x3D;&quot;1&quot; eaccelerator.compress_level&#x3D;&quot;9&quot; ” &gt;&gt; &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php.ini#echo “OK,Eaccelerator-0.9.6.1 has been successfully installed!”#sleep 2 #cd ..#echo “Start the installation of memcached…”#sleep 2#tar zxvf memcached-1.4.13.tar.gz &amp;&amp; cd memcached-1.4.13 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;memcached –with-libevent &amp;&amp; make &amp;&amp; make install || exit#echo “OK,memcached-1.4.13 has been successfully installed!”#sleep 2 #echo “Starting memcached,please wait….”#sleep 2#&#x2F;usr&#x2F;local&#x2F;memcached&#x2F;bin&#x2F;memcached -d -m 256 -u root -P &#x2F;tmp&#x2F;memcached.pid &amp;&amp; echo “OK,memcached is runing now” || exit 1#echo “&#x2F;usr&#x2F;local&#x2F;memcached&#x2F;bin&#x2F;memcached -d -m 256 -u root -P &#x2F;tmp&#x2F;memcached.pid” &gt;&gt; &#x2F;etc&#x2F;rc.d&#x2F;rc.local#sleep 2 cd ..echo “Start install memcache extension…”#���php�汾Ϊ5.2����memcacheʹ��2.2.6�汾���������汾���⵼��php�޷�����memcachģ�顣sleep 2tar zxvf memcache-3.0.6.tgz &amp;&amp; cd memcache-3.0.6 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –enable-memcache –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;memcache.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;echo “OK,Memcache-3.0.6 installed successfully!” #cd ..#echo “Start install ImageMagick…”#sleep 2#tar zxvf ImageMagick-6.6.9-10.tar.gz &amp;&amp; cd ImageMagick-6.6.9-10 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;imagemagick &amp;&amp; make &amp;&amp; make install || exit 1#echo “&#x2F;usr&#x2F;local&#x2F;imagemagick&#x2F;lib” &gt;&gt; &#x2F;etc&#x2F;ld.so.conf &amp;&amp; ldconfig#echo “OK,ImageMagick-6.6.9-10 has been installed successfully!”#sleep 2 #cd ..#echo “Start install imagick for php …”#tar zxvf imagick-3.0.1.tgz &amp;&amp; cd imagick-3.0.1 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –with-imagick&#x3D;&#x2F;usr&#x2F;local&#x2F;imagemagick –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1#cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20060613&#x2F;imagick.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;#echo “OK,imagick-3.0.1 for php has been installed successfully!”#sleep 2 cd ..echo “Start install PDO_MYSQL …”tar zxvf PDO_MYSQL-1.0.2.tgz &amp;&amp; cd PDO_MYSQL-1.0.2 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config –with-pdo-mysql&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql &amp;&amp; make &amp;&amp; make install || exit 1cp modules&#x2F;pdo_mysql.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;echo “OK,PDO_MYSQL-1.0.2 has been installed successfully!” cd ..echo “Start install APC …”tar zxvf APC-3.1.9.tgz &amp;&amp; cd APC-3.1.9&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize.&#x2F;configure –enable-apc –with-apc-mmap –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make installcp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;apc.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;#echo -ne “[APC] extension &#x3D; &quot;apc.so&quot; apc.enabled &#x3D; 1 apc.cache_by_default &#x3D; on apc.shm_size &#x3D; 32M apc.ttl &#x3D; 600 apc.user_ttl &#x3D; 600 apc.write_lock &#x3D; on” &gt;&gt; &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php.iniecho -ne “APC-3.1.9 has been installed successfully!”cd .. #yaf.so#yaf.sotar zxvf yaf-2.2.7.tgz &amp;&amp; cd yaf-2.2.7&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make installcp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;yaf.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F; #nginx&#x2F;mysql&#x2F;php auto runningecho “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf” &gt;&gt; &#x2F;etc&#x2F;rc.d&#x2F;rc.localecho “&#x2F;usr&#x2F;local&#x2F;php&#x2F;sbin&#x2F;php-fpm” &gt;&gt; &#x2F;etc&#x2F;rc.d&#x2F;rc.local#chkconfig –level 3 mysqld on#ulimitsed -i ‘$i * - nofile 65535\\ soft core 0\\ hard core 0&#39; /etc/security/limits.conf #sysctl.confcat sysctl.conf &gt;&gt; &#x2F;etc&#x2F;sysctl.conf &amp;&amp; chown root:root &#x2F;etc&#x2F;sysctl.conf &amp;&amp; chmod 0600 &#x2F;etc&#x2F;sysctl.conf #history��������ʱ��sed -i ‘&#x2F;HISTSIZE&#x2F;a HISTTIMEFORMAT&#x3D;”%Y%m%d-%H%M%S:”‘ &#x2F;etc&#x2F;profilesed -i ‘&#x2F;export&#x2F; s&#x2F;$&#x2F; HISTTIMEFORMAT&#x2F;‘ &#x2F;etc&#x2F;profile #su&#x2F;sudo#��wheel���Ա����ʹ��sused -i ‘&#x2F;required&#x2F; s&#x2F;^#&#x2F;&#x2F;‘ &#x2F;etc&#x2F;pam.d&#x2F;suecho “SU_WHEEL_ONLY yes” &gt;&gt; &#x2F;etc&#x2F;login.defs#sudo#Cmnd_Alias MANAGER &#x3D; &#x2F;sbin&#x2F;route, &#x2F;sbin&#x2F;ifconfig, &#x2F;bin&#x2F;ping, &#x2F;sbin&#x2F;iptables, &#x2F;sbin&#x2F;service, &#x2F;sbin&#x2F;chkconfig, &#x2F;bin&#x2F;chmod, &#x2F;bin&#x2F;chown, &#x2F;bin&#x2F;chgrp#User_Alias ADMINS &#x3D; #root ALL&#x3D;(ALL) ALL#ADMINS ALL&#x3D;(ALL) MANAGER #vim_editoryum install vim-enhancedcp &#x2F;etc&#x2F;vimrc &#x2F;root&#x2F;.vimrcecho -ne “set confirm set nobackup set noswapfile set hlsearch set incsearch set cmdheight&#x3D;2 let &amp;termencoding&#x3D;&amp;encoding set fileencodings&#x3D;utf-8,gbk set autoindent set smartindent set tabstop&#x3D;4 set shiftwidth&#x3D;4” &gt;&gt; &#x2F;root&#x2F;.vimrcsource &#x2F;root&#x2F;.vimrcsed -i “7a alias vi&#x3D;’vim’” &#x2F;root&#x2F;.bashrcsource &#x2F;root&#x2F;.bashrc echo -ne “OK,That is all! Thanks ” #10���Ӻ�����for i in $(seq 10| tac)do echo -ne “\\aThe system will reboot after $i seconds…\\r” sleep 1doneechoshutdown -r now"},{"path":"/2023/09/28/Linux配置文件/lnmp/iptables_web.sh/","content":"#!&#x2F;bin&#x2F;bashecho “[+] Setting up Defult policy…”iptables -P INPUT DROPiptables -P FORWARD DROPiptables -P OUTPUT DROP echo “[+] Setting up INPUT chain…”-A INPUT -m state –state INVALID -j LOG –log-prefix “DROP VALID” –log-ip-optioins –log-tcp-optionsiptables -A INPUT -m state –state INVALID -j DROPiptables -A INPUT -i lo -j ACCEPT#开放httpiptables -A INPUT -i eth0 -p tcp –dport 80 –syn -m state –state NEW -j ACCEPT#开放sshiptables -A INPUT -i eth0 -p tcp –dport 22 –syn -m state –state NEW -j ACCEPT#ICMPiptables -A INPUT -P icmp –icmp-type echo-request -j ACCEPT #SYN洪水攻击#iptables -A INPUT -p tcp –syn -m limit –limit 1&#x2F;s -j ACCEPT#屏蔽 SYN_RECV 的连接#iptables -A INPUT -p tcp –tcp-flags SYN,RST,ACK SYN -m limit –limit 1&#x2F;sec -j ACCEPT #封包状态iptables -A INPUT -i eth0 -m state –state ESTABLISHED,RELATED -j ACCEPT echo “[+] Setting up OUTPUT chain…”iptables -A OUTPUT -m state –state INVALID -j LOG –log-prefix “DROP INVALID” –log-ip-options –log-tcp-optionsiptables -A OUTPUT -m state –state INVALID -j DROPiptables -A OUTPUT -o lo -j ACCEPT#dnsiptables -A OUTPUT -p udp –dport 53 -m state –state NEW -j ACCEPT#开放邮件发送iptables -A OUTPUT -p tcp –dport 25 –syn -m state –state NEW -j ACCEPT#允许服务器发起http请求iptables -A OUTPUT -p tcp –dport 80 –syn -m state –state NEW -j ACCEPT#ICMPiptables -A OUTPUT -p icmp –icmp-type echo-request -j ACCEPT#封包状态iptables -A OUTPUT -m state –state ESTABLISHED,RELATED -j ACCEPT iptables saveecho “[+] Done.”"},{"path":"/2023/09/28/Linux配置文件/lnmp/iptables_vps_master/","content":"Generated by iptables-save v1.3.5 on Wed Jul 20 16:22:45 2011*nat:PREROUTING ACCEPT [625:44365]:POSTROUTING ACCEPT [10:1067]:OUTPUT ACCEPT [3:723]#phpchina.com-A PREROUTING -i eth0 -p tcp -m state –state NEW –dport 22110 -j DNAT –to-destination 192.168.122.110:22#wintest-A PREROUTING -i eth0 -p tcp -m state –state NEW –dport 4001 -j DNAT –to-destination 192.168.122.101:3389 wintest-cwrsync#-A PREROUTING -i eth0 -p tcp -m state –state NEW –dport 873 -j DNAT –to-destination 192.168.122.101:873#vps100-ssh-A PREROUTING -i eth0 -p tcp -m state –state NEW –dport 22100 -j DNAT –to-destination 192.168.122.100:22#Tvps-ssh-A PREROUTING -i eth0 -p tcp -m state –state NEW –dport 22106 -j DNAT –to-destination 192.168.122.106:22-A PREROUTING -i eth0 -p tcp -m state –state NEW –dport 8080 -j DNAT –to-destination 192.168.122.106:8080#eduvps-ssh-A PREROUTING -i eth0 -p tcp -m state –state NEW –dport 22108 -j DNAT –to-destination 192.168.122.108:22#cactivps-ssh-A PREROUTING -i eth0 -p tcp -m state –state NEW –dport 22109 -j DNAT –to-destination 192.168.122.109:22#output-A POSTROUTING -s 192.168.122.0&#x2F;255.255.255.0 -j MASQUERADECOMMIT Completed on Wed Jul 20 16:22:45 2011Generated by iptables-save v1.3.5 on Wed Jul 20 16:22:45 2011*filter:INPUT DROP [0:0]:FORWARD DROP [6579:984621]:OUTPUT DROP [5509:4582680]:RH-Firewall-1-INPUT - [0:0]-A INPUT -m state –state INVALID -j LOG –log-prefix “DROP VALID” –log-ip-optioins –log-tcp-options-A INPUT -m state –state INVALID -j DROP-A INPUT -i lo -j ACCEPT-A INPUT -i virbr0 -j ACCEPT-A INPUT -i eth0 -p tcp –syn -m state –state NEW –dport 22111 -j ACCEPT-A INPUT -i eth0 -p tcp –syn -m state –state NEW –dport 80 -j ACCEPT-A INPUT -i eth0 -p icmp –icmp-type echo-request -j ACCEPT-A INPUT -i eth0 -m state –state RELATED,ESTABLISHED -j ACCEPT-A FORWARD -m state –state INVALID -j DROP-A FORWARD -p tcp -s 192.168.122.0&#x2F;255.255.255.0 –dport 80 –syn -m state –state NEW -j ACCEPT-A FORWARD -p tcp -s 192.168.122.0&#x2F;255.255.255.0 –dport 3690 –syn -m state –state NEW -j ACCEPT-A FORWARD -p tcp -s 192.168.122.0&#x2F;255.255.255.0 –dport 5666 –syn -m state –state NEW -j ACCEPT-A FORWARD -p tcp -s 192.168.122.0&#x2F;255.255.255.0 –dport 22 –syn -m state –state NEW -j ACCEPT-A FORWARD -p tcp -s 192.168.122.0&#x2F;255.255.255.0 –dport 25 –syn -m state –state NEW -j ACCEPT-A FORWARD -p udp -s 192.168.122.0&#x2F;255.255.255.0 –dport 53 -m state –state NEW -j ACCEPT-A FORWARD -p tcp -i eth0 –dport 22 –syn -m state –state NEW -j ACCEPT-A FORWARD -p tcp -i eth0 –dport 80 –syn -m state –state NEW -j ACCEPT-A FORWARD -p tcp -i eth0 –dport 3690 –syn -m state –state NEW -j ACCEPT-A FORWARD -p tcp -i eth0 –dport 3389 –syn -m state –state NEW -j ACCEPT-A FORWARD -p tcp -i eth0 –dport 5666 –syn -m state –state NEW -j ACCEPT-A FORWARD -p icmp –icmp-type echo-request -j ACCEPT-A FORWARD -m state –state ESTABLISHED,RELATED -j ACCEPT-A OUTPUT -m state –state INVALID -j DROP-A OUTPUT -o lo -j ACCEPT-A OUTPUT -o virbr0 -j ACCEPT#-A OUTPUT -p tcp -m tcp –sport 80 -m state –state RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -p udp –dport 53 -m state –state NEW -j ACCEPT-A OUTPUT -p tcp –dport 25 –syn -m state –state NEW -j ACCEPT-A OUTPUT -p udp –dport 123 -m state –state NEW -j ACCEPT-A OUTPUT -p icmp –icmp-type echo-request -j ACCEPT#-A OUTPUT -p tcp -m state –state NEW -m tcp –dport 80 -j ACCEPT-A OUTPUT -m state –state RELATED,ESTABLISHED -j ACCEPTCOMMIT Completed on Wed Jul 20 16:22:45 2011"},{"path":"/2023/09/28/Linux配置文件/lnmp/iptables.sh/","content":"#!&#x2F;bin&#x2F;bashiptables -P INPUT DROPiptables -P FORWARD DROPiptables -P OUTPUT DROPiptables -A INPUT -i lo -j ACCEPTiptables -A OUTPUT -o lo -j ACCEPT#����httpiptables -A INPUT -i eth0 -p tcp -m tcp –dport 80 -j ACCEPTiptables -A OUTPUT -p tcp -m tcp –sport 80 -m state –state ESTABLISHED,RELATED -j ACCEPT#����sshiptables -A INPUT -i eth0 -p tcp –syn -m state –state NEW –dport 22 -j ACCEPT#���״̬iptables -A INPUT -i eth0 -p all -m state –state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -i eth0 -p all -m state –state INVALID -j DROPiptables -A INPUT -j REJECT –reject-with icmp-host-prohibitediptables -A OUTPUT -p tcp -m state –state ESTABLISHED,RELATED -j ACCEPT#dnsiptables -A OUTPUT -p udp -m udp –dport 53 -j ACCEPTiptables -A OUTPUT -p tcp -m tcp –dport 53 -j ACCEPT#�����ʼ�����iptables -A OUTPUT -p tcp -m state –state NEW –dport 25 -j ACCEPT#��������������http����iptables -A OUTPUT -p tcp -m state –state NEW –dport 80 -j ACCEPT"},{"path":"/2023/09/28/Linux配置文件/lnmp/iptables/","content":"Generated by iptables-save v1.3.5 on Wed Jul 20 16:22:45 2011*nat:PREROUTING ACCEPT [625:44365]:POSTROUTING ACCEPT [10:1067]#blog-web-1-A PREROUTING -i br0 -p tcp -m tcp –dport 80 -j DNAT –to-destination 192.168.122.119:80-A PREROUTING -i br0 -p tcp -m tcp –dport 2201 -j DNAT –to-destination 192.168.122.117:22-A PREROUTING -i br0 -p tcp -m tcp –dport 2202 -j DNAT –to-destination 192.168.122.118:22-A PREROUTING -i br0 -p tcp -m tcp –dport 5666 -j DNAT –to-destination 192.168.122.117:5666-A PREROUTING -i br0 -p tcp -m tcp –dport 5667 -j DNAT –to-destination 192.168.122.118:5666#output-A POSTROUTING -s 192.168.122.0&#x2F;255.255.255.0 -j SNAT –to-source 10.8.33.21COMMIT Generatea by iptabes-save v1.3.5 on Wed Jul 20 16:22:45 2011*filter:INPUT DROP [0:0]:FORWARD ACCEPT [6579:984621]:OUTPUT ACCEPT [5509:4582680]-A INPUT -i lo -j ACCEPT-A INPUT -i virbr0 -j ACCEPT-A INPUT -i br0 -j ACCEPT-A INPUT -i br0 -p tcp -m tcp –dport 22 -j ACCEPT-A INPUT -i br0 -p tcp -m tcp –dport 80 -j ACCEPT-A INPUT -i br0 -s 10.8.20.20 -j ACCEPT-A INPUT -i br0 -s 10.8.20.100 -j ACCEPT-A INPUT -i br0 -p icmp -m icmp –icmp-type 8 -j ACCEPT-A INPUT -i br0 -m state –state RELATED,ESTABLISHED -j ACCEPT-A INPUT -i br0 -m state –state INVALID -j DROPCOMMIT Completed on Wed Jul 20 16:22:45 2011"},{"path":"/2023/09/28/Linux配置文件/lnmp/cutlog.sh/","content":"#!&#x2F;bin&#x2F;bash This script run at 00:00cut yesterday log and gzip the day before yesterday log files.yesterday logs to awstatsThe Nginx logs pathlogs_from_path&#x3D;”&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs&#x2F;“logs_to_path&#x3D;”&#x2F;data&#x2F;logs&#x2F;nginx&#x2F;“ DAY&#x3D;date -d &#39;-1 day&#39; +%Y%m%dDAY_BEFORE&#x3D;date -d &#39;-2 day&#39; +%Y%m%dNGINX&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx #beginfor i in bbs cms train job phper ucdo mv ${logs_from_path}$i-access.log ${logs_to_path}access&#x2F;$i-$DAY.logdonemv ${logs_from_path}access.log ${logs_to_path}access&#x2F;access-$DAY.logmv ${logs_from_path}error.log ${logs_to_path}error&#x2F;error-$DAY.log $NGINX -s reopen gzip -9 ${logs_to_path}access&#x2F;*${DAY_BEFORE}.loggzip -9 ${logs_to_path}error&#x2F;error-$DAY.logfind ${logs_to_path}access -mtime +30 | xargs -i rm -rf {}find ${logs_to_path}error -mtime +30 | xargs -i rm -rf {}"},{"path":"/2023/09/28/Linux配置文件/lnmp/apc_tt.php/","content":"'/^\\d+$/', // operational mode switch 'CC'\t=> '/^[01]$/', // clear cache requested 'DU'\t=> '/^.*$/', // Delete User Key 'SH'\t=> '/^[a-z0-9]+$/', // shared object description 'IMG'\t=> '/^[123]$/', // image to generate 'LO'\t=> '/^1$/', // login requested 'COUNT'\t=> '/^\\d+$/', // number of line displayed in list 'SCOPE'\t=> '/^[AD]$/', // list view scope 'SORT1'\t=> '/^[AHSMCDTZ]$/',\t// first sort key 'SORT2'\t=> '/^[DA]$/', // second sort key 'AGGR'\t=> '/^\\d+$/', // aggregation by dir level 'SEARCH'\t=> '~^[a-zA-Z0-1/_.-]*$~' // aggregation by dir level ); // default cache mode $cache_mode='opcode'; // cache scope $scope_list=array( 'A' => 'cache_list', 'D' => 'deleted_list' ); // handle POST and GET requests if (empty($_REQUEST)) { if (!empty($_GET) && !empty($_POST)) { $_REQUEST = array_merge($_GET, $_POST); } else if (!empty($_GET)) { $_REQUEST = $_GET; } else if (!empty($_POST)) { $_REQUEST = $_POST; } else { $_REQUEST = array(); } } // check parameter syntax foreach($vardom as $var => $dom) { if (!isset($_REQUEST[$var])) { $MYREQUEST[$var]=NULL; } else if (!is_array($_REQUEST[$var]) && preg_match($dom.'D',$_REQUEST[$var])) { $MYREQUEST[$var]=$_REQUEST[$var]; } else { $MYREQUEST[$var]=$_REQUEST[$var]=NULL; } } // check parameter sematics if (empty($MYREQUEST['SCOPE'])) $MYREQUEST['SCOPE']=\"A\"; if (empty($MYREQUEST['SORT1'])) $MYREQUEST['SORT1']=\"H\"; if (empty($MYREQUEST['SORT2'])) $MYREQUEST['SORT2']=\"D\"; if (empty($MYREQUEST['OB']))\t$MYREQUEST['OB']=OB_HOST_STATS; if (!isset($MYREQUEST['COUNT'])) $MYREQUEST['COUNT']=20; if (!isset($scope_list[$MYREQUEST['SCOPE']])) $MYREQUEST['SCOPE']='A'; $MY_SELF= \"$PHP_SELF\". \"?SCOPE=\".$MYREQUEST['SCOPE']. \"&SORT1=\".$MYREQUEST['SORT1']. \"&SORT2=\".$MYREQUEST['SORT2']. \"&COUNT=\".$MYREQUEST['COUNT']; $MY_SELF_WO_SORT= \"$PHP_SELF\". \"?SCOPE=\".$MYREQUEST['SCOPE']. \"&COUNT=\".$MYREQUEST['COUNT']; // authentication needed? // if (!USE_AUTHENTICATION) { $AUTHENTICATED=1; } else { $AUTHENTICATED=0; if (ADMIN_PASSWORD!='password' && ($MYREQUEST['LO'] == 1 || isset($_SERVER['PHP_AUTH_USER']))) { if (!isset($_SERVER['PHP_AUTH_USER']) || !isset($_SERVER['PHP_AUTH_PW']) || $_SERVER['PHP_AUTH_USER'] != ADMIN_USERNAME || $_SERVER['PHP_AUTH_PW'] != ADMIN_PASSWORD) { Header(\"WWW-Authenticate: Basic realm=\\\"APC Login\\\"\"); Header(\"HTTP/1.0 401 Unauthorized\"); echo"},{"path":"/2023/09/28/Linux配置文件/lamp/http-conf/extra/httpd-vhosts.conf/","content":"Virtual HostsIf you want to maintain multiple domains&#x2F;hostnames on yourmachine you can setup VirtualHost containers for them. Most configurationsuse only name-based virtual hosts so the server doesn’t need to worry aboutIP addresses. This is indicated by the asterisks in the directives below.Please see the documentation atURL:http://httpd.apache.org/docs/2.2/vhosts/for further details before you try to setup virtual hosts.You may use the command line option ‘-S’ to verify your virtual hostconfiguration.Use name-based virtual hosting.NameVirtualHost *:80 VirtualHost example:Almost any Apache directive may go into a VirtualHost container.The first VirtualHost section is used for all requests that do notmatch a ServerName or ServerAlias in any block.&lt;VirtualHost :80&gt; DocumentRoot “&#x2F;data&#x2F;www” ServerName localhost #ServerAlias www.dummy-host.example.com #RewriteEngine on #RewriteCond %{HTTP_HOST} ^abc.org [NC] #RewriteRule ^(.)$ http://www.abc.com/$1 [R&#x3D;permanent,L] #RewriteCond %{HTTP_HOST} !^www.abc\\.com [NC] #RewriteRule ^&#x2F;(.*) &#x2F;error.html [L] ErrorLog “|usr&#x2F;local&#x2F;sbin&#x2F;cronolog &#x2F;data&#x2F;logs&#x2F;error&#x2F;error_%Y%m%d.log” CustomLog “|&#x2F;usr&#x2F;local&#x2F;sbin&#x2F;cronolog &#x2F;data&#x2F;logs&#x2F;access&#x2F;access_%Y%m%d.log” combined"},{"path":"/2023/09/28/Linux配置文件/lamp/http-conf/extra/httpd-mpm.conf/","content":"Server-Pool Management (MPM specific)PidFile: The file in which the server should record its processidentification number when it starts.Note that this is the default PidFile for most MPMs.&lt;IfModule !mpm_netware_module&gt; PidFile “logs&#x2F;httpd.pid” The accept serialization lock file MUST BE STORED ON A LOCAL DISK.&lt;IfModule !mpm_winnt_module&gt;&lt;IfModule !mpm_netware_module&gt;LockFile “logs&#x2F;accept.lock” Only one of the below sections will be relevant on yourinstalled httpd. Use “apachectl -l” to find out theactive mpm.prefork MPMStartServers: number of server processes to startMinSpareServers: minimum number of server processes which are kept spareMaxSpareServers: maximum number of server processes which are kept spareMaxClients: maximum number of server processes allowed to startMaxRequestsPerChild: maximum number of requests a server process serves StartServers 5 MinSpareServers 5 MaxSpareServers 10 ServerLimit 600 MaxClients 500 MaxRequestsPerChild 800 worker MPMStartServers: initial number of server processes to startMaxClients: maximum number of simultaneous client connectionsMinSpareThreads: minimum number of worker threads which are kept spareMaxSpareThreads: maximum number of worker threads which are kept spareThreadsPerChild: constant number of worker threads in each server processMaxRequestsPerChild: maximum number of requests a server process serves StartServers 2 MaxClients 150 MinSpareThreads 25 MaxSpareThreads 75 ThreadsPerChild 25 MaxRequestsPerChild 0 BeOS MPMStartThreads: how many threads do we initially spawn?MaxClients: max number of threads we can have (1 thread &#x3D;&#x3D; 1 client)MaxRequestsPerThread: maximum number of requests each thread will process StartThreads 10 MaxClients 50 MaxRequestsPerThread 10000 NetWare MPMThreadStackSize: Stack size allocated for each worker threadStartThreads: Number of worker threads launched at server startupMinSpareThreads: Minimum number of idle threads, to handle request spikesMaxSpareThreads: Maximum number of idle threadsMaxThreads: Maximum number of worker threads alive at the same timeMaxRequestsPerChild: Maximum number of requests a thread serves. It isrecommended that the default value of 0 be set for thisdirective on NetWare. This will allow the thread tocontinue to service requests indefinitely. ThreadStackSize 65536 StartThreads 250 MinSpareThreads 25 MaxSpareThreads 250 MaxThreads 1000 MaxRequestsPerChild 0 MaxMemFree 100 OS&#x2F;2 MPMStartServers: Number of server processes to maintainMinSpareThreads: Minimum number of idle threads per process,to handle request spikesMaxSpareThreads: Maximum number of idle threads per processMaxRequestsPerChild: Maximum number of connections per server process StartServers 2 MinSpareThreads 5 MaxSpareThreads 10 MaxRequestsPerChild 0 WinNT MPMThreadsPerChild: constant number of worker threads in the server processMaxRequestsPerChild: maximum number of requests a server process serves ThreadsPerChild 150 MaxRequestsPerChild 0"},{"path":"/2023/09/28/Linux配置文件/lamp/http-conf/extra/httpd-default.conf/","content":"This configuration file reflects default settings for Apache HTTP Server.You may change these, but chances are that you may not need to.Timeout: The number of seconds before receives and sends time out.Timeout 5 KeepAlive: Whether or not to allow persistent connections (more thanone request per connection). Set to “Off” to deactivate.KeepAlive On MaxKeepAliveRequests: The maximum number of requests to allowduring a persistent connection. Set to 0 to allow an unlimited amount.We recommend you leave this number high, for maximum performance.MaxKeepAliveRequests 150 KeepAliveTimeout: Number of seconds to wait for the next request from thesame client on the same connection.KeepAliveTimeout 5 UseCanonicalName: Determines how Apache constructs self-referencingURLs and the SERVER_NAME and SERVER_PORT variables.When set “Off”, Apache will use the Hostname and Port suppliedby the client. When set “On”, Apache will use the value of theServerName directive.UseCanonicalName Off AccessFileName: The name of the file to look for in each directoryfor additional configuration directives. See also the AllowOverridedirective.AccessFileName .htaccess ServerTokensThis directive configures what you return as the Server HTTP responseHeader. The default is ‘Full’ which sends information about the OS-Typeand compiled in modules.Set to one of: Full | OS | Minor | Minimal | Major | Prodwhere Full conveys the most information, and Prod the least.ServerTokens Prod Optionally add a line containing the server version and virtual hostname to server-generated pages (internal error documents, FTP directorylistings, mod_status and mod_info output etc., but not CGI generateddocuments or custom error documents).Set to “EMail” to also include a mailto: link to the ServerAdmin.Set to one of: On | Off | EMailServerSignature Off HostnameLookups: Log the names of clients or just their IP addressese.g., www.apache.org (on) or 204.62.129.132 (off).The default is off because it’d be overall better for the net if peoplehad to knowingly turn this feature on, since enabling it means thateach client request will result in AT LEAST one lookup request to thenameserver.HostnameLookups Off"},{"path":"/2023/09/28/Linux配置文件/lamp/http-conf/httpd.conf/","content":"This is the main Apache HTTP server configuration file. It contains theconfiguration directives that give the server its instructions.See URL:http://httpd.apache.org/docs/2.4/ for detailed information.In particular, seeURL:http://httpd.apache.org/docs/2.4/mod/directives.htmlfor a discussion of each configuration directive.Do NOT simply read the instructions in here without understandingwhat they do. They’re here only as hints or reminders. If you are unsureconsult the online docs. You have been warned.Configuration and logfile names: If the filenames you specify for manyof the server’s control files begin with “&#x2F;“ (or “drive:&#x2F;“ for Win32), theserver will use that explicit path. If the filenames do not beginwith “&#x2F;“, the value of ServerRoot is prepended – so “logs&#x2F;access_log”with ServerRoot set to “&#x2F;usr&#x2F;local&#x2F;apache2” will be interpreted by theserver as “&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;logs&#x2F;access_log”, whereas “&#x2F;logs&#x2F;access_log”will be interpreted as ‘&#x2F;logs&#x2F;access_log’.ServerRoot: The top of the directory tree under which the server’sconfiguration, error, and log files are kept.Do not add a slash at the end of the directory path. If you pointServerRoot at a non-local disk, be sure to specify a local disk on theMutex directive, if file-based mutexes are used. If you wish to share thesame ServerRoot for multiple httpd daemons, you will need to change atleast PidFile.ServerRoot “&#x2F;usr&#x2F;local&#x2F;apache2” Mutex: Allows you to set the mutex mechanism and mutex file directoryfor individual mutexes, or change the global defaultsUncomment and change the directory if mutexes are file-based and the defaultmutex file directory is not on a local disk or is not appropriate for someother reason.Mutex default:logsListen: Allows you to bind Apache to specific IP addresses and&#x2F;orports, instead of the default. See also the directive.Change this to Listen on specific IP addresses as shown below toprevent Apache from glomming onto all bound IP addresses.#Listen 12.34.56.78:80Listen 80 Dynamic Shared Object (DSO) SupportTo be able to use the functionality of a module which was built as a DSO youhave to place corresponding &#96;LoadModule’ lines at this location so thedirectives contained in it are actually available before they are used.Statically compiled modules (those listed by &#96;httpd -l’) do not needto be loaded here.Example:LoadModule foo_module modules&#x2F;mod_foo.soLoadModule authn_file_module modules&#x2F;mod_authn_file.so#LoadModule authn_dbm_module modules&#x2F;mod_authn_dbm.so#LoadModule authn_anon_module modules&#x2F;mod_authn_anon.so#LoadModule authn_dbd_module modules&#x2F;mod_authn_dbd.so#LoadModule authn_socache_module modules&#x2F;mod_authn_socache.soLoadModule authn_core_module modules&#x2F;mod_authn_core.soLoadModule authz_host_module modules&#x2F;mod_authz_host.soLoadModule authz_groupfile_module modules&#x2F;mod_authz_groupfile.soLoadModule authz_user_module modules&#x2F;mod_authz_user.so#LoadModule authz_dbm_module modules&#x2F;mod_authz_dbm.so#LoadModule authz_owner_module modules&#x2F;mod_authz_owner.so#LoadModule authz_dbd_module modules&#x2F;mod_authz_dbd.soLoadModule authz_core_module modules&#x2F;mod_authz_core.soLoadModule access_compat_module modules&#x2F;mod_access_compat.soLoadModule auth_basic_module modules&#x2F;mod_auth_basic.so#LoadModule auth_form_module modules&#x2F;mod_auth_form.so#LoadModule auth_digest_module modules&#x2F;mod_auth_digest.so#LoadModule allowmethods_module modules&#x2F;mod_allowmethods.so#LoadModule file_cache_module modules&#x2F;mod_file_cache.so#LoadModule cache_module modules&#x2F;mod_cache.so#LoadModule cache_disk_module modules&#x2F;mod_cache_disk.so#LoadModule cache_socache_module modules&#x2F;mod_cache_socache.so#LoadModule socache_shmcb_module modules&#x2F;mod_socache_shmcb.so#LoadModule socache_dbm_module modules&#x2F;mod_socache_dbm.so#LoadModule socache_memcache_module modules&#x2F;mod_socache_memcache.so#LoadModule macro_module modules&#x2F;mod_macro.so#LoadModule dbd_module modules&#x2F;mod_dbd.so#LoadModule dumpio_module modules&#x2F;mod_dumpio.so#LoadModule buffer_module modules&#x2F;mod_buffer.so#LoadModule ratelimit_module modules&#x2F;mod_ratelimit.soLoadModule reqtimeout_module modules&#x2F;mod_reqtimeout.so#LoadModule ext_filter_module modules&#x2F;mod_ext_filter.so#LoadModule request_module modules&#x2F;mod_request.so#LoadModule include_module modules&#x2F;mod_include.soLoadModule filter_module modules&#x2F;mod_filter.so#LoadModule substitute_module modules&#x2F;mod_substitute.so#LoadModule sed_module modules&#x2F;mod_sed.so#LoadModule deflate_module modules&#x2F;mod_deflate.soLoadModule mime_module modules&#x2F;mod_mime.soLoadModule log_config_module modules&#x2F;mod_log_config.so#LoadModule log_debug_module modules&#x2F;mod_log_debug.so#LoadModule logio_module modules&#x2F;mod_logio.soLoadModule env_module modules&#x2F;mod_env.so#LoadModule expires_module modules&#x2F;mod_expires.soLoadModule headers_module modules&#x2F;mod_headers.so#LoadModule unique_id_module modules&#x2F;mod_unique_id.soLoadModule setenvif_module modules&#x2F;mod_setenvif.soLoadModule version_module modules&#x2F;mod_version.so#LoadModule remoteip_module modules&#x2F;mod_remoteip.so#LoadModule proxy_module modules&#x2F;mod_proxy.so#LoadModule proxy_connect_module modules&#x2F;mod_proxy_connect.so#LoadModule proxy_ftp_module modules&#x2F;mod_proxy_ftp.so#LoadModule proxy_http_module modules&#x2F;mod_proxy_http.so#LoadModule proxy_fcgi_module modules&#x2F;mod_proxy_fcgi.so#LoadModule proxy_scgi_module modules&#x2F;mod_proxy_scgi.so#LoadModule proxy_wstunnel_module modules&#x2F;mod_proxy_wstunnel.so#LoadModule proxy_ajp_module modules&#x2F;mod_proxy_ajp.so#LoadModule proxy_balancer_module modules&#x2F;mod_proxy_balancer.so#LoadModule proxy_express_module modules&#x2F;mod_proxy_express.so#LoadModule session_module modules&#x2F;mod_session.so#LoadModule session_cookie_module modules&#x2F;mod_session_cookie.so#LoadModule session_dbd_module modules&#x2F;mod_session_dbd.so#LoadModule slotmem_shm_module modules&#x2F;mod_slotmem_shm.so#LoadModule lbmethod_byrequests_module modules&#x2F;mod_lbmethod_byrequests.so#LoadModule lbmethod_bytraffic_module modules&#x2F;mod_lbmethod_bytraffic.so#LoadModule lbmethod_bybusyness_module modules&#x2F;mod_lbmethod_bybusyness.so#LoadModule lbmethod_heartbeat_module modules&#x2F;mod_lbmethod_heartbeat.soLoadModule unixd_module modules&#x2F;mod_unixd.so#LoadModule dav_module modules&#x2F;mod_dav.soLoadModule status_module modules&#x2F;mod_status.soLoadModule autoindex_module modules&#x2F;mod_autoindex.so#LoadModule info_module modules&#x2F;mod_info.so#LoadModule cgid_module modules&#x2F;mod_cgid.so#LoadModule dav_fs_module modules&#x2F;mod_dav_fs.so#LoadModule vhost_alias_module modules&#x2F;mod_vhost_alias.so#LoadModule negotiation_module modules&#x2F;mod_negotiation.soLoadModule dir_module modules&#x2F;mod_dir.so#LoadModule actions_module modules&#x2F;mod_actions.so#LoadModule speling_module modules&#x2F;mod_speling.so#LoadModule userdir_module modules&#x2F;mod_userdir.soLoadModule alias_module modules&#x2F;mod_alias.so#LoadModule rewrite_module modules&#x2F;mod_rewrite.so # # If you wish httpd to run as a different user or group, you must run # httpd as root initially and it will switch. # # User/Group: The name (or #number) of the user/group to run httpd as. # It is usually good practice to create a dedicated user and group for # running httpd, as with most system services. # User www Group www ‘Main’ server configurationThe directives in this section set up the values used by the ‘main’server, which responds to any requests that aren’t handled by a definition. These values also provide defaults forany containers you may define later in the file.All of these directives may appear inside containers,in which case these default settings will be overridden for thevirtual host being defined.ServerAdmin: Your address, where problems with the server should bee-mailed. This address appears on some server-generated pages, suchas error documents. e.g. &#97;&#100;&#x6d;&#105;&#110;&#x40;&#121;&#111;&#117;&#114;&#45;&#100;&#x6f;&#x6d;&#x61;&#x69;&#110;&#46;&#x63;&#111;&#x6d;ServerAdmin &#x79;&#x6f;&#117;&#x40;&#x65;&#x78;&#97;&#x6d;&#x70;&#108;&#101;&#x2e;&#99;&#x6f;&#109; ServerName gives the name and port that the server uses to identify itself.This can often be determined automatically, but we recommend you specifyit explicitly to prevent problems during startup.If your host doesn’t have a registered DNS name, enter its IP address here.ServerName mail.lxy.kk:80 Deny access to the entirety of your server’s filesystem. You mustexplicitly permit access to web content directories in other blocks below. AllowOverride none Require all denied Note that from this point forward you must specifically allowparticular features to be enabled - so if something’s not working asyou might expect, make sure that you have specifically enabled itbelow.DocumentRoot: The directory out of which you will serve yourdocuments. By default, all requests are taken from this directory, butsymbolic links and aliases may be used to point to other locations.DocumentRoot “&#x2F;data&#x2F;www”&lt;Directory “&#x2F;data&#x2F;www”&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted #验证方式与2.2版本不通 #Require ip 192.168.1.100 #Require not ip 192.168.1.100 #Require all denied ExpiresActive On ExpiresByType image/gif \"access plus 12 months\" ExpiresByType image/jpeg \"access plus 12 months\" ExpiresByType image/png \"access plus 12 months\" ExpiresByType image/x-icon \"access plus 12 months\" ExpiresByType application/x-javascript \"access plus 12 months\" ExpiresByType text/css \"access plus 12 months\" AddOutputFilterByType DEFLATE text/html text/plain application/x-javascript text/css application/xml DirectoryIndex: sets the file that Apache will serve if a directoryis requested. DirectoryIndex index.php index.html The following lines prevent .htaccess and .htpasswd files from beingviewed by Web clients.&lt;Files “.ht*”&gt; Require all denied ErrorLog: The location of the error log file.If you do not specify an ErrorLog directive within a container, error messages relating to that virtual host will belogged here. If you do define an error logfile for a container, that host’s errors will be logged there and not here.ErrorLog “logs&#x2F;error_log” LogLevel: Control the number of messages logged to the error_log.Possible values include: debug, info, notice, warn, error, crit,alert, emerg.LogLevel warn # # The following directives define some format nicknames for use with # a CustomLog directive (see below). # LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b\" common &lt;IfModule logio_module&gt; # You need to enable mod_logio.c to use %I and %O LogFormat &quot;%h %l %u %t \\&quot;%r\\&quot; %&gt;s %b \\&quot;%&#123;Referer&#125;i\\&quot; \\&quot;%&#123;User-Agent&#125;i\\&quot; %I %O&quot; combinedio &lt;/IfModule&gt; # # The location and format of the access logfile (Common Logfile Format). # If you do not define any access logfiles within a &lt;VirtualHost&gt; # container, they will be logged here. Contrariwise, if you *do* # define per-&lt;VirtualHost&gt; access logfiles, transactions will be # logged therein and *not* in this file. # CustomLog &quot;logs/access_log&quot; common # # If you prefer a logfile with access, agent, and referer information # (Combined Logfile Format) you can use the following directive. # #CustomLog &quot;logs/access_log&quot; combined # # Redirect: Allows you to tell clients about documents that used to # exist in your server's namespace, but do not anymore. The client # will make a new request for the document at its new location. # Example: # Redirect permanent /foo http://www.example.com/bar # # Alias: Maps web paths into filesystem paths and is used to # access content that does not live under the DocumentRoot. # Example: # Alias /webpath /full/filesystem/path # # If you include a trailing / on /webpath then the server will # require it to be present in the URL. You will also likely # need to provide a &lt;Directory&gt; section to allow access to # the filesystem path. # # ScriptAlias: This controls which directories contain server scripts. # ScriptAliases are essentially the same as Aliases, except that # documents in the target directory are treated as applications and # run by the server when requested rather than as documents sent to the # client. The same rules about trailing &quot;/&quot; apply to ScriptAlias # directives as to Alias. # ScriptAlias /cgi-bin/ &quot;/usr/local/apache2/cgi-bin/&quot; # # ScriptSock: On threaded servers, designate the path to the UNIX # socket used to communicate with the CGI daemon of mod_cgid. # #Scriptsock cgisock “&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;cgi-bin” should be changed to whatever your ScriptAliasedCGI directory exists, if you have that configured.&lt;Directory “&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;cgi-bin”&gt; AllowOverride None Options None Require all granted # # TypesConfig points to the file containing the list of mappings from # filename extension to MIME-type. # TypesConfig /etc/httpd/mime.types # # AddType allows you to add to or override the MIME configuration # file specified in TypesConfig for specific file types. # #AddType application/x-gzip .tgz # # AddEncoding allows you to have certain browsers uncompress # information on the fly. Note: Not all browsers support this. # #AddEncoding x-compress .Z #AddEncoding x-gzip .gz .tgz # # If the AddEncoding directives above are commented-out, then you # probably should define those extensions to indicate media types: # AddType application/x-compress .Z AddType application/x-gzip .gz .tgz AddType application/x-httpd-php .php # # AddHandler allows you to map certain file extensions to &quot;handlers&quot;: # actions unrelated to filetype. These can be either built into the server # or added with the Action directive (see below) # # To use CGI scripts outside of ScriptAliased directories: # (You will also need to add &quot;ExecCGI&quot; to the &quot;Options&quot; directive.) # #AddHandler cgi-script .cgi # For type maps (negotiated resources): #AddHandler type-map var # # Filters allow you to process content before it is sent to the client. # # To parse .shtml files for server-side includes (SSI): # (You will also need to add &quot;Includes&quot; to the &quot;Options&quot; directive.) # #AddType text/html .shtml #AddOutputFilter INCLUDES .shtml The mod_mime_magic module allows the server to use various hints from thecontents of the file itself to determine its type. The MIMEMagicFiledirective tells the module where the hint definitions are located.#MIMEMagicFile &#x2F;etc&#x2F;httpd&#x2F;magic Customizable error responses come in three flavors:1) plain text 2) local redirects 3) external redirectsSome examples:#ErrorDocument 500 “The server made a boo boo.”#ErrorDocument 404 &#x2F;missing.html#ErrorDocument 404 “&#x2F;cgi-bin&#x2F;missing_handler.pl”#ErrorDocument 402 http://www.example.com/subscription_info.html# MaxRanges: Maximum number of Ranges in a request beforereturning the entire resource, or one of the specialvalues ‘default’, ‘none’ or ‘unlimited’.Default setting is to accept 200 Ranges.#MaxRanges unlimited EnableMMAP and EnableSendfile: On systems that support it,memory-mapping or the sendfile syscall may be used to deliverfiles. This usually improves server performance, but mustbe turned off when serving from networked-mountedfilesystems or if support for these functions is otherwisebroken on your system.Defaults: EnableMMAP On, EnableSendfile Off#EnableMMAP off#EnableSendfile on Supplemental configurationThe configuration files in the &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F; directory can beincluded to add extra features or to modify the default configuration ofthe server, or you may simply copy their contents here and change asnecessary.Server-pool management (MPM specific)#Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-mpm.conf Multi-language error messages#Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-multilang-errordoc.conf Fancy directory listings#Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-autoindex.conf Language settings#Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-languages.conf User home directories#Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-userdir.conf Real-time info on requests and configuration#Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-info.conf Virtual hosts#Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-vhosts.conf Local access to the Apache HTTP Server Manual#Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-manual.conf Distributed authoring and versioning (WebDAV)#Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-dav.conf Various default settingsInclude &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-default.conf Configure mod_proxy_html to understand HTML4&#x2F;XHTML1 Include /etc/httpd/extra/proxy-html.conf Secure (SSL&#x2F;TLS) connections#Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-ssl.conf# Note: The following must must be present to supportstarting without SSL on platforms with no &#x2F;dev&#x2F;random equivalentbut a statically compiled-in mod_ssl. SSLRandomSeed startup builtin SSLRandomSeed connect builtin # # uncomment out the below to deal with user agents that deliberately # violate open standards by misusing DNT (DNT *must* be a specific # end-user choice) # # #BrowserMatch \"MSIE 10.0;\" bad_DNT # # #RequestHeader unset DNT env=bad_DNT #"},{"path":"/2023/09/28/Linux配置文件/wireshark/kickstart/ks.cfg/","content":"auth –useshadow –passalgo&#x3D;sha512 #用户密码的加密方式key –skipbootloader –location&#x3D;mbrclearpart –all –initlabeltextfirewall –disabledfirstboot –disablekeyboard uslang en_USlogging –level&#x3D;infourl –url&#x3D;http://10.10.67.11/pxe/network –device&#x3D;em1 bootproto&#x3D;dhcp –onboot&#x3D;yesrootpw admincpselinux –disabledtimezone Asia&#x2F;Shanghai#xconfig –defaultdesktop&#x3D;GNOME -depth&#x3D;8 –resolution&#x3D;640x480zerombr yes #任何磁盘上的无效分区表都将被初始化part &#x2F;boot –fstype&#x3D;”ext4” –size&#x3D;512part &#x2F; –fstype&#x3D;”ext4” –size&#x3D;20480part &#x2F;var –fstype&#x3D;”ext4” –size&#x3D;20480part &#x2F;home –fstype&#x3D;”ext4” –size&#x3D;20480part &#x2F;tmp –fstype&#x3D;”ext4” –size&#x3D;10240part swap –fstype&#x3D;”swap” –size&#x3D;8196part &#x2F;Data –fstype&#x3D;”ext4” –grow –size&#x3D;1%packages@base #安装后将执行的命令%postmakdir &#x2F;root&#x2F;post_testsed -i ‘s&#x2F;#Port&#x2F;Port&#x2F;‘ &#x2F;etc&#x2F;ssh&#x2F;sshd_config"},{"path":"/2023/09/28/Linux配置文件/wireshark/kickstart/default/","content":"default linuxprompt 1timeout 1 display boot.msg menu background splash.jpgmenu title Welcome to CentOS 6.5!menu color border 0 #ffffffff #00000000menu color sel 7 #ffffffff #ff000000menu color title 0 #ffffffff #00000000menu color tabmsg 0 #ffffffff #00000000menu color unsel 0 #ffffffff #00000000menu color hotsel 0 #ff000000 #ffffffffmenu color hotkey 7 #ffffffff #ff000000menu color scrollbar 0 #ffffffff #00000000 label linuxkernel vmlinuzappend ks&#x3D;http://10.10.67.11/ks.cfg initrd&#x3D;initrd.img ksdevice&#x3D;em1 #ksdevice&#x3D;em1防止安装过程中提示选择网卡，多网卡服务器使用"},{"path":"/2023/09/28/Linux配置文件/wireshark/kickstart/crypt/","content":"linux kickstart֮��root���������ʹ�����ģ�Ҳ����ʹ�ü��ܹ���ֵrootpw �Ciscrypted $1$BYSimLw0$I515yLiKzudlwkIskBqQE1 ���Ƕ�ȡ���ܺ��ֵ���������ֵ����ô���ɵ��أ�����linuxϵͳ������shadowһ�������ɷ������£� perl -e ‘print crypt(“123456”,q($1$BYSimLw0)),” ”‘ ����123456�ǽ�Ҫ���õ�����,crypt���������ļ���, $1$BYSimLw0�Ľ��ͣ� $1 ��Ϊ$id�����id��1Ϊmd5���ܣ�idΪ5Ϊsha256���ܣ�idΪ6Ϊsha512���� BYSimLw0Ϊ�Զ����ַ�������Ϊsalt�����ܲ����Ὣ���Զ����ַ�����ͬ��������һͬ���м��� &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; ����ֱ��ʹ��ϵͳ�е�grub-crypt����"},{"path":"/2023/09/28/Linux配置文件/inotify+rsync/10.10.67.81/rsyncd.conf/","content":"Minimal configuration file for rsync daemonSee rsync(1) and rsyncd.conf(5) man pages for helpThis line is required by the &#x2F;etc&#x2F;init.d&#x2F;rsyncd scriptpid file &#x3D; &#x2F;var&#x2F;run&#x2F;rsyncd.pidport &#x3D; 873uid &#x3D; wwwgid &#x3D; wwwuse chroot &#x3D; yesread only &#x3D; no #limit access to private LANshosts allow &#x3D; 10.10.67.80max connections &#x3D; 5motd file &#x3D; &#x2F;etc&#x2F;rsyncd&#x2F;rsyncd.motd #This will give you a separate log filelog file &#x3D; &#x2F;var&#x2F;log&#x2F;rsync.log #This will log every file transferred - up to 85,000+ per user, per sync#transfer logging &#x3D; yes log format &#x3D; %t %a %m %f %bsyslog facility &#x3D; local3timeout &#x3D; 300 [cache]path &#x3D; &#x2F;Data&#x2F;nfs&#x2F;cachelist&#x3D;yesignore errorsauth users &#x3D; rsync_usersecrets file &#x3D; &#x2F;etc&#x2F;rsyncd&#x2F;rsyncd.secretscomment &#x3D; nfs 81[mzt]path &#x3D; &#x2F;Data&#x2F;nfs&#x2F;mztlist&#x3D;yesignore errorsauth users &#x3D; rsync_usersecrets file &#x3D; &#x2F;etc&#x2F;rsyncd&#x2F;rsyncd.secretscomment &#x3D; nfs 81[upload]path &#x3D; &#x2F;Data&#x2F;nfs&#x2F;uploadlist&#x3D;yesignore errorsauth users &#x3D; rsync_usersecrets file &#x3D; &#x2F;etc&#x2F;rsyncd&#x2F;rsyncd.secretscomment &#x3D; nfs 81"},{"path":"/2023/09/28/Linux配置文件/inotify+rsync/10.10.67.80/inotify_nfs_upload.sh/","content":"#!&#x2F;bin&#x2F;bash inotify_nfs_upload.shThis script will run in the background.When file that in &#x2F;Data&#x2F;nfs&#x2F;upload&#x2F; has changed,this script will push these changes to 10.10.67.81 with rsyncCreated by shidegang at 2013.11.04src&#x3D;&#x2F;Data&#x2F;nfs&#x2F;upload&#x2F;user&#x3D;rsync_userhost&#x3D;10.10.67.81module&#x3D;uploadINOTIFYWAIT&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;inotifywait $INOTIFYWAIT -mrq –timefmt ‘%d&#x2F;%m&#x2F;%y %H:%M’ –format ‘%T %w %f %e’ –event close_write,delete,create,move,attrib –exclude ‘(.swp|.swx|.svn)’ $src | while read date time dir file eventdo case $event in CLOSE_WRITE,CLOSE|CREATE,ISDIR|MOVED_TO|MOVED_TO,ISDIR) if [ “${file: -4}” !&#x3D; ‘4913’ ] &amp;&amp; [ “${file: -1}” !&#x3D; ‘~’ ]; then rsync -az –password-file&#x3D;&#x2F;etc&#x2F;rsync.pas $src $user@$host::$module &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 fi ;; MOVED_FROM|MOVED_FROM,ISDIR|DELETE|DELETE,ISDIR) if [ &quot;$&#123;file: -4&#125;&quot; != &#39;4913&#39; ] &amp;&amp; [ &quot;$&#123;file: -1&#125;&quot; != &#39;~&#39; ]; then rsync -az --delete --password-file=/etc/rsync.pas $src $user@$host::$module &gt; /dev/null 2&gt;&amp;1 fi ;; esac done End"},{"path":"/2023/09/28/Linux配置文件/wireshark/git/etc/gitconfig/","content":"[gui]encoding &#x3D; utf-8[i18n]commitencoding &#x3D; gbk[svn]pathnameencoding &#x3D; gbk[core] symlinks &#x3D; false autocrlf &#x3D; false[color] diff &#x3D; auto status &#x3D; auto branch &#x3D; auto interactive &#x3D; true[pack] packSizeLimit &#x3D; 2g[help] format &#x3D; html[http] sslCAinfo &#x3D; &#x2F;bin&#x2F;curl-ca-bundle.crt[sendemail] smtpserver &#x3D; &#x2F;bin&#x2F;msmtp.exe [diff “astextplain”] textconv &#x3D; astextplain[rebase] autosquash &#x3D; true"},{"path":"/2023/09/28/Linux配置文件/wireshark/git/etc/git-completion.bash/","content":"bash&#x2F;zsh completion support for core Git.Copyright (C) 2006,2007 Shawn O. Pearce &#x73;&#x70;&#101;&#97;&#x72;&#99;&#101;&#x40;&#115;&#112;&#101;&#97;&#x72;&#99;&#x65;&#x2e;&#111;&#x72;&#x67;Conceptually based on gitcompletion (http://gitweb.hawaga.org.uk/).Distributed under the GNU General Public License, version 2.0.The contained completion routines provide support for completing:*) local and remote branch names*) local and remote tag names*) .git&#x2F;remotes file names*) git ‘subcommands’*) tree paths within ‘ref:path&#x2F;to&#x2F;file’ expressions*) file paths within current working directory and index*) common –long-optionsTo use these routines:1) Copy this file to somewhere (e.g. ~&#x2F;.git-completion.sh).2) Add the following line to your .bashrc&#x2F;.zshrc:source ~&#x2F;.git-completion.sh3) Consider changing your PS1 to also show the current branch,see git-prompt.sh for details.case “$COMP_WORDBREAKS” in:) : great ;;*) COMP_WORDBREAKS&#x3D;”$COMP_WORDBREAKS:”esac __gitdir accepts 0 or 1 arguments (i.e., location)returns location of .git repo__gitdir (){ if [ -z “${1-}” ]; then if [ -n “${__git_dir-}” ]; then echo “$__git_dir” elif [ -n “${GIT_DIR-}” ]; then test -d “${GIT_DIR-}” || return 1 echo “$GIT_DIR” elif [ -d .git ]; then echo .git else git rev-parse –git-dir 2&gt;&#x2F;dev&#x2F;null fi elif [ -d “$1&#x2F;.git” ]; then echo “$1&#x2F;.git” else echo “$1” fi} The following function is based on code from:bash_completion - programmable completion functions for bash 3.2+Copyright © 2006-2008, Ian Macdonald &#105;&#97;&#110;&#x40;&#99;&#97;&#108;&#x69;&#98;&#97;&#x6e;&#46;&#x6f;&#x72;&#103;© 2009-2010, Bash Completion Maintainers&#98;&#97;&#x73;&#x68;&#45;&#99;&#111;&#109;&#x70;&#108;&#x65;&#x74;&#x69;&#x6f;&#110;&#45;&#100;&#101;&#x76;&#101;&#108;&#64;&#x6c;&#x69;&#x73;&#116;&#x73;&#x2e;&#x61;&#x6c;&#x69;&#x6f;&#x74;&#104;&#x2e;&#x64;&#101;&#x62;&#x69;&#97;&#x6e;&#x2e;&#111;&#x72;&#103;This program is free software; you can redistribute it and&#x2F;or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation; either version 2, or (at your option)any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program; if not, write to the Free Software Foundation,Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.The latest version of this software can be obtained here:http://bash-completion.alioth.debian.org/RELEASE: 2.xThis function can be used to access a tokenized list of wordson the command line:__git_reassemble_comp_words_by_ref ‘&#x3D;:’if test “${words_[cword_-1]}” &#x3D; -wthen…fiThe argument should be a collection of characters from the list ofword completion separators (COMP_WORDBREAKS) to treat as ordinarycharacters.This is roughly equivalent to going back in time and settingCOMP_WORDBREAKS to exclude those characters. The intent is tomake option types like –date&#x3D; and : easy torecognize by treating each shell word as a single token.It is best not to set COMP_WORDBREAKS directly because the value isshared with other completion scripts. By the time the completionfunction gets called, COMP_WORDS has already been populated so localchanges to COMP_WORDBREAKS have no effect.Output: words_, cword_, cur_.git_reassemble_comp_words_by_ref(){ local exclude i j first # Which word separators to exclude? exclude&#x3D;”${1&#x2F;&#x2F;[^$COMP_WORDBREAKS]}” cword&#x3D;$COMP_CWORD if [ -z “$exclude” ]; then words&#x3D;(“${COMP_WORDS[@]}”) return fi # List of word completion separators has shrunk; # re-assemble words to complete. for ((i&#x3D;0, j&#x3D;0; i &lt; $"},{"path":"/2023/09/28/Linux配置文件/wireshark/git/install/","content":"#安装依赖库yum install expat-devel zlib-devel curl-devel openssl-devel gettext-devel #获取git源码git clone https://github.com/git/git #安装,进入到git目录 make prefix&#x3D;&#x2F;Data&#x2F;appmake prefix&#x3D;&#x2F;Data&#x2F;app install #git的项目仓库克隆到本地，以便更新git clone git:&#x2F;&#x2F;git.kernel.org&#x2F;pub&#x2F;scm&#x2F;git&#x2F;git.git ##########gitolite控制权限############# #安装在git用户下 ###客户端su gitssh-keygen -f ~&#x2F;.ssh&#x2F;admin admin.pub发送到server端&#x2F;home&#x2F;git下 ###服务端 su gitcdgit clone git:&#x2F;&#x2F;github.com&#x2F;sitaramc&#x2F;gitolite mkdir ~&#x2F;bin .&#x2F;gitolite&#x2F;install -to ~&#x2F;bin .&#x2F;bin&#x2F;gitolite setup -pk admin.pub #将admin公钥组添加到&#x2F;home&#x2F;git&#x2F;.ssh&#x2F;authorized_keys下，执行此操作前要确保authorized_keys为空或者不存在 ###################客户端常用命令####################################################################################git config –system user.name “”#git config –system user.email xx@.com #git config –global user.name “”#git config –global user.email xx@.com##git config –global push.default simple ######################################################### #初始化一个新的版本库git init git add file git commit file -m “” #与远程git版本库建立联系git remote add origin &#x67;&#x69;&#x74;&#64;&#x67;&#105;&#116;&#104;&#117;&#98;&#46;&#99;&#111;&#x6d;:shidg&#x2F;test.git #推送到远程版本库git push -u origin master 查看版本库状态git status 修改记录git log 命令记录git reflog #版本库回退到上个版本git reset –hard HEAD^ #版本库回退到上上个版本git reset –hard HEAD^^ #回退到指定版本git reset –hard d27413c #丢弃工作区的修改,让工作区文件回到最近的git add状态，若修改后尚未git add,则回到最近的git commit状态。git checkout – file #丢弃暂存区的修改,撤销git addgit reset HEAD file"},{"path":"/2023/09/28/Linux配置文件/fastdfs/4.06/tracker.conf/","content":"is this config file disabledfalse for enabledtrue for disableddisabled&#x3D;false ��������ļ��Ƿ���Ч,�Ǻ�(�ĳ��Ƿ���Ч�ǲ��ǻ����˸о��õ���?) false Ϊ��Ч(������Ч) true��֮bind an address of this hostempty for bind all addresses of this hostbind_addr&#x3D; �Ƿ��IP,bind_addr&#x3D; ����Ϊ�󶨵�IP��ַ (�����ڷ������ж��IP��ֻϣ��һ��IP�ṩ����)������������ʾ���е�(һ�㲻���OK),���Ž�������SA�����õ����ƹ���,�ܶ�ϵͳ��Ӧ�ö���the tracker server portport&#x3D;22122 �ṩ����Ķ˿�,�������������connect timeout in secondsdefault value is 30sconnect_timeout&#x3D;30#���ӳ�ʱʱ�䣬���socket�׽��ֺ���connect network timeout in secondsnetwork_timeout&#x3D;60 tracker server�����糬ʱ����λΪ�롣���ͻ��������ʱ������ڳ�ʱʱ��󻹲��ܷ��ͻ�������ݣ��򱾴�����ͨ��ʧ�ܡ�the base path to store data and log filesbase_path&#x3D;&#x2F;home&#x2F;yuqing&#x2F;fastdfs base_path Ŀ¼��ַ(��Ŀ¼�������,��Ŀ¼���Զ�����)��Ŀ¼˵��: tracker serverĿ¼���ļ��ṹ�� ${base_path} |__data | |__storage_groups.dat���洢������Ϣ | |__storage_servers.dat���洢�������б� |__logs |__trackerd.log��tracker server��־�ļ� �����ļ�storage_groups.dat��storage_servers.dat�еļ�¼֮���Ի��з��� ���ָ����ֶ�֮�������Ķ��ţ�,���ָ���storage_groups.dat�е��ֶ�����Ϊ�� group_name������ storage_port��storage server�˿ں� storage_servers.dat�м�¼storage server�����Ϣ���ֶ�����Ϊ�� group_name���������� ip_addr��ip��ַ status��״̬ sync_src_ip_addr�����storage serverͬ�����������ļ���Դ������ sync_until_timestamp��ͬ�����������ļ��Ľ���ʱ�䣨UNIXʱ����� stat.total_upload_count���ϴ��ļ����� stat.success_upload_count���ɹ��ϴ��ļ����� stat.total_set_meta_count������meta data���� stat.success_set_meta_count���ɹ�����meta data���� stat.total_delete_count��ɾ���ļ����� stat.success_delete_count���ɹ�ɾ���ļ����� stat.total_download_count�������ļ����� stat.success_download_count���ɹ������ļ����� stat.total_get_meta_count����ȡmeta data���� stat.success_get_meta_count���ɹ���ȡmeta data���� stat.last_source_update�����һ��Դͷ����ʱ�䣨���²������Կͻ��ˣ� stat.last_sync_update�����һ��ͬ������ʱ�䣨���²�����������storage server��ͬ���� max concurrent connections this server supportedmax_connections worker threads start when this service startupmax_connections&#x3D;256 ϵͳ�ṩ����ʱ�����������������V1.x����һ��������һ���̷߳���Ҳ���ǹ����߳���������V2.x������������͹����߳���û���κι�ϵwork thread count, should &lt;&#x3D; max_connectionsdefault value is 4since V2.00V2.0�������������������߳�����ͨ������ΪCPU��work_threads&#x3D;4 the method of selecting group to upload files0: round robin1: specify group2: load balance, select the max free space group to upload filestore_lookup&#x3D;2 �ϴ���(��) �ķ�ʽ 0:��ѯ��ʽ 1: ָ���� 2: ƽ�⸺��(ѡ�����ʣ��ռ����(��)�ϴ�)���������Ӧ�ò�ָ�����ϴ���һ���̶���,��ô����������ƹ�which group to upload filewhen store_lookup set to 1, must set store_group to the group namestore_group&#x3D;group2 ����һ�������趨Ϊ1 ʱ (store_lookup&#x3D;1����ָ������ʱ)���������ñ�����Ϊϵͳ�д��ڵ�һ�����������ѡ���������ϴ���ʽ�����������û��Ч�ˡ�which storage server to upload file0: round robin (default)1: the first server order by ip address2: the first server order by priority (the minimal)store_server&#x3D;0 ѡ���ĸ�storage server �����ϴ�����(һ���ļ����ϴ������storage server���൱������ļ���storage serverԴ�����ͬ���storage server��������ļ��ﵽͬ��Ч��)0: ��ѯ��ʽ1: ����ip ��ַ��������ѡ���һ����������IP��ַ��С�ߣ�2: �������ȼ����������ϴ����ȼ���storage server�����ã�������Ϊupload_priority��which path(means disk or mount point) of the storage server to upload file0: round robin2: load balance, select the max free space path to upload filestore_path&#x3D;0 ѡ��storage server �е��ĸ�Ŀ¼�����ϴ���storage server�����ж������ļ���base path����������Ϊ������̣���0: ������ʽ�����Ŀ¼���δ���ļ�2: ѡ��ʣ��ռ�����Ŀ¼����ļ���ע�⣺ʣ����̿ռ��Ƕ�̬�ģ���˴洢����Ŀ¼����̿���Ҳ�Ǳ仯�ģ�which storage server to download file0: round robin (default)1: the source storage server which the current file uploaded todownload_server&#x3D;0 ѡ���ĸ� storage server ��Ϊ���ط�����0: ��ѯ��ʽ���������ص�ǰ�ļ�����һstorage server1: �ĸ�ΪԴstorage server ������һ�� (ǰ��˵�������storage serverԴ ������������) ����֮ǰ�ϴ����ĸ�storage server�����������ĸ���reserved storage space for system or other applications.if the free(available) space of any stoarge server ina group &lt;&#x3D; reserved_storage_space,no file can be uploaded to this group.bytes unit can be one of follows:G or g for gigabyte(GB)M or m for megabyte(MB)K or k for kilobyte(KB)no unit for byte(B)XX.XX% as ratio such as reserved_storage_space &#x3D; 10%reserved_storage_space &#x3D; 10% storage server �ϱ����Ŀռ䣬��֤ϵͳ������Ӧ������ռ䡣�����þ���ֵ���߰ٷֱȣ�V4��ʼ֧�ְٷֱȷ�ʽ����#(ָ�� ���ͬ��ķ�������Ӳ�̴�Сһ��,����С��Ϊ׼,Ҳ����ֻҪͬ������һ̨�������ﵽ�����׼��,�����׼����Ч,ԭ�������Ϊ���ǽ��б���) #standard log level as syslog, case insensitive, value list: emerg for emergencyalertcrit for criticalerrorwarn for warningnoticeinfodebuglog_level&#x3D;info ѡ����־����(��־д����?��ǰ���˵����,��Ŀ¼����Ŷ �Ǻ�)#unix group name to run this program,#not set (empty) means run by the group of current userrun_by_group&#x3D; ����ϵͳ����FastDFS���û��� (���� ���ǵ�ǰ�û���,�ĸ��������̾����ĸ�)#unix username to run this program,#not set (empty) means run by current userrun_by_user&#x3D; ����ϵͳ����FastDFS���û� (���� ���ǵ�ǰ�û�,�ĸ��������̾����ĸ�)allow_hosts can ocur more than once, host can be hostname or ip address,“*” means match all ip addresses, can use range like this: 10.0.1.[1-15,20] orhost[01-08,20-25].domain.com, for example:allow_hosts&#x3D;10.0.1.[1-15,20]allow_hosts&#x3D;host[01-08,20-25].domain.comallow_hosts&#x3D;* �������ӵ��� tracker server ��ip��Χ�����������͵����Ӷ���Ӱ�죬�����ͻ��ˣ�storage server��sync log buff to disk every interval secondsdefault value is 10 secondssync_log_buff_interval &#x3D; 10 ͬ����ˢ����־��Ϣ��Ӳ�̵�ʱ��������λΪ��ע�⣺tracker server ����־����ʱʱдӲ�̵ģ�������д�ڴ档check storage server alive intervalcheck_active_interval &#x3D; 120 ��� storage server ����ʱ�������λΪ�롣storage server������tracker server �����������tracker server��һ��check_active_interval�ڻ�û���յ�storage server��һ���������Ǳ߽���Ϊ��storage server�Ѿ����ߡ����Ա�����ֵ�������storage server���õ�����ʱ������ͨ������Ϊstorage server����ʱ������2����3����thread stack size, should &gt; 512KBdefault value is 1MBthread_stack_size&#x3D;1MB �߳�ջ�Ĵ�С��FastDFS server�˲������̷߳�ʽ������һ�£�tracker server�߳�ջ��ӦС��64KB������512KB���߳�ջԽ��һ���߳�ռ�õ�ϵͳ��Դ��Խ�ࡣ���Ҫ����������̣߳�V1.x��Ӧ�Ĳ���Ϊmax_connections��V2.0Ϊwork_threads���������ʵ����ͱ�����ֵ�� auto adjust when the ip address of the storage server changeddefault value is truestorage_ip_changed_auto_adjust&#x3D;true ����������Ƶ�storage server IP��ַ�ı�ʱ����Ⱥ�Ƿ��Զ�������ע��ֻ����storage server��������ʱ������Զ�������storage sync file max delay secondsdefault value is 86400 seconds (one day)since V2.00storage_sync_file_max_delay &#x3D; 86400 V2.0����Ĳ������洢������֮��ͬ���ļ�������ӳ�ʱ�䣬ȱʡΪ1�졣����ʵ��������е���ע������������Ӱ���ļ�ͬ�����̡����������������ļ�ʱ���ж��ļ��Ƿ��Ѿ���ͬ����ɵ�һ����ֵ������ֵ��the max time of storage sync a filedefault value is 300 secondssince V2.00storage_sync_file_max_time &#x3D; 300 V2.0����Ĳ������洢������ͬ��һ���ļ���Ҫ���ĵ����ʱ�䣬ȱʡΪ300s����5���ӡ�ע������������Ӱ���ļ�ͬ�����̡����������������ļ�ʱ����Ϊ�жϵ�ǰ�ļ��Ƿ�ͬ����ɵ�һ����ֵ������ֵ��if use a trunk file to store several small filesdefault value is falsesince V3.00use_trunk_file &#x3D; false V3.0����Ĳ������Ƿ�ʹ��С�ļ��ϲ��洢���ԣ�ȱʡ�ǹرյġ�the min slot size, should &lt;&#x3D; 4KBdefault value is 256 bytessince V3.00slot_min_size &#x3D; 256 V3.0����Ĳ�����trunk file�������С�ֽ����������ļ�ֻ��16���ֽڣ�ϵͳҲ�����slot_min_size���ֽڡ�the max slot size, should &gt; slot_min_sizestore the upload file to trunk file when it’s size &lt;&#x3D; this valuedefault value is 16MBsince V3.00slot_max_size &#x3D; 16MB V3.0����Ĳ�����ֻ���ļ���С&lt;&#x3D;�������ֵ���ļ����Ż�ϲ��洢�����һ���ļ��Ĵ�С�����������ֵ����ֱ�ӱ��浽һ���ļ��У��������úϲ��洢��ʽ����the trunk file size, should &gt;&#x3D; 4MBdefault value is 64MBsince V3.00trunk_file_size &#x3D; 64MB V3.0����Ĳ������ϲ��洢��trunk file��С������4MB��ȱʡֵ��64MB�����������õù���if create trunk file advancelydefault value is falsetrunk_create_file_advance &#x3D; false �Ƿ���ǰ����trunk file��ֻ�е��������Ϊtrue������3����trunk_create_file_��ͷ�Ĳ�������Ч��the time base to create trunk filethe time format: HH:MMdefault value is 02:00trunk_create_file_time_base &#x3D; 02:00 ��ǰ����trunk file����ʼʱ��㣨��׼ʱ�䣩��02:00��ʾ��һ�δ�����ʱ������賿2�㡣the interval of create trunk file, unit: seconddefault value is 38400 (one day)trunk_create_file_interval &#x3D; 86400 ����trunk file��ʱ��������λΪ�롣���ÿ��ֻ��ǰ����һ�Σ�������Ϊ86400the threshold to create trunk filewhen the free trunk file size less than the threshold, will createthe trunk filesdefault value is 0trunk_create_file_space_threshold &#x3D; 20G ��ǰ����trunk fileʱ����Ҫ�ﵽ�Ŀ���trunk��С���籾����Ϊ20G������ǰ����trunkΪ4GB����ôֻ��Ҫ����16GB��trunk file���ɡ�if check trunk space occupying when loading trunk free spacesthe occupied spaces will be ignoreddefault value is falsesince V3.09NOTICE: set this parameter to true will slow the loading of trunk spaceswhen startup. you should set this parameter to true when neccessary.trunk_init_check_occupying &#x3D; false#trunk��ʼ��ʱ���Ƿ�����ÿռ��Ƿ�ռ�� if ignore storage_trunk.dat, reload from trunk binlogdefault value is falsesince V3.10set to true once for version upgrade when your version less than V3.10trunk_init_reload_from_binlog &#x3D; false �Ƿ���������trunk binlog�м���trunk���ÿռ���ϢFastDFSȱʡ�Ǵӿ����ļ�storage_trunk.dat�м���trunk���ÿռ䣬���ļ��ĵ�һ�м�¼����trunk binlog��offset��Ȼ���binlog��offset��ʼ����if use storage ID instead of IP addressdefault value is falsesince V4.00use_storage_id &#x3D; false �Ƿ�ʹ��server ID��Ϊstorage server��ʶspecify storage ids filename, can use relative or absolute pathsince V4.00storage_ids_filename &#x3D; storage_ids.conf use_storage_id ����Ϊtrue������Ҫ���ñ��������ļ�������������server ID�Ͷ�Ӧ��IP��ַ���μ�Դ��Ŀ¼�µ�����ʾ����conf&#x2F;storage_ids.confid type of the storage server in the filename, values are:ip: the ip address of the storage serverid: the server id of the storage serverthis paramter is valid only when use_storage_id set to truedefault value is ipsince V4.03id_type_in_filename &#x3D; ip use_storage_id ����Ϊtrue������Ҫ���ñ�����if store slave file use symbol linkdefault value is falsesince V4.01store_slave_file_use_link &#x3D; false �洢���ļ��Ƿ����symbol link���������ӣ���ʽ�������Ϊtrue��һ�����ļ���ռ�������ļ���ԭʼ�ļ���ָ�����ķ������ӡ�if rotate the error log every daydefault value is falsesince V4.02rotate_error_log &#x3D; false �Ƿ�����תerror log��Ŀǰ��֧��һ����תһ��rotate error log time base, time format: Hour:MinuteHour from 0 to 23, Minute from 0 to 59default value is 00:00since V4.02error_log_rotate_time&#x3D;00:00 error log������ת��ʱ��㣬ֻ�е�rotate_error_log����Ϊtrueʱ��Чrotate error log when the log file exceeds this size0 means never rotates log file by log file sizedefault value is 0since V4.02rotate_error_log_size &#x3D; 0 error log����С��ת����Ϊ0��ʾ�����ļ���С��ת������error log�ﵽ�ô�С���ͻ���ת�����ļ���if use connection pooldefault value is falsesince V4.05use_connection_pool &#x3D; false �Ƿ�ʹ�����ӳ�connections whose the idle time exceeds this time will be closedunit: seconddefault value is 3600since V4.05connection_pool_max_idle_time &#x3D; 3600 ���ӵĿ���ʱ�䳬�����ʱ�佫���ر�HTTP port on this tracker serverhttp.server_port&#x3D;8080 ͨ��tracker:8080&#x2F;status.html �鿴����storage�Ĵ��״̬check storage HTTP server alive interval seconds&lt;&#x3D; 0 for never checkdefault value is 30http.check_alive_interval&#x3D;30 ��� storage HTTP���������ʱ����check storage HTTP server alive type, values are:tcp : connect to the storge server with HTTP port only,do not request and get responsehttp: storage check alive url must return http status 200default value is tcphttp.check_alive_type&#x3D;tcp ���torage HTTP��������ͨ������check storage HTTP server alive uri&#x2F;urlNOTE: storage embed HTTP server support uri: &#x2F;status.htmlhttp.check_alive_uri&#x3D;&#x2F;status.html"},{"path":"/2023/09/28/Linux配置文件/fastdfs/4.06/fastdfs-nginx-module_v1.15mod_fastdfs.conf/","content":"connect timeout in secondsdefault value is 30sconnect_timeout&#x3D;2#���ӳ�ʱʱ�� network recv and send timeout in secondsdefault value is 30snetwork_timeout&#x3D;30#���糬ʱʱ�䣬��λΪ��.���ͻ��������ʱ������ڳ�ʱʱ��󻹲��ܷ��ͻ�������ݣ��򱾴�����ͨ��ʧ�� the base path to store log filesbase_path&#x3D;&#x2F;home&#x2F;fastdfs&#x2F;storage&#x2F;logs#fastdfs-nginx������־���Ŀ¼ if load FastDFS parameters from tracker serversince V1.12default value is falseload_fdfs_parameters_from_tracker&#x3D;true#�Ƿ��tracker server���ر���#ѡ��true�����ظ�����tracker�����õĲ�������storage_id������ʵ��,#�����Ļ�storage_idģʽֻ��Ҫ��tracker���þͺ��� storage sync file max delay secondssame as tracker.confvalid only when load_fdfs_parameters_from_tracker is falsesince V1.12default value is 86400 seconds (one day)storage_sync_file_max_delay &#x3D; 86400 if use storage ID instead of IP addresssame as tracker.confvalid only when load_fdfs_parameters_from_tracker is falsedefault value is falsesince V1.13use_storage_id &#x3D; false specify storage ids filename, can use relative or absolute pathsame as tracker.confvalid only when load_fdfs_parameters_from_tracker is falsesince V1.13storage_ids_filename &#x3D; storage_ids.conf FastDFS tracker_server can ocur more than once, and tracker_server format is“host:port”, host can be hostname or ip addressvalid only when load_fdfs_parameters_from_tracker is truetracker_server&#x3D;tracker:22122#���load_fdfs_parameters_from_tracker����Ϊtrue�Ļ���nginx������tracker���ͨ�Ų��ܻ�ȡ#storage_ids���������� the port of the local storage serverthe default value is 23000storage_server_port&#x3D;23000#��fastdfs-nginx�������ͬһ��������storage server�Ķ˿� the group name of the local storage servergroup_name&#x3D;group1#��fastdfs-nginx�������ͬһ��������storage server�������� if the url &#x2F; uri including the group nameset to false when uri like &#x2F;M00&#x2F;00&#x2F;00&#x2F;xxxset to true when uri like ${group_name}&#x2F;M00&#x2F;00&#x2F;00&#x2F;xxx, such as group1&#x2F;M00&#x2F;xxxdefault value is falseurl_have_group_name &#x3D; false#�ⲿͨ��nginx����url���Ƿ�� group name path(disk or mount point) count, default value is 1must same as storage.confstore_path_count&#x3D;1#��fastdfs-nginx�������ͬһ��������storage server#����ļ�ʱstorage server֧�ֶ��·����������̣�.store_path0��Ӧ�洢·��#storage �������д˲������ɸ��ƹ�������һ�� store_path#, based 0, if store_path0 not exists, it’s value is base_paththe paths must be existmust same as storage.confstore_path0&#x3D;&#x2F;home&#x2F;yuqing&#x2F;fastdfs#store_path1&#x3D;&#x2F;home&#x2F;yuqing&#x2F;fastdfs1#storage �������д˲������ɸ��ƹ�������һ�� standard log level as syslog, case insensitive, value list:emerg for emergencyalertcrit for criticalerrorwarn for warningnoticeinfodebuglog_level&#x3D;info set the log filename, such as &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;logs&#x2F;mod_fastdfs.logempty for output to stderr (apache and nginx error_log file)log_filename&#x3D; response mode when the file not exist in the local file systemproxy: get the content from other storage server, then send to clientredirect: redirect to the original storage server (HTTP Header is Location)response_mode&#x3D;proxy the NIC alias prefix, such as eth in Linux, you can see it by ifconfig -amulti aliases split by comma. empty value means auto set by OS typethis paramter used to get all ip address of the local hostdefault values is emptyif_alias_prefix&#x3D; if need find content type from file extension nameshould set to false in apache server because it done by apacheshould set to true in nginx serverhttp.need_find_content_type&#x3D;false#nginx����Ϊtrue��apache����Ϊfalse use “#include” directive to include HTTP config fileNOTE: #include is an include directive, do NOT remove the # before include#include http.conf if support flvdefault value is falsesince v1.15flv_support &#x3D; false#�Ƿ�֧��flv��Ƶ�� flv file extension namedefault value is flvsince v1.15flv_extension &#x3D; flv#��Ƶ�ļ���չ Ĭ��flv set the group countset to none zero to support multi-groupset to 0 for single group onlygroups settings section as [group1], [group2], …, [groupN]default value is 0since v1.14group_count &#x3D; 0 group settings for group #1since v1.14when support multi-group, uncomment following section#[group1]#group_name&#x3D;group1#storage_server_port&#x3D;23000#store_path_count&#x3D;2#store_path0&#x3D;&#x2F;home&#x2F;yuqing&#x2F;fastdfs#store_path1&#x3D;&#x2F;home&#x2F;yuqing&#x2F;fastdfs1 group settings for group #2since v1.14when support multi-group, uncomment following section as neccessary#[group2]#group_name&#x3D;group2#storage_server_port&#x3D;23000#store_path_count&#x3D;1#store_path0&#x3D;&#x2F;home&#x2F;yuqing&#x2F;fastdfs"},{"path":"/2023/09/28/Linux配置文件/wireshark/cacti/template/varnish/Cacti_Plugin_for_Varnish_3.x/varnish_stats.sh/","content":"#!&#x2F;bin&#x2F;bash &#x2F;usr&#x2F;local&#x2F;bin&#x2F;varnishstat -1 &gt; &#x2F;tmp&#x2F;varnish.$$ awk ‘{ printf (“%s:%s “,$1,$2)}’ &#x2F;tmp&#x2F;varnish.$$ rm -rf &#x2F;tmp&#x2F;varnish.$$"},{"path":"/2023/09/28/Linux配置文件/wireshark/cacti/template/varnish/Cacti_Plugin_for_Varnish_3.x/README/","content":"How to install1 - Import cacti_host_template_varnish.xml to Cacti (tested with 0.8.8a)2 - Copy getVarnishStats.sh to “scripts”3 - Configure snmpd.conf into the varnish server 3.1 - Add this line to snmpd.conf extend varnishstats “&#x2F;etc&#x2F;snmp&#x2F;varnish_stats.sh” 3.2 - Copy varnish_stats.sh to “&#x2F;etc&#x2F;snmp” ###############################################################################IMPORTANT: You need to recompile spine with “.&#x2F;configure –with-results-buffer&#x3D;2048”############################################################################### NOTE: Changing “getVarnishStats.sh” you can change your poll method. ��ΰ�װ1 - ���� cacti_host_template_varnish.xml ģ�嵽 Cacti (tested with 0.8.8a)2 - ���� getVarnishStats.sh �� Cacti�� “scripts” Ŀ¼��3 - ���� snmpd.conf ��֧��Varnish 3.1 - �� snmpd.conf β������һ������ extend varnishstats “&#x2F;etc&#x2F;snmp&#x2F;varnish_stats.sh” 3.2 - ���� varnish_stats.sh �� “&#x2F;etc&#x2F;snmp” ###############################################################################ע��: ��varnish����snmp���ݳ��ȹ�����Ҫ���±��� spine �����ϻ����С�������磺 “.&#x2F;configure –with-results-buffer&#x3D;2048”############################################################################### ˵��: ���� “getVarnishStats.sh” �еĲ�������ѡ��SNMP�汾,SNMP V3��Ҫ�ڽű���ָ���û���������"},{"path":"/2023/09/28/Linux配置文件/wireshark/cacti/template/varnish/Cacti_Plugin_for_Varnish_3.x/getVarnishStats.sh/","content":"#!&#x2F;bin&#x2F;bash host&#x3D;$1com&#x3D;$2OID&#x3D;”.1.3.6.1.4.1.8072.1.3.2.3.1.1.12.118.97.114.110.105.115.104.115.116.97.116.115” For SNMP V2resultados&#x3D;snmpwalk -t 20 -Oqv -v 2c -c $com $host $OID | awk &#39;&#123; printf(&quot;%s&quot;, $0) &#125;&#39; For SNMP V3 -u username -A password#resultados&#x3D;snmpwalk -v3 -u cactiuser -l auth -a MD5 -A cactiuser $host $OID | awk &#39;&#123; printf(&quot;%s&quot;, $0) &#125;&#39; echo -n $resultados"},{"path":"/2023/09/28/Linux配置文件/wireshark/cacti/template/php-fpm/sh/cacti_check_php-fpm.sh/","content":"#!&#x2F;bin&#x2F;shhost&#x3D;$1port&#x3D;$2url&#x3D;$3conn&#x3D;curl -s http://$&#123;host&#125;:$&#123;port&#125;$&#123;url&#125; | grep &quot;accepted conn&quot;conn&#x3D;echo $conn | awk &#39;&#123;print $3&#125;&#39;idle&#x3D;curl -s http://$&#123;host&#125;:$&#123;port&#125;$&#123;url&#125; | grep &quot;idle processes&quot;idle&#x3D;echo $idle | awk &#39;&#123;print $3&#125;&#39;active&#x3D;curl -s http://$&#123;host&#125;:$&#123;port&#125;$&#123;url&#125; | grep &quot;active processes&quot;active&#x3D;echo $active | awk &#39;&#123;print $3&#125;&#39;total&#x3D;curl -s http://$&#123;host&#125;:$&#123;port&#125;$&#123;url&#125; | grep &quot;total processes&quot;total&#x3D;echo $total | awk &#39;&#123;print $3&#125;&#39;echo “conn:$conn idle:$idle active:$active total:$total”"},{"path":"/2023/09/28/Linux配置文件/wireshark/cacti/template/mysql/README/","content":"READMEmysql_stats.phpversion 2.0.1enables cacti to read mysql statisticssupport: Scott McCarty &#x73;&#99;&#111;&#116;&#116;&#46;&#x6d;&#x63;&#99;&#97;&#x72;&#x74;&#x79;&#64;&#103;&#x6d;&#x61;&#x69;&#108;&#x2e;&#x63;&#111;&#x6d;author: Otto Berger &#x62;&#x65;&#x72;&#103;&#101;&#x72;&#x40;&#104;&#x6b;&#x2d;&#110;&#101;&#116;&#46;&#100;&#x65;date: 2005&#x2F;01&#x2F;18 - 2011 INSTALLATION put the mysql_stats.php file inside the cacti&#x2F;scripts&#x2F; directory import the .xml-Files using the cacti webinterface To upgrade a previous installation, have a look below. USAGEConfigure the mysql-server you want to graph. To enable access from thecacti-machine to the mysql-status informations, you must have the“process” right. Use for example the following mysql-command to set the process-right for themysql-user “cactiuser” with the password “cactipasswd”: GRANT PROCESS ON . TO cactiuser@’localhost’ IDENTIFIED by ‘cactipasswd’; To monitor a foreign host, fill in the hostname where you came from,for example: GRANT PROCESS ON . TO cactiuser@’cactihost.com’ IDENTIFIED by ‘cactipasswd’; GRAPH CREATION Click inside cacti on “New Graphs” Choose host and a mysql-template Click create Fill in the MySQL-username and password as specified obove Finished! UPGRADEPut the new mysql_stats.php file inside the cacti&#x2F;scripts&#x2F; directoryYou can now delete the other mysql_* php-files… –&gt; Normally the import of the xml-files using the cacti-interface–&gt; would be enough to upgrade. In case of errors, or to prevent them, you have to edit the“data input methods” manually through the webinterface. For each MySQL-input method you have to change the input string to one of the following: MySQL - QCache statistics: -q &#x2F;scripts&#x2F;mysql_stats.php cache MySQL - Single Statistics: -q &#x2F;scripts&#x2F;mysql_stats.php status MySQL - Handler statistics: -q &#x2F;scripts&#x2F;mysql_stats.php handler MySQL - Command statistics: -q &#x2F;scripts&#x2F;mysql_stats.php command MySQL - Thread statistics: -q &#x2F;scripts&#x2F;mysql_stats.php thread"},{"path":"/2023/09/28/Linux配置文件/wireshark/cacti/template/lvs/install.sh/","content":"#服务端cacti导入模版 cacti_data_query_lvs.xmlsnmp-lvs.xml上传到cacti_path&#x2F;resource&#x2F;net_queries目录下 Host Templates–&gt;Add#填写一下信息Name：自定义 Associated Graph Templates： ucd&#x2F;net-LVS-Connections –&gt; AddSave Data Templates –&gt; ucd&#x2F;net - LVS-Connections Data Input Method –&gt; Get SNMP DataOID Save #客户端安装snmp-lvs-module rpm -ivh net-snmp-lvs-module-0.0.4-5.el6.x86_64.rpm#验证是否安装成功snmptranslate -m LVS-MIB -On -IR lvsServiceEntry snmpwalk -v 2c 172.16.83.93 -c public .1.3.6.1.4.1.8225.4711.17.1.10 vi &#x2F;etc&#x2F;snmp&#x2F;snmpd.conf ,加入以下行 dlmod lvs &#x2F;usr&#x2F;lib64&#x2F;libnetsnmplvs.so service snmpd restart"},{"path":"/2023/09/28/Linux配置文件/wireshark/cacti/scripts/snmp-cacti-mailq.sh/","content":"#!&#x2F;bin&#x2F;sh snmp-cacti-mailq.shAutor : Danny Bendersky &#x64;&#x61;&#110;&#110;&#x79;&#64;&#116;&#x65;&#x61;&#109;&#x2e;&#105;&#x6e;&#116;&#x65;&#114;&#x2e;&#x6e;&#x65;&#116;Date : 12 Feb 2002Version : 1.0Description\t: Script that give the mailq in a server with SNMPVerify that there is an input——————————if [ -z “$1” ]; thenecho “usage: snmp-cacti-mailq.sh “echoexitfi# Variables———SERVER&#x3D;$1 # Example: 10.0.0.3SNMPCOMUNITY&#x3D;$2 # Example: public#&#x2F;usr&#x2F;bin&#x2F;snmpwalk -v 1 $SERVER $SNMPCOMUNITY .1.3.6.1.4.1.2021.53.101.0| awk ‘{ print $5 }’|sed -e “s&#x2F;(&#x2F;&#x2F;g”## End of File"},{"path":"/2023/09/28/Linux配置文件/wireshark/cacti/scripts/snmp-cacti-load.sh/","content":"#!&#x2F;bin&#x2F;sh snmp-cacti-load.shAutor : Danny Bendersky &#x64;&#97;&#x6e;&#x6e;&#121;&#64;&#x74;&#x65;&#x61;&#109;&#x2e;&#105;&#110;&#x74;&#x65;&#x72;&#x2e;&#x6e;&#101;&#116;Date : 11 Feb 2002Version : 1.0Description\t: Script that give the load in a server with SNMP.Verify that there is an input——————————if [ -z “$1” ]; thenecho “usage: snmp-cacti-load.sh “echoexitfi# Variables———SERVER&#x3D;$1 # Example: 10.0.0.3SNMPCOMUNITY&#x3D;$2 # Example: publicNUM&#x3D;$3 # Example: 1#case $NUM in 1) &#x2F;usr&#x2F;bin&#x2F;snmpget $SERVER $SNMPCOMUNITY .1.3.6.1.4.1.2021.10.1.3.1 | awk ‘{print $3}’ ;; 5) &#x2F;usr&#x2F;bin&#x2F;snmpget $SERVER $SNMPCOMUNITY .1.3.6.1.4.1.2021.10.1.3.2 | awk ‘{print $3}’ ;; 15) &#x2F;usr&#x2F;bin&#x2F;snmpget $SERVER $SNMPCOMUNITY .1.3.6.1.4.1.2021.10.1.3.3 | awk ‘{print $3}’ ;; *) &#x2F;usr&#x2F;bin&#x2F;snmpget $SERVER $SNMPCOMUNITY .1.3.6.1.4.1.2021.10.1.3.1 | awk ‘{print $3}’ &#x2F;usr&#x2F;bin&#x2F;snmpget $SERVER $SNMPCOMUNITY .1.3.6.1.4.1.2021.10.1.3.2 | awk ‘{print $3}’ &#x2F;usr&#x2F;bin&#x2F;snmpget $SERVER $SNMPCOMUNITY .1.3.6.1.4.1.2021.10.1.3.3 | awk ‘{print $3}’ ;;esac# End of File"},{"path":"/2023/09/28/Linux配置文件/wireshark/cacti/scripts/sendmail_messages.sh/","content":"#!&#x2F;bin&#x2F;bash# Autor : Stefan Arts, HollandDate : 07&#x2F;22&#x2F;05Version : 1.0Description : Script to output the number of messages send to sendmailOutput is If you run the cacti poller as non-root, then you may needneed to change the permissions of the sendmail statisticsfile. Example:chmod 644 &#x2F;etc&#x2F;mail&#x2F;statistics&#x2F;usr&#x2F;sbin&#x2F;mailstats | grep ^\\ T | cut -b25-32 | sed s&#x2F;\\ *&#x2F;&#x2F;"},{"path":"/2023/09/28/Linux配置文件/wireshark/cacti/scripts/edit_rrd.sh/","content":"#!&#x2F;bin&#x2F;bash if [ $# &#x3D; 0 ]then echo “Usage .&#x2F;edit_rrd.sh [FILENAME]” exitfi rrdtool dump $1 &gt; &#x2F;tmp&#x2F;work.xml vi &#x2F;tmp&#x2F;work.xml rm -f $1 rrdtool restore &#x2F;tmp&#x2F;work.xml $1"},{"title":"denyhosts.conf","path":"/2023/09/28/Linux配置文件/denyhosts/denyhosts.conf/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634 ############ THESE SETTINGS ARE REQUIRED ###################################################################################### SECURE_LOG: the log file that contains sshd logging info# if you are not sure, grep &quot;sshd:&quot; /var/log/*## The file to process can be overridden with the --file command line# argument## Redhat or Fedora Core:SECURE_LOG = /var/log/secure## Mandrake, FreeBSD or OpenBSD: #SECURE_LOG = /var/log/auth.log## SuSE:#SECURE_LOG = /var/log/messages## Mac OS X (v10.4 or greater - # also refer to: http://www.denyhosts.net/faq.html#macos#SECURE_LOG = /private/var/log/asl.log## Mac OS X (v10.3 or earlier):#SECURE_LOG=/private/var/log/system.log################################################################################################################################################### HOSTS_DENY: the file which contains restricted host access information## Most operating systems:HOSTS_DENY = /etc/hosts.deny## Some BSD (FreeBSD) Unixes:#HOSTS_DENY = /etc/hosts.allow## Another possibility (also see the next option):#HOSTS_DENY = /etc/hosts.evil################################################################################################################################################# PURGE_DENY: removed HOSTS_DENY entries that are older than this time# when DenyHosts is invoked with the --purge flag## format is: i[dhwmy]# Where &#x27;i&#x27; is an integer (eg. 7) # &#x27;m&#x27; = minutes# &#x27;h&#x27; = hours# &#x27;d&#x27; = days# &#x27;w&#x27; = weeks# &#x27;y&#x27; = years## never purge:#PURGE_DENY = ## purge entries older than 1 week#PURGE_DENY = 1w## purge entries older than 5 days#PURGE_DENY = 5d## For the default Fedora Extras install, we want timestamping but no# expiration (at least by default) so this is deliberately set high.# Adjust to taste.PURGE_DENY = 1w################################################################################################################################################ PURGE_THRESHOLD: defines the maximum times a host will be purged. # Once this value has been exceeded then this host will not be purged. # Setting this parameter to 0 (the default) disables this feature.## default: a denied host can be purged/re-added indefinitely#PURGE_THRESHOLD = 0## a denied host will be purged at most 2 times. PURGE_THRESHOLD = 2 ################################################################################################################################################# BLOCK_SERVICE: the service name that should be blocked in HOSTS_DENY# # man 5 hosts_access for details## eg. sshd: 127.0.0.1 # will block sshd logins from 127.0.0.1## To block all services for the offending host:#BLOCK_SERVICE = ALL# To block only sshd:BLOCK_SERVICE = sshd# To only record the offending host and nothing else (if using# an auxilary file to list the hosts). Refer to: # http://denyhosts.sourceforge.net/faq.html#aux#BLOCK_SERVICE = ################################################################################################################################################# DENY_THRESHOLD_INVALID: block each host after the number of failed login # attempts has exceeded this value. This value applies to invalid# user login attempts (eg. non-existent user accounts)#DENY_THRESHOLD_INVALID = 1################################################################################################################################################# DENY_THRESHOLD_VALID: block each host after the number of failed # login attempts has exceeded this value. This value applies to valid# user login attempts (eg. user accounts that exist in /etc/passwd) except# for the &quot;root&quot; user#DENY_THRESHOLD_VALID = 5################################################################################################################################################# DENY_THRESHOLD_ROOT: block each host after the number of failed # login attempts has exceeded this value. This value applies to # &quot;root&quot; user login attempts only.#DENY_THRESHOLD_ROOT = 3################################################################################################################################################# DENY_THRESHOLD_RESTRICTED: block each host after the number of failed # login attempts has exceeded this value. This value applies to # usernames that appear in the WORK_DIR/restricted-usernames file only.#DENY_THRESHOLD_RESTRICTED = 1################################################################################################################################################# WORK_DIR: the path that DenyHosts will use for writing data to# (it will be created if it does not already exist). ## Note: it is recommended that you use an absolute pathname# for this value (eg. /home/foo/denyhosts/data)#WORK_DIR = /var/lib/denyhosts################################################################################################################################################# SUSPICIOUS_LOGIN_REPORT_ALLOWED_HOSTS## SUSPICIOUS_LOGIN_REPORT_ALLOWED_HOSTS=YES|NO# If set to YES, if a suspicious login attempt results from an allowed-host# then it is considered suspicious. If this is NO, then suspicious logins # from allowed-hosts will not be reported. All suspicious logins from # ip addresses that are not in allowed-hosts will always be reported.#SUSPICIOUS_LOGIN_REPORT_ALLOWED_HOSTS=YES############################################################################################################################################## HOSTNAME_LOOKUP## HOSTNAME_LOOKUP=YES|NO# If set to YES, for each IP address that is reported by Denyhosts,# the corresponding hostname will be looked up and reported as well# (if available).#HOSTNAME_LOOKUP=NO############################################################################################################################################### LOCK_FILE## LOCK_FILE=/path/denyhosts# If this file exists when DenyHosts is run, then DenyHosts will exit# immediately. Otherwise, this file will be created upon invocation# and deleted upon exit. This ensures that only one instance is# running at a time.## Redhat/Fedora:LOCK_FILE = /var/lock/subsys/denyhosts## Debian#LOCK_FILE = /var/run/denyhosts.pid## Misc#LOCK_FILE = /tmp/denyhosts.lock####################################################################### ############ THESE SETTINGS ARE OPTIONAL ##################################################################################### ADMIN_EMAIL: if you would like to receive emails regarding newly# restricted hosts and suspicious logins, set this address to # match your email address. If you do not want to receive these reports# leave this field blank (or run with the --noemail option)## Multiple email addresses can be delimited by a comma, eg:# ADMIN_EMAIL = foo@bar.com, bar@foo.com, etc@foobar.com#ADMIN_EMAIL = root################################################################################################################################################# SMTP_HOST and SMTP_PORT: if DenyHosts is configured to email # reports (see ADMIN_EMAIL) then these settings specify the # email server address (SMTP_HOST) and the server port (SMTP_PORT)# #SMTP_HOST = localhostSMTP_PORT = 25################################################################################################################################################ # SMTP_USERNAME and SMTP_PASSWORD: set these parameters if your # smtp email server requires authentication##SMTP_USERNAME=foo#SMTP_PASSWORD=bar################################################################################################################################################ SMTP_FROM: you can specify the &quot;From:&quot; address in messages sent# from DenyHosts when it reports thwarted abuse attempts#SMTP_FROM = DenyHosts &lt;nobody@localhost&gt;################################################################################################################################################# SMTP_SUBJECT: you can specify the &quot;Subject:&quot; of messages sent# by DenyHosts when it reports thwarted abuse attemptsSMTP_SUBJECT = DenyHosts Report from $[HOSTNAME]############################################################################################################################################### SMTP_DATE_FORMAT: specifies the format used for the &quot;Date:&quot; header# when sending email messages.## for possible values for this parameter refer to: man strftime## the default:##SMTP_DATE_FORMAT = %a, %d %b %Y %H:%M:%S %z############################################################################################################################################### SYSLOG_REPORT## SYSLOG_REPORT=YES|NO# If set to yes, when denied hosts are recorded the report data# will be sent to syslog (syslog must be present on your system).# The default is: NO##SYSLOG_REPORT=NO##SYSLOG_REPORT=YES############################################################################################################################################### ALLOWED_HOSTS_HOSTNAME_LOOKUP## ALLOWED_HOSTS_HOSTNAME_LOOKUP=YES|NO# If set to YES, for each entry in the WORK_DIR/allowed-hosts file,# the hostname will be looked up. If your versions of tcp_wrappers# and sshd sometimes log hostnames in addition to ip addresses# then you may wish to specify this option.# #ALLOWED_HOSTS_HOSTNAME_LOOKUP=NO############################################################################################################################################# # # AGE_RESET_VALID: Specifies the period of time between failed login# attempts that, when exceeded will result in the failed count for # this host to be reset to 0. This value applies to login attempts # to all valid users (those within /etc/passwd) with the # exception of root. If not defined, this count will never# be reset.## See the comments in the PURGE_DENY section (above) # for details on specifying this value or for complete details # refer to: http://denyhosts.sourceforge.net/faq.html#timespec#AGE_RESET_VALID=5d############################################################################################################################################# # # AGE_RESET_ROOT: Specifies the period of time between failed login# attempts that, when exceeded will result in the failed count for # this host to be reset to 0. This value applies to all login # attempts to the &quot;root&quot; user account. If not defined,# this count will never be reset.## See the comments in the PURGE_DENY section (above) # for details on specifying this value or for complete details # refer to: http://denyhosts.sourceforge.net/faq.html#timespec#AGE_RESET_ROOT=25d############################################################################################################################################# # # AGE_RESET_RESTRICTED: Specifies the period of time between failed login# attempts that, when exceeded will result in the failed count for # this host to be reset to 0. This value applies to all login # attempts to entries found in the WORK_DIR/restricted-usernames file. # If not defined, the count will never be reset.## See the comments in the PURGE_DENY section (above) # for details on specifying this value or for complete details # refer to: http://denyhosts.sourceforge.net/faq.html#timespec#AGE_RESET_RESTRICTED=25d############################################################################################################################################# # # AGE_RESET_INVALID: Specifies the period of time between failed login# attempts that, when exceeded will result in the failed count for # this host to be reset to 0. This value applies to login attempts # made to any invalid username (those that do not appear # in /etc/passwd). If not defined, count will never be reset.## See the comments in the PURGE_DENY section (above) # for details on specifying this value or for complete details # refer to: http://denyhosts.sourceforge.net/faq.html#timespec#AGE_RESET_INVALID=10d############################################################################################################################################### RESET_ON_SUCCESS: If this parameter is set to &quot;yes&quot; then the# failed count for the respective ip address will be reset to 0# if the login is successful. ## The default is RESET_ON_SUCCESS = no##RESET_ON_SUCCESS = yes############################################################################################################################################## PLUGIN_DENY: If set, this value should point to an executable# program that will be invoked when a host is added to the# HOSTS_DENY file. This executable will be passed the host# that will be added as it&#x27;s only argument.##PLUGIN_DENY=/usr/bin/true############################################################################################################################################### PLUGIN_PURGE: If set, this value should point to an executable# program that will be invoked when a host is removed from the# HOSTS_DENY file. This executable will be passed the host# that is to be purged as it&#x27;s only argument.##PLUGIN_PURGE=/usr/bin/true## The following plugin will restore the file contexts on /etc/hosts.deny after# denyhosts purges old entries. This prevents breakage when selinux is set to# enforcing mode, but still has a small window where the context is set# incorrectly. The correct place to fix this is in the selinux policy.##PLUGIN_PURGE=/usr/share/denyhosts/plugins/restorecon.sh############################################################################################################################################### USERDEF_FAILED_ENTRY_REGEX: if set, this value should contain# a regular expression that can be used to identify additional# hackers for your particular ssh configuration. This functionality# extends the built-in regular expressions that DenyHosts uses.# This parameter can be specified multiple times.# See this faq entry for more details:# http://denyhosts.sf.net/faq.html#userdef_regex##USERDEF_FAILED_ENTRY_REGEX=######################################################################## ######### THESE SETTINGS ARE SPECIFIC TO DAEMON MODE ################################################################################### DAEMON_LOG: when DenyHosts is run in daemon mode (--daemon flag)# this is the logfile that DenyHosts uses to report it&#x27;s status.# To disable logging, leave blank. (default is: /var/log/denyhosts)#DAEMON_LOG = /var/log/denyhosts## disable logging:#DAEMON_LOG = ############################################################################################################################################### # DAEMON_LOG_TIME_FORMAT: when DenyHosts is run in daemon mode # (--daemon flag) this specifies the timestamp format of # the DAEMON_LOG messages (default is the ISO8061 format:# ie. 2005-07-22 10:38:01,745)## for possible values for this parameter refer to: man strftime## Jan 1 13:05:59 #DAEMON_LOG_TIME_FORMAT = %b %d %H:%M:%S## Jan 1 01:05:59 #DAEMON_LOG_TIME_FORMAT = %b %d %I:%M:%S####################################################################### ######################################################################## # DAEMON_LOG_MESSAGE_FORMAT: when DenyHosts is run in daemon mode # (--daemon flag) this specifies the message format of each logged# entry. By default the following format is used:## %(asctime)s - %(name)-12s: %(levelname)-8s %(message)s## Where the &quot;%(asctime)s&quot; portion is expanded to the format# defined by DAEMON_LOG_TIME_FORMAT## This string is passed to python&#x27;s logging.Formatter contstuctor.# For details on the possible format types please refer to:# http://docs.python.org/lib/node357.html## This is the default:#DAEMON_LOG_MESSAGE_FORMAT = %(asctime)s - %(name)-12s: %(levelname)-8s %(message)s######################################################################## ######################################################################### DAEMON_SLEEP: when DenyHosts is run in daemon mode (--daemon flag)# this is the amount of time DenyHosts will sleep between polling# the SECURE_LOG. See the comments in the PURGE_DENY section (above)# for details on specifying this value or for complete details# refer to: http://denyhosts.sourceforge.net/faq.html#timespec# #DAEMON_SLEEP = 30s################################################################################################################################################# DAEMON_PURGE: How often should DenyHosts, when run in daemon mode,# run the purge mechanism to expire old entries in HOSTS_DENY# This has no effect if PURGE_DENY is blank.#DAEMON_PURGE = 1w######################################################################## ######### THESE SETTINGS ARE SPECIFIC TO ########## ######### DAEMON SYNCHRONIZATION ################################################################################### Synchronization mode allows the DenyHosts daemon the ability# to periodically send and receive denied host data such that # DenyHosts daemons worldwide can automatically inform one# another regarding banned hosts. This mode is disabled by# default, you must uncomment SYNC_SERVER to enable this mode.## for more information, please refer to: # http:/denyhosts.sourceforge.net/faq.html#sync ################################################################################################################################################# SYNC_SERVER: The central server that communicates with DenyHost# daemons. Currently, denyhosts.net is the only available server# however, in the future, it may be possible for organizations to# install their own server for internal network synchronization## To disable synchronization (the default), do nothing. ## To enable synchronization, you must uncomment the following line:## NOTE: Please read README.Fedora before enabling sync#SYNC_SERVER = http://xmlrpc.denyhosts.net:9911################################################################################################################################################# SYNC_INTERVAL: the interval of time to perform synchronizations if# SYNC_SERVER has been uncommented. The default is 1 hour.# #SYNC_INTERVAL = 1h################################################################################################################################################# SYNC_UPLOAD: allow your DenyHosts daemon to transmit hosts that have# been denied? This option only applies if SYNC_SERVER has# been uncommented.# The default is SYNC_UPLOAD = yes##SYNC_UPLOAD = no#SYNC_UPLOAD = yes################################################################################################################################################# SYNC_DOWNLOAD: allow your DenyHosts daemon to receive hosts that have# been denied by others? This option only applies if SYNC_SERVER has# been uncommented.# The default is SYNC_DOWNLOAD = yes##SYNC_DOWNLOAD = no#SYNC_DOWNLOAD = yes################################################################################################################################################### SYNC_DOWNLOAD_THRESHOLD: If SYNC_DOWNLOAD is enabled this parameter# filters the returned hosts to those that have been blocked this many# times by others. That is, if set to 1, then if a single DenyHosts# server has denied an ip address then you will receive the denied host.# # See also SYNC_DOWNLOAD_RESILIENCY##SYNC_DOWNLOAD_THRESHOLD = 10## The default is SYNC_DOWNLOAD_THRESHOLD = 3 ##SYNC_DOWNLOAD_THRESHOLD = 3################################################################################################################################################# SYNC_DOWNLOAD_RESILIENCY: If SYNC_DOWNLOAD is enabled then the# value specified for this option limits the downloaded data# to this resiliency period or greater.## Resiliency is defined as the timespan between a hackers first known # attack and it&#x27;s most recent attack. Example:# # If the centralized denyhosts.net server records an attack at 2 PM # and then again at 5 PM, specifying a SYNC_DOWNLOAD_RESILIENCY = 4h # will not download this ip address.## However, if the attacker is recorded again at 6:15 PM then the # ip address will be downloaded by your DenyHosts instance. ## This value is used in conjunction with the SYNC_DOWNLOAD_THRESHOLD # and only hosts that satisfy both values will be downloaded. # This value has no effect if SYNC_DOWNLOAD_THRESHOLD = 1 ## The default is SYNC_DOWNLOAD_RESILIENCY = 5h (5 hours)## Only obtain hackers that have been at it for 2 days or more:#SYNC_DOWNLOAD_RESILIENCY = 2d## Only obtain hackers that have been at it for 5 hours or more:#SYNC_DOWNLOAD_RESILIENCY = 5h########################################################################","categories":["Linux配置文件","denyhosts"]},{"title":"install","path":"/2023/09/28/Linux配置文件/denyhosts/install/","content":"12345678910111213141516171819tar zxvf DenyHosts-2.6.tar.gz cd DenyHosts-2.6#install python setup.py install# install to here by defaultcd /usr/share/denyhostscp daemon-control-dist /etc/init.d/denyhosts#config filecp denyhosts.cfg-dist denyhosts.cfgchown root /etc/init.d/denyhostschmod 700 /etc/init.d/denyhostschkconfig --level 3 denyhosts on","categories":["Linux配置文件","denyhosts"]},{"title":"install","path":"/2023/09/28/Linux配置文件/vncserver/install/","content":"#服务器安装了桌面环境，可以使用vnc远程连接到服务器的桌面环境进行操作，即使服务器运行在字符模式下。 #安装vnc-serveryum install tigervnc-server vi &#x2F;etc&#x2F;sysconfig&#x2F;vncservers VNCSERVERS&#x3D;”10:root” #vncserver默认端口5900，如果指定桌面号为10，那么连接的时候就连接（5900+10）这个端口VNCSERVERARGS[10]&#x3D;”-geometry 800x600 -nolisten tcp” #默认是只对localhost开放的，这里去掉了”-localhost” #设置vncserver的连接密码： vncspasswd service vncserver start #vnc多用户登录 vi &#x2F;etc&#x2F;sysconfig&#x2F;vncservers VNCSERVERS&#x3D;”10:root 20:tom 30 herry”VNCSERVERARGS[10]&#x3D;”-geometry 800x600 -nolisten tcp”VNCSERVERARGS[20]&#x3D;”-geometry 800x600 -nolisten tcp”VNCSERVERARGS[30]&#x3D;”-geometry 800x600 -nolisten tcp” 为各用户设置vnc密码需要切换到各自的用户之后再执行vncpasswd设置tom的vnc密码su tomvncpasswd 设置herry的vnc密码su herryvncpasswd","categories":["Linux配置文件","vncserver"]},{"title":"csft_mysql.conf","path":"/2023/09/28/Linux配置文件/coreseek/csft_mysql.conf/","content":"#MySQL����Դ���ã�������鿴��http://www.coreseek.cn/products-install/mysql/#���Ƚ�var&#x2F;test&#x2F;documents.sql�������ݿ⣬�����ú����µ�MySQL�û��������ݿ� #Դ����source mysql{ type = mysql sql_host = 10.10.66.54 sql_user = wap sql_pass = PQM+295bna!93 sql_db = wap_manager sql_port = 3306\t# optional, default is 3306 sql_sock = /Data/app/mysql-5.1.42/mysql.sock sql_query_pre = SET NAMES utf8 sql_query = \\ SELECT gid,title,intro,UNIX_TIMESTAMP(add_time) AS date_added,price_sale,status,cid,cname,py,item_code,item_code as ritem_code,brand_id,brand_name,brand_py,sales \\ FROM view_goods_zh sql_attr_uint = cid sql_attr_uint = sales sql_attr_uint = ritem_code sql_attr_uint = brand_id sql_attr_uint = price_sale sql_attr_uint = status sql_attr_timestamp = date_added sql_ranged_throttle\t= 0 sql_query_info = SELECT * FROM view_goods_zh WHERE gid=$id } #index����index mysql{ source &#x3D; mysql #��Ӧ��source���� path &#x3D; &#x2F;Data&#x2F;app&#x2F;coreseek&#x2F;var&#x2F;data&#x2F;mysql #���޸�Ϊʵ��ʹ�õľ���·�������磺&#x2F;usr&#x2F;local&#x2F;coreseek&#x2F;var&#x2F;… docinfo &#x3D; extern mlock &#x3D; 0 morphology &#x3D; none min_word_len &#x3D; 1 html_strip &#x3D; 0 #���ķִ����ã�������鿴��http://www.coreseek.cn/products-install/coreseek_mmseg/ charset_dictpath = /Data/app/mmseg3/etc/ #BSD��Linux���������ã�/���Ž�β #charset_dictpath = etc/ #Windows���������ã�/���Ž�β����ø�������·�������磺C:/usr/local/coreseek/etc/... charset_type = zh_cn.utf-8 } #ȫ��index����indexer{ mem_limit &#x3D; 128M} #searchd������searchd{ listen &#x3D; 9312 read_timeout &#x3D; 5 max_children &#x3D; 30 max_matches &#x3D; 1000 seamless_rotate &#x3D; 0 preopen_indexes &#x3D; 0 unlink_old &#x3D; 1 compat_sphinxql_magics &#x3D;0 pid_file &#x3D; &#x2F;Data&#x2F;app&#x2F;coreseek&#x2F;var&#x2F;log&#x2F;searchd_mysql.pid #���޸�Ϊʵ��ʹ�õľ���·�������磺&#x2F;usr&#x2F;local&#x2F;coreseek&#x2F;var&#x2F;… log &#x3D; &#x2F;Data&#x2F;app&#x2F;coreseek&#x2F;var&#x2F;log&#x2F;searchd_mysql.log #���޸�Ϊʵ��ʹ�õľ���·�������磺&#x2F;usr&#x2F;local&#x2F;coreseek&#x2F;var&#x2F;… query_log &#x3D; &#x2F;Data&#x2F;app&#x2F;coreseek&#x2F;var&#x2F;log&#x2F;query_mysql.log #���޸�Ϊʵ��ʹ�õľ���·�������磺&#x2F;usr&#x2F;local&#x2F;coreseek&#x2F;var&#x2F;… binlog_path &#x3D; #�ر�binlog��־}","categories":["Linux配置文件","coreseek"]},{"title":"install","path":"/2023/09/28/Linux配置文件/coreseek/install/","content":"yum install make gcc gcc-c++ libtool autoconf automake imake libxml2-devel expat-devel ��װlibiconv���ذ�װ��wget http://www.coreseek.cn/uploads/csft/4.0/coreseek-4.1-beta.tar.gz tar zxvf coreseek-4.1-beta.tar.gz &amp;&amp; cd coreseek-4.1-beta cd mmseg-3.2.14&#x2F;.&#x2F;bootstrap #autoconf�汾������2.62 .&#x2F;configure –prefix&#x3D;&#x2F;Data&#x2F;app&#x2F;mmseg3 make &amp;&amp; make install cd .. cd csft-4.1&#x2F; sh buildconf.sh .&#x2F;configure –prefix&#x3D;&#x2F;Data&#x2F;app&#x2F;coreseek –without-unixodbc –with-mmseg –with-mmseg-includes&#x3D;&#x2F;Data&#x2F;app&#x2F;mmseg3&#x2F;include&#x2F;mmseg –with-mmseg-libs&#x3D;&#x2F;Data&#x2F;app&#x2F;mmseg3&#x2F;lib&#x2F; –with-mysql&#x3D;&#x2F;Data&#x2F;app&#x2F;mysql make &amp;&amp; make install �������������iconv��صĴ���undefined reference to libiconv_open’vi src&#x2F;Makefile LIBS &#x3D; -ldl -lm -lz -lexpat -L&#x2F;usr&#x2F;local&#x2F;lib �޸�Ϊ LIBS &#x3D; -ldl -lm -lz -lexpat -liconv -L&#x2F;usr&#x2F;local&#x2F;lib ����&#x2F;Data&#x2F;app&#x2F;coreseek&#x2F;bin&#x2F;searchd -c &#x2F;Data&#x2F;app&#x2F;coreseek&#x2F;etc&#x2F;csft_mysql.conf #ÿСʱ����һ������ &#x2F;Data&#x2F;app&#x2F;coreseek&#x2F;bin&#x2F;indexer -c &#x2F;Data&#x2F;app&#x2F;coreseek&#x2F;etc&#x2F;csft_mysql.conf –all –rotate","categories":["Linux配置文件","coreseek"]},{"title":"install.sh","path":"/2023/09/28/Linux配置文件/varnish/install.sh/","content":"yum install automake autoconf","categories":["Linux配置文件","varnish"]},{"title":"install.sh","path":"/2023/09/28/Linux配置文件/svn+apache/install.sh/","content":"#��װaprtar jxvf apr-1.5.0.tar.bz2 &amp;&amp; cd apr-1.5.0 sed -i ‘&#x2F;$RM “$cfgfile”&#x2F; s&#x2F;^&#x2F;#&#x2F;‘ configure .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr make &amp;&amp; make install #��װapr-utiltar jxvf apr-util-1.5.3.tar.bz2 &amp;&amp; cd apr-util-1.5.3 .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F;bin&#x2F;apr-1-config make &amp;&amp; make install #��װpcretar jxvf pcre-8.34.tar.bz2 &amp;&amp; cd pcre-8.34 .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre make &amp;&amp; make install #����openssltar zxvf openssl-1.0.1g.tar.gzcd openssl-1.0.1g .&#x2F;config shared zlibmake &amp;&amp; make install mv &#x2F;usr&#x2F;bin&#x2F;openssl &#x2F;usr&#x2F;bin&#x2F;openssl.OFFmv &#x2F;usr&#x2F;include&#x2F;openssl &#x2F;usr&#x2F;include&#x2F;openssl.OFFln -s &#x2F;usr&#x2F;local&#x2F;ssl&#x2F;bin&#x2F;openssl &#x2F;usr&#x2F;bin&#x2F;opensslln -s &#x2F;usr&#x2F;local&#x2F;ssl&#x2F;include&#x2F;openssl &#x2F;usr&#x2F;include&#x2F;openssl #��װapache tar jxvf httpd-2.4.7.tar.bz2 &amp;&amp; cd httpd-2.4.7 .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2 –sysconfdir&#x3D;&#x2F;etc&#x2F;httpd –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F;bin&#x2F;apr-1-config –with-apr-util&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util&#x2F;bin&#x2F;apu-1-config –with-pcre&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre&#x2F; –enable-so –enable-mods-shared&#x3D;most –enable-rewirte –enable-ssl&#x3D;shared –with-ssl&#x3D;&#x2F;usr&#x2F;local&#x2F;ssl make &amp;&amp; make install #��װsqlitetar zxvf sqlite-autoconf-3080403.tar.gz &amp;&amp; cd sqlite-autoconf-3080403 .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;sqlite make &amp;&amp; make install #��װsvntar jxvf subversion-1.8.9.tar.bz2 &amp;&amp; cd subversion-1.8.9 .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;subversion –with-apxs&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;apxs –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr –with-apr-util&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util&#x2F; –with-sqlite&#x3D;&#x2F;usr&#x2F;local&#x2F;sqlite&#x2F; make &amp;&amp; make install make install-tools #�ڰ�װĿ¼������svn-toolsĿ¼�������һЩ��չ���ߣ�����svnauthz-validate #Ϊapache����ģ�� cp libexec&#x2F;mod_authz_svn.so &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;modules&#x2F;cp libexec&#x2F;mod_dav_svn.so &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;modules&#x2F; #��httpd.conf���ӣ�LoadModule dav_module modules&#x2F;mod_dav.soLoadModule dav_svn_module modules&#x2F;mod_dav_svn.soLoadModule authz_svn_module modules&#x2F;mod_authz_svn.so #ȥ��Include &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-vhosts.conf��ǰע��ʹ֮��Ч #��httpd-vhosts.conf��������������&lt;VirtualHost *:80&gt; ServerName svn.happigo.com &lt;Location &#x2F;svn&gt; #�����&#x2F;svnҪ������AliasĿ¼���� DAV svn SVNParentPath &#x2F;data&#x2F;svn #svn�汾���Ŀ¼,��Ŀ¼���ж���汾��ʹ��SVNParentPath,�����汾���ʹ��SVNPath AuthType Basic AuthName “Subversion repository” #��֤ҳ����ʾ��Ϣ AuthUserFile &#x2F;data&#x2F;svn&#x2F;passwd #�û������� Require valid-user # ֻ����ͨ����֤���û����� AuthzSVNAccessFile &#x2F;data&#x2F;svn&#x2F;authz #�汾��Ȩ�޿��� ����passwd��authz�ļ�������֤�ļ��û��������ļ���&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;htpasswd -c &#x2F;data&#x2F;svn&#x2F;passwd user1 #�״������û����������û�ʹ��-m�������� �汾��Ȩ����֤�ļ�vi &#x2F;data&#x2F;svn&#x2F;authz #����svn�汾���µ�authz�ļ���ʽ�༭Ȩ�޼��� �����汾��&#x2F;usr&#x2F;local&#x2F;subversion&#x2F;bin&#x2F;svnadmin create &#x2F;data&#x2F;svn&#x2F;happigo ����http://svn.happigo.com/svn/happigo ����apache https������Ҫ��װ��openssl,�ϱߵĲ������Ѿ���װ��apacheҪ����sslģ����߰�װapache��ʱ���Ѿ�ʹ��enable-ssl��̬������ssl#httpd.conf��ȥ�������е�ע�ͣ�ʹ֮��ЧLoadModule ssl_module modules&#x2F;mod_ssl.soLoadModule socache_shmcb_module modules&#x2F;mod_socache_shmcb.soInclude &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-ssl.conf #�༭httpd-ssl.conf�ļ� ServerName svn.happigo.com:443 DAV svn SVNParentPath /data/svn AuthType Basic AuthName \"Subversion repository\" AuthUserFile /data/svn/passwd Require valid-user AuthzSVNAccessFile /data/svn/authz SSLEngine on SSLCertificateFile \"/etc/httpd/server.crt\" SSLCertificateKeyFile \"/etc/httpd/server.key\" ����ssl֤��openssl genrsa -out server.key 1024 openssl req -new -key server.key -out server.csr openssl req -x509 -days 365 -key server.key -in server.csr -out server.crt #�����ɵ������ļ��ŵ�&#x2F;et&#x2F;httpdĿ¼�£�&#x2F;etc&#x2F;httpdĿ¼����һ��httpd-ssl.conf��ָ���ģ� ����apache����#���� https://svn.happigo.com/svn/happigo #ע��������ģʽ�£�svn���񲢲�������ͨ��http��https������svn������svn�ύ���ݵ�ʱ��Ҫ��֤��������apache���û���svn�汾��Ŀ¼�ж�дȨ�ޣ���Ȼ��������db&#x2F;txn-current-lock’: Permission denied�� �Ĵ���","categories":["Linux配置文件","svn+apache"]},{"title":"liuliangyuzhi","path":"/2023/09/28/Linux配置文件/cacti+nagios/liuliangyuzhi/","content":"#cacti������ֵĬ�ϵ�λΪbyte��ʹ�ò�������ʾ���Ǻ�׼ȷ����������һ��CDEF������ֵ��ʾ�ĵ�λ��ΪMbits 1 ����̨–&gt;ͼ�ι���–&gt; CDEF –&gt;���ӣ�����дΪByte to Mbits 2 ������ӵ�Byte to Mbits,�Դ��������¼������ݣ� ָ������Դ—&gt;��ǰͼ������Դ �Զ����ַ���–&gt; 8 ����� –&gt; * �Զ����ַ���–&gt; 1024 ����� –&gt; &#x2F; �Զ����ַ���–&gt; 1024 ����� –&gt; &#x2F; ���ս����cdef&#x3D;CURRENT_DATA_SOURCE,8,*,1024,&#x2F;,1024,&#x2F; 3 ����̨–&gt;��ֵ–&gt;ѡ��������ֵ–&gt;���ݲ���–&gt;��������–&gt;CDEF–&gt;Byte to Mbits 4 ��ֵ��������Ϊ2����������������2Mbits����������","categories":["Linux配置文件","cacti+nagios"]},{"title":"install.sh","path":"/2023/09/28/Linux配置文件/cacti+nagios/install.sh/","content":"#��װLAMP��������apche 2.4.6 php 5.5.3�� #apache tar jxvf apr-1.5.0.tar.bz2 &amp;&amp; cd apr-1.5.0#ע�͵�configure�ļ��е�ĳ�У������&#x2F;bin&#x2F;rm: cannot remove &#96;libtoolT��: No such file or directory ��sed -i ‘&#x2F;$RM “$cfgfile”&#x2F; s&#x2F;^&#x2F;#&#x2F;‘ configure.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr &amp;&amp; make &amp;&amp; make install || exit 1cd ..#apr-utiltar jxvf apr-util-1.5.3.tar.bz2 &amp;&amp; apr-util-1.5.3.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F;bin&#x2F;apr-1-config &amp;&amp; make &amp;&amp; make install #pcrecd ..echo “Start the installation of pcre…”tar jxvf pcre-8.34.tar.bz2 &amp;&amp; cd pcre-8.34.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre &amp;&amp; make &amp;&amp; make install sleep 2tar zxvf httpd-2.4.9.tar.gz &amp;&amp; cd httpd-2.4.9 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2 –sysconfdir&#x3D;&#x2F;etc&#x2F;httpd –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F;bin&#x2F;apr-1-config –with-apr-util&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util&#x2F;bin&#x2F;apu-1-config –with-pcre&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre&#x2F; –enable-mods-shared&#x3D;most –enable-rewirte –enable-so –enable-ssl&#x3D;static –with-ssl &amp;&amp; make &amp;&amp; make install #php��ذ���snmp��sockets��PDO_MYSQL��json��չ(jsonĬ�ϰ���) #sockets��snmpΪcacti���裬����sockets��չ����װ�����޷��򿪣���ʾȱ��sockets��չ����װ������Ҫָ��snmp��·��#pdo_mysql��json��չΪNPC�������Ҫ ��nagios plugin for cacti�� yum install net-snmp net-snmp-devel net-snmp-utils#snmpd.conf���Ա���ԭ����ֱ���������񼴿� #php�������.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;php5.3 –with-config-file-path&#x3D;&#x2F;usr&#x2F;local&#x2F;php5.3&#x2F;etc –with-apxs2&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;apxs –with-libxml-dir –with-iconv-dir –with-png-dir –with-jpeg-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-zlib –with-gd&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-freetype-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype –with-mcrypt –with-mhash –enable-gd-native-ttf –with-curl –with-bz2 –enable-mysqlnd –with-mysql&#x3D;mysqlnd –with-mysqli&#x3D;mysqlnd –with-pdo-mysql&#x3D;mysqlnd –with-openssl-dir –without-pear –enable-xml –enable-zip –enable-sockets –with-snmpmakemake install php.ini������1 phpһ��Ҫ����exec()������ִ��2 date.timezone &#x3D; Asia&#x2F;Chongqing#��װrrdtoolyum install rrdtool #����cactiʹ�õ����ݿ�,�������û� mysql –user&#x3D;root –password&#x3D;123456 &lt;&lt;EOFCREATE DATABASE cacti;GRANT ALL PRIVILEGES ON cacti.* TO cactiuser@localhost IDENTIFIED BY ‘cactiuser’;FLUSH PRIVILEGES;EOF #cacti��װtar zxvf cacti-0.8.8b.tar.gz -C ${apache_DocumentRoot}#��ѹ������cacti.sql��cacti��,��дmysql������Ϣ��URL������web���ʿ�ʼ��װ #��װ��������Ҫ��ָ���������·����php snmp�� #��װ��ɺ��������Ҫ��Console-&gt;Settings-&gt;general���ø�����İ汾net-snmp –&gt;5.xrrdtool –&gt;1.3xsnmp —&gt; version2 #Devices–&gt;���õ�����������Ϣsnmp–&gt; version2 #���Ӽƻ�����*&#x2F;5 * * * * php poller.php &gt; &#x2F;dev&#x2F;null 2&amp;1 #������Ļ�������apache����־�����кܶ���ʾ &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #��װspine,һ�ָ���Ч����ѯ���ƣ��滻cacti�Դ���[poller type]— cmd.php#http://www.cacti.net/downloads/spine/ ���ص�ַ��ע����cacti�汾����һ��tar zxvf cacti-spine-0.8.8b.tar.gz &amp;&amp; cd cacti-spine-0.8.8b.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;spinemake &amp;&amp; make install #�༭spine�����ļ� &#x2F;usr&#x2F;local&#x2F;spine&#x2F;etc&#x2F;spine.conf,��д��ȷ�����ݿ�������Ϣ #cacti��Console–&gt;Settings–&gt;Poller,����ѯ��ʽ����Ϊspine &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; ndoutils,��nagios�ռ������ݴ���mysql,Ȼ����cacti��ȡ����ʾ����tar zxvf ndoutils-1.5.2.tar.gz &amp;&amp; cd ndoutils-1.5.2.&#x2F;configure –enable-mysql –with-mysql&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F; #�����Ĵ���..&#x2F;include&#x2F;config.h:261:25: error: mysql&#x2F;mysql.h: No such file or directory..&#x2F;include&#x2F;config.h:262:26: error: mysql&#x2F;errmsg.h: No such file or directory #�����vi ndoutils-1.5.2&#x2F;include&#x2F;config.h�����������е�&#x2F;mysql&#x2F;ȥ��,��Ӧ���Ǹ�ƴ�ӣ�#include����&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;include&#x2F;(.&#x2F;configure��ָ����)����ƴ���Ϻ�ߵı����&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;include&#x2F;mysql&#x2F;mysql.h,���Զ����һ��Ŀ¼������ʾ�Ҳ���#include &lt;&#x2F;mysql&#x2F;mysql.h&gt;#include &lt;&#x2F;mysql&#x2F;errmsg.h&gt; make cp -v src&#x2F;{ndomod-3x.o,ndo2db-3x,file2sock,log2ndo} &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;bin#����ndodb��mysql –user&#x3D;root –password&#x3D;123456 &lt;&lt;EOFCREATE DATABAS ndodb;GRANT ALL PRIVILEGES ON ndodb.* TO ndouser@localhost IDENTIFIED BY ‘123456’;FLUSH PRIVILEGES;EOF cd ndoutils-1.5.2&#x2F;db#����ndoutils����Ҫ�����ݿ���ȣ���Щ��Ĭ���ԡ�nagios_��Ϊǰ׺.&#x2F;installdb -u ndouser -p 123456 -h localhost -d ndodb#installdb��һ��perl�ű���ִ������Ҫ�õ�perl��DBI��DBD::mysqlģ�飬���û���Ȱ�װ #���ơ��༭�����ļ�cd ndoutils-1.5.2&#x2F;configcp ndo2db.cfg-sample &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;etc&#x2F;ndo2db.cfgcp ndomod.cfg-sample &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;etc&#x2F;ndomod.cfgchmod 644 &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;etc&#x2F;ndo*chown nagios:nagios &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;etc&#x2F;ndo*chown nagios:nagios &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;bin&#x2F;* vi &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;etc&#x2F;nagios.cfgevent_broker_options&#x3D;-1broker_module&#x3D;&#x2F;usr&#x2F;local&#x2F;nagios&#x2F;bin&#x2F;ndomod-3x.o config_file&#x3D;&#x2F;usr&#x2F;local&#x2F;nagios&#x2F;etc&#x2F;ndomod.cfg #�༭ndo2db��ndomod�������ļ�vi &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;etc&#x2F;ndo2db.cfg socket_type&#x3D;unixsocket_name&#x3D;&#x2F;usr&#x2F;local&#x2F;nagios&#x2F;var&#x2F;ndo.sock db_servertype&#x3D;mysqldb_host&#x3D;localhostdb_port&#x3D;3306db_name&#x3D;ndodbdb_prefix&#x3D;nagios_db_user&#x3D;ndouserdb_pass&#x3D;123456 vi &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;etc&#x2F;ndomod.cfgoutput_type&#x3D;unixsocketoutput&#x3D;&#x2F;usr&#x2F;local&#x2F;nagios&#x2F;var&#x2F;ndo.sock #����ndo2db&#x2F;usr&#x2F;local&#x2F;nagios&#x2F;bin&#x2F;ndo2db-3x -c &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;etc&#x2F;ndo2db.cfg #�鿴ϵͳ��־ȷ���������� #����nagios,���׹ر�������service nagios stoprm -f &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;var&#x2F;nagios.lockservice nagios start #����webҳ��鿴nagios����־�Ƿ�ɹ�����ndomodģ���Լ�ndo2db�Ƿ����ӵ��ɹ����ӵ�mysql &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;#��װntop #���Ȱ�װGeoIP GeoIP-devel��Ĭ�ϵ�yumԴ��û����������������epel yumԴwget http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpmrpm -Uvh epel-release-6-8.noarch.rpm yum install ntop#����ntop����Ա������ntop -A #����һ����ͨ�û�������ntopuseradd -M -s &#x2F;sbin&#x2F;nologin -r ntop#����ntopntop -i eth0 -d -L -u ntop#�鿴ntop��Ч��http://ip:3000 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #��ntop��nagios���Ͻ�cacti��Ҳ���Ǹ�cacti��װ��� #����ntop,��װntop-v0.2-1.tgz���tar zxvf ntop-v0.2-1.tgz -C &#x2F;data&#x2F;www&#x2F;cacti&#x2F;plugins #��cacti��console-&gt;Settings-&gt;Misc����дntopd��url,����http://192.168.126.130:3000#Ȼ����cacti��console-&gt;Plugin Management�а�װ������ntop����Ϳ����� &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; #����nagios,��װnpc(nagios-plgin-for-cacti)tar zxvf npc-2.0.4.tar.gz -C &#x2F;data&#x2F;www&#x2F;cacti&#x2F;plugins#��cacti��Console–&gt;Plugin Management�а�װnpc�������װ�����л���cacti��������npc_*���ݱ����ṹ��֮ǰ��װndoutilsʱ������ndodb��#���nagios_*��һ���ģ�����npc����Ժ�ԭ����ndodb���û���ˣ�Ӧ���޸�ndo2db�����ã�������nagios������ֱ��д��cacti���У�npc���#���ȡndo2dbд������ݣ�Ȼ����cacti������չ�ֳ��� #Console–&gt;Settings–&gt;NPC����nagios�������Ϣ Remote Commands [ѡ��]Nagios Command File Path–&gt;&#x2F;usr&#x2F;local&#x2F;nagios&#x2F;var&#x2F;rw&#x2F;nagios.cmdNagios URL http://xxxxx/nagios�޸�ndo2db�������ļ�db_name ��ndodb��Ϊcactidb_prefix ��nagios_��Ϊnpc_��Ȼ��Ҫȷ��ndo2dbʹ�õ��û���Ȩ����cacti��npc_*��д����#Ϊcacti���е�npc_*������ȱʧ���ֶΣ�ndo2db�ڽ�nagios�ռ�������д��cacti��npc_��д�����ݵ�ʱ��ᱨȱ��long_output�ֶεĴ���mysql –user&#x3D;root –password&#x3D;123456 &lt;&lt;EOFuse cacti;ALTER TABLE npc_eventhandlers ADD long_output TEXT NOT NULL AFTER output;ALTER TABLE npc_hostchecks ADD long_output TEXT NOT NULL AFTER output;ALTER TABLE npc_hoststatus ADD long_output TEXT NOT NULL AFTER output;ALTER TABLE npc_notifications ADD long_output TEXT NOT NULL AFTER output;ALTER TABLE npc_servicechecks ADD long_output TEXT NOT NULL AFTER output;ALTER TABLE npc_servicestatus ADD long_output TEXT NOT NULL AFTER output;ALTER TABLE npc_statehistory ADD long_output TEXT NOT NULL AFTER output;ALTER TABLE npc_systemcommands ADD long_output TEXT NOT NULL AFTER output;EOF #����ndo2db��nagios,ע�⳹�׹ر������� &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;bin&#x2F;ndo2db-3x -c &#x2F;usr&#x2F;local&#x2F;nagios&#x2F;etc&#x2F;ndo2db.cfgservice nagios start#�鿴ϵͳ��־ȷ��ndo2db�Ѿ�������д��cacti����","categories":["Linux配置文件","cacti+nagios"]},{"title":"install.sh","path":"/2023/09/28/Linux配置文件/ubuntu_solarized/install.sh/","content":"sudo apt-get install git-core #dircolorscd git clone git:&#x2F;&#x2F;github.com&#x2F;seebi&#x2F;dircolors-solarized.git cd dircolors-solarizedcp dircolors.256dark ~&#x2F;.dircolors vi ~&#x2F;.bashrc, add:eval dircolors ~/.dircolorsexport TERM&#x3D;xterm-256color source ~.bashrc #terminal-colorscdgit clone git:&#x2F;&#x2F;github.com&#x2F;sigurdga&#x2F;gnome-terminal-colors-solarized.git cd gnome-terminal-colors-solarized&#x2F; .&#x2F;set_dark.sh vim solarizedmkdir -p ~&#x2F;.vim&#x2F;autoloadmkdir -p ~&#x2F;.vim&#x2F;bundle cd ~&#x2F;.vim&#x2F;autoloadcurl -LSso ~&#x2F;.vim&#x2F;autoload&#x2F;pathogen.vim https://raw.github.com/tpope/vim-pathogen/master/autoload/pathogen.vim cd ~&#x2F;.vim&#x2F;bundlegit clone git:&#x2F;&#x2F;github.com&#x2F;altercation&#x2F;vim-colors-solarized.git .vimrcsyntax onexecute pathogen#infect()set background&#x3D;darkcolorscheme solarized","categories":["Linux配置文件","ubuntu_solarized"]},{"title":"install.sh","path":"/2023/09/28/Linux配置文件/loganalyzer/install.sh/","content":"#�������������������apache��mysql#��װrsyslogyum install rsyslog#��װrsyslog��mysqlģ�飬ʹ֮���Խ���־д��mysqlyum install rsyslog-mysql #�޸�rsyslog�������ļ�vi &#x2F;etc&#x2F;rsyslog.conf #һ�����е�ע��ȥ������rsyslog������UDP514�˿ڣ��ͻ��˻Ὣ�Լ�����־���͵�����˵�UDP514�˿�$ModLoad imudp$UDPServerRun 514 $ModLoad ommysql.so #�¼Ӵ��У�rsyslog����mysqlģ��. :ommysql:localhost,Syslog,rsyslog,123456 #�¼Ӵ��У�rsyslogʹ���û�rsyslog,��������־д��mysql��Syslog���У�123456���û�rsyslog������ #����rsyslog��Ҫ�����ݿ�cd &#x2F;usr&#x2F;share&#x2F;doc&#x2F;rsyslog-mysql-5.8.10&#x2F;mysql -u root -p &lt; createDB.sql #�ò����ᴴ��Syslog�⣬���к����ű������е�SystemEvents����loganalyzerҪ��ȡ�ı� grant all privileges on Syslog.* to rsyslog@’localhost’ identified by ‘123456’; flush privileges; #����rsyslog service rsyslog restart #�����Ļ���ʱSystemEvents����Ӧ���Ѿ���д�����ݣ���Ϊrsyslog�Ѿ���ʼ����־�洢��mysql #���ϲ���ʹ��rsyslog��ϵͳ��־д��mysql����������װloganalyzer,�����ǽ���־��mysql������������web��ʽչʾ #����loganalyzer wget http://download.adiscon.com/loganalyzer/loganalyzer-3.6.3.tar.gz #��apache���Է��ʵ���λ�ô���Ŀ¼���������loganalyzer�ĳ���mkdir &#x2F;data&#x2F;www&#x2F;loganalyzer tar zxvf loganalyzer-3.6.3.tar.gzcd loganalyzer-3.6.3 #����װ�ļ����Ƶ�������loganalyzerĿ¼ cp -a src&#x2F;* &#x2F;data&#x2F;www&#x2F;loganalyzer&#x2F;cp -a contrib&#x2F;* &#x2F;data&#x2F;www&#x2F;loganalyzer&#x2F; cd &#x2F;data&#x2F;www&#x2F;loganalyzer sh configure.sh #����config.php�ļ���������д��Ȩ�� http://ip/loganalyzer #����web��װ���� ��װ��ɺ�ִ��secure.sh,��config.phpȨ���޸�Ϊ644�� #��ʾip��ַ��Ĭ��loganalyzerֻ��ʾ��־����Դ������������������־����������̨����������������ʾ��־����ԴIP #��Syslog���е�SystemEvents��������һ���ֶΣ�������¼��ԴIPALTER TABLE SystemEvents ADD FromIP VARCHAR(60) DEFAULT NULL AFTER FromHost; #�޸�rsyslog.conf #�������ݵ���������rsyslog�ڽ���־д��Mysql��ʱ����ԴIPд�뵽FromIP�ֶΣ�������loganalyzer��ȡ��־��ʱ��ſ���ȡ��ip��Ϣ$template insertpl,”insert into SystemEvents (Message, Facility, FromHost, FromIP, Priority, DeviceReportedTime, ReceivedAt, InfoUnitID, SysLogTag) values (‘%msg%’, %syslogfacility%, ‘%HOSTNAME%’, ‘%fromhost-ip%’, %syslogpriority%, ‘%timereported:::date-mysql%’, ‘%timegenerated:::date-mysql%’, %iut%, ‘%syslogtag%’)”,SQL $ModLoad ommysql.so. :ommysql:localhost,Syslog,rsyslog,123456;insertpl #����rsyslog #����Ա���ݵ�¼loganalyzer����Aamin Center���½�Field View ��DBmapping��Ȼ�����µ�view����ʾ��ҳ���Ͼͻ���ip��Ϣ�� #field����ı�����view������Щ��������ʾ��ҳ���ϣ�DBmapping�����field����ȡʲôֵ","categories":["Linux配置文件","loganalyzer"]},{"title":"install","path":"/2023/09/28/Linux配置文件/aria2/install/","content":"如果是源码安装，gcc 版本需要升级，4.7 or later.&#x2F;configure &amp;&amp; make &amp;&amp; make install 错误记录make时出现如下错误 CXX XmlRpcDiskWriter.lo CXX FallocFileAllocationIterator.lo CXX EpollEventPoll.lo CXX LibgnutlsTLSContext.lo CXX LibgnutlsTLSSession.loLibgnutlsTLSSession.cc: In member function ‘virtual int aria2::GnuTLSSession::init(int)’:LibgnutlsTLSSession.cc:86:40: error: invalid conversion from ‘unsigned int’ to ‘gnutls_connection_end_t’ [-fpermissive]In file included from LibgnutlsTLSSession.h:40:0, from LibgnutlsTLSSession.cc:35:&#x2F;usr&#x2F;include&#x2F;gnutls&#x2F;gnutls.h:680:7: error: initializing argument 2 of ‘int gnutls_init(gnutls_session_int**, gnutls_connection_end_t)’ [-fpermissive]make[3]: *** [LibgnutlsTLSSession.lo] Error 1make[3]: Leaving directory /usr/src/RPM/BUILD/aria2-1.18.5/src&#39; make[2]: *** [all-recursive] Error 1 make[2]: Leaving directory &#x2F;usr&#x2F;src&#x2F;RPM&#x2F;BUILD&#x2F;aria2-1.18.5&#x2F;src’make[1]: *** [all-recursive] Error 1make[1]: Leaving directory &#96;&#x2F;usr&#x2F;src&#x2F;RPM&#x2F;BUILD&#x2F;aria2-1.18.5’make: *** [all] Error 2 解决方法修改src&#x2F;LibgnutlsTLSSession.cc,约在文件第76行，行前带+的为添加的内容123456789101112131415161718int GnuTLSSession::init(sock_t sockfd) &#123; +#if GNUTLS_VERSION_NUMBER &gt;= 0x030000 unsigned int flags = tlsContext_-&gt;getSide() == TLS_CLIENT ? GNUTLS_CLIENT : GNUTLS_SERVER; #ifdef A2_DISABLE_OCSP @@ -84,6 +85,11 @@ int GnuTLSSession::init(sock_t sockfd) #endif // A2_DISABLE_OCSP rv_ = gnutls_init(&amp;sslSession_, flags); +#else // GNUTLS_VERSION_NUMBER &gt;= 0x030000 + rv_ = gnutls_init( + &amp;sslSession_, + tlsContext_-&gt;getSide() == TLS_CLIENT ? GNUTLS_CLIENT : GNUTLS_SERVER); +#endif // GNUTLS_VERSION_NUMBER &gt;= 0x030000 if(rv_ != GNUTLS_E_SUCCESS) &#123; return TLS_ERR_ERROR; &#125;","categories":["Linux配置文件","aria2"]},{"title":"install.sh","path":"/2023/09/28/Linux配置文件/xen/install.sh/","content":"##CentOS- #��������װyum install hmaccalc ncurses-devel zlib-devel openssl-devel python-devel bridge-utils libtool-ltdl iasl xorg-x11-drv-evdev xorg-x11-drv-fbdev xorg-x11-drv-i810-devel xorg-x11-drv-via-devel xorg-x11-proto-devel xorg-x11-server-sdk xorg-x11-xtrans-devel flex bison(��װacpica��Ҫ)yum install flex bison #��װacpi ca (https://acpica.org/downloads)#���������԰�װ���°棬��δ�ɹ��������������⣬��ͨ������߰汾Ϊacpica-unix-20130823.tar.gz tar zxvf acpica-unix-20130823.tar.gz &amp;&amp; cd acpica-unix-20130823makemake install ��װ Xen hypervisor �� tools���Ȱ�װ����������dev86��uuid��glib��yajl��git��texinfo)#wget http://rdebath.nfshost.com/dev86/Dev86bin-0.16.19.tar.gz #tar zxvf Dev86bin-0.16.19.tar.gz &amp;&amp; cd usr #cp lib&#x2F;* &#x2F;usr&#x2F;lib#cp bin&#x2F;* &#x2F;usr&#x2F;binyum install dev86yum install libuuid libuuid-develyum install glib2 glib2-develyum install yajl yajl-develyum install gityum install texinfo#xen��װ�����л�ʹ��git�������ݣ������������ #xen��װ tar zxvf xen-4.3.1.tar.gz &amp;&amp; cd xen-4.3.1 make xen tools stubdom make install-xen install-tools install-stubdom ����linux�ںˣ�ʹ֧֮��xenxz -d linux-3.11.8.tar.xz &amp;&amp; tar xvf linux-3.11.8.tar &amp;&amp; cd linux-3.11.8 make menuconfig #ѡ�������� Processor type and features–&gt; Linux guest support–&gt; Xen guest support Device Drivers–&gt;Network device support–&gt;Xen network device frontend driver&#x2F;Xen backend network device Device Drivers–&gt;Block devices–&gt;Xen virtual block device support&#x2F;Xen block-device backend driver Device Drivers–&gt;Xen driver support make make modules make modules_install make install depmod 3.11.8 �޸������ļ���ʹ��xen����ϵͳvi &#x2F;etc&#x2F;grub.conf title CentOS6.0 (linux-3.11.8-xen)kernel &#x2F;xen.gzmodule &#x2F;vmlinuz-3.11.8 ro root&#x3D;&#x2F;dev&#x2F;sda3module &#x2F;initramfs-3.11.8.img ���&#x2F;boot���ǵ��������Ļ���kernel &#x2F;boot&#x2F;xen.gz modules &#x2F;boot&#x2F;vmlinuz-3.11.8����ϵͳreboot","categories":["Linux配置文件","xen"]},{"title":"install","path":"/2023/09/28/Linux配置文件/xen/install/","content":"##CentOS- #��������װyum install hmaccalc ncurses-devel zlib-devel openssl-devel python-devel bridge-utils libtool-ltdl iasl xorg-x11-drv-evdev xorg-x11-drv-fbdev xorg-x11-drv-i810-devel xorg-x11-drv-via-devel xorg-x11-proto-devel xorg-x11-server-sdk xorg-x11-xtrans-devel flex bison(��װacpica��Ҫ)yum install flex bison #��װacpi ca (https://acpica.org/downloads)#���������԰�װ���°棬��δ�ɹ��������������⣬��ͨ������߰汾Ϊacpica-unix-20130823.tar.gz tar zxvf acpica-unix-20130823.tar.gz &amp;&amp; cd acpica-unix-20130823makemake install ��װ Xen hypervisor �� tools���Ȱ�װ����������as86��ld86��uuid)wget http://rdebath.nfshost.com/dev86/Dev86bin-0.16.19.tar.gz tar zxvf Dev86bin-0.16.19.tar.gz &amp;&amp; cd usr cp lib&#x2F;* &#x2F;usr&#x2F;libcp bin&#x2F;* &#x2F;usr&#x2F;bin","categories":["Linux配置文件","xen"]},{"title":"repare","path":"/2023/09/28/Linux配置文件/xen/repare/","content":"#ĳ�Σ���Ϊʹ��xm destroyǿ�ƶϵ���������ĵ�Դ�����¸���������������𻵣���Ҳ�޷������������������ 1 �鿴&#x2F;etc&#x2F;xen�µ�����������ļ�����֪�������������&#x2F;Data&#x2F;xen&#x2F;images&#x2F;c5.img�ϡ� 2 fdisk -l &#x2F;Data&#x2F;xen&#x2F;images&#x2F;c5.img # ��������Բ鿴�����������������ļ��Ϸ��˼������� 3 kpartx -a &#x2F;Data&#x2F;xen&#x2F;images&#x2F;c5.img # ��������ķ���ӳ�䵽������&#x2F;dev&#x2F;mapper�� 4 fsck &#x2F;dev&#x2F;mapper&#x2F;loop2 #�޸��𻵵��ļ�ϵͳ 5 kpartx -d &#x2F;Data&#x2F;xen&#x2F;images&#x2F;c5.img # ɾ��ӳ�� 6 xm create ���������������������","categories":["Linux配置文件","xen"]},{"title":"install.sh","path":"/2023/09/28/Linux配置文件/tomcat/install.sh/","content":"#jave-jdk#java版本不低于6 #http://www.oracle.com/technetwork/java/javase/downloads/index.html chmod +x jdk-6u37-linux-x64.bin .&#x2F;jdk-6u37-linux-x64.bin #安装完成后将生成jdk1.6.0_37目录 mv jdk1.6.0_37 &#x2F;usr&#x2F;local&#x2F; #修改环境变量#最好不要直接修改&#x2F;etc&#x2F;profile文件，而是通过修改用户家目录下的.bashrc文件来单独为制定用户设置环境变量 echo -ne “JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk1.6.0_37 PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin CLASSPATH&#x3D;.:JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar export JAVA_HOME PATH CLASSPATH” &gt;&gt; .bashrc #测试是否安装成功java -version #tomcat #http://apache.dataguru.cn/tomcat/tomcat-7/v7.0.52/src/apache-tomcat-7.0.52-src.tar.gz tar zxvf apache-tomcat-7.0.53.tar.gz mv apache-tomcat-7.0.53 &#x2F;usr&#x2F;local&#x2F;tomcat $tomcat_home&#x2F;bin&#x2F;startup.sh | shutdown.sh #修改tomcat根目录 $tomcat_home&#x2F;conf&#x2F;server.xml #这一句是自行添加的","categories":["Linux配置文件","tomcat"]},{"title":"java_install","path":"/2023/09/28/Linux配置文件/tomcat/java_install/","content":"#http://download.oracle.com/otn-pub/java/jdk/7u51-b13/jdk-7u51-linux-x64.tar.gz tar zxvf jdk-7u51-linux-x64.tar.gz -C &#x2F;usr&#x2F;local&#x2F; ����java������[~&#x2F;.bashrc]JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk1.7.0_51PATH&#x3D;$PATH:$JAVA_HOME&#x2F;binCLASSPATH&#x3D;.:JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jarexport JAVA_HOME PATH CLASSPATH #ʹ������Ч source ~&#x2F;.bashrc java -version","categories":["Linux配置文件","tomcat"]},{"title":"check-dependencies.py","path":"/2023/09/28/Linux配置文件/Graphite+collectl/check-dependencies.py/","content":"#!&#x2F;usr&#x2F;bin&#x2F;env python import sys Simple python version testmajor,minor &#x3D; sys.version_info[:2]py_version &#x3D; sys.version.split()[0]if major !&#x3D; 2 or minor &lt; 4: print “You are using python %s, but version 2.4 or greater is required” % py_version raise SystemExit(1) fatal &#x3D; 0warning &#x3D; 0 Test for whispertry: import whisperexcept: print “[FATAL] Unable to import the ‘whisper’ module, please download this package from the Graphite project page and install it.” fatal +&#x3D; 1 Test for pycairotry: import cairoexcept: print “[FATAL] Unable to import the ‘cairo’ module, do you have pycairo installed for python %s?” % py_version cairo &#x3D; None fatal +&#x3D; 1 Test that pycairo has the PNG backendtry: if cairo: surface &#x3D; cairo.ImageSurface(cairo.FORMAT_ARGB32, 10, 10) del surfaceexcept: print “[FATAL] Failed to create an ImageSurface with cairo, you probably need to recompile cairo with PNG support” fatal +&#x3D; 1 Test that cairo can find fontstry: if cairo: surface &#x3D; cairo.ImageSurface(cairo.FORMAT_ARGB32, 10, 10) context &#x3D; cairo.Context(surface) context.font_extents() del surface, contextexcept: print “[FATAL] Failed to create text with cairo, this probably means cairo cant find any fonts. Install some system fonts and try again” Test for djangotry: import djangoexcept: print “[FATAL] Unable to import the ‘django’ module, do you have Django installed for python %s?” % py_version django &#x3D; None fatal +&#x3D; 1 Test for django-taggingtry: import taggingexcept: print “[FATAL] Unable to import the ‘tagging’ module, do you have django-tagging installed for python %s?” % py_version fatal +&#x3D; 1 Verify django versionif django and django.VERSION[:2] &lt; (1,1): print “[FATAL] You have django version %s installed, but version 1.1 or greater is required” % django.get_version() fatal +&#x3D; 1 Test for a json moduletry: import jsonexcept ImportError: try: import simplejson except ImportError: print “[FATAL] Unable to import either the ‘json’ or ‘simplejson’ module, at least one is required.” fatal +&#x3D; 1 Test for zope.interfacetry: from zope.interface import Interfaceexcept ImportError: print “[WARNING] Unable to import Interface from zope.interface.” print “Without it, you will be unable to run carbon on this server.” warning +&#x3D;1 Test for mod_pythontry: import mod_pythonexcept: print “[WARNING] Unable to import the ‘mod_python’ module, do you have mod_python installed for python %s?” % py_version print “mod_python is one of the most common ways to run graphite-web under apache.” print “Without mod_python you will still be able to use the built in development server; which is not” print “recommended for production use.” print “wsgi or other approaches for production scale use are also possible without mod_python” warning +&#x3D; 1 Test for python-memcachedtry: import memcacheexcept: print “[WARNING]” print “Unable to import the ‘memcache’ module, do you have python-memcached installed for python %s?” % py_version print “This feature is not required but greatly improves performance. ” warning +&#x3D; 1 Test for sqlitetry: try: import sqlite3 #python 2.5+ except: from pysqlite2 import dbapi2 #python 2.4except: print “[WARNING]” print “Unable to import the sqlite module, do you have python-sqlite2 installed for python %s?” % py_version print “If you plan on using another database backend that Django supports (such as mysql or postgres)” print “then don’t worry about this. However if you do not want to setup the database yourself, you will” print “need to install sqlite2 and python-sqlite2. ” warning +&#x3D; 1 Test for python-ldaptry: import ldapexcept: print “[WARNING]” print “Unable to import the ‘ldap’ module, do you have python-ldap installed for python %s?” % py_version print “Without python-ldap, you will not be able to use LDAP authentication in the graphite webapp. ” warning +&#x3D; 1 Test for Twisted pythontry: import twistedexcept: print “[WARNING]” print “Unable to import the ‘twisted’ package, do you have Twisted installed for python %s?” % py_version print “Without Twisted, you cannot run carbon on this server.” warning +&#x3D; 1else: tv &#x3D; [] tv &#x3D; twisted.version.split(‘.’) if int(tv[0]) &lt; 8 or (int(tv[0]) &#x3D;&#x3D; 8 and int(tv[1]) &lt; 2): print “[WARNING]” print “Your version of Twisted is too old to run carbon.” print “You will not be able to run carbon on this server until you upgrade Twisted &gt;&#x3D; 8.2.” warning +&#x3D; 1 Test for txamqptry: import txamqpexcept: print “[WARNING]” print “Unable to import the ‘txamqp’ module, this is required if you want to use AMQP.” print “Note that txamqp requires python 2.5 or greater.” warning +&#x3D; 1 if fatal: print “%d necessary dependencies not met. Graphite will not function until these dependencies are fulfilled.” % fatal else: print “All necessary dependencies are met.” if warning: print “%d optional dependencies not met. Please consider the warning messages before proceeding.” % warning else: print “All optional dependencies are met.”","categories":["Linux配置文件","Graphite+collectl"]},{"title":"apache+tomcat_115_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/apache+tomcat_115_ipt.sav/","content":"123456789101112131415161718192021222324252627282930313233343536373839# Generated by iptables-save v1.4.7 on Tue Apr 15 21:59:33 2014*filter:INPUT DROP [0:0]:FORWARD DROP [0:0]:OUTPUT DROP [13:712]-A INPUT -m conntrack --ctstate INVALID -j DROP -A INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -s 10.10.67.253/32 -j ACCEPT -A INPUT -d 224.0.0.0/8 -j ACCEPT -A INPUT -p tcp -m tcp --dport 5122 --tcp-flags FIN,SYN,RST,ACK SYN -m state --state NEW -j ACCEPT -A INPUT -p tcp -m tcp --dport 80 --tcp-flags FIN,SYN,RST,ACK SYN -m state --state NEW -j ACCEPT -A INPUT -p tcp -m tcp --dport 45564 --tcp-flags FIN,SYN,RST,ACK SYN -m state --state NEW -j ACCEPT -A INPUT -p udp -m udp --dport 45564 -j ACCEPT -A INPUT -s 10.10.67.114/32 -p tcp -m tcp --dport 4000 -m state --state NEW -j ACCEPT -A INPUT -s 10.10.67.114/32 -p tcp -m tcp --dport 4001 -m state --state NEW -j ACCEPT -A INPUT -s 10.10.67.114/32 -p tcp -m tcp --dport 8009 -m state --state NEW -j ACCEPT -A INPUT -s 10.10.67.114/32 -p tcp -m tcp --dport 8010 -m state --state NEW -j ACCEPT -A INPUT -s 10.10.38.238/32 -p udp -m udp --dport 161 -j ACCEPT -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT -A INPUT ! -i lo -j LOG --log-prefix &quot;DROP &quot; --log-tcp-options --log-ip-options -A OUTPUT -m conntrack --ctstate INVALID -j DROP -A OUTPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT -A OUTPUT -o lo -j ACCEPT -A OUTPUT -d 224.0.0.0/8 -j ACCEPT -A OUTPUT -p tcp -m tcp --dport 25 --tcp-flags FIN,SYN,RST,ACK SYN -m conntrack --ctstate NEW -j ACCEPT -A OUTPUT -p tcp -m tcp --dport 80 --tcp-flags FIN,SYN,RST,ACK SYN -m conntrack --ctstate NEW -j ACCEPT -A OUTPUT -p tcp -m tcp --dport 45564 --tcp-flags FIN,SYN,RST,ACK SYN -m state --state NEW -j ACCEPT -A OUTPUT -p udp -m udp --dport 45564 -j ACCEPT -A OUTPUT -d 10.10.67.114/32 -p tcp -m tcp --dport 4000 -m state --state NEW -j ACCEPT -A OUTPUT -d 10.10.67.114/32 -p tcp -m tcp --dport 4001 -m state --state NEW -j ACCEPT -A OUTPUT -d 10.10.67.0/24 -p tcp -m tcp --dport 8009 -m state --state NEW -j ACCEPT -A OUTPUT -d 10.10.67.0/24 -p tcp -m tcp --dport 8010 -m state --state NEW -j ACCEPT -A OUTPUT -p udp -m udp --dport 53 -j ACCEPT -A OUTPUT -p udp -m udp --dport 123 -m conntrack --ctstate NEW -j ACCEPT -A OUTPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT -A OUTPUT ! -o lo -j LOG --log-prefix &quot;DROP &quot; --log-tcp-options --log-ip-options COMMIT# Completed on Tue Apr 15 21:59:33 2014","categories":["Linux配置文件","iptables"]},{"title":"apache+tomcat_114_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/apache+tomcat_114_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Apr 15 21:59:44 2014*filter:INPUT DROP [0:0]:FORWARD DROP [0:0]:OUTPUT DROP [1:136]-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -d 224.0.0.0&#x2F;8 -j ACCEPT-A INPUT -s 10.10.67.253&#x2F;32 -j ACCEPT-A INPUT -p tcp -m tcp –dport 5122 –tcp-flags FIN,SYN,RST,ACK SYN -m state –state NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 80 –tcp-flags FIN,SYN,RST,ACK SYN -m state –state NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 45564 –tcp-flags FIN,SYN,RST,ACK SYN -m state –state NEW -j ACCEPT-A INPUT -p udp -m udp –dport 45564 -j ACCEPT-A INPUT -s 10.10.67.115&#x2F;32 -p tcp -m tcp –dport 4000 -m state –state NEW -j ACCEPT-A INPUT -s 10.10.67.115&#x2F;32 -p tcp -m tcp –dport 4001 -m state –state NEW -j ACCEPT-A INPUT -s 10.10.67.115&#x2F;32 -p tcp -m tcp –dport 8009 -m state –state NEW -j ACCEPT-A INPUT -s 10.10.67.115&#x2F;32 -p tcp -m tcp –dport 8010 -m state –state NEW -j ACCEPT-A INPUT -s 10.10.38.238&#x2F;32 -p udp -m udp –dport 161 -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -o lo -j ACCEPT-A OUTPUT -d 224.0.0.0&#x2F;8 -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 25 –tcp-flags FIN,SYN,RST,ACK SYN -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 80 –tcp-flags FIN,SYN,RST,ACK SYN -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 45564 -m state –state NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 45564 -j ACCEPT-A OUTPUT -d 10.10.67.115&#x2F;32 -p tcp -m tcp –dport 4000 -m state –state NEW -j ACCEPT-A OUTPUT -d 10.10.67.115&#x2F;32 -p tcp -m tcp –dport 4001 -m state –state NEW -j ACCEPT-A OUTPUT -d 10.10.67.0&#x2F;24 -p tcp -m tcp –dport 8009 -m state –state NEW -j ACCEPT-A OUTPUT -d 10.10.67.0&#x2F;24 -p tcp -m tcp –dport 8010 -m state –state NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 53 -j ACCEPT-A OUTPUT -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A OUTPUT ! -o lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-optionsCOMMIT Completed on Tue Apr 15 21:59:44 2014","categories":["Linux配置文件","iptables"]},{"title":"db_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/db_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*filter:INPUT DROP [253:28094]:FORWARD DROP [0:0]:OUTPUT DROP [56:3360]#-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT#-A INPUT ! -s 172.16.83.0&#x2F;24 -i em2 -j LOG –log-prefix “SPOOFED PKT “-A INPUT ! -s 172.16.83.0&#x2F;24 -i em2 -j DROP-A INPUT -p tcp -m tcp –dport 22 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em2 -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em2 -p tcp -m tcp –dport 5666 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em2 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A INPUT -i lo -j ACCEPT#-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -p udp -m udp –dport 53 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 25 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p udp -m udp –dport 514 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A OUTPUT ! -o lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -o lo -j ACCEPTCOMMIT Completed on Tue Oct 15 11:10:51 2013Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*nat:PREROUTING ACCEPT [293:34284]:POSTROUTING ACCEPT [172:11324]:OUTPUT ACCEPT [228:14684]COMMIT Completed on Tue Oct 15 11:10:51 2013","categories":["Linux配置文件","iptables"]},{"title":"db_master_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/db_master_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 29 17:52:08 2013*nat:PREROUTING ACCEPT [1195:64976]:POSTROUTING ACCEPT [1410:84600]:OUTPUT ACCEPT [1410:84600]COMMIT Completed on Tue Oct 29 17:52:08 2013Generated by iptables-save v1.4.7 on Tue Oct 29 17:52:08 2013*filter:INPUT DROP [0:0]:FORWARD DROP [0:0]:OUTPUT DROP [0:0]-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m tcp –dport 5122 –syn -m state –state NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 3306 –syn -m state –state NEW -j ACCEPT-A INPUT -s 10.10.67.61 -j ACCEPT-A INPUT -s 10.10.67.62 -j ACCEPT-A INPUT -s 10.10.67.63 -j ACCEPT-A INPUT -s 10.10.67.64 -j ACCEPT-A INPUT -s 10.10.38.238&#x2F;32 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -o lo -j ACCEPT-A OUTPUT -d 10.10.67.61 -j ACCEPT-A OUTPUT -d 10.10.67.62 -j ACCEPT-A OUTPUT -d 10.10.67.63 -j ACCEPT-A OUTPUT -d 10.10.67.64 -j ACCEPT-A OUTPUT -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 6379 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A OUTPUT ! -o lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-optionsCOMMIT Completed on Tue Oct 29 17:52:08 2013","categories":["Linux配置文件","iptables"]},{"title":"lvs_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/lvs_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*filter:INPUT DROP [253:28094]:FORWARD DROP [0:0]:OUTPUT DROP [56:3360]#-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT#-A INPUT ! -s 172.16.83.0&#x2F;24 -i em2 -j LOG –log-prefix “SPOOFED PKT “-A INPUT ! -s 172.16.83.0&#x2F;24 -i em2 -j DROP-A INPUT -p vrrp -j ACCEPT-A INPUT -d 224.0.0.0&#x2F;8 -j ACCEPT-A INPUT -p tcp -m tcp –dport 22 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em1 -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em1 -p tcp -m tcp –dport 8080 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -s 172.16.83.0&#x2F;24 -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -s 172.16.83.121 -p tcp -m tcp –dport 5666 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -s 172.16.83.121 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A INPUT -i lo -j ACCEPT#-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -p vrrp -j ACCEPT-A OUTPUT -d 224.0.0.0&#x2F;8 -j ACCEPT-A OUTPUT -o em2 -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em1 -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em1 -p tcp -m tcp –dport 25 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 53 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p udp -m udp –dport 514 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A OUTPUT ! -o lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -o lo -j ACCEPT#-A FORWARD -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-ip-options –log-tcp-options-A FORWARD -m conntrack –ctstate INVALID -j DROP-A FORWARD -m conntrack –ctstate ESTABLISHED,RELATED -j ACCEPT-A FORWARD -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A FORWARD -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPTCOMMIT Completed on Tue Oct 15 11:10:51 2013Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*nat:PREROUTING ACCEPT [293:34284]:POSTROUTING ACCEPT [172:11324]:OUTPUT ACCEPT [228:14684]COMMIT Completed on Tue Oct 15 11:10:51 2013","categories":["Linux配置文件","iptables"]},{"title":"redis_master_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/redis_master_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 29 17:52:08 2013*nat:PREROUTING ACCEPT [1195:64976]:POSTROUTING ACCEPT [1410:84600]:OUTPUT ACCEPT [1410:84600]COMMIT Completed on Tue Oct 29 17:52:08 2013Generated by iptables-save v1.4.7 on Tue Oct 29 17:52:08 2013*filter:INPUT DROP [0:0]:FORWARD DROP [0:0]:OUTPUT DROP [0:0]-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m tcp –dport 5122 –syn -m state –state NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 6379 –syn -m state –state NEW -j ACCEPT-A INPUT -s 10.10.38.238&#x2F;32 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -o lo -j ACCEPT-A OUTPUT -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 57822 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 53 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 53 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A OUTPUT ! -o lo -j LOG –log-prefix “DROP” –log-tcp-options –log-ip-optionsCOMMIT Completed on Tue Oct 29 17:52:08 2013","categories":["Linux配置文件","iptables"]},{"title":"mysql_lvs_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/mysql_lvs_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*filter:INPUT DROP [253:28094]:FORWARD DROP [0:0]:OUTPUT DROP [56:3360]#-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p vrrp -j ACCEPT-A INPUT -d 224.0.0.0&#x2F;8 -j ACCEPT-A INPUT -p tcp -m tcp –dport 5122 –syn -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -s 10.10.38.238&#x2F;32 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options#-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -o lo -j ACCEPT-A OUTPUT -p vrrp -j ACCEPT-A OUTPUT -d 224.0.0.0&#x2F;8 -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A OUTPUT ! -o lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A FORWARD -m conntrack –ctstate INVALID -j DROP-A FORWARD -m conntrack –ctstate ESTABLISHED,RELATED -j ACCEPT-A FORWARD -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPTCOMMIT Completed on Tue Oct 15 11:10:51 2013Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*nat:PREROUTING ACCEPT [293:34284]:POSTROUTING ACCEPT [172:11324]:OUTPUT ACCEPT [228:14684]COMMIT Completed on Tue Oct 15 11:10:51 2013","categories":["Linux配置文件","iptables"]},{"title":"manager_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/manager_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*filter:INPUT DROP [253:28094]:FORWARD DROP [0:0]:OUTPUT DROP [56:3360]#-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT#-A INPUT ! -s 172.16.83.0&#x2F;24 -i em2 -j LOG –log-prefix “SPOOFED PKT “-A INPUT ! -s 172.16.83.0&#x2F;24 -i em2 -j DROP-A INPUT -p tcp -m tcp –dport 22 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em1 -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em1 -p tcp -m tcp –dport 8080 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em2 -p udp -m udp –dport 514 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A INPUT -i lo -j ACCEPT#-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -o em2 -p tcp -m tcp –dport 22 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 25 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 53 -m conntrack –ctstate NEW -j ACCEPT for cacti(next 5 lines)-A OUTPUT -o em2 -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p tcp -m tcp –dport 5666 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p tcp -m tcp –dport 3000 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p tcp -m tcp –dport 11211 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT#for ntpdate (next line)-A OUTPUT -o em2 -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A OUTPUT ! -o lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -o lo -j ACCEPTCOMMIT Completed on Tue Oct 15 11:10:51 2013Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*nat:PREROUTING ACCEPT [293:34284]:POSTROUTING ACCEPT [172:11324]:OUTPUT ACCEPT [228:14684]COMMIT Completed on Tue Oct 15 11:10:51 2013","categories":["Linux配置文件","iptables"]},{"title":"db_slave_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/db_slave_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 29 17:52:08 2013*nat:PREROUTING ACCEPT [1195:64976]:POSTROUTING ACCEPT [1410:84600]:OUTPUT ACCEPT [1410:84600]COMMIT Completed on Tue Oct 29 17:52:08 2013Generated by iptables-save v1.4.7 on Tue Oct 29 17:52:08 2013*filter:INPUT DROP [0:0]:FORWARD DROP [0:0]:OUTPUT DROP [0:0]-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m tcp –dport 5122 –syn -m state –state NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 3306 –syn -m state –state NEW -j ACCEPT-A INPUT -s 10.10.67.60 -j ACCEPT-A INPUT -s 10.10.38.238&#x2F;32 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -o lo -j ACCEPT-A OUTPUT -d 10.10.67.60 -j ACCEPT-A OUTPUT -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 6379 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A OUTPUT ! -o lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-optionsCOMMIT Completed on Tue Oct 29 17:52:08 2013","categories":["Linux配置文件","iptables"]},{"title":"redis_slave_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/redis_slave_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 29 17:52:08 2013*nat:PREROUTING ACCEPT [1195:64976]:POSTROUTING ACCEPT [1410:84600]:OUTPUT ACCEPT [1410:84600]COMMIT Completed on Tue Oct 29 17:52:08 2013Generated by iptables-save v1.4.7 on Tue Oct 29 17:52:08 2013*filter:INPUT DROP [0:0]:FORWARD DROP [0:0]:OUTPUT DROP [0:0]-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -s 10.10.67.90 -j ACCEPT-A INPUT -p tcp -m tcp –dport 5122 –syn -m state –state NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 6379 –syn -m state –state NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 57822 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -s 10.10.38.238&#x2F;32 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -o lo -j ACCEPT-A OUTPUT -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 53 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 53 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A OUTPUT ! -o lo -j LOG –log-prefix “DROP” –log-tcp-options –log-ip-optionsCOMMIT Completed on Tue Oct 29 17:52:08 2013","categories":["Linux配置文件","iptables"]},{"title":"varnish_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/varnish_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*filter:INPUT DROP [253:28094]:FORWARD DROP [0:0]:OUTPUT DROP [56:3360]#-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT#-A INPUT ! -s 172.16.83.0&#x2F;24 -i em2 -j LOG –log-prefix “SPOOFED PKT “-A INPUT ! -s 172.16.83.0&#x2F;24 -i em2 -j DROP-A INPUT -p tcp -m tcp –dport 22 -m conntrack –ctstate NEW -j ACCEPT#-A INPUT -p tcp -m tcp –dport 10050 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em2 -p tcp -m tcp –dport 5666 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em2 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em2 -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A INPUT -i lo -j ACCEPT#-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -o em2 -p tcp -m tcp –dport 22 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p udp -m udp –dport 514 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 53 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 25 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A OUTPUT ! -o lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -o lo -j ACCEPTCOMMIT Completed on Tue Oct 15 11:10:51 2013Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*nat:PREROUTING ACCEPT [293:34284]:POSTROUTING ACCEPT [172:11324]:OUTPUT ACCEPT [228:14684]COMMIT Completed on Tue Oct 15 11:10:51 2013","categories":["Linux配置文件","iptables"]},{"title":"web_server_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/web_server_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 29 17:52:08 2013*nat:PREROUTING ACCEPT [1195:64976]:POSTROUTING ACCEPT [1410:84600]:OUTPUT ACCEPT [1410:84600]COMMIT Completed on Tue Oct 29 17:52:08 2013Generated by iptables-save v1.4.7 on Tue Oct 29 17:52:08 2013*filter:INPUT DROP [0:0]:FORWARD DROP [0:0]:OUTPUT DROP [0:0]-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m tcp –dport 5122 –syn -m state –state NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 80 –syn -m state –state NEW -j ACCEPT-A INPUT -s 10.10.38.238&#x2F;32 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -s 10.10.67.10&#x2F;32 -p tcp -m tcp –dport 873 –syn -m state –state NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -o lo -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 25 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -m iprange –dst-range 10.10.67.80-10.10.67.81 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -d 10.10.66.49&#x2F;32 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 6379 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 53 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT-A OUTPUT ! -o lo -j LOG –log-prefix “DROP” –log-tcp-options –log-ip-optionsCOMMIT Completed on Tue Oct 29 17:52:08 2013","categories":["Linux配置文件","iptables"]},{"title":"web_lvs_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/web_lvs_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*filter:INPUT DROP [253:28094]:FORWARD DROP [0:0]:OUTPUT DROP [56:3360]#-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p vrrp -j ACCEPT-A INPUT -d 224.0.0.0&#x2F;8 -j ACCEPT-A INPUT -p tcp -m tcp –dport 5122 –syn -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -s 10.10.38.238&#x2F;32 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options#-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -o lo -j ACCEPT-A OUTPUT -p vrrp -j ACCEPT-A OUTPUT -d 224.0.0.0&#x2F;8 -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A OUTPUT ! -o lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A FORWARD -m conntrack –ctstate INVALID -j DROP-A FORWARD -m conntrack –ctstate ESTABLISHED,RELATED -j ACCEPT-A FORWARD -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPTCOMMIT Completed on Tue Oct 15 11:10:51 2013Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*nat:PREROUTING ACCEPT [293:34284]:POSTROUTING ACCEPT [172:11324]:OUTPUT ACCEPT [228:14684]COMMIT Completed on Tue Oct 15 11:10:51 2013","categories":["Linux配置文件","iptables"]},{"title":"web_ipt.sav","path":"/2023/09/28/Linux配置文件/iptables/web_ipt.sav/","content":"Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*filter:INPUT DROP [253:28094]:FORWARD DROP [0:0]:OUTPUT DROP [56:3360]#-A INPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A INPUT -m conntrack –ctstate INVALID -j DROP-A INPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT#-A INPUT ! -s 172.16.83.0&#x2F;24 -i em2 -j LOG –log-prefix “SPOOFED PKT “-A INPUT ! -s 172.16.83.0&#x2F;24 -i em2 -j DROP-A INPUT -p tcp -m tcp –dport 22 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p tcp -m tcp –dport 3000 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em1 -p tcp -m tcp –dport 21211 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em1 -p tcp -m tcp –dport 30000:40000 -j ACCEPT-A INPUT -i em2 -p tcp -m tcp –dport 5666 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em2 -p tcp -m tcp –dport 3000 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -i em2 -p udp -m udp –dport 161 -m conntrack –ctstate NEW -j ACCEPT-A INPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A INPUT ! -i lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A INPUT -i lo -j ACCEPT#-A OUTPUT -m conntrack –ctstate INVALID -j LOG –log-prefix “DROP INVALID “ –log-tcp-options –log-ip-options-A OUTPUT -m conntrack –ctstate INVALID -j DROP-A OUTPUT -m conntrack –ctstate RELATED,ESTABLISHED -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 80 -m conntrack –ctstate NEW -j ACCEPT nfs-A OUTPUT -d 172.16.83.196 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p tcp -m tcp –dport 22 -m conntrack –ctstate NEW -j ACCEPT#next line for connect ro rsync_server(172.16.83.162)-A OUTPUT -o em2 -p tcp -m tcp –dport 873 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p tcp -m tcp –dport 3306 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 53 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p udp -m udp –dport 514 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -o em2 -p udp -m udp –dport 123 -m conntrack –ctstate NEW -j ACCEPT-A OUTPUT -p icmp -m icmp –icmp-type 8 -j ACCEPT#-A OUTPUT ! -o lo -j LOG –log-prefix “DROP “ –log-tcp-options –log-ip-options-A OUTPUT -o lo -j ACCEPTCOMMIT Completed on Tue Oct 15 11:10:51 2013Generated by iptables-save v1.4.7 on Tue Oct 15 11:10:51 2013*nat:PREROUTING ACCEPT [293:34284]:POSTROUTING ACCEPT [172:11324]:OUTPUT ACCEPT [228:14684]COMMIT Completed on Tue Oct 15 11:10:51 2013","categories":["Linux配置文件","iptables"]},{"title":"install.sh","path":"/2023/09/28/Linux配置文件/gcc/install.sh/","content":"#&#x2F; bin&#x2F;bash 依赖yum install gcc gcc-c++ gibc-static cloog-ppl gmp-devel islwget ftp://gcc.gnu.org/pub/gcc/infrastructure/isl-0.12.2.tar.bz2tar jxvf isl-0.12.2.tar.bz2 &amp;&amp; cd isl-0.12.2.&#x2F;configuremakemake install #gcc #获取最新gcc源码#svn checkout svn:&#x2F;&#x2F;gcc.gnu.org&#x2F;svn&#x2F;gcc&#x2F;trunk localdircd localdir&#x2F;gccmkdir build #下载gmp，mpfr，mpc源码，gcc-4.10.tgz里已经包含下载完的三个源码包，不必再次下载.&#x2F;contrib&#x2F;download_prerequisites cd build..&#x2F;configure –prefix&#x3D;&#x2F;usr –enable-languages&#x3D;c,c++ –disable-multilib make -j4#make -j选项，与cpu个数及线程数有关 make install","categories":["Linux配置文件","gcc"]},{"title":"rhel-debuginfo.repo","path":"/2023/09/28/Linux配置文件/kvm/rhel-debuginfo.repo/","content":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[rhel-debuginfo]name=Red Hat Enterprise Linux $releasever - $basearch - Debugbaseurl=file:///mnt/Serverenabled=1gpgcheck=0[Cluster]name=Red Hat Enterprise Linux $releasever - $basearch - Clusterbaseurl= file:///mnt/Clusterenabled=1gpgcheck=0[ClusterStorage]name=Red Hat Enterprise Linux $releasever - $basearch - ClusterStoragebaseurl= file:///mnt/ClusterStorageenabled=1gpgcheck=0[Server]name=Red Hat Enterprise Linux $releasever - $basearch - Serverbaseurl= file:///mnt/Serverenabled=1gpgcheck=0[VT]name=Red Hat Enterprise Linux $releasever - $basearch - VTbaseurl= file:///mnt/VTenabled=1gpgcheck=0","categories":["Linux配置文件","yum仓库"]},{"title":"apc_tt.php","path":"/2023/09/28/Linux配置文件/lamp/apc_tt.php/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179118011811182118311841185118611871188118911901191119211931194119511961197119811991200120112021203120412051206120712081209121012111212121312141215121612171218121912201221122212231224122512261227122812291230123112321233123412351236123712381239124012411242124312441245124612471248124912501251125212531254125512561257125812591260126112621263126412651266126712681269127012711272127312741275127612771278127912801281128212831284128512861287128812891290129112921293129412951296129712981299130013011302130313041305130613071308130913101311131213131314131513161317131813191320132113221323132413251326132713281329133013311332133313341335133613371338133913401341134213431344134513461347134813491350135113521353135413551356135713581359136013611362&lt;?php/* +----------------------------------------------------------------------+ | APC | +----------------------------------------------------------------------+ | Copyright (c) 2006-2011 The PHP Group | +----------------------------------------------------------------------+ | This source file is subject to version 3.01 of the PHP license, | | that is bundled with this package in the file LICENSE, and is | | available through the world-wide-web at the following url: | | http://www.php.net/license/3_01.txt | | If you did not receive a copy of the PHP license and are unable to | | obtain it through the world-wide-web, please send a note to | | license@php.net so we can mail you a copy immediately. | +----------------------------------------------------------------------+ | Authors: Ralf Becker &lt;beckerr@php.net&gt; | | Rasmus Lerdorf &lt;rasmus@php.net&gt; | | Ilia Alshanetsky &lt;ilia@prohost.org&gt; | +----------------------------------------------------------------------+ All other licensing and usage conditions are those of the PHP Group. */$VERSION=&#x27;$Id: apc.php 307048 2011-01-03 23:53:17Z kalle $&#x27;;////////// READ OPTIONAL CONFIGURATION FILE ////////////if (file_exists(&quot;apc.conf.php&quot;)) include(&quot;apc.conf.php&quot;);////////////////////////////////////////////////////////////////// BEGIN OF DEFAULT CONFIG AREA ///////////////////////////////////////////////////////////defaults(&#x27;USE_AUTHENTICATION&#x27;,1); // Use (internal) authentication - best choice if // no other authentication is available // If set to 0: // There will be no further authentication. You // will have to handle this by yourself! // If set to 1: // You need to change ADMIN_PASSWORD to make // this work!defaults(&#x27;ADMIN_USERNAME&#x27;,&#x27;apc&#x27;); // Admin Usernamedefaults(&#x27;ADMIN_PASSWORD&#x27;,&#x27;a221010pc&#x27;); // Admin Password - CHANGE THIS TO ENABLE!!!// (beckerr) I&#x27;m using a clear text password here, because I&#x27;ve no good idea how to let // users generate a md5 or crypt password in a easy way to fill it in above//defaults(&#x27;DATE_FORMAT&#x27;, &quot;d.m.Y H:i:s&quot;);\t// Germandefaults(&#x27;DATE_FORMAT&#x27;, &#x27;Y/m/d H:i:s&#x27;); // USdefaults(&#x27;GRAPH_SIZE&#x27;,200); // Image size//defaults(&#x27;PROXY&#x27;, &#x27;tcp://127.0.0.1:8080&#x27;);////////// END OF DEFAULT CONFIG AREA /////////////////////////////////////////////////////////////// &quot;define if not defined&quot;function defaults($d,$v) &#123;\tif (!defined($d)) define($d,$v); // or just @define(...)&#125;// rewrite $PHP_SELF to block XSS attacks//$PHP_SELF= isset($_SERVER[&#x27;PHP_SELF&#x27;]) ? htmlentities(strip_tags($_SERVER[&#x27;PHP_SELF&#x27;],&#x27;&#x27;), ENT_QUOTES, &#x27;UTF-8&#x27;) : &#x27;&#x27;;$time = time();$host = php_uname(&#x27;n&#x27;);if($host) &#123; $host = &#x27;(&#x27;.$host.&#x27;)&#x27;; &#125;if (isset($_SERVER[&#x27;SERVER_ADDR&#x27;])) &#123; $host .= &#x27; (&#x27;.$_SERVER[&#x27;SERVER_ADDR&#x27;].&#x27;)&#x27;;&#125;// operation constantsdefine(&#x27;OB_HOST_STATS&#x27;,1);define(&#x27;OB_SYS_CACHE&#x27;,2);define(&#x27;OB_USER_CACHE&#x27;,3);define(&#x27;OB_SYS_CACHE_DIR&#x27;,4);define(&#x27;OB_VERSION_CHECK&#x27;,9);// check validity of input variables$vardom=array(\t&#x27;OB&#x27;\t=&gt; &#x27;/^\\d+$/&#x27;, // operational mode switch\t&#x27;CC&#x27;\t=&gt; &#x27;/^[01]$/&#x27;, // clear cache requested\t&#x27;DU&#x27;\t=&gt; &#x27;/^.*$/&#x27;, // Delete User Key\t&#x27;SH&#x27;\t=&gt; &#x27;/^[a-z0-9]+$/&#x27;, // shared object description\t&#x27;IMG&#x27;\t=&gt; &#x27;/^[123]$/&#x27;, // image to generate\t&#x27;LO&#x27;\t=&gt; &#x27;/^1$/&#x27;, // login requested\t&#x27;COUNT&#x27;\t=&gt; &#x27;/^\\d+$/&#x27;, // number of line displayed in list\t&#x27;SCOPE&#x27;\t=&gt; &#x27;/^[AD]$/&#x27;, // list view scope\t&#x27;SORT1&#x27;\t=&gt; &#x27;/^[AHSMCDTZ]$/&#x27;,\t// first sort key\t&#x27;SORT2&#x27;\t=&gt; &#x27;/^[DA]$/&#x27;, // second sort key\t&#x27;AGGR&#x27;\t=&gt; &#x27;/^\\d+$/&#x27;, // aggregation by dir level\t&#x27;SEARCH&#x27;\t=&gt; &#x27;~^[a-zA-Z0-1/_.-]*$~&#x27; // aggregation by dir level);// default cache mode$cache_mode=&#x27;opcode&#x27;;// cache scope$scope_list=array(\t&#x27;A&#x27; =&gt; &#x27;cache_list&#x27;,\t&#x27;D&#x27; =&gt; &#x27;deleted_list&#x27;);// handle POST and GET requestsif (empty($_REQUEST)) &#123;\tif (!empty($_GET) &amp;&amp; !empty($_POST)) &#123; $_REQUEST = array_merge($_GET, $_POST);\t&#125; else if (!empty($_GET)) &#123; $_REQUEST = $_GET;\t&#125; else if (!empty($_POST)) &#123; $_REQUEST = $_POST;\t&#125; else &#123; $_REQUEST = array();\t&#125;&#125;// check parameter syntaxforeach($vardom as $var =&gt; $dom) &#123;\tif (!isset($_REQUEST[$var])) &#123; $MYREQUEST[$var]=NULL;\t&#125; else if (!is_array($_REQUEST[$var]) &amp;&amp; preg_match($dom.&#x27;D&#x27;,$_REQUEST[$var])) &#123; $MYREQUEST[$var]=$_REQUEST[$var];\t&#125; else &#123; $MYREQUEST[$var]=$_REQUEST[$var]=NULL;\t&#125;&#125;// check parameter sematicsif (empty($MYREQUEST[&#x27;SCOPE&#x27;])) $MYREQUEST[&#x27;SCOPE&#x27;]=&quot;A&quot;;if (empty($MYREQUEST[&#x27;SORT1&#x27;])) $MYREQUEST[&#x27;SORT1&#x27;]=&quot;H&quot;;if (empty($MYREQUEST[&#x27;SORT2&#x27;])) $MYREQUEST[&#x27;SORT2&#x27;]=&quot;D&quot;;if (empty($MYREQUEST[&#x27;OB&#x27;]))\t$MYREQUEST[&#x27;OB&#x27;]=OB_HOST_STATS;if (!isset($MYREQUEST[&#x27;COUNT&#x27;])) $MYREQUEST[&#x27;COUNT&#x27;]=20;if (!isset($scope_list[$MYREQUEST[&#x27;SCOPE&#x27;]])) $MYREQUEST[&#x27;SCOPE&#x27;]=&#x27;A&#x27;;$MY_SELF=\t&quot;$PHP_SELF&quot;.\t&quot;?SCOPE=&quot;.$MYREQUEST[&#x27;SCOPE&#x27;].\t&quot;&amp;SORT1=&quot;.$MYREQUEST[&#x27;SORT1&#x27;].\t&quot;&amp;SORT2=&quot;.$MYREQUEST[&#x27;SORT2&#x27;].\t&quot;&amp;COUNT=&quot;.$MYREQUEST[&#x27;COUNT&#x27;];$MY_SELF_WO_SORT=\t&quot;$PHP_SELF&quot;.\t&quot;?SCOPE=&quot;.$MYREQUEST[&#x27;SCOPE&#x27;].\t&quot;&amp;COUNT=&quot;.$MYREQUEST[&#x27;COUNT&#x27;];// authentication needed?//if (!USE_AUTHENTICATION) &#123;\t$AUTHENTICATED=1;&#125; else &#123;\t$AUTHENTICATED=0;\tif (ADMIN_PASSWORD!=&#x27;password&#x27; &amp;&amp; ($MYREQUEST[&#x27;LO&#x27;] == 1 || isset($_SERVER[&#x27;PHP_AUTH_USER&#x27;]))) &#123; if (!isset($_SERVER[&#x27;PHP_AUTH_USER&#x27;]) || !isset($_SERVER[&#x27;PHP_AUTH_PW&#x27;]) || $_SERVER[&#x27;PHP_AUTH_USER&#x27;] != ADMIN_USERNAME || $_SERVER[&#x27;PHP_AUTH_PW&#x27;] != ADMIN_PASSWORD) &#123; Header(&quot;WWW-Authenticate: Basic realm=\\&quot;APC Login\\&quot;&quot;); Header(&quot;HTTP/1.0 401 Unauthorized&quot;); echo &lt;&lt;&lt;EOB &lt;html&gt;&lt;body&gt; &lt;h1&gt;Rejected!&lt;/h1&gt; &lt;big&gt;Wrong Username or Password!&lt;/big&gt;&lt;br/&gt;&amp;nbsp;&lt;br/&gt;&amp;nbsp; &lt;big&gt;&lt;a href=&#x27;$PHP_SELF?OB=&#123;$MYREQUEST[&#x27;OB&#x27;]&#125;&#x27;&gt;Continue...&lt;/a&gt;&lt;/big&gt; &lt;/body&gt;&lt;/html&gt;EOB; exit; &#125; else &#123; $AUTHENTICATED=1; &#125;\t&#125;&#125;\t// select cache modeif ($AUTHENTICATED &amp;&amp; $MYREQUEST[&#x27;OB&#x27;] == OB_USER_CACHE) &#123;\t$cache_mode=&#x27;user&#x27;;&#125;// clear cacheif ($AUTHENTICATED &amp;&amp; isset($MYREQUEST[&#x27;CC&#x27;]) &amp;&amp; $MYREQUEST[&#x27;CC&#x27;]) &#123;\tapc_clear_cache($cache_mode);&#125;if ($AUTHENTICATED &amp;&amp; !empty($MYREQUEST[&#x27;DU&#x27;])) &#123;\tapc_delete($MYREQUEST[&#x27;DU&#x27;]);&#125;if(!function_exists(&#x27;apc_cache_info&#x27;) || !($cache=@apc_cache_info($cache_mode))) &#123;\techo &quot;No cache info available. APC does not appear to be running.&quot;; exit;&#125;$cache_user = apc_cache_info(&#x27;user&#x27;, 1); $mem=apc_sma_info();if(!$cache[&#x27;num_hits&#x27;]) &#123; $cache[&#x27;num_hits&#x27;]=1; $time++; &#125; // Avoid division by 0 errors on a cache clear// don&#x27;t cache this page//header(&quot;Cache-Control: no-store, no-cache, must-revalidate&quot;); // HTTP/1.1header(&quot;Cache-Control: post-check=0, pre-check=0&quot;, false);header(&quot;Pragma: no-cache&quot;); // HTTP/1.0function duration($ts) &#123; global $time; $years = (int)((($time - $ts)/(7*86400))/52.177457); $rem = (int)(($time-$ts)-($years * 52.177457 * 7 * 86400)); $weeks = (int)(($rem)/(7*86400)); $days = (int)(($rem)/86400) - $weeks*7; $hours = (int)(($rem)/3600) - $days*24 - $weeks*7*24; $mins = (int)(($rem)/60) - $hours*60 - $days*24*60 - $weeks*7*24*60; $str = &#x27;&#x27;; if($years==1) $str .= &quot;$years year, &quot;; if($years&gt;1) $str .= &quot;$years years, &quot;; if($weeks==1) $str .= &quot;$weeks week, &quot;; if($weeks&gt;1) $str .= &quot;$weeks weeks, &quot;; if($days==1) $str .= &quot;$days day,&quot;; if($days&gt;1) $str .= &quot;$days days,&quot;; if($hours == 1) $str .= &quot; $hours hour and&quot;; if($hours&gt;1) $str .= &quot; $hours hours and&quot;; if($mins == 1) $str .= &quot; 1 minute&quot;; else $str .= &quot; $mins minutes&quot;; return $str;&#125;// create graphics//function graphics_avail() &#123;\treturn extension_loaded(&#x27;gd&#x27;);&#125;if (isset($MYREQUEST[&#x27;IMG&#x27;]))&#123;\tif (!graphics_avail()) &#123; exit(0);\t&#125;\tfunction fill_arc($im, $centerX, $centerY, $diameter, $start, $end, $color1,$color2,$text=&#x27;&#x27;,$placeindex=0) &#123; $r=$diameter/2; $w=deg2rad((360+$start+($end-$start)/2)%360); if (function_exists(&quot;imagefilledarc&quot;)) &#123; // exists only if GD 2.0.1 is avaliable imagefilledarc($im, $centerX+1, $centerY+1, $diameter, $diameter, $start, $end, $color1, IMG_ARC_PIE); imagefilledarc($im, $centerX, $centerY, $diameter, $diameter, $start, $end, $color2, IMG_ARC_PIE); imagefilledarc($im, $centerX, $centerY, $diameter, $diameter, $start, $end, $color1, IMG_ARC_NOFILL|IMG_ARC_EDGED); &#125; else &#123; imagearc($im, $centerX, $centerY, $diameter, $diameter, $start, $end, $color2); imageline($im, $centerX, $centerY, $centerX + cos(deg2rad($start)) * $r, $centerY + sin(deg2rad($start)) * $r, $color2); imageline($im, $centerX, $centerY, $centerX + cos(deg2rad($start+1)) * $r, $centerY + sin(deg2rad($start)) * $r, $color2); imageline($im, $centerX, $centerY, $centerX + cos(deg2rad($end-1)) * $r, $centerY + sin(deg2rad($end)) * $r, $color2); imageline($im, $centerX, $centerY, $centerX + cos(deg2rad($end)) * $r, $centerY + sin(deg2rad($end)) * $r, $color2); imagefill($im,$centerX + $r*cos($w)/2, $centerY + $r*sin($w)/2, $color2); &#125; if ($text) &#123; if ($placeindex&gt;0) &#123; imageline($im,$centerX + $r*cos($w)/2, $centerY + $r*sin($w)/2,$diameter, $placeindex*12,$color1); imagestring($im,4,$diameter, $placeindex*12,$text,$color1); &#125; else &#123; imagestring($im,4,$centerX + $r*cos($w)/2, $centerY + $r*sin($w)/2,$text,$color1); &#125; &#125;\t&#125; function text_arc($im, $centerX, $centerY, $diameter, $start, $end, $color1,$text,$placeindex=0) &#123; $r=$diameter/2; $w=deg2rad((360+$start+($end-$start)/2)%360); if ($placeindex&gt;0) &#123; imageline($im,$centerX + $r*cos($w)/2, $centerY + $r*sin($w)/2,$diameter, $placeindex*12,$color1); imagestring($im,4,$diameter, $placeindex*12,$text,$color1); &#125; else &#123; imagestring($im,4,$centerX + $r*cos($w)/2, $centerY + $r*sin($w)/2,$text,$color1); &#125;\t&#125; function fill_box($im, $x, $y, $w, $h, $color1, $color2,$text=&#x27;&#x27;,$placeindex=&#x27;&#x27;) &#123; global $col_black; $x1=$x+$w-1; $y1=$y+$h-1; imagerectangle($im, $x, $y1, $x1+1, $y+1, $col_black); if($y1&gt;$y) imagefilledrectangle($im, $x, $y, $x1, $y1, $color2); else imagefilledrectangle($im, $x, $y1, $x1, $y, $color2); imagerectangle($im, $x, $y1, $x1, $y, $color1); if ($text) &#123; if ($placeindex&gt;0) &#123; if ($placeindex&lt;16) &#123; $px=5; $py=$placeindex*12+6; imagefilledrectangle($im, $px+90, $py+3, $px+90-4, $py-3, $color2); imageline($im,$x,$y+$h/2,$px+90,$py,$color2); imagestring($im,2,$px,$py-6,$text,$color1); &#125; else &#123; if ($placeindex&lt;31) &#123; $px=$x+40*2; $py=($placeindex-15)*12+6; &#125; else &#123; $px=$x+40*2+100*intval(($placeindex-15)/15); $py=($placeindex%15)*12+6; &#125; imagefilledrectangle($im, $px, $py+3, $px-4, $py-3, $color2); imageline($im,$x+$w,$y+$h/2,$px,$py,$color2); imagestring($im,2,$px+2,$py-6,$text,$color1); &#125; &#125; else &#123; imagestring($im,4,$x+5,$y1-16,$text,$color1); &#125; &#125;\t&#125;\t$size = GRAPH_SIZE; // image size\tif ($MYREQUEST[&#x27;IMG&#x27;]==3) $image = imagecreate(2*$size+150, $size+10);\telse $image = imagecreate($size+50, $size+10);\t$col_white = imagecolorallocate($image, 0xFF, 0xFF, 0xFF);\t$col_red = imagecolorallocate($image, 0xD0, 0x60, 0x30);\t$col_green = imagecolorallocate($image, 0x60, 0xF0, 0x60);\t$col_black = imagecolorallocate($image, 0, 0, 0);\timagecolortransparent($image,$col_white);\tswitch ($MYREQUEST[&#x27;IMG&#x27;]) &#123; case 1: $s=$mem[&#x27;num_seg&#x27;]*$mem[&#x27;seg_size&#x27;]; $a=$mem[&#x27;avail_mem&#x27;]; $x=$y=$size/2; $fuzz = 0.000001; // This block of code creates the pie chart. It is a lot more complex than you // would expect because we try to visualize any memory fragmentation as well. $angle_from = 0; $string_placement=array(); for($i=0; $i&lt;$mem[&#x27;num_seg&#x27;]; $i++) &#123; $ptr = 0; $free = $mem[&#x27;block_lists&#x27;][$i]; uasort($free, &#x27;block_sort&#x27;); foreach($free as $block) &#123; if($block[&#x27;offset&#x27;]!=$ptr) &#123; // Used block $angle_to = $angle_from+($block[&#x27;offset&#x27;]-$ptr)/$s; if(($angle_to+$fuzz)&gt;1) $angle_to = 1; if( ($angle_to*360) - ($angle_from*360) &gt;= 1) &#123; fill_arc($image,$x,$y,$size,$angle_from*360,$angle_to*360,$col_black,$col_red); if (($angle_to-$angle_from)&gt;0.05) &#123; array_push($string_placement, array($angle_from,$angle_to)); &#125; &#125; $angle_from = $angle_to; &#125; $angle_to = $angle_from+($block[&#x27;size&#x27;])/$s; if(($angle_to+$fuzz)&gt;1) $angle_to = 1; if( ($angle_to*360) - ($angle_from*360) &gt;= 1) &#123; fill_arc($image,$x,$y,$size,$angle_from*360,$angle_to*360,$col_black,$col_green); if (($angle_to-$angle_from)&gt;0.05) &#123; array_push($string_placement, array($angle_from,$angle_to)); &#125; &#125; $angle_from = $angle_to; $ptr = $block[&#x27;offset&#x27;]+$block[&#x27;size&#x27;]; &#125; if ($ptr &lt; $mem[&#x27;seg_size&#x27;]) &#123; // memory at the end $angle_to = $angle_from + ($mem[&#x27;seg_size&#x27;] - $ptr)/$s; if(($angle_to+$fuzz)&gt;1) $angle_to = 1; fill_arc($image,$x,$y,$size,$angle_from*360,$angle_to*360,$col_black,$col_red); if (($angle_to-$angle_from)&gt;0.05) &#123; array_push($string_placement, array($angle_from,$angle_to)); &#125; &#125; &#125; foreach ($string_placement as $angle) &#123; text_arc($image,$x,$y,$size,$angle[0]*360,$angle[1]*360,$col_black,bsize($s*($angle[1]-$angle[0]))); &#125; break; case 2: $s=$cache[&#x27;num_hits&#x27;]+$cache[&#x27;num_misses&#x27;]; $a=$cache[&#x27;num_hits&#x27;]; fill_box($image, 30,$size,50,-$a*($size-21)/$s,$col_black,$col_green,sprintf(&quot;%.1f%%&quot;,$cache[&#x27;num_hits&#x27;]*100/$s)); fill_box($image,130,$size,50,-max(4,($s-$a)*($size-21)/$s),$col_black,$col_red,sprintf(&quot;%.1f%%&quot;,$cache[&#x27;num_misses&#x27;]*100/$s)); break; case 3: $s=$mem[&#x27;num_seg&#x27;]*$mem[&#x27;seg_size&#x27;]; $a=$mem[&#x27;avail_mem&#x27;]; $x=130; $y=1; $j=1; // This block of code creates the bar chart. It is a lot more complex than you // would expect because we try to visualize any memory fragmentation as well. for($i=0; $i&lt;$mem[&#x27;num_seg&#x27;]; $i++) &#123; $ptr = 0; $free = $mem[&#x27;block_lists&#x27;][$i]; uasort($free, &#x27;block_sort&#x27;); foreach($free as $block) &#123; if($block[&#x27;offset&#x27;]!=$ptr) &#123; // Used block $h=(GRAPH_SIZE-5)*($block[&#x27;offset&#x27;]-$ptr)/$s; if ($h&gt;0) &#123; $j++; if($j&lt;75) fill_box($image,$x,$y,50,$h,$col_black,$col_red,bsize($block[&#x27;offset&#x27;]-$ptr),$j); else fill_box($image,$x,$y,50,$h,$col_black,$col_red); &#125; $y+=$h; &#125; $h=(GRAPH_SIZE-5)*($block[&#x27;size&#x27;])/$s; if ($h&gt;0) &#123; $j++; if($j&lt;75) fill_box($image,$x,$y,50,$h,$col_black,$col_green,bsize($block[&#x27;size&#x27;]),$j); else fill_box($image,$x,$y,50,$h,$col_black,$col_green); &#125; $y+=$h; $ptr = $block[&#x27;offset&#x27;]+$block[&#x27;size&#x27;]; &#125; if ($ptr &lt; $mem[&#x27;seg_size&#x27;]) &#123; // memory at the end $h = (GRAPH_SIZE-5) * ($mem[&#x27;seg_size&#x27;] - $ptr) / $s; if ($h &gt; 0) &#123; fill_box($image,$x,$y,50,$h,$col_black,$col_red,bsize($mem[&#x27;seg_size&#x27;]-$ptr),$j++); &#125; &#125; &#125; break;\tcase 4: $s=$cache[&#x27;num_hits&#x27;]+$cache[&#x27;num_misses&#x27;]; $a=$cache[&#x27;num_hits&#x27;]; fill_box($image, 30,$size,50,-$a*($size-21)/$s,$col_black,$col_green,sprintf(&quot;%.1f%%&quot;,$cache[&#x27;num_hits&#x27;]*100/$s)); fill_box($image,130,$size,50,-max(4,($s-$a)*($size-21)/$s),$col_black,$col_red,sprintf(&quot;%.1f%%&quot;,$cache[&#x27;num_misses&#x27;]*100/$s)); break; &#125;\theader(&quot;Content-type: image/png&quot;);\timagepng($image);\texit;&#125;// pretty printer for byte values//function bsize($s) &#123;\tforeach (array(&#x27;&#x27;,&#x27;K&#x27;,&#x27;M&#x27;,&#x27;G&#x27;) as $i =&gt; $k) &#123; if ($s &lt; 1024) break; $s/=1024;\t&#125;\treturn sprintf(&quot;%5.1f %sBytes&quot;,$s,$k);&#125;// sortable table header in &quot;scripts for this host&quot; viewfunction sortheader($key,$name,$extra=&#x27;&#x27;) &#123;\tglobal $MYREQUEST, $MY_SELF_WO_SORT; if ($MYREQUEST[&#x27;SORT1&#x27;]==$key) &#123; $MYREQUEST[&#x27;SORT2&#x27;] = $MYREQUEST[&#x27;SORT2&#x27;]==&#x27;A&#x27; ? &#x27;D&#x27; : &#x27;A&#x27;;\t&#125;\treturn &quot;&lt;a class=sortable href=\\&quot;$MY_SELF_WO_SORT$extra&amp;SORT1=$key&amp;SORT2=&quot;.$MYREQUEST[&#x27;SORT2&#x27;].&quot;\\&quot;&gt;$name&lt;/a&gt;&quot;;&#125;// create menu entry function menu_entry($ob,$title) &#123;\tglobal $MYREQUEST,$MY_SELF;\tif ($MYREQUEST[&#x27;OB&#x27;]!=$ob) &#123; return &quot;&lt;li&gt;&lt;a href=\\&quot;$MY_SELF&amp;OB=$ob\\&quot;&gt;$title&lt;/a&gt;&lt;/li&gt;&quot;;\t&#125; else if (empty($MYREQUEST[&#x27;SH&#x27;])) &#123; return &quot;&lt;li&gt;&lt;span class=active&gt;$title&lt;/span&gt;&lt;/li&gt;&quot;;\t&#125; else &#123; return &quot;&lt;li&gt;&lt;a class=\\&quot;child_active\\&quot; href=\\&quot;$MY_SELF&amp;OB=$ob\\&quot;&gt;$title&lt;/a&gt;&lt;/li&gt;&quot;; &#125;&#125;function put_login_link($s=&quot;Login&quot;)&#123;\tglobal $MY_SELF,$MYREQUEST,$AUTHENTICATED;\t// needs ADMIN_PASSWORD to be changed!\t//\tif (!USE_AUTHENTICATION) &#123; return;\t&#125; else if (ADMIN_PASSWORD==&#x27;password&#x27;)\t&#123; print &lt;&lt;&lt;EOB &lt;a href=&quot;#&quot; onClick=&quot;javascript:alert(&#x27;You need to set a password at the top of apc.php before this will work!&#x27;);return false&quot;;&gt;$s&lt;/a&gt;EOB;\t&#125; else if ($AUTHENTICATED) &#123; print &lt;&lt;&lt;EOB &#x27;&#123;$_SERVER[&#x27;PHP_AUTH_USER&#x27;]&#125;&#x27;&amp;nbsp;logged&amp;nbsp;in!EOB;\t&#125; else&#123; print &lt;&lt;&lt;EOB &lt;a href=&quot;$MY_SELF&amp;LO=1&amp;OB=&#123;$MYREQUEST[&#x27;OB&#x27;]&#125;&quot;&gt;$s&lt;/a&gt;EOB;\t&#125;&#125;function block_sort($array1, $array2)&#123;\tif ($array1[&#x27;offset&#x27;] &gt; $array2[&#x27;offset&#x27;]) &#123; return 1;\t&#125; else &#123; return -1;\t&#125;&#125;?&gt;&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;APC INFO &lt;?php echo $host ?&gt;&lt;/title&gt;&lt;style&gt;&lt;!--body &#123; background:white; font-size:100.01%; margin:0; padding:0; &#125;body,p,td,th,input,submit &#123; font-size:0.8em;font-family:arial,helvetica,sans-serif; &#125;* html body &#123;font-size:0.8em&#125;* html p &#123;font-size:0.8em&#125;* html td &#123;font-size:0.8em&#125;* html th &#123;font-size:0.8em&#125;* html input &#123;font-size:0.8em&#125;* html submit &#123;font-size:0.8em&#125;td &#123; vertical-align:top &#125;a &#123; color:black; font-weight:none; text-decoration:none; &#125;a:hover &#123; text-decoration:underline; &#125;div.content &#123; padding:1em 1em 1em 1em; position:absolute; width:97%; z-index:100; &#125;div.head div.login &#123;\tposition:absolute;\tright: 1em;\ttop: 1.2em;\tcolor:white;\twidth:6em;\t&#125;div.head div.login a &#123;\tposition:absolute;\tright: 0em;\tbackground:rgb(119,123,180);\tborder:solid rgb(102,102,153) 2px;\tcolor:white;\tfont-weight:bold;\tpadding:0.1em 0.5em 0.1em 0.5em;\ttext-decoration:none;\t&#125;div.head div.login a:hover &#123;\tbackground:rgb(193,193,244);\t&#125;h1.apc &#123; background:rgb(153,153,204); margin:0; padding:0.5em 1em 0.5em 1em; &#125;* html h1.apc &#123; margin-bottom:-7px; &#125;h1.apc a:hover &#123; text-decoration:none; color:rgb(90,90,90); &#125;h1.apc div.logo span.logo &#123;\tbackground:rgb(119,123,180);\tcolor:black;\tborder-right: solid black 1px;\tborder-bottom: solid black 1px;\tfont-style:italic;\tfont-size:1em;\tpadding-left:1.2em;\tpadding-right:1.2em;\ttext-align:right;\t&#125;h1.apc div.logo span.name &#123; color:white; font-size:0.7em; padding:0 0.8em 0 2em; &#125;h1.apc div.nameinfo &#123; color:white; display:inline; font-size:0.4em; margin-left: 3em; &#125;h1.apc div.copy &#123; color:black; font-size:0.4em; position:absolute; right:1em; &#125;hr.apc &#123;\tbackground:white;\tborder-bottom:solid rgb(102,102,153) 1px;\tborder-style:none;\tborder-top:solid rgb(102,102,153) 10px;\theight:12px;\tmargin:0;\tmargin-top:1px;\tpadding:0;&#125;ol,menu &#123; margin:1em 0 0 0; padding:0.2em; margin-left:1em;&#125;ol.menu li &#123; display:inline; margin-right:0.7em; list-style:none; font-size:85%&#125;ol.menu a &#123;\tbackground:rgb(153,153,204);\tborder:solid rgb(102,102,153) 2px;\tcolor:white;\tfont-weight:bold;\tmargin-right:0em;\tpadding:0.1em 0.5em 0.1em 0.5em;\ttext-decoration:none;\tmargin-left: 5px;\t&#125;ol.menu a.child_active &#123;\tbackground:rgb(153,153,204);\tborder:solid rgb(102,102,153) 2px;\tcolor:white;\tfont-weight:bold;\tmargin-right:0em;\tpadding:0.1em 0.5em 0.1em 0.5em;\ttext-decoration:none;\tborder-left: solid black 5px;\tmargin-left: 0px;\t&#125;ol.menu span.active &#123;\tbackground:rgb(153,153,204);\tborder:solid rgb(102,102,153) 2px;\tcolor:black;\tfont-weight:bold;\tmargin-right:0em;\tpadding:0.1em 0.5em 0.1em 0.5em;\ttext-decoration:none;\tborder-left: solid black 5px;\t&#125;ol.menu span.inactive &#123;\tbackground:rgb(193,193,244);\tborder:solid rgb(182,182,233) 2px;\tcolor:white;\tfont-weight:bold;\tmargin-right:0em;\tpadding:0.1em 0.5em 0.1em 0.5em;\ttext-decoration:none;\tmargin-left: 5px;\t&#125;ol.menu a:hover &#123;\tbackground:rgb(193,193,244);\ttext-decoration:none;\t&#125; div.info &#123;\tbackground:rgb(204,204,204);\tborder:solid rgb(204,204,204) 1px;\tmargin-bottom:1em;\t&#125;div.info h2 &#123;\tbackground:rgb(204,204,204);\tcolor:black;\tfont-size:1em;\tmargin:0;\tpadding:0.1em 1em 0.1em 1em;\t&#125;div.info table &#123;\tborder:solid rgb(204,204,204) 1px;\tborder-spacing:0;\twidth:100%;\t&#125;div.info table th &#123;\tbackground:rgb(204,204,204);\tcolor:white;\tmargin:0;\tpadding:0.1em 1em 0.1em 1em;\t&#125;div.info table th a.sortable &#123; color:black; &#125;div.info table tr.tr-0 &#123; background:rgb(238,238,238); &#125;div.info table tr.tr-1 &#123; background:rgb(221,221,221); &#125;div.info table td &#123; padding:0.3em 1em 0.3em 1em; &#125;div.info table td.td-0 &#123; border-right:solid rgb(102,102,153) 1px; white-space:nowrap; &#125;div.info table td.td-n &#123; border-right:solid rgb(102,102,153) 1px; &#125;div.info table td h3 &#123;\tcolor:black;\tfont-size:1.1em;\tmargin-left:-0.3em;\t&#125;div.graph &#123; margin-bottom:1em &#125;div.graph h2 &#123; background:rgb(204,204,204);; color:black; font-size:1em; margin:0; padding:0.1em 1em 0.1em 1em; &#125;div.graph table &#123; border:solid rgb(204,204,204) 1px; color:black; font-weight:normal; width:100%; &#125;div.graph table td.td-0 &#123; background:rgb(238,238,238); &#125;div.graph table td.td-1 &#123; background:rgb(221,221,221); &#125;div.graph table td &#123; padding:0.2em 1em 0.4em 1em; &#125;div.div1,div.div2 &#123; margin-bottom:1em; width:35em; &#125;div.div3 &#123; position:absolute; left:40em; top:1em; width:580px; &#125;//div.div3 &#123; position:absolute; left:37em; top:1em; right:1em; &#125;div.sorting &#123; margin:1.5em 0em 1.5em 2em &#125;.center &#123; text-align:center &#125;.aright &#123; position:absolute;right:1em &#125;.right &#123; text-align:right &#125;.ok &#123; color:rgb(0,200,0); font-weight:bold&#125;.failed &#123; color:rgb(200,0,0); font-weight:bold&#125;span.box &#123;\tborder: black solid 1px;\tborder-right:solid black 2px;\tborder-bottom:solid black 2px;\tpadding:0 0.5em 0 0.5em;\tmargin-right:1em;&#125;span.green &#123; background:#60F060; padding:0 0.5em 0 0.5em&#125;span.red &#123; background:#D06030; padding:0 0.5em 0 0.5em &#125;div.authneeded &#123;\tbackground:rgb(238,238,238);\tborder:solid rgb(204,204,204) 1px;\tcolor:rgb(200,0,0);\tfont-size:1.2em;\tfont-weight:bold;\tpadding:2em;\ttext-align:center;\t&#125;\tinput &#123;\tbackground:rgb(153,153,204);\tborder:solid rgb(102,102,153) 2px;\tcolor:white;\tfont-weight:bold;\tmargin-right:1em;\tpadding:0.1em 0.5em 0.1em 0.5em;\t&#125;//--&gt;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=&quot;head&quot;&gt;\t&lt;h1 class=&quot;apc&quot;&gt; &lt;div class=&quot;logo&quot;&gt;&lt;span class=&quot;logo&quot;&gt;&lt;a href=&quot;http://pecl.php.net/package/APC&quot;&gt;APC&lt;/a&gt;&lt;/span&gt;&lt;/div&gt; &lt;div class=&quot;nameinfo&quot;&gt;Opcode Cache&lt;/div&gt;\t&lt;/h1&gt;\t&lt;div class=&quot;login&quot;&gt;\t&lt;?php put_login_link(); ?&gt;\t&lt;/div&gt;\t&lt;hr class=&quot;apc&quot;&gt;&lt;/div&gt;&lt;?php// Display main Menuecho &lt;&lt;&lt;EOB\t&lt;ol class=menu&gt;\t&lt;li&gt;&lt;a href=&quot;$MY_SELF&amp;OB=&#123;$MYREQUEST[&#x27;OB&#x27;]&#125;&amp;SH=&#123;$MYREQUEST[&#x27;SH&#x27;]&#125;&quot;&gt;Refresh Data&lt;/a&gt;&lt;/li&gt;EOB;echo\tmenu_entry(1,&#x27;View Host Stats&#x27;),\tmenu_entry(2,&#x27;System Cache Entries&#x27;);if ($AUTHENTICATED) &#123;\techo menu_entry(4,&#x27;Per-Directory Entries&#x27;);&#125;echo\tmenu_entry(3,&#x27;User Cache Entries&#x27;),\tmenu_entry(9,&#x27;Version Check&#x27;);\tif ($AUTHENTICATED) &#123;\techo &lt;&lt;&lt;EOB &lt;li&gt;&lt;a class=&quot;aright&quot; href=&quot;$MY_SELF&amp;CC=1&amp;OB=&#123;$MYREQUEST[&#x27;OB&#x27;]&#125;&quot; onClick=&quot;javascript:return confirm(&#x27;Are you sure?&#x27;);&quot;&gt;Clear $cache_mode Cache&lt;/a&gt;&lt;/li&gt;EOB;&#125;echo &lt;&lt;&lt;EOB\t&lt;/ol&gt;EOB;// CONTENTecho &lt;&lt;&lt;EOB\t&lt;div class=content&gt;EOB;// MAIN SWITCH STATEMENT switch ($MYREQUEST[&#x27;OB&#x27;]) &#123;// -----------------------------------------------// Host Stats// -----------------------------------------------case OB_HOST_STATS:\t$mem_size = $mem[&#x27;num_seg&#x27;]*$mem[&#x27;seg_size&#x27;];\t$mem_avail= $mem[&#x27;avail_mem&#x27;];\t$mem_used = $mem_size-$mem_avail;\t$seg_size = bsize($mem[&#x27;seg_size&#x27;]);\t$req_rate = sprintf(&quot;%.2f&quot;,($cache[&#x27;num_hits&#x27;]+$cache[&#x27;num_misses&#x27;])/($time-$cache[&#x27;start_time&#x27;]));\t$hit_rate = sprintf(&quot;%.2f&quot;,($cache[&#x27;num_hits&#x27;])/($time-$cache[&#x27;start_time&#x27;]));\t$miss_rate = sprintf(&quot;%.2f&quot;,($cache[&#x27;num_misses&#x27;])/($time-$cache[&#x27;start_time&#x27;]));\t$insert_rate = sprintf(&quot;%.2f&quot;,($cache[&#x27;num_inserts&#x27;])/($time-$cache[&#x27;start_time&#x27;]));\t$req_rate_user = sprintf(&quot;%.2f&quot;,($cache_user[&#x27;num_hits&#x27;]+$cache_user[&#x27;num_misses&#x27;])/($time-$cache_user[&#x27;start_time&#x27;]));\t$hit_rate_user = sprintf(&quot;%.2f&quot;,($cache_user[&#x27;num_hits&#x27;])/($time-$cache_user[&#x27;start_time&#x27;]));\t$miss_rate_user = sprintf(&quot;%.2f&quot;,($cache_user[&#x27;num_misses&#x27;])/($time-$cache_user[&#x27;start_time&#x27;]));\t$insert_rate_user = sprintf(&quot;%.2f&quot;,($cache_user[&#x27;num_inserts&#x27;])/($time-$cache_user[&#x27;start_time&#x27;]));\t$apcversion = phpversion(&#x27;apc&#x27;);\t$phpversion = phpversion();\t$number_files = $cache[&#x27;num_entries&#x27;]; $size_files = bsize($cache[&#x27;mem_size&#x27;]);\t$number_vars = $cache_user[&#x27;num_entries&#x27;]; $size_vars = bsize($cache_user[&#x27;mem_size&#x27;]);\t$i=0;\techo &lt;&lt;&lt; EOB &lt;div class=&quot;info div1&quot;&gt;&lt;h2&gt;General Cache Information&lt;/h2&gt; &lt;table cellspacing=0&gt;&lt;tbody&gt; &lt;tr class=tr-0&gt;&lt;td class=td-0&gt;APC Version&lt;/td&gt;&lt;td&gt;$apcversion&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-1&gt;&lt;td class=td-0&gt;PHP Version&lt;/td&gt;&lt;td&gt;$phpversion&lt;/td&gt;&lt;/tr&gt;EOB;\tif(!empty($_SERVER[&#x27;SERVER_NAME&#x27;])) echo &quot;&lt;tr class=tr-0&gt;&lt;td class=td-0&gt;APC Host&lt;/td&gt;&lt;td&gt;&#123;$_SERVER[&#x27;SERVER_NAME&#x27;]&#125; $host&lt;/td&gt;&lt;/tr&gt; &quot;;\tif(!empty($_SERVER[&#x27;SERVER_SOFTWARE&#x27;])) echo &quot;&lt;tr class=tr-1&gt;&lt;td class=td-0&gt;Server Software&lt;/td&gt;&lt;td&gt;&#123;$_SERVER[&#x27;SERVER_SOFTWARE&#x27;]&#125;&lt;/td&gt;&lt;/tr&gt; &quot;;\techo &lt;&lt;&lt;EOB &lt;tr class=tr-0&gt;&lt;td class=td-0&gt;Shared Memory&lt;/td&gt;&lt;td&gt;&#123;$mem[&#x27;num_seg&#x27;]&#125; Segment(s) with $seg_size &lt;br/&gt; (&#123;$cache[&#x27;memory_type&#x27;]&#125; memory, &#123;$cache[&#x27;locking_type&#x27;]&#125; locking) &lt;/td&gt;&lt;/tr&gt;EOB;\techo &#x27;&lt;tr class=tr-1&gt;&lt;td class=td-0&gt;Start Time&lt;/td&gt;&lt;td&gt;&#x27;,date(DATE_FORMAT,$cache[&#x27;start_time&#x27;]),&#x27;&lt;/td&gt;&lt;/tr&gt;&#x27;;\techo &#x27;&lt;tr class=tr-0&gt;&lt;td class=td-0&gt;Uptime&lt;/td&gt;&lt;td&gt;&#x27;,duration($cache[&#x27;start_time&#x27;]),&#x27;&lt;/td&gt;&lt;/tr&gt;&#x27;;\techo &#x27;&lt;tr class=tr-1&gt;&lt;td class=td-0&gt;File Upload Support&lt;/td&gt;&lt;td&gt;&#x27;,$cache[&#x27;file_upload_progress&#x27;],&#x27;&lt;/td&gt;&lt;/tr&gt;&#x27;;\techo &lt;&lt;&lt;EOB &lt;/tbody&gt;&lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;info div1&quot;&gt;&lt;h2&gt;File Cache Information&lt;/h2&gt; &lt;table cellspacing=0&gt;&lt;tbody&gt; &lt;tr class=tr-0&gt;&lt;td class=td-0&gt;Cached Files&lt;/td&gt;&lt;td&gt;$number_files ($size_files)&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-1&gt;&lt;td class=td-0&gt;Hits&lt;/td&gt;&lt;td&gt;&#123;$cache[&#x27;num_hits&#x27;]&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-0&gt;&lt;td class=td-0&gt;Misses&lt;/td&gt;&lt;td&gt;&#123;$cache[&#x27;num_misses&#x27;]&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-1&gt;&lt;td class=td-0&gt;Request Rate (hits, misses)&lt;/td&gt;&lt;td&gt;$req_rate cache requests/second&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-0&gt;&lt;td class=td-0&gt;Hit Rate&lt;/td&gt;&lt;td&gt;$hit_rate cache requests/second&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-1&gt;&lt;td class=td-0&gt;Miss Rate&lt;/td&gt;&lt;td&gt;$miss_rate cache requests/second&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-0&gt;&lt;td class=td-0&gt;Insert Rate&lt;/td&gt;&lt;td&gt;$insert_rate cache requests/second&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-1&gt;&lt;td class=td-0&gt;Cache full count&lt;/td&gt;&lt;td&gt;&#123;$cache[&#x27;expunges&#x27;]&#125;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;info div1&quot;&gt;&lt;h2&gt;User Cache Information&lt;/h2&gt; &lt;table cellspacing=0&gt;&lt;tbody&gt; &lt;tr class=tr-0&gt;&lt;td class=td-0&gt;Cached Variables&lt;/td&gt;&lt;td&gt;$number_vars ($size_vars)&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-1&gt;&lt;td class=td-0&gt;Hits&lt;/td&gt;&lt;td&gt;&#123;$cache_user[&#x27;num_hits&#x27;]&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-0&gt;&lt;td class=td-0&gt;Misses&lt;/td&gt;&lt;td&gt;&#123;$cache_user[&#x27;num_misses&#x27;]&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-1&gt;&lt;td class=td-0&gt;Request Rate (hits, misses)&lt;/td&gt;&lt;td&gt;$req_rate_user cache requests/second&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-0&gt;&lt;td class=td-0&gt;Hit Rate&lt;/td&gt;&lt;td&gt;$hit_rate_user cache requests/second&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-1&gt;&lt;td class=td-0&gt;Miss Rate&lt;/td&gt;&lt;td&gt;$miss_rate_user cache requests/second&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-0&gt;&lt;td class=td-0&gt;Insert Rate&lt;/td&gt;&lt;td&gt;$insert_rate_user cache requests/second&lt;/td&gt;&lt;/tr&gt; &lt;tr class=tr-1&gt;&lt;td class=td-0&gt;Cache full count&lt;/td&gt;&lt;td&gt;&#123;$cache_user[&#x27;expunges&#x27;]&#125;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;info div2&quot;&gt;&lt;h2&gt;Runtime Settings&lt;/h2&gt;&lt;table cellspacing=0&gt;&lt;tbody&gt;EOB;\t$j = 0;\tforeach (ini_get_all(&#x27;apc&#x27;) as $k =&gt; $v) &#123; echo &quot;&lt;tr class=tr-$j&gt;&lt;td class=td-0&gt;&quot;,$k,&quot;&lt;/td&gt;&lt;td&gt;&quot;,str_replace(&#x27;,&#x27;,&#x27;,&lt;br /&gt;&#x27;,$v[&#x27;local_value&#x27;]),&quot;&lt;/td&gt;&lt;/tr&gt; &quot;; $j = 1 - $j;\t&#125;\tif($mem[&#x27;num_seg&#x27;]&gt;1 || $mem[&#x27;num_seg&#x27;]==1 &amp;&amp; count($mem[&#x27;block_lists&#x27;][0])&gt;1) $mem_note = &quot;Memory Usage&lt;br /&gt;&lt;font size=-2&gt;(multiple slices indicate fragments)&lt;/font&gt;&quot;;\telse $mem_note = &quot;Memory Usage&quot;;\techo &lt;&lt;&lt; EOB &lt;/tbody&gt;&lt;/table&gt; &lt;/div&gt; &lt;div class=&quot;graph div3&quot;&gt;&lt;h2&gt;Host Status Diagrams&lt;/h2&gt; &lt;table cellspacing=0&gt;&lt;tbody&gt;EOB;\t$size=&#x27;width=&#x27;.(GRAPH_SIZE+50).&#x27; height=&#x27;.(GRAPH_SIZE+10);\techo &lt;&lt;&lt;EOB &lt;tr&gt; &lt;td class=td-0&gt;$mem_note&lt;/td&gt; &lt;td class=td-1&gt;Hits &amp;amp; Misses&lt;/td&gt; &lt;/tr&gt;EOB;\techo graphics_avail() ? &#x27;&lt;tr&gt;&#x27;. &quot;&lt;td class=td-0&gt;&lt;img alt=\\&quot;\\&quot; $size src=\\&quot;$PHP_SELF?IMG=1&amp;$time\\&quot;&gt;&lt;/td&gt;&quot;. &quot;&lt;td class=td-1&gt;&lt;img alt=\\&quot;\\&quot; $size src=\\&quot;$PHP_SELF?IMG=2&amp;$time\\&quot;&gt;&lt;/td&gt;&lt;/tr&gt; &quot; : &quot;&quot;, &#x27;&lt;tr&gt;&#x27;, &#x27;&lt;td class=td-0&gt;&lt;span class=&quot;green box&quot;&gt;&amp;nbsp;&lt;/span&gt;Free: &#x27;,bsize($mem_avail).sprintf(&quot; (%.1f%%)&quot;,$mem_avail*100/$mem_size),&quot;&lt;/td&gt; &quot;, &#x27;&lt;td class=td-1&gt;&lt;span class=&quot;green box&quot;&gt;&amp;nbsp;&lt;/span&gt;Hits: &#x27;,$cache[&#x27;num_hits&#x27;].sprintf(&quot; (%.1f%%)&quot;,$cache[&#x27;num_hits&#x27;]*100/($cache[&#x27;num_hits&#x27;]+$cache[&#x27;num_misses&#x27;])),&quot;&lt;/td&gt; &quot;, &#x27;&lt;/tr&gt;&#x27;, &#x27;&lt;tr&gt;&#x27;, &#x27;&lt;td class=td-0&gt;&lt;span class=&quot;red box&quot;&gt;&amp;nbsp;&lt;/span&gt;Used: &#x27;,bsize($mem_used ).sprintf(&quot; (%.1f%%)&quot;,$mem_used *100/$mem_size),&quot;&lt;/td&gt; &quot;, &#x27;&lt;td class=td-1&gt;&lt;span class=&quot;red box&quot;&gt;&amp;nbsp;&lt;/span&gt;Misses: &#x27;,$cache[&#x27;num_misses&#x27;].sprintf(&quot; (%.1f%%)&quot;,$cache[&#x27;num_misses&#x27;]*100/($cache[&#x27;num_hits&#x27;]+$cache[&#x27;num_misses&#x27;])),&quot;&lt;/td&gt; &quot;;\techo &lt;&lt;&lt; EOB &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;br/&gt; &lt;h2&gt;Detailed Memory Usage and Fragmentation&lt;/h2&gt; &lt;table cellspacing=0&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td class=td-0 colspan=2&gt;&lt;br/&gt;EOB;\t// Fragementation: (freeseg - 1) / total_seg\t$nseg = $freeseg = $fragsize = $freetotal = 0;\tfor($i=0; $i&lt;$mem[&#x27;num_seg&#x27;]; $i++) &#123; $ptr = 0; foreach($mem[&#x27;block_lists&#x27;][$i] as $block) &#123; if ($block[&#x27;offset&#x27;] != $ptr) &#123; ++$nseg; &#125; $ptr = $block[&#x27;offset&#x27;] + $block[&#x27;size&#x27;]; /* Only consider blocks &lt;5M for the fragmentation % */ if($block[&#x27;size&#x27;]&lt;(5*1024*1024)) $fragsize+=$block[&#x27;size&#x27;]; $freetotal+=$block[&#x27;size&#x27;]; &#125; $freeseg += count($mem[&#x27;block_lists&#x27;][$i]);\t&#125; if ($freeseg &gt; 1) &#123; $frag = sprintf(&quot;%.2f%% (%s out of %s in %d fragments)&quot;, ($fragsize/$freetotal)*100,bsize($fragsize),bsize($freetotal),$freeseg);\t&#125; else &#123; $frag = &quot;0%&quot;;\t&#125;\tif (graphics_avail()) &#123; $size=&#x27;width=&#x27;.(2*GRAPH_SIZE+150).&#x27; height=&#x27;.(GRAPH_SIZE+10); echo &lt;&lt;&lt;EOB &lt;img alt=&quot;&quot; $size src=&quot;$PHP_SELF?IMG=3&amp;$time&quot;&gt;EOB;\t&#125;\techo &lt;&lt;&lt;EOB &lt;/br&gt;Fragmentation: $frag &lt;/td&gt; &lt;/tr&gt;EOB; if(isset($mem[&#x27;adist&#x27;])) &#123; foreach($mem[&#x27;adist&#x27;] as $i=&gt;$v) &#123; $cur = pow(2,$i); $nxt = pow(2,$i+1)-1; if($i==0) $range = &quot;1&quot;; else $range = &quot;$cur - $nxt&quot;; echo &quot;&lt;tr&gt;&lt;th align=right&gt;$range&lt;/th&gt;&lt;td align=right&gt;$v&lt;/td&gt;&lt;/tr&gt; &quot;; &#125; &#125; echo &lt;&lt;&lt;EOB &lt;/tbody&gt;&lt;/table&gt; &lt;/div&gt;EOB; break;// -----------------------------------------------// User Cache Entries// -----------------------------------------------case OB_USER_CACHE:\tif (!$AUTHENTICATED) &#123; echo &#x27;&lt;div class=&quot;error&quot;&gt;You need to login to see the user values here!&lt;br/&gt;&amp;nbsp;&lt;br/&gt;&#x27;; put_login_link(&quot;Login now!&quot;); echo &#x27;&lt;/div&gt;&#x27;; break;\t&#125;\t$fieldname=&#x27;info&#x27;;\t$fieldheading=&#x27;User Entry Label&#x27;;\t$fieldkey=&#x27;info&#x27;;// -----------------------------------------------// System Cache Entries // -----------------------------------------------case OB_SYS_CACHE: if (!isset($fieldname))\t&#123; $fieldname=&#x27;filename&#x27;; $fieldheading=&#x27;Script Filename&#x27;; if(ini_get(&quot;apc.stat&quot;)) $fieldkey=&#x27;inode&#x27;; else $fieldkey=&#x27;filename&#x27;; &#125;\tif (!empty($MYREQUEST[&#x27;SH&#x27;]))\t&#123; echo &lt;&lt;&lt; EOB &lt;div class=&quot;info&quot;&gt;&lt;table cellspacing=0&gt;&lt;tbody&gt; &lt;tr&gt;&lt;th&gt;Attribute&lt;/th&gt;&lt;th&gt;Value&lt;/th&gt;&lt;/tr&gt;EOB; $m=0; foreach($scope_list as $j =&gt; $list) &#123; foreach($cache[$list] as $i =&gt; $entry) &#123; if (md5($entry[$fieldkey])!=$MYREQUEST[&#x27;SH&#x27;]) continue; foreach($entry as $k =&gt; $value) &#123; if (!$AUTHENTICATED) &#123; // hide all path entries if not logged in $value=preg_replace(&#x27;/^.*(\\\\/|\\\\\\\\)/&#x27;,&#x27;&lt;i&gt;&amp;lt;hidden&amp;gt;&lt;/i&gt;/&#x27;,$value); &#125; if ($k == &quot;num_hits&quot;) &#123; $value=sprintf(&quot;%s (%.2f%%)&quot;,$value,$value*100/$cache[&#x27;num_hits&#x27;]); &#125; if ($k == &#x27;deletion_time&#x27;) &#123; if(!$entry[&#x27;deletion_time&#x27;]) $value = &quot;None&quot;; &#125; echo &quot;&lt;tr class=tr-$m&gt;&quot;, &quot;&lt;td class=td-0&gt;&quot;,ucwords(preg_replace(&quot;/_/&quot;,&quot; &quot;,$k)),&quot;&lt;/td&gt;&quot;, &quot;&lt;td class=td-last&gt;&quot;,(preg_match(&quot;/time/&quot;,$k) &amp;&amp; $value!=&#x27;None&#x27;) ? date(DATE_FORMAT,$value) : htmlspecialchars($value, ENT_QUOTES, &#x27;UTF-8&#x27;),&quot;&lt;/td&gt;&quot;, &quot;&lt;/tr&gt;&quot;; $m=1-$m; &#125; if($fieldkey==&#x27;info&#x27;) &#123; echo &quot;&lt;tr class=tr-$m&gt;&lt;td class=td-0&gt;Stored Value&lt;/td&gt;&lt;td class=td-last&gt;&lt;pre&gt;&quot;; $output = var_export(apc_fetch($entry[$fieldkey]),true); echo htmlspecialchars($output, ENT_QUOTES, &#x27;UTF-8&#x27;); echo &quot;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt; &quot;; &#125; break; &#125; &#125; echo &lt;&lt;&lt;EOB &lt;/tbody&gt;&lt;/table&gt; &lt;/div&gt;EOB; break;\t&#125;\t$cols=6;\techo &lt;&lt;&lt;EOB &lt;div class=sorting&gt;&lt;form&gt;Scope: &lt;input type=hidden name=OB value=&#123;$MYREQUEST[&#x27;OB&#x27;]&#125;&gt; &lt;select name=SCOPE&gt;EOB;\techo &quot;&lt;option value=A&quot;,$MYREQUEST[&#x27;SCOPE&#x27;]==&#x27;A&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Active&lt;/option&gt;&quot;, &quot;&lt;option value=D&quot;,$MYREQUEST[&#x27;SCOPE&#x27;]==&#x27;D&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Deleted&lt;/option&gt;&quot;, &quot;&lt;/select&gt;&quot;, &quot;, Sorting:&lt;select name=SORT1&gt;&quot;, &quot;&lt;option value=H&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;H&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Hits&lt;/option&gt;&quot;, &quot;&lt;option value=Z&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;Z&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Size&lt;/option&gt;&quot;, &quot;&lt;option value=S&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;S&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;$fieldheading&lt;/option&gt;&quot;, &quot;&lt;option value=A&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;A&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Last accessed&lt;/option&gt;&quot;, &quot;&lt;option value=M&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;M&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Last modified&lt;/option&gt;&quot;, &quot;&lt;option value=C&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;C&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Created at&lt;/option&gt;&quot;, &quot;&lt;option value=D&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;D&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Deleted at&lt;/option&gt;&quot;;\tif($fieldname==&#x27;info&#x27;) echo &quot;&lt;option value=D&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;T&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Timeout&lt;/option&gt;&quot;;\techo &#x27;&lt;/select&gt;&#x27;, &#x27;&lt;select name=SORT2&gt;&#x27;, &#x27;&lt;option value=D&#x27;,$MYREQUEST[&#x27;SORT2&#x27;]==&#x27;D&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;DESC&lt;/option&gt;&#x27;, &#x27;&lt;option value=A&#x27;,$MYREQUEST[&#x27;SORT2&#x27;]==&#x27;A&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;ASC&lt;/option&gt;&#x27;, &#x27;&lt;/select&gt;&#x27;, &#x27;&lt;select name=COUNT onChange=&quot;form.submit()&quot;&gt;&#x27;, &#x27;&lt;option value=10 &#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;10&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 10&lt;/option&gt;&#x27;, &#x27;&lt;option value=20 &#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;20&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 20&lt;/option&gt;&#x27;, &#x27;&lt;option value=50 &#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;50&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 50&lt;/option&gt;&#x27;, &#x27;&lt;option value=100&#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;100&#x27;? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 100&lt;/option&gt;&#x27;, &#x27;&lt;option value=150&#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;150&#x27;? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 150&lt;/option&gt;&#x27;, &#x27;&lt;option value=200&#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;200&#x27;? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 200&lt;/option&gt;&#x27;, &#x27;&lt;option value=500&#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;500&#x27;? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 500&lt;/option&gt;&#x27;, &#x27;&lt;option value=0 &#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;0&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;All&lt;/option&gt;&#x27;, &#x27;&lt;/select&gt;&#x27;, &#x27;&amp;nbsp; Search: &lt;input name=SEARCH value=&quot;&#x27;,$MYREQUEST[&#x27;SEARCH&#x27;],&#x27;&quot; type=text size=25/&gt;&#x27;, &#x27;&amp;nbsp;&lt;input type=submit value=&quot;GO!&quot;&gt;&#x27;, &#x27;&lt;/form&gt;&lt;/div&gt;&#x27;; if (isset($MYREQUEST[&#x27;SEARCH&#x27;])) &#123; // Don&#x27;t use preg_quote because we want the user to be able to specify a // regular expression subpattern. $MYREQUEST[&#x27;SEARCH&#x27;] = &#x27;/&#x27;.str_replace(&#x27;/&#x27;, &#x27;\\\\/&#x27;, $MYREQUEST[&#x27;SEARCH&#x27;]).&#x27;/i&#x27;; if (preg_match($MYREQUEST[&#x27;SEARCH&#x27;], &#x27;test&#x27;) === false) &#123; echo &#x27;&lt;div class=&quot;error&quot;&gt;Error: enter a valid regular expression as a search query.&lt;/div&gt;&#x27;; break; &#125; &#125; echo &#x27;&lt;div class=&quot;info&quot;&gt;&lt;table cellspacing=0&gt;&lt;tbody&gt;&#x27;, &#x27;&lt;tr&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;S&#x27;,$fieldheading, &quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;H&#x27;,&#x27;Hits&#x27;, &quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;Z&#x27;,&#x27;Size&#x27;, &quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;A&#x27;,&#x27;Last accessed&#x27;,&quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;M&#x27;,&#x27;Last modified&#x27;,&quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;C&#x27;,&#x27;Created at&#x27;, &quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;;\tif($fieldname==&#x27;info&#x27;) &#123; $cols+=2; echo &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;T&#x27;,&#x27;Timeout&#x27;,&quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;;\t&#125;\techo &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;D&#x27;,&#x27;Deleted at&#x27;,&quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&lt;/tr&gt;&#x27;;\t// builds list with alpha numeric sortable keys\t//\t$list = array();\tforeach($cache[$scope_list[$MYREQUEST[&#x27;SCOPE&#x27;]]] as $i =&gt; $entry) &#123; switch($MYREQUEST[&#x27;SORT1&#x27;]) &#123; case &#x27;A&#x27;: $k=sprintf(&#x27;%015d-&#x27;,$entry[&#x27;access_time&#x27;]); break; case &#x27;H&#x27;: $k=sprintf(&#x27;%015d-&#x27;,$entry[&#x27;num_hits&#x27;]); break; case &#x27;Z&#x27;: $k=sprintf(&#x27;%015d-&#x27;,$entry[&#x27;mem_size&#x27;]); break; case &#x27;M&#x27;: $k=sprintf(&#x27;%015d-&#x27;,$entry[&#x27;mtime&#x27;]); break; case &#x27;C&#x27;: $k=sprintf(&#x27;%015d-&#x27;,$entry[&#x27;creation_time&#x27;]);\tbreak; case &#x27;T&#x27;: $k=sprintf(&#x27;%015d-&#x27;,$entry[&#x27;ttl&#x27;]); break; case &#x27;D&#x27;: $k=sprintf(&#x27;%015d-&#x27;,$entry[&#x27;deletion_time&#x27;]);\tbreak; case &#x27;S&#x27;: $k=&#x27;&#x27;; break; &#125; if (!$AUTHENTICATED) &#123; // hide all path entries if not logged in $list[$k.$entry[$fieldname]]=preg_replace(&#x27;/^.*(\\\\/|\\\\\\\\)/&#x27;,&#x27;*hidden*/&#x27;,$entry); &#125; else &#123; $list[$k.$entry[$fieldname]]=$entry; &#125;\t&#125;\tif ($list) &#123; // sort list // switch ($MYREQUEST[&#x27;SORT2&#x27;]) &#123; case &quot;A&quot;:\tkrsort($list);\tbreak; case &quot;D&quot;:\tksort($list);\tbreak; &#125; // output list $i=0; foreach($list as $k =&gt; $entry) &#123; if(!$MYREQUEST[&#x27;SEARCH&#x27;] || preg_match($MYREQUEST[&#x27;SEARCH&#x27;], $entry[$fieldname]) != 0) &#123; $field_value = htmlentities(strip_tags($entry[$fieldname],&#x27;&#x27;), ENT_QUOTES, &#x27;UTF-8&#x27;); echo &#x27;&lt;tr class=tr-&#x27;,$i%2,&#x27;&gt;&#x27;, &quot;&lt;td class=td-0&gt;&lt;a href=\\&quot;$MY_SELF&amp;OB=&quot;,$MYREQUEST[&#x27;OB&#x27;],&quot;&amp;SH=&quot;,md5($entry[$fieldkey]),&quot;\\&quot;&gt;&quot;,$field_value,&#x27;&lt;/a&gt;&lt;/td&gt;&#x27;, &#x27;&lt;td class=&quot;td-n center&quot;&gt;&#x27;,$entry[&#x27;num_hits&#x27;],&#x27;&lt;/td&gt;&#x27;, &#x27;&lt;td class=&quot;td-n right&quot;&gt;&#x27;,$entry[&#x27;mem_size&#x27;],&#x27;&lt;/td&gt;&#x27;, &#x27;&lt;td class=&quot;td-n center&quot;&gt;&#x27;,date(DATE_FORMAT,$entry[&#x27;access_time&#x27;]),&#x27;&lt;/td&gt;&#x27;, &#x27;&lt;td class=&quot;td-n center&quot;&gt;&#x27;,date(DATE_FORMAT,$entry[&#x27;mtime&#x27;]),&#x27;&lt;/td&gt;&#x27;, &#x27;&lt;td class=&quot;td-n center&quot;&gt;&#x27;,date(DATE_FORMAT,$entry[&#x27;creation_time&#x27;]),&#x27;&lt;/td&gt;&#x27;; if($fieldname==&#x27;info&#x27;) &#123; if($entry[&#x27;ttl&#x27;]) echo &#x27;&lt;td class=&quot;td-n center&quot;&gt;&#x27;.$entry[&#x27;ttl&#x27;].&#x27; seconds&lt;/td&gt;&#x27;; else echo &#x27;&lt;td class=&quot;td-n center&quot;&gt;None&lt;/td&gt;&#x27;; &#125; if ($entry[&#x27;deletion_time&#x27;]) &#123; echo &#x27;&lt;td class=&quot;td-last center&quot;&gt;&#x27;, date(DATE_FORMAT,$entry[&#x27;deletion_time&#x27;]), &#x27;&lt;/td&gt;&#x27;; &#125; else if ($MYREQUEST[&#x27;OB&#x27;] == OB_USER_CACHE) &#123; echo &#x27;&lt;td class=&quot;td-last center&quot;&gt;&#x27;; echo &#x27;[&lt;a href=&quot;&#x27;, $MY_SELF, &#x27;&amp;OB=&#x27;, $MYREQUEST[&#x27;OB&#x27;], &#x27;&amp;DU=&#x27;, urlencode($entry[$fieldkey]), &#x27;&quot;&gt;Delete Now&lt;/a&gt;]&#x27;; echo &#x27;&lt;/td&gt;&#x27;; &#125; else &#123; echo &#x27;&lt;td class=&quot;td-last center&quot;&gt; &amp;nbsp; &lt;/td&gt;&#x27;; &#125; echo &#x27;&lt;/tr&gt;&#x27;; $i++; if ($i == $MYREQUEST[&#x27;COUNT&#x27;]) break; &#125; &#125; &#125; else &#123; echo &#x27;&lt;tr class=tr-0&gt;&lt;td class=&quot;center&quot; colspan=&#x27;,$cols,&#x27;&gt;&lt;i&gt;No data&lt;/i&gt;&lt;/td&gt;&lt;/tr&gt;&#x27;;\t&#125;\techo &lt;&lt;&lt; EOB &lt;/tbody&gt;&lt;/table&gt;EOB;\tif ($list &amp;&amp; $i &lt; count($list)) &#123; echo &quot;&lt;a href=\\&quot;$MY_SELF&amp;OB=&quot;,$MYREQUEST[&#x27;OB&#x27;],&quot;&amp;COUNT=0\\&quot;&gt;&lt;i&gt;&quot;,count($list)-$i,&#x27; more available...&lt;/i&gt;&lt;/a&gt;&#x27;;\t&#125;\techo &lt;&lt;&lt; EOB &lt;/div&gt;EOB;\tbreak;// -----------------------------------------------// Per-Directory System Cache Entries// -----------------------------------------------case OB_SYS_CACHE_DIR: if (!$AUTHENTICATED) &#123; break;\t&#125;\techo &lt;&lt;&lt;EOB &lt;div class=sorting&gt;&lt;form&gt;Scope: &lt;input type=hidden name=OB value=&#123;$MYREQUEST[&#x27;OB&#x27;]&#125;&gt; &lt;select name=SCOPE&gt;EOB;\techo &quot;&lt;option value=A&quot;,$MYREQUEST[&#x27;SCOPE&#x27;]==&#x27;A&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Active&lt;/option&gt;&quot;, &quot;&lt;option value=D&quot;,$MYREQUEST[&#x27;SCOPE&#x27;]==&#x27;D&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Deleted&lt;/option&gt;&quot;, &quot;&lt;/select&gt;&quot;, &quot;, Sorting:&lt;select name=SORT1&gt;&quot;, &quot;&lt;option value=H&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;H&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Total Hits&lt;/option&gt;&quot;, &quot;&lt;option value=Z&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;Z&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Total Size&lt;/option&gt;&quot;, &quot;&lt;option value=T&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;T&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Number of Files&lt;/option&gt;&quot;, &quot;&lt;option value=S&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;S&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Directory Name&lt;/option&gt;&quot;, &quot;&lt;option value=A&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;A&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Avg. Size&lt;/option&gt;&quot;, &quot;&lt;option value=C&quot;,$MYREQUEST[&#x27;SORT1&#x27;]==&#x27;C&#x27; ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;Avg. Hits&lt;/option&gt;&quot;, &#x27;&lt;/select&gt;&#x27;, &#x27;&lt;select name=SORT2&gt;&#x27;, &#x27;&lt;option value=D&#x27;,$MYREQUEST[&#x27;SORT2&#x27;]==&#x27;D&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;DESC&lt;/option&gt;&#x27;, &#x27;&lt;option value=A&#x27;,$MYREQUEST[&#x27;SORT2&#x27;]==&#x27;A&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;ASC&lt;/option&gt;&#x27;, &#x27;&lt;/select&gt;&#x27;, &#x27;&lt;select name=COUNT onChange=&quot;form.submit()&quot;&gt;&#x27;, &#x27;&lt;option value=10 &#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;10&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 10&lt;/option&gt;&#x27;, &#x27;&lt;option value=20 &#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;20&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 20&lt;/option&gt;&#x27;, &#x27;&lt;option value=50 &#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;50&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 50&lt;/option&gt;&#x27;, &#x27;&lt;option value=100&#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;100&#x27;? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 100&lt;/option&gt;&#x27;, &#x27;&lt;option value=150&#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;150&#x27;? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 150&lt;/option&gt;&#x27;, &#x27;&lt;option value=200&#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;200&#x27;? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 200&lt;/option&gt;&#x27;, &#x27;&lt;option value=500&#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;500&#x27;? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;Top 500&lt;/option&gt;&#x27;, &#x27;&lt;option value=0 &#x27;,$MYREQUEST[&#x27;COUNT&#x27;]==&#x27;0&#x27; ? &#x27; selected&#x27;:&#x27;&#x27;,&#x27;&gt;All&lt;/option&gt;&#x27;, &#x27;&lt;/select&gt;&#x27;, &quot;, Group By Dir Level:&lt;select name=AGGR&gt;&quot;, &quot;&lt;option value=&#x27;&#x27; selected&gt;None&lt;/option&gt;&quot;; for ($i = 1; $i &lt; 10; $i++) echo &quot;&lt;option value=$i&quot;,$MYREQUEST[&#x27;AGGR&#x27;]==$i ? &quot; selected&quot;:&quot;&quot;,&quot;&gt;$i&lt;/option&gt;&quot;; echo &#x27;&lt;/select&gt;&#x27;, &#x27;&amp;nbsp;&lt;input type=submit value=&quot;GO!&quot;&gt;&#x27;, &#x27;&lt;/form&gt;&lt;/div&gt;&#x27;, &#x27;&lt;div class=&quot;info&quot;&gt;&lt;table cellspacing=0&gt;&lt;tbody&gt;&#x27;, &#x27;&lt;tr&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;S&#x27;,&#x27;Directory Name&#x27;,\t&quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;T&#x27;,&#x27;Number of Files&#x27;,&quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;H&#x27;,&#x27;Total Hits&#x27;,\t&quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;Z&#x27;,&#x27;Total Size&#x27;,\t&quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;C&#x27;,&#x27;Avg. Hits&#x27;,\t&quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;th&gt;&#x27;,sortheader(&#x27;A&#x27;,&#x27;Avg. Size&#x27;,\t&quot;&amp;OB=&quot;.$MYREQUEST[&#x27;OB&#x27;]),&#x27;&lt;/th&gt;&#x27;, &#x27;&lt;/tr&gt;&#x27;;\t// builds list with alpha numeric sortable keys\t//\t$tmp = $list = array();\tforeach($cache[$scope_list[$MYREQUEST[&#x27;SCOPE&#x27;]]] as $entry) &#123; $n = dirname($entry[&#x27;filename&#x27;]); if ($MYREQUEST[&#x27;AGGR&#x27;] &gt; 0) &#123; $n = preg_replace(&quot;!^(/?(?:[^/\\\\\\\\]+[/\\\\\\\\])&#123;&quot;.($MYREQUEST[&#x27;AGGR&#x27;]-1).&quot;&#125;[^/\\\\\\\\]*).*!&quot;, &quot;$1&quot;, $n); &#125; if (!isset($tmp[$n])) &#123; $tmp[$n] = array(&#x27;hits&#x27;=&gt;0,&#x27;size&#x27;=&gt;0,&#x27;ents&#x27;=&gt;0); &#125; $tmp[$n][&#x27;hits&#x27;] += $entry[&#x27;num_hits&#x27;]; $tmp[$n][&#x27;size&#x27;] += $entry[&#x27;mem_size&#x27;]; ++$tmp[$n][&#x27;ents&#x27;];\t&#125;\tforeach ($tmp as $k =&gt; $v) &#123; switch($MYREQUEST[&#x27;SORT1&#x27;]) &#123; case &#x27;A&#x27;: $kn=sprintf(&#x27;%015d-&#x27;,$v[&#x27;size&#x27;] / $v[&#x27;ents&#x27;]);break; case &#x27;T&#x27;: $kn=sprintf(&#x27;%015d-&#x27;,$v[&#x27;ents&#x27;]); break; case &#x27;H&#x27;: $kn=sprintf(&#x27;%015d-&#x27;,$v[&#x27;hits&#x27;]); break; case &#x27;Z&#x27;: $kn=sprintf(&#x27;%015d-&#x27;,$v[&#x27;size&#x27;]); break; case &#x27;C&#x27;: $kn=sprintf(&#x27;%015d-&#x27;,$v[&#x27;hits&#x27;] / $v[&#x27;ents&#x27;]);break; case &#x27;S&#x27;: $kn = $k; break; &#125; $list[$kn.$k] = array($k, $v[&#x27;ents&#x27;], $v[&#x27;hits&#x27;], $v[&#x27;size&#x27;]);\t&#125;\tif ($list) &#123; // sort list // switch ($MYREQUEST[&#x27;SORT2&#x27;]) &#123; case &quot;A&quot;:\tkrsort($list);\tbreak; case &quot;D&quot;:\tksort($list);\tbreak; &#125; // output list $i = 0; foreach($list as $entry) &#123; echo &#x27;&lt;tr class=tr-&#x27;,$i%2,&#x27;&gt;&#x27;, &quot;&lt;td class=td-0&gt;&quot;,$entry[0],&#x27;&lt;/a&gt;&lt;/td&gt;&#x27;, &#x27;&lt;td class=&quot;td-n center&quot;&gt;&#x27;,$entry[1],&#x27;&lt;/td&gt;&#x27;, &#x27;&lt;td class=&quot;td-n center&quot;&gt;&#x27;,$entry[2],&#x27;&lt;/td&gt;&#x27;, &#x27;&lt;td class=&quot;td-n center&quot;&gt;&#x27;,$entry[3],&#x27;&lt;/td&gt;&#x27;, &#x27;&lt;td class=&quot;td-n center&quot;&gt;&#x27;,round($entry[2] / $entry[1]),&#x27;&lt;/td&gt;&#x27;, &#x27;&lt;td class=&quot;td-n center&quot;&gt;&#x27;,round($entry[3] / $entry[1]),&#x27;&lt;/td&gt;&#x27;, &#x27;&lt;/tr&gt;&#x27;; if (++$i == $MYREQUEST[&#x27;COUNT&#x27;]) break; &#125; &#125; else &#123; echo &#x27;&lt;tr class=tr-0&gt;&lt;td class=&quot;center&quot; colspan=6&gt;&lt;i&gt;No data&lt;/i&gt;&lt;/td&gt;&lt;/tr&gt;&#x27;;\t&#125;\techo &lt;&lt;&lt; EOB &lt;/tbody&gt;&lt;/table&gt;EOB;\tif ($list &amp;&amp; $i &lt; count($list)) &#123; echo &quot;&lt;a href=\\&quot;$MY_SELF&amp;OB=&quot;,$MYREQUEST[&#x27;OB&#x27;],&quot;&amp;COUNT=0\\&quot;&gt;&lt;i&gt;&quot;,count($list)-$i,&#x27; more available...&lt;/i&gt;&lt;/a&gt;&#x27;;\t&#125;\techo &lt;&lt;&lt; EOB &lt;/div&gt;EOB;\tbreak;// -----------------------------------------------// Version check// -----------------------------------------------case OB_VERSION_CHECK:\techo &lt;&lt;&lt;EOB &lt;div class=&quot;info&quot;&gt;&lt;h2&gt;APC Version Information&lt;/h2&gt; &lt;table cellspacing=0&gt;&lt;tbody&gt; &lt;tr&gt; &lt;th&gt;&lt;/th&gt; &lt;/tr&gt;EOB; if (defined(&#x27;PROXY&#x27;)) &#123; $ctxt = stream_context_create( array( &#x27;http&#x27; =&gt; array( &#x27;proxy&#x27; =&gt; PROXY, &#x27;request_fulluri&#x27; =&gt; True ) ) ); $rss = @file_get_contents(&quot;http://pecl.php.net/feeds/pkg_apc.rss&quot;, False, $ctxt); &#125; else &#123; $rss = @file_get_contents(&quot;http://pecl.php.net/feeds/pkg_apc.rss&quot;); &#125;\tif (!$rss) &#123; echo &#x27;&lt;tr class=&quot;td-last center&quot;&gt;&lt;td&gt;Unable to fetch version information.&lt;/td&gt;&lt;/tr&gt;&#x27;;\t&#125; else &#123; $apcversion = phpversion(&#x27;apc&#x27;); preg_match(&#x27;!&lt;title&gt;APC ([0-9.]+)&lt;/title&gt;!&#x27;, $rss, $match); echo &#x27;&lt;tr class=&quot;tr-0 center&quot;&gt;&lt;td&gt;&#x27;; if (version_compare($apcversion, $match[1], &#x27;&gt;=&#x27;)) &#123; echo &#x27;&lt;div class=&quot;ok&quot;&gt;You are running the latest version of APC (&#x27;.$apcversion.&#x27;)&lt;/div&gt;&#x27;; $i = 3; &#125; else &#123; echo &#x27;&lt;div class=&quot;failed&quot;&gt;You are running an older version of APC (&#x27;.$apcversion.&#x27;), newer version &#x27;.$match[1].&#x27; is available at &lt;a href=&quot;http://pecl.php.net/package/APC/&#x27;.$match[1].&#x27;&quot;&gt; http://pecl.php.net/package/APC/&#x27;.$match[1].&#x27;&lt;/a&gt; &lt;/div&gt;&#x27;; $i = -1; &#125; echo &#x27;&lt;/td&gt;&lt;/tr&gt;&#x27;; echo &#x27;&lt;tr class=&quot;tr-0&quot;&gt;&lt;td&gt;&lt;h3&gt;Change Log:&lt;/h3&gt;&lt;br/&gt;&#x27;; preg_match_all(&#x27;!&lt;(title|description)&gt;([^&lt;]+)&lt;/\\\\1&gt;!&#x27;, $rss, $match); next($match[2]); next($match[2]); while (list(,$v) = each($match[2])) &#123; list(,$ver) = explode(&#x27; &#x27;, $v, 2); if ($i &lt; 0 &amp;&amp; version_compare($apcversion, $ver, &#x27;&gt;=&#x27;)) &#123; break; &#125; else if (!$i--) &#123; break; &#125; echo &quot;&lt;b&gt;&lt;a href=\\&quot;http://pecl.php.net/package/APC/$ver\\&quot;&gt;&quot;.htmlspecialchars($v, ENT_QUOTES, &#x27;UTF-8&#x27;).&quot;&lt;/a&gt;&lt;/b&gt;&lt;br&gt;&lt;blockquote&gt;&quot;; echo nl2br(htmlspecialchars(current($match[2]), ENT_QUOTES, &#x27;UTF-8&#x27;)).&quot;&lt;/blockquote&gt;&quot;; next($match[2]); &#125; echo &#x27;&lt;/td&gt;&lt;/tr&gt;&#x27;;\t&#125;\techo &lt;&lt;&lt; EOB &lt;/tbody&gt;&lt;/table&gt; &lt;/div&gt;EOB;\tbreak;&#125;echo &lt;&lt;&lt; EOB\t&lt;/div&gt;EOB;?&gt;&lt;!-- &lt;?php echo &quot; Based on APCGUI By R.Becker $VERSION &quot;?&gt; --&gt;&lt;/body&gt;&lt;/html&gt;","categories":["Linux配置文件","lamp"]},{"title":"lamp_32.sh","path":"/2023/09/28/Linux配置文件/lamp/lamp_32.sh/","content":"#!&#x2F;bin&#x2F;bashecho “Renew the sources for yum,please wait…”sleep 2#cd &#x2F;etc&#x2F;yum.repos.d &amp;&amp; mv CentOS-Base.repo CentOS-Base.repo.bak &amp;&amp; wget http://mirrors.163.com/.help/CentOS-Base-163.repo#echo “First,Update the system,Please wait…”#yum -y updateecho “Now,install dependent libraries.Please waiting…”sleep 2yum -y install gcc gcc-c++ libtool ncurses ncurses-devel openssl openssl-devel curl curl-devel readline readline-devel bzip2 bzip2-devel fontconfig-devel sqlite sqlite-devel zlib zlib-develsourcedir&#x3D;”&#x2F;usr&#x2F;local&#x2F;src&#x2F;lnmp&#x2F;“ [ “$PWD” !&#x3D; “$sourcedir” ] &amp;&amp; cd $sourcedir echo “Start the installation of libxml2…”sleep 2#tar zxvf libxml2-2.7.6.tar.gz &amp;&amp; cd libxml2-2.7.6#ע�͵�configure�ļ��е�ĳ�У������&#x2F;bin&#x2F;rm: cannot remove &#96;libtoolT��: No such file or directory ��#.&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1 #echo ‘OK,libxml2-2.7.6 has been successfully installed!’##########################cd ..echo “Start the installation of libiconv…”sleep 2tar zxvf libiconv-1.14.tar.gz &amp;&amp; cd libiconv-1.14 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libiconv-1.14 has been successfully installed!’ cd ..echo “Start the installation of libxslt…”sleep 2tar zxvf libxslt-1.1.28.tar.gz &amp;&amp; cd libxslt-1.1.28 || exit 1#ע�͵�configure�ļ��е�ĳ�У������&#x2F;bin&#x2F;rm: cannot remove &#96;libtoolT��: No such file or directory ��sed -i ‘&#x2F;$RM “$cfgfile”&#x2F; s&#x2F;^&#x2F;#&#x2F;‘ configure.&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libxslt-1.1.26 has been successfully installed!’ cd ..echo “Start the installation of libmcrypt…”sleep 2tar zxvf libmcrypt-2.5.8.tar.gz &amp;&amp; cd libmcrypt-2.5.8 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libmcrypt-2.5.8 has been successfully installed!’ echo “Start the installation of libltdl…”sleep 2cd libltdl &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F; –enable-ltdl-install &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libltdl has been successfully installed!’ cd ..&#x2F;..&#x2F;echo “Start the installation of mhash…”sleep 2tar jxvf mhash-0.9.9.9.tar.bz2 &amp;&amp; cd mhash-0.9.9.9 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,mhash-0.9.9.9 has been successfully installed!’ echo “&#x2F;usr&#x2F;local&#x2F;lib” &gt;&gt; &#x2F;etc&#x2F;ld.so.confldconfig cd ..echo “Start the installation of mcrypt…”sleep 2tar zxvf mcrypt-2.6.8.tar.gz &amp;&amp; cd mcrypt-2.6.8 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,mcrypt-2.6.8 has been successfully installed!’ cd ..echo “Start the installation of libevent…”sleep 2tar zxvf libevent-2.0.21-stable.tar.gz &amp;&amp; cd libevent-2.0.19-stable &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libevent-2.0.21 has been successfully installed!’ cd ..echo “Start the installation of libpng…”sleep 2tar zxvf libpng-1.6.2.tar.gz &amp;&amp; cd libpng-1.6.2 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libpng-1.6.2 has been successfully installed!’ cd ..echo “Start the installation of jpeg…”sleep 2tar zxvf jpegsrc.v9.tar.gz &amp;&amp; cd jpeg-9 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –enable-shared –enable-static &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,jpeg-v9 has been successfully installed!’ cd ..echo “Start the installation of freetype…”sleep 2tar zxvf freetype-2.4.12.tar.gz &amp;&amp; cd freetype-2.4.12 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,freetype-2.4.12 has been successfully installed!’ cd ..echo “Start the installation of gd2…”sleep 2tar zxvf gd-2.0.35.tar.gz &amp;&amp; cd gd&#x2F;2.0.35 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-zlib –with-png –with-jpeg&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-freetype&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,gd-2.0.35 has been successfully installed!’ cd ..&#x2F;..&#x2F;echo “Start the installation of cmake…”sleep 2tar zxvf cmake-2.8.11.2.tar.gz &amp;&amp; cd cmake-2.8.11.2 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,cmake-2.8.11has been successfully installed!’ cd ..echo “Start the installation of mysql…”sleep 2 tar zxvf mysql-5.6.12.tar.gz &amp;&amp; cd mysql-5.6.12 &amp;&amp; cmake . -DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F; -DMYSQL_DATADIR&#x3D;&#x2F;data&#x2F;mysql&#x2F;data -DWITH_INNOBASE_STORAGE_ENGINE&#x3D;1 -DWITH_MYISAM_STORAGE_ENGINE&#x3D;1 -DWITH_MEMORY_STORAGE_ENGINE&#x3D;1 -DENABLED_LOCAL_INFILE&#x3D;1 -DMYSQL_TCP_PORT&#x3D;3306 -DEXTRA_CHARSETS&#x3D;all -DDEFAULT_CHARSET&#x3D;utf8 -DDEFAULT_COLLATION&#x3D;utf8_general_ci -DWITH_PARTITION_STORAGE_ENGINE&#x3D;1 -DMYSQL_UNIX_ADDR&#x3D;&#x2F;tmp&#x2F;mysql.sock -DWITH_DEBUG&#x3D;0 -DWITH_SSL&#x3D;yes -DSYSCONFDIR&#x3D;&#x2F;data&#x2F;mysql -DMYSQL_TCP_PORT&#x3D;3306 &amp;&amp; make &amp;&amp; make install || exit 1 echo ‘OK,MySQL-5.6.12 has been successfully installed!’sleep 2echo “Prepare for start MySQL,Please wait….”sleep 2useradd -s &#x2F;sbin&#x2F;nologin wwwuseradd -s &#x2F;sbin&#x2F;nologin mysqlmkdir -p &#x2F;data&#x2F;mysql&#x2F;{data,binlog,relaylog}chown -R mysql:mysql &#x2F;data&#x2F;mysqltouch &#x2F;data&#x2F;mysql&#x2F;my.cnfecho -ne “[client] default-character-set&#x3D;gbk port &#x3D; 3306 socket &#x3D; &#x2F;tmp&#x2F;mysql.sock [mysqld] character-set-server &#x3D; gbk collation-server &#x3D; gbk_chinese_ci #replicate-ignore-db &#x3D; mysql #replicate-ignore-db &#x3D; test #replicate-ignore-db &#x3D; information_schema user &#x3D; mysql port &#x3D; 3306 socket &#x3D; &#x2F;tmp&#x2F;mysql.sock basedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql datadir &#x3D; &#x2F;data&#x2F;mysql&#x2F;data explicit_defaults_for_timestamp&#x3D;true log-error &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql_error.log pid-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql.pid open_files_limit &#x3D; 10240 back_log &#x3D; 600 max_connections &#x3D; 5000 max_connect_errors &#x3D; 6000 table_cache &#x3D; 614 external-locking &#x3D; FALSE max_allowed_packet &#x3D; 32M sort_buffer_size &#x3D; 1M join_buffer_size &#x3D; 1M thread_cache_size &#x3D; 300 thread_concurrency &#x3D; 8 query_cache_size &#x3D; 512M query_cache_limit &#x3D; 2M query_cache_min_res_unit &#x3D; 2k default-storage-engine &#x3D; MyISAM thread_stack &#x3D; 192K transaction_isolation &#x3D; READ-COMMITTED tmp_table_size &#x3D; 246M max_heap_table_size &#x3D; 246M long_query_time &#x3D; 3 log-slave-updates log-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;binlog&#x2F;binlog binlog_cache_size &#x3D; 4M binlog_format &#x3D; MIXED max_binlog_cache_size &#x3D; 8M max_binlog_size &#x3D; 1G expire-logs-days &#x3D; 30 relay-log-index &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog relay-log-info-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog relay-log &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog expire_logs_days &#x3D; 30 key_buffer_size &#x3D; 256M read_buffer_size &#x3D; 1M read_rnd_buffer_size &#x3D; 16M bulk_insert_buffer_size &#x3D; 64M myisam_sort_buffer_size &#x3D; 128M myisam_max_sort_file_size &#x3D; 10G myisam_repair_threads &#x3D; 1 ;myisam_recover interactive_timeout &#x3D; 120 wait_timeout &#x3D; 120 skip-name-resolve slave-skip-errors &#x3D; 1032,1062,126,1114,1146,1048,1396 server-id &#x3D; 1 ;innodb_additional_mem_pool_size &#x3D; 16M ;innodb_buffer_pool_size &#x3D; 512M ;innodb_data_file_path &#x3D; ibdata1:256M:autoextend ;innodb_file_io_threads &#x3D; 4 ;innodb_thread_concurrency &#x3D; 8 ;innodb_flush_log_at_trx_commit &#x3D; 2 ;innodb_log_buffer_size &#x3D; 16M ;innodb_log_file_size &#x3D; 128M ;innodb_log_files_in_group &#x3D; 3 ;innodb_max_dirty_pages_pct &#x3D; 90 ;innodb_lock_wait_timeout &#x3D; 120 ;innodb_file_per_table &#x3D; 0 slow_query_log slow_query_log_file &#x3D; &#x2F;data&#x2F;mysql&#x2F;slow.log long_query_time &#x3D; 1 log-queries-not-using-indexes [mysqldump] quick max_allowed_packet &#x3D; 32M ” &gt;&gt; &#x2F;data&#x2F;mysql&#x2F;my.cnfln -s &#x2F;data&#x2F;mysql&#x2F;my.cnf &#x2F;etc&#x2F;my.cnfcp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysql* &#x2F;usr&#x2F;bin&#x2F; &amp;&amp; cp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;support-files&#x2F;mysql.server &#x2F;etc&#x2F;init.d&#x2F;mysqld &amp;&amp; chmod +x &#x2F;etc&#x2F;init.d&#x2F;mysqld || exit 1&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;scripts&#x2F;mysql_install_db –user&#x3D;mysql –basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysqlmysqld_safe –user&#x3D;mysql &amp;killall mysqldservice mysqld start #Apachecd ..echo “Start the installation of Apache…”sleep 2#apr tar jxvf apr-1.4.8.tar.bz2 $$ cd apr-1.4.8#ע�͵�configure�ļ��е�ĳ�У������&#x2F;bin&#x2F;rm: cannot remove &#96;libtoolT��: No such file or directory ��sed -i ‘&#x2F;$RM “$cfgfile”&#x2F; s&#x2F;^&#x2F;#&#x2F;‘ configure.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr &amp;&amp; make &amp;&amp; make install || exit 1cd ..#apr-utiltar jxvf apr-util-1.5.2.tar.bz2 &amp;&amp; cd tar jxvf apr-util-1.5.2.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F;bin&#x2F;apr-1-config &amp;&amp; make &amp;&amp; make install || exit 1#pcrecd ..echo “Start the installation of pcre…”tar jxvf pcre-8.33.tar.bz2 &amp;&amp; cd pcre-8.33.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,pcre-8.33 has been successfully installed!’cd .. sleep 2tar zxvf httpd-2.4.6.tar.gz &amp;&amp; cd httpd-2.4.6 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2 –sysconfdir&#x3D;&#x2F;etc&#x2F;httpd –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F;bin&#x2F;apr-1-config –with-apr-util&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util&#x2F;bin&#x2F;apu-1-config –with-pcre&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre&#x2F; –enable-mods-shared&#x3D;most –enable-rewirte –enable-so –enable-ssl&#x3D;static –with-ssl –enable-proxy&#x3D;shared –enable-proxy-balancer&#x3D;shared –enable-proxy-http&#x3D;shared –enable-cache –enable-disk-cache –enable-mem-cache –enable-file-cache &amp;&amp; make &amp;&amp; make install || exit 1if [ ! -d &#x2F;data&#x2F;logs ];thenmkdir -p &#x2F;data&#x2F;logs&#x2F;{error,access} #apache��־���Ŀ¼fiecho “OK,apache-2.4.6 has been successfully installed!”sleep 2#����PHP�汾�Ըýű����ʵ��޸�#PHP-5.3.27cd ..echo “Start the installation of php…”sleep 2 tar zxvf php-5.3.27.tar.gz &amp;&amp; cd php-5.3.27 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;php –with-config-file-path&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;etc –with-apxs2&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;apxs –with-libxml-dir –with-iconv-dir –with-png-dir –with-jpeg-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-zlib –with-gd&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-freetype-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype –with-mcrypt –with-mhash –enable-gd-native-ttf –with-readline –with-curl –with-bz2 –with-mysql&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql –with-mysqli&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysql_config –with-openssl-dir –without-pear –enable-mbstring –enable-soap –enable-xml –enable-pdo –enable-ftp –enable-zip –enable-bcmath &amp;&amp; make &amp;&amp; make install || exit 1if [ ! -d &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc ];thenmkdir &#x2F;usr&#x2F;local&#x2F;php&#x2F;etcficp ..&#x2F;php.ini &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F; &amp;&amp; mkdir &#x2F;usr&#x2F;local&#x2F;php&#x2F;extmkdir -p &#x2F;data&#x2F;logs&#x2F;php #��־���Ŀ¼echo ‘OK,PHP-5.3.27 has been successfully installed!’sleep 2 cd ..echo “Start install memcache extension…”#���php�汾Ϊ5.2����memcacheʹ��2.2.6�汾���������汾���⵼��php�޷�����memcachģ�顣sleep 2tar zxvf memcache-3.0.6.tgz &amp;&amp; cd memcache-3.0.6 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –enable-memcache –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;memcache.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;echo “OK,Memcache-3.0.6 installed successfully!”sleep 2 #cd ..#echo “Start install ImageMagick…”#sleep 2#tar zxvf ImageMagick-6.6.9-10.tar.gz &amp;&amp; cd ImageMagick-6.6.9-10 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;imagemagick &amp;&amp; make &amp;&amp; make install || exit 1#echo “&#x2F;usr&#x2F;local&#x2F;imagemagick&#x2F;lib” &gt;&gt; &#x2F;etc&#x2F;ld.so.conf &amp;&amp; ldconfig#echo “OK,ImageMagick-6.6.9-10 has been installed successfully!”#sleep 2 #cd ..#echo “Start install imagick for php …”#tar zxvf imagick-3.0.1.tgz &amp;&amp; cd imagick-3.0.1 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –with-imagick&#x3D;&#x2F;usr&#x2F;local&#x2F;imagemagick –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1#cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20060613&#x2F;imagick.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;#echo “OK,imagick-3.0.1 for php has been installed successfully!”#sleep 2 cd ..echo “Start install PDO_MYSQL …”tar zxvf PDO_MYSQL-1.0.2.tgz &amp;&amp; cd PDO_MYSQL-1.0.2 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config –with-pdo-mysql&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql &amp;&amp; make &amp;&amp; make install || exit 1cp modules&#x2F;pdo_mysql.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;echo “OK,PDO_MYSQL-1.0.2 has been installed successfully!”sleep 2 cd ..echo “Start install APC …”tar zxvf APC-3.1.9.tgz &amp;&amp; cd APC-3.1.9&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize.&#x2F;configure –enable-apc –with-apc-mmap –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make installcp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;apc.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;#echo -ne “[APC] extension &#x3D; &quot;apc.so&quot; apc.enabled &#x3D; 1 apc.cache_by_default &#x3D; on apc.shm_size &#x3D; 32M apc.ttl &#x3D; 600 apc.user_ttl &#x3D; 600 apc.write_lock &#x3D; on” &gt;&gt; &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php.iniecho -ne “APC-3.1.9 has been installed successfully!”cd ..sleep 2 #httpd auto runingcp &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;apachectl &#x2F;etc&#x2F;init.d&#x2F;httpdsed -i ‘2a # chkconfig: 2345 65 37\\ description: apache service manager.’ &#x2F;etc&#x2F;init.d&#x2F;httpdchkconfig –level 3 httpd on #http_confmv &#x2F;etc&#x2F;httpd&#x2F;httpd.conf &#x2F;etc&#x2F;httpd&#x2F;httpd.conf.defaultmv &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-default.conf &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-default.conf.defaultmv &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-vhosts.conf &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-vhosts.conf.defaultmv &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-mpm.conf &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-mpm.conf.defaultcp http-conf&#x2F;httpd.conf &#x2F;etc&#x2F;httpd&#x2F;cp http-conf&#x2F;extra&#x2F;* &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F; #apache_cutlogtar zxvf cronolog-1.6.2.tar.gz &amp;&amp; cd cronolog-1.6.2 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1 cd ..#ulimitsed -i ‘$i * - nofile 65535\\ soft core 0\\ hard core 0&#39; /etc/security/limits.conf #sysctl.confcat sysctl.conf &gt;&gt; &#x2F;etc&#x2F;sysctl.conf &amp;&amp; sysctl -p #history��������ʱ��sed -i ‘&#x2F;HISTSIZE&#x2F;a HISTTIMEFORMAT&#x3D;”%Y%m%d-%H%M%S:”‘ &#x2F;etc&#x2F;profilesed -i ‘&#x2F;export&#x2F; s&#x2F;$&#x2F; HISTTIMEFORMAT&#x2F;‘ &#x2F;etc&#x2F;profile #su&#x2F;sudo#��wheel���Ա����ʹ��sused -i ‘&#x2F;required&#x2F; s&#x2F;^#&#x2F;&#x2F;‘ &#x2F;etc&#x2F;pam.d&#x2F;suecho “SU_WHEEL_ONLY yes” &gt;&gt; &#x2F;etc&#x2F;login.defs #sudo#Cmnd_Alias MANAGER &#x3D; &#x2F;sbin&#x2F;route, &#x2F;sbin&#x2F;ifconfig, &#x2F;bin&#x2F;ping, &#x2F;sbin&#x2F;iptables, &#x2F;sbin&#x2F;service, &#x2F;sbin&#x2F;chkconfig, &#x2F;bin&#x2F;chmod, &#x2F;bin&#x2F;chown, &#x2F;bin&#x2F;chgrp#User_Alias ADMINS &#x3D; #root ALL&#x3D;(ALL) ALL#ADMINS ALL&#x3D;(ALL) MANAGER #document_rootif [ ! -d &#x2F;data&#x2F;www ];thenmkdir -p &#x2F;data&#x2F;wwwfichown www:www &#x2F;data&#x2F;www &amp;&amp; touch &#x2F;data&#x2F;www&#x2F;index.php &amp;&amp; echo -ne ‘‘ &gt; &#x2F;data&#x2F;www&#x2F;index.phpsleep 2 echo -ne “OK,That is all,Thanks for using,Bye! ”#10��֮������for i in $(seq 10| tac)do echo -ne “\\aThe system will reboot after $i seconds…\\r” sleep 1doneechoshutdown -r now","categories":["Linux配置文件","lamp"]},{"title":"mysql.user.sql","path":"/2023/09/28/Linux配置文件/lamp/mysql.user.sql/","content":"title: mysql.user.sqldate: 2023-09-28 02:33:14tags:categories: [Linux配置文件, lamp]– MySQL dump 10.13 Distrib 5.5.27, for Linux (i686)– Host: localhost Database: mysql – Server version\t5.5.27-log &#x2F;*!40101 SET @OLD_CHARACTER_SET_CLIENT&#x3D;@@CHARACTER_SET_CLIENT &#x2F;;&#x2F;!40101 SET @OLD_CHARACTER_SET_RESULTS&#x3D;@@CHARACTER_SET_RESULTS &#x2F;;&#x2F;!40101 SET @OLD_COLLATION_CONNECTION&#x3D;@@COLLATION_CONNECTION &#x2F;;&#x2F;!40101 SET NAMES gbk &#x2F;;&#x2F;!40103 SET @OLD_TIME_ZONE&#x3D;@@TIME_ZONE &#x2F;;&#x2F;!40103 SET TIME_ZONE&#x3D;’+00:00’ &#x2F;;&#x2F;!40014 SET @OLD_UNIQUE_CHECKS&#x3D;@@UNIQUE_CHECKS, UNIQUE_CHECKS&#x3D;0 &#x2F;;&#x2F;!40014 SET @OLD_FOREIGN_KEY_CHECKS&#x3D;@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS&#x3D;0 &#x2F;;&#x2F;!40101 SET @OLD_SQL_MODE&#x3D;@@SQL_MODE, SQL_MODE&#x3D;’NO_AUTO_VALUE_ON_ZERO’ &#x2F;;&#x2F;!40111 SET @OLD_SQL_NOTES&#x3D;@@SQL_NOTES, SQL_NOTES&#x3D;0 *&#x2F;; –– Table structure for table userDROP TABLE IF EXISTS user;&#x2F;*!40101 SET @saved_cs_client &#x3D; @@character_set_client &#x2F;;&#x2F;!40101 SET character_set_client &#x3D; utf8 &#x2F;;CREATE TABLE user ( Host char(60) COLLATE utf8_bin NOT NULL DEFAULT ‘’, User char(16) COLLATE utf8_bin NOT NULL DEFAULT ‘’, Password char(41) CHARACTER SET latin1 COLLATE latin1_bin NOT NULL DEFAULT ‘’, Select_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Insert_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Update_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Delete_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Drop_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Reload_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Shutdown_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Process_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, File_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Grant_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, References_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Index_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Alter_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Show_db_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Super_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_tmp_table_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Lock_tables_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Execute_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Repl_slave_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Repl_client_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_view_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Show_view_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_routine_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Alter_routine_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_user_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Event_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Trigger_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, Create_tablespace_priv enum(‘N’,’Y’) CHARACTER SET utf8 NOT NULL DEFAULT ‘N’, ssl_type enum(‘’,’ANY’,’X509’,’SPECIFIED’) CHARACTER SET utf8 NOT NULL DEFAULT ‘’, ssl_cipher blob NOT NULL, x509_issuer blob NOT NULL, x509_subject blob NOT NULL, max_questions int(11) unsigned NOT NULL DEFAULT ‘0’, max_updates int(11) unsigned NOT NULL DEFAULT ‘0’, max_connections int(11) unsigned NOT NULL DEFAULT ‘0’, max_user_connections int(11) unsigned NOT NULL DEFAULT ‘0’, plugin char(64) COLLATE utf8_bin DEFAULT ‘’, authentication_string text COLLATE utf8_bin, PRIMARY KEY (Host,User)) ENGINE&#x3D;MyISAM DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;’Users and global privileges’;&#x2F;!40101 SET character_set_client &#x3D; @saved_cs_client *&#x2F;; –– Dumping data for table userLOCK TABLES user WRITE;&#x2F;*!40000 ALTER TABLE user DISABLE KEYS *&#x2F;;INSERT INTO user VALUES (‘localhost’,’root’,’897F89E43B915C47FA5769CDD90A24AF32CE733A’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’Y’,’’,’’,’’,’’,0,0,0,0,’’,’’);&#x2F;!40000 ALTER TABLE user ENABLE KEYS &#x2F;;UNLOCK TABLES;&#x2F;!40103 SET TIME_ZONE&#x3D;@OLD_TIME_ZONE *&#x2F;; &#x2F;*!40101 SET SQL_MODE&#x3D;@OLD_SQL_MODE &#x2F;;&#x2F;!40014 SET FOREIGN_KEY_CHECKS&#x3D;@OLD_FOREIGN_KEY_CHECKS &#x2F;;&#x2F;!40014 SET UNIQUE_CHECKS&#x3D;@OLD_UNIQUE_CHECKS &#x2F;;&#x2F;!40101 SET CHARACTER_SET_CLIENT&#x3D;@OLD_CHARACTER_SET_CLIENT &#x2F;;&#x2F;!40101 SET CHARACTER_SET_RESULTS&#x3D;@OLD_CHARACTER_SET_RESULTS &#x2F;;&#x2F;!40101 SET COLLATION_CONNECTION&#x3D;@OLD_COLLATION_CONNECTION &#x2F;;&#x2F;!40111 SET SQL_NOTES&#x3D;@OLD_SQL_NOTES *&#x2F;; – Dump completed on 2012-09-05 5:57:21","categories":["Linux配置文件","lamp"]},{"title":"lamp_64.sh","path":"/2023/09/28/Linux配置文件/lamp/lamp_64.sh/","content":"title: lamp_64.shdate: 2023-09-28 02:33:14tags:categories: [Linux配置文件, lamp]#!&#x2F;bin&#x2F;bashecho “Renew the sources for yum,please wait…”sleep 2cd &#x2F;etc&#x2F;yum.repos.d &amp;&amp; mv CentOS-Base.repo CentOS-Base.repo.bak &amp;&amp; wget http://mirrors.163.com/.help/CentOS-Base-163.repoecho “First,Update the system,Please wait…”yum -y updateecho “Now,install dependent libraries.Please waiting…”sleep 2yum -y install gcc gcc-c++ libtool ncurses ncurses-devel openssl openssl-devel curl curl-devel readline readline-devel bzip2 bzip2-devel fontconfig-devel sqlite sqlite-devel zlib zlib-devel#ncurses openssl为编译mysql5必须sourcedir&#x3D;”&#x2F;usr&#x2F;local&#x2F;src&#x2F;lnmp&#x2F;“ [ “$PWD” !&#x3D; “$sourcedir” ] &amp;&amp; cd $sourcedir echo “Start the installation of libxml2…”sleep 2tar zxvf libxml2-2.7.6.tar.gz &amp;&amp; cd libxml2-2.7.6#注释掉configure文件中的某行，解决“&#x2F;bin&#x2F;rm: cannot remove &#96;libtoolT’: No such file or directory ”sed -i ‘&#x2F;$RM “$cfgfile”&#x2F; s&#x2F;^&#x2F;#&#x2F;‘ configure.&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1 #下边的操作将解决PHP等安装过程中提示libxml2.so.2版本有误、libxml找不到及找不到libpng14.so.14的问题。if [ -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so ];thenrm -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so &amp;&amp; ln -s &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.7.6 &#x2F;usr&#x2F;lib&#x2F;libxml2.sofiif [ -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2 ];thenrm -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2 &amp;&amp; ln -s &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.7.6 &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2fiif [ -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.6.26 ];thenrm -f &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.6.26fiif [ -f &#x2F;usr&#x2F;lib64&#x2F;libxml2.so ];thenrm -f &#x2F;usr&#x2F;lib64&#x2F;libxml2.sofiif [ -f &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2 ];thenrm -f &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2ficp &#x2F;usr&#x2F;lib&#x2F;libxml2.so.2.7.6 &#x2F;usr&#x2F;lib64 &amp;&amp; ln -s &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2.7.6 &#x2F;usr&#x2F;lib64&#x2F;libxml2.so &amp;&amp; ln -s &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2.7.6 &#x2F;usr&#x2F;lib64&#x2F;libxml2.so.2 echo “&#x2F;usr&#x2F;lib64” &gt;&gt; &#x2F;etc&#x2F;ld.so.confldconfig echo ‘OK,libxml2-2.7.6 has been successfully installed!’##########################cd ..echo “Start the installation of libiconv…”sleep 2tar zxvf libiconv-1.14.tar.gz &amp;&amp; cd libiconv-1.14 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libiconv-1.14 has been successfully installed!’ cd ..echo “Start the installation of libxslt…”sleep 2tar zxvf libxslt-1.1.28.tar.gz &amp;&amp; cd libxslt-1.1.28 || exit 1#注释掉configure文件中的某行，解决“&#x2F;bin&#x2F;rm: cannot remove &#96;libtoolT’: No such file or directory ”sed -i ‘&#x2F;$RM “$cfgfile”&#x2F; s&#x2F;^&#x2F;#&#x2F;‘ configure.&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libxslt-1.1.26 has been successfully installed!’ cd ..echo “Start the installation of libmcrypt…”sleep 2tar zxvf libmcrypt-2.5.8.tar.gz &amp;&amp; cd libmcrypt-2.5.8 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libmcrypt-2.5.8 has been successfully installed!’ echo “Start the installation of libltdl…”sleep 2cd libltdl &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F; –enable-ltdl-install &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libltdl has been successfully installed!’ cd ..&#x2F;..&#x2F;echo “Start the installation of mhash…”sleep 2tar jxvf mhash-0.9.9.9.tar.bz2 &amp;&amp; cd mhash-0.9.9.9 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,mhash-0.9.9.9 has been successfully installed!’ echo “&#x2F;usr&#x2F;local&#x2F;lib” &gt;&gt; &#x2F;etc&#x2F;ld.so.confldconfig cd ..echo “Start the installation of mcrypt…”sleep 2tar zxvf mcrypt-2.6.8.tar.gz &amp;&amp; cd mcrypt-2.6.8 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,mcrypt-2.6.8 has been successfully installed!’ cd ..echo “Start the installation of libevent…”sleep 2tar zxvf libevent-2.0.21-stable.tar.gz &amp;&amp; cd libevent-2.0.19-stable &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,libevent-2.0.21 has been successfully installed!’ cd ..echo “Start the installation of libpng…”sleep 2tar zxvf libpng-1.6.2.tar.gz &amp;&amp; cd libpng-1.6.2 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1#ln -s &#x2F;usr&#x2F;lib&#x2F;libpng15.so.15.12.0 &#x2F;usr&#x2F;lib64&#x2F;libpng15.so.15echo ‘OK,libpng-1.6.2 has been successfully installed!’ cd ..echo “Start the installation of jpeg…”sleep 2tar zxvf jpegsrc.v9.tar.gz &amp;&amp; cd jpeg-9 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –enable-shared –enable-static &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,jpeg-v9 has been successfully installed!’ cd ..echo “Start the installation of freetype…”sleep 2tar zxvf freetype-2.4.12.tar.gz &amp;&amp; cd freetype-2.4.12 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,freetype-2.4.12 has been successfully installed!’ cd ..echo “Start the installation of gd2…”sleep 2tar zxvf gd-2.0.35.tar.gz &amp;&amp; cd gd&#x2F;2.0.35 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-zlib –with-png –with-jpeg&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-freetype&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,gd-2.0.35 has been successfully installed!’ cd ..&#x2F;..&#x2F;echo “Start the installation of cmake…”sleep 2tar zxvf cmake-2.8.11.2.tar.gz &amp;&amp; cd cmake-2.8.11.2 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,cmake-2.8.11has been successfully installed!’ cd ..echo “Start the installation of mysql…”sleep 2 tar zxvf mysql-5.6.12.tar.gz &amp;&amp; cd mysql-5.6.12 &amp;&amp; cmake . -DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F; -DMYSQL_DATADIR&#x3D;&#x2F;data&#x2F;mysql&#x2F;data -DWITH_INNOBASE_STORAGE_ENGINE&#x3D;1 -DWITH_MYISAM_STORAGE_ENGINE&#x3D;1 -DWITH_MEMORY_STORAGE_ENGINE&#x3D;1 -DENABLED_LOCAL_INFILE&#x3D;1 -DMYSQL_TCP_PORT&#x3D;3306 -DEXTRA_CHARSETS&#x3D;all -DDEFAULT_CHARSET&#x3D;utf8 -DDEFAULT_COLLATION&#x3D;utf8_general_ci -DWITH_PARTITION_STORAGE_ENGINE&#x3D;1 -DMYSQL_UNIX_ADDR&#x3D;&#x2F;tmp&#x2F;mysql.sock -DWITH_DEBUG&#x3D;0 -DWITH_SSL&#x3D;yes -DSYSCONFDIR&#x3D;&#x2F;data&#x2F;mysql -DMYSQL_TCP_PORT&#x3D;3306 &amp;&amp; make &amp;&amp; make install || exit 1 echo ‘OK,MySQL-5.6.12 has been successfully installed!’sleep 2echo “Prepare for start MySQL,Please wait….”sleep 2useradd -s &#x2F;sbin&#x2F;nologin wwwuseradd -s &#x2F;sbin&#x2F;nologin mysqlmkdir -p &#x2F;data&#x2F;mysql&#x2F;{data,binlog,relaylog}chown -R mysql:mysql &#x2F;data&#x2F;mysqltouch &#x2F;data&#x2F;mysql&#x2F;my.cnfecho -ne “[client] default-character-set&#x3D;gbk port &#x3D; 3306 socket &#x3D; &#x2F;tmp&#x2F;mysql.sock [mysqld] character-set-server &#x3D; gbk collation-server &#x3D; gbk_chinese_ci #replicate-ignore-db &#x3D; mysql #replicate-ignore-db &#x3D; test #replicate-ignore-db &#x3D; information_schema user &#x3D; mysql port &#x3D; 3306 socket &#x3D; &#x2F;tmp&#x2F;mysql.sock basedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql datadir &#x3D; &#x2F;data&#x2F;mysql&#x2F;data explicit_defaults_for_timestamp&#x3D;true log-error &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql_error.log pid-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql.pid open_files_limit &#x3D; 10240 back_log &#x3D; 600 max_connections &#x3D; 5000 max_connect_errors &#x3D; 6000 table_cache &#x3D; 614 external-locking &#x3D; FALSE max_allowed_packet &#x3D; 32M sort_buffer_size &#x3D; 1M join_buffer_size &#x3D; 1M thread_cache_size &#x3D; 300 thread_concurrency &#x3D; 8 query_cache_size &#x3D; 512M query_cache_limit &#x3D; 2M query_cache_min_res_unit &#x3D; 2k default-storage-engine &#x3D; MyISAM thread_stack &#x3D; 192K transaction_isolation &#x3D; READ-COMMITTED tmp_table_size &#x3D; 246M max_heap_table_size &#x3D; 246M long_query_time &#x3D; 3 log-slave-updates log-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;binlog&#x2F;binlog binlog_cache_size &#x3D; 4M binlog_format &#x3D; MIXED max_binlog_cache_size &#x3D; 8M max_binlog_size &#x3D; 1G expire-logs-days &#x3D; 30 relay-log-index &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog relay-log-info-file &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog relay-log &#x3D; &#x2F;data&#x2F;mysql&#x2F;relaylog&#x2F;relaylog expire_logs_days &#x3D; 30 key_buffer_size &#x3D; 256M read_buffer_size &#x3D; 1M read_rnd_buffer_size &#x3D; 16M bulk_insert_buffer_size &#x3D; 64M myisam_sort_buffer_size &#x3D; 128M myisam_max_sort_file_size &#x3D; 10G myisam_repair_threads &#x3D; 1 ;myisam_recover interactive_timeout &#x3D; 120 wait_timeout &#x3D; 120 skip-name-resolve slave-skip-errors &#x3D; 1032,1062,126,1114,1146,1048,1396 server-id &#x3D; 1 ;innodb_additional_mem_pool_size &#x3D; 16M ;innodb_buffer_pool_size &#x3D; 512M ;innodb_data_file_path &#x3D; ibdata1:256M:autoextend ;innodb_file_io_threads &#x3D; 4 ;innodb_thread_concurrency &#x3D; 8 ;innodb_flush_log_at_trx_commit &#x3D; 2 ;innodb_log_buffer_size &#x3D; 16M ;innodb_log_file_size &#x3D; 128M ;innodb_log_files_in_group &#x3D; 3 ;innodb_max_dirty_pages_pct &#x3D; 90 ;innodb_lock_wait_timeout &#x3D; 120 ;innodb_file_per_table &#x3D; 0 slow_query_log slow_query_log_file &#x3D; &#x2F;data&#x2F;mysql&#x2F;slow.log long_query_time &#x3D; 1 log-queries-not-using-indexes [mysqldump] quick max_allowed_packet &#x3D; 32M ” &gt;&gt; &#x2F;data&#x2F;mysql&#x2F;my.cnfln -s &#x2F;data&#x2F;mysql&#x2F;my.cnf &#x2F;etc&#x2F;my.cnfcp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysql* &#x2F;usr&#x2F;bin&#x2F; &amp;&amp; cp &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;support-files&#x2F;mysql.server &#x2F;etc&#x2F;init.d&#x2F;mysqld &amp;&amp; chmod +x &#x2F;etc&#x2F;init.d&#x2F;mysqld || exit 1&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;scripts&#x2F;mysql_install_db –user&#x3D;mysql –basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysqlmysqld_safe –user&#x3D;mysql &amp;killall mysqldservice mysqld start #Apachecd ..echo “Start the installation of Apache…”sleep 2#apr tar jxvf apr-1.4.8.tar.bz2 &amp;&amp; cd apr-1.4.8#注释掉configure文件中的某行，解决“&#x2F;bin&#x2F;rm: cannot remove &#96;libtoolT’: No such file or directory ”sed -i ‘&#x2F;$RM “$cfgfile”&#x2F; s&#x2F;^&#x2F;#&#x2F;‘ configure.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr &amp;&amp; make &amp;&amp; make install || exit 1cd ..#apr-utiltar jxvf apr-util-1.5.2.tar.bz2 &amp;&amp; apr-util-1.5.2.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F;bin&#x2F;apr-1-config &amp;&amp; make &amp;&amp; make install || exit 1#pcrecd ..echo “Start the installation of pcre…”tar jxvf pcre-8.33.tar.bz2 &amp;&amp; cd pcre-8.33.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre &amp;&amp; make &amp;&amp; make install || exit 1echo ‘OK,pcre-8.33 has been successfully installed!’cd .. sleep 2tar zxvf httpd-2.4.6.tar.gz &amp;&amp; cd httpd-2.4.6 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2 –sysconfdir&#x3D;&#x2F;etc&#x2F;httpd –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F;bin&#x2F;apr-1-config –with-apr-util&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util&#x2F;bin&#x2F;apu-1-config –with-pcre&#x3D;&#x2F;usr&#x2F;local&#x2F;pcre&#x2F; –enable-mods-shared&#x3D;most –enable-rewirte –enable-so –enable-ssl&#x3D;static –with-ssl –enable-proxy&#x3D;shared –enable-proxy-balancer&#x3D;shared –enable-proxy-http&#x3D;shared –enable-cache –enable-disk-cache –enable-mem-cache –enable-file-cache &amp;&amp; make &amp;&amp; make install || exit 1if [ ! -d &#x2F;data&#x2F;logs ];thenmkdir -p &#x2F;data&#x2F;logs&#x2F;{error,access} #apache日志存放目录fiecho “OK,apache-2.4.6 has been successfully installed!”sleep 2#根据PHP版本对该脚本做适当修改#PHP-5.3.27cd ..echo “Start the installation of php…”sleep 2 tar zxvf php-5.3.27.tar.gz &amp;&amp; cd php-5.3.27 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;php5.5 –with-config-file-path&#x3D;&#x2F;usr&#x2F;local&#x2F;php5.5&#x2F;etc –with-apxs2&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;apxs –with-libxml-dir –with-iconv-dir –with-png-dir –with-jpeg-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;jpeg –with-zlib –with-gd&#x3D;&#x2F;usr&#x2F;local&#x2F;gd –with-freetype-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;freetype –with-mcrypt –with-mhash –enable-gd-native-ttf –with-readline –with-curl –with-bz2 –enable-mysqlnd –with-mysql&#x3D;mysqlnd –with-mysqli&#x3D;mysqlnd –with-pdo-mysql&#x3D;mysqlnd –with-openssl-dir –without-pear –enable-mbstring –enable-soap –enable-xml –enable-ftp –enable-zip –enable-bcmath –enable-sockets –enable-opcache &amp;&amp; make &amp;&amp; make install || exit 1if [ ! -d &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc ];thenmkdir &#x2F;usr&#x2F;local&#x2F;php&#x2F;etcficp ..&#x2F;php.ini &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F; &amp;&amp; mkdir &#x2F;usr&#x2F;local&#x2F;php&#x2F;extmkdir -p &#x2F;data&#x2F;logs&#x2F;php #日志存放目录echo ‘OK,PHP-5.3.27 has been successfully installed!’sleep 2 cd ..echo “Start install memcache extension…”#如果php版本为5.2，则memcache使用2.2.6版本，否则会因版本问题导致php无法加载memcach模块。sleep 2tar zxvf memcache-3.0.6.tgz &amp;&amp; cd memcache-3.0.6 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –enable-memcache –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;memcache.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;echo “OK,Memcache-3.0.6 installed successfully!”sleep 2 #cd ..#echo “Start install ImageMagick…”#sleep 2#tar zxvf ImageMagick-6.6.9-10.tar.gz &amp;&amp; cd ImageMagick-6.6.9-10 &amp;&amp; .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;imagemagick &amp;&amp; make &amp;&amp; make install || exit 1#echo “&#x2F;usr&#x2F;local&#x2F;imagemagick&#x2F;lib” &gt;&gt; &#x2F;etc&#x2F;ld.so.conf &amp;&amp; ldconfig#echo “OK,ImageMagick-6.6.9-10 has been installed successfully!”#sleep 2 #cd ..#echo “Start install imagick for php …”#tar zxvf imagick-3.0.1.tgz &amp;&amp; cd imagick-3.0.1 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –with-imagick&#x3D;&#x2F;usr&#x2F;local&#x2F;imagemagick –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make install || exit 1#cp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20060613&#x2F;imagick.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;#echo “OK,imagick-3.0.1 for php has been installed successfully!”#sleep 2 cd ..echo “Start install PDO_MYSQL …”tar zxvf PDO_MYSQL-1.0.2.tgz &amp;&amp; cd PDO_MYSQL-1.0.2 &amp;&amp; &#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize &amp;&amp; .&#x2F;configure –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config –with-pdo-mysql&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql &amp;&amp; make &amp;&amp; make install || exit 1cp modules&#x2F;pdo_mysql.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;echo “OK,PDO_MYSQL-1.0.2 has been installed successfully!”sleep 2 cd ..echo “Start install APC …”tar zxvf APC-3.1.9.tgz &amp;&amp; cd APC-3.1.9&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;phpize.&#x2F;configure –enable-apc –enable-apc-mmap –with-php-config&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;bin&#x2F;php-config &amp;&amp; make &amp;&amp; make installcp &#x2F;usr&#x2F;local&#x2F;php&#x2F;lib&#x2F;php&#x2F;extensions&#x2F;no-debug-non-zts-20090626&#x2F;apc.so &#x2F;usr&#x2F;local&#x2F;php&#x2F;ext&#x2F;#echo -ne “[APC] extension &#x3D; &quot;apc.so&quot; apc.enabled &#x3D; 1 apc.cache_by_default &#x3D; on apc.shm_size &#x3D; 32M apc.ttl &#x3D; 600 apc.user_ttl &#x3D; 600 apc.write_lock &#x3D; on” &gt;&gt; &#x2F;usr&#x2F;local&#x2F;php&#x2F;etc&#x2F;php.iniecho -ne “APC-3.1.9 has been installed successfully!”cd ..sleep 2 #httpd auto runingcp &#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;apachectl &#x2F;etc&#x2F;init.d&#x2F;httpdsed -i ‘2a # chkconfig: 2345 65 37\\ description: apache service manager.’ &#x2F;etc&#x2F;init.d&#x2F;httpdchkconfig –level 3 httpd on #http_confmv &#x2F;etc&#x2F;httpd&#x2F;httpd.conf &#x2F;etc&#x2F;httpd&#x2F;httpd.conf.defaultmv &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-default.conf &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-default.conf.defaultmv &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-vhosts.conf &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-vhosts.conf.defaultmv &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-mpm.conf &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F;httpd-mpm.conf.defaultcp http-conf&#x2F;httpd.conf &#x2F;etc&#x2F;httpd&#x2F;cp http-conf&#x2F;extra&#x2F;* &#x2F;etc&#x2F;httpd&#x2F;extra&#x2F; #apache_cutlogtar zxvf cronolog-1.6.2.tar.gz &amp;&amp; cd cronolog-1.6.2 &amp;&amp; .&#x2F;configure &amp;&amp; make &amp;&amp; make install || exit 1 cd ..#ulimitsed -i ‘$i * - nofile 65535\\ soft core 0\\ hard core 0&#39; /etc/security/limits.conf #sysctl.confcat sysctl.conf &gt;&gt; &#x2F;etc&#x2F;sysctl.conf &amp;&amp; sysctl -p #history保留操作时间sed -i ‘&#x2F;HISTSIZE&#x2F;a HISTTIMEFORMAT&#x3D;”%Y%m%d-%H%M%S:”‘ &#x2F;etc&#x2F;profilesed -i ‘&#x2F;export&#x2F; s&#x2F;$&#x2F; HISTTIMEFORMAT&#x2F;‘ &#x2F;etc&#x2F;profile #su&#x2F;sudo#仅wheel组成员可以使用sused -i ‘&#x2F;required&#x2F; s&#x2F;^#&#x2F;&#x2F;‘ &#x2F;etc&#x2F;pam.d&#x2F;suecho “SU_WHEEL_ONLY yes” &gt;&gt; &#x2F;etc&#x2F;login.defs #sudo#Cmnd_Alias MANAGER &#x3D; &#x2F;sbin&#x2F;route, &#x2F;sbin&#x2F;ifconfig, &#x2F;bin&#x2F;ping, &#x2F;sbin&#x2F;iptables, &#x2F;sbin&#x2F;service, &#x2F;sbin&#x2F;chkconfig, &#x2F;bin&#x2F;chmod, &#x2F;bin&#x2F;chown, &#x2F;bin&#x2F;chgrp#User_Alias ADMINS &#x3D; #root ALL&#x3D;(ALL) ALL#ADMINS ALL&#x3D;(ALL) MANAGER #document_rootif [ ! -d &#x2F;data&#x2F;www ];thenmkdir -p &#x2F;data&#x2F;wwwfichown www:www &#x2F;data&#x2F;www &amp;&amp; touch &#x2F;data&#x2F;www&#x2F;index.php &amp;&amp; echo -ne ‘‘ &gt; &#x2F;data&#x2F;www&#x2F;index.phpsleep 2 echo -ne “OK,That is all,Thanks for using,Bye! ”#10秒之后重启for i in $(seq 10| tac)do echo -ne “\\aThe system will reboot after $i seconds…\\r” sleep 1doneechoshutdown -r now","categories":["Linux配置文件","lamp"]},{"title":"sysctl.conf","path":"/2023/09/28/Linux配置文件/lamp/sysctl.conf/","content":"title: sysctl.confdate: 2023-09-28 02:33:14tags:categories: [Linux配置文件, lamp]###linux�ںˣ���������Ż�####����ip��ת��net.ipv4.ip_forward &#x3D; 0net.ipv4.conf.all.forwarding &#x3D; 0 #��ֱ�����ӵ�������з���·������net.ipv4.conf.all.rp_filter &#x3D; 1net.ipv4.conf.default.rp_filter &#x3D; 1 #���������ܺ���Դ·����Ϣ��ip��net.ipv4.conf.all.accept_source_route &#x3D; 0net.ipv4.conf.default.accept_source_route &#x3D; 0 #��TCP SYN cookies������һ���̶�Ԥ��SYN����net.ipv4.tcp_syncookies &#x3D; 1 #SYN���еĳ��ȣ��ʵ������ֵ�������ڵֵ�SYN����net.ipv4.tcp_max_syn_backlog &#x3D; 3072#SYN�����Դ������ʵ����͸�ֵ�������ڷ���SYN����net.ipv4.tcp_synack_retries &#x3D; 3net.ipv4.tcp_syn_retries &#x3D; 3 #�ر�Linux kernel��·���ض�����net.ipv4.conf.all.send_redirects &#x3D; 0net.ipv4.conf.default.send_redirects &#x3D; 0 #������ip�ض�����Ϣnet.ipv4.conf.all.accept_redirects &#x3D; 0 #ȡ����ȫ�ض���net.ipv4.conf.all.secure_redirects &#x3D; 0 #Ԥ��ICMP̽��net.ipv4.icmp_echo_ignore_broadcasts &#x3D; 1net.ipv4.icmp_ignore_bogus_error_responses &#x3D; 1 #���̿��ٻ��գ�����ϵͳ�д��ڴ���TIME_WAIT����net.ipv4.tcp_tw_recycle &#x3D; 1net.ipv4.tcp_fin_timeout &#x3D; 30 #�˿����ã�һ�㲻����#net.ipv4.tcp_tw_reuse &#x3D; 1 #��ʱ�˿ڷ�Χnet.ipv4.ip_local_port_range &#x3D; 1024 65535","categories":["Linux配置文件","lamp"]},{"title":"php.ini","path":"/2023/09/28/Linux配置文件/lamp/php.ini/","content":"title: php.inidate: 2023-09-28 02:33:14tags:categories: [Linux配置文件, lamp][PHP] ;;;;;;;;;;;;;;;;;;;; About php.ini ;;;;;;;;;;;;;;;;;;;;; PHP’s initialization file, generally called php.ini, is responsible for; configuring many of the aspects of PHP’s behavior. ; PHP attempts to find and load this configuration from a number of locations.; The following is a summary of its search order:; 1. SAPI module specific location.; 2. The PHPRC environment variable. (As of PHP 5.2.0); 3. A number of predefined registry keys on Windows (As of PHP 5.2.0); 4. Current working directory (except CLI); 5. The web server’s directory (for SAPI modules), or directory of PHP; (otherwise in Windows); 6. The directory from the –with-config-file-path compile time option, or the; Windows directory (C:\\windows or C:\\winnt); See the PHP docs for more specific information.; http://php.net/configuration.file ; The syntax of the file is extremely simple. Whitespace and Lines; beginning with a semicolon are silently ignored (as you probably guessed).; Section headers (e.g. [Foo]) are also silently ignored, even though; they might mean something in the future. ; Directives following the section heading [PATH&#x3D;&#x2F;www&#x2F;mysite] only; apply to PHP files in the &#x2F;www&#x2F;mysite directory. Directives; following the section heading [HOST&#x3D;www.example.com] only apply to; PHP files served from www.example.com. Directives set in these; special sections cannot be overridden by user-defined INI files or; at runtime. Currently, [PATH&#x3D;] and [HOST&#x3D;] sections only work under; CGI&#x2F;FastCGI.; http://php.net/ini.sections ; Directives are specified using the following syntax:; directive &#x3D; value; Directive names are case sensitive - foo&#x3D;bar is different from FOO&#x3D;bar.; Directives are variables used to configure PHP or PHP extensions.; There is no name validation. If PHP can’t find an expected; directive because it is not set or is mistyped, a default value will be used. ; The value can be a string, a number, a PHP constant (e.g. E_ALL or M_PI), one; of the INI constants (On, Off, True, False, Yes, No and None) or an expression; (e.g. E_ALL &amp; ~E_NOTICE), a quoted string (“bar”), or a reference to a; previously set variable or directive (e.g. ${foo}) ; Expressions in the INI file are limited to bitwise operators and parentheses:; | bitwise OR; ^ bitwise XOR; &amp; bitwise AND; ~ bitwise NOT; ! boolean NOT ; Boolean flags can be turned on using the values 1, On, True or Yes.; They can be turned off using the values 0, Off, False or No. ; An empty string can be denoted by simply not writing anything after the equal; sign, or by using the None keyword: ; foo &#x3D; ; sets foo to an empty string; foo &#x3D; None ; sets foo to an empty string; foo &#x3D; “None” ; sets foo to the string ‘None’ ; If you use constants in your value, and these constants belong to a; dynamically loaded extension (either a PHP extension or a Zend extension),; you may only use these constants after the line that loads the extension. ;;;;;;;;;;;;;;;;;;;; About this file ;;;;;;;;;;;;;;;;;;;;; PHP comes packaged with two INI files. One that is recommended to be used; in production environments and one that is recommended to be used in; development environments. ; php.ini-production contains settings which hold security, performance and; best practices at its core. But please be aware, these settings may break; compatibility with older or less security conscience applications. We; recommending using the production ini in production and testing environments. ; php.ini-development is very similar to its production variant, except it’s; much more verbose when it comes to errors. We recommending using the; development version only in development environments as errors shown to; application users can inadvertently leak otherwise secure information. ;;;;;;;;;;;;;;;;;;;; Quick Reference ;;;;;;;;;;;;;;;;;;;;; The following are all the settings which are different in either the production; or development versions of the INIs with respect to PHP’s default behavior.; Please see the actual settings later in the document for more details as to why; we recommend these changes in PHP’s behavior. ; allow_call_time_pass_reference; Default Value: On; Development Value: Off; Production Value: Off ; display_errors; Default Value: On; Development Value: On; Production Value: Off ; display_startup_errors; Default Value: Off; Development Value: On; Production Value: Off ; error_reporting; Default Value: E_ALL &amp; ~E_NOTICE; Development Value: E_ALL | E_STRICT; Production Value: E_ALL &amp; ~E_DEPRECATED ; html_errors; Default Value: On; Development Value: On; Production value: Off ; log_errors; Default Value: Off; Development Value: On; Production Value: On ; magic_quotes_gpc; Default Value: On; Development Value: Off; Production Value: Off ; max_input_time; Default Value: -1 (Unlimited); Development Value: 60 (60 seconds); Production Value: 60 (60 seconds) ; output_buffering; Default Value: Off; Development Value: 4096; Production Value: 4096 ; register_argc_argv; Default Value: On; Development Value: Off; Production Value: Off ; register_long_arrays; Default Value: On; Development Value: Off; Production Value: Off ; request_order; Default Value: None; Development Value: “GP”; Production Value: “GP” ; session.bug_compat_42; Default Value: On; Development Value: On; Production Value: Off ; session.bug_compat_warn; Default Value: On; Development Value: On; Production Value: Off ; session.gc_divisor; Default Value: 100; Development Value: 1000; Production Value: 1000 ; session.hash_bits_per_character; Default Value: 4; Development Value: 5; Production Value: 5 ; short_open_tag; Default Value: On; Development Value: Off; Production Value: Off ; track_errors; Default Value: Off; Development Value: On; Production Value: Off ; url_rewriter.tags; Default Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,form&#x3D;,fieldset&#x3D;”; Development Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,input&#x3D;src,form&#x3D;fakeentry”; Production Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,input&#x3D;src,form&#x3D;fakeentry” ; variables_order; Default Value: “EGPCS”; Development Value: “GPCS”; Production Value: “GPCS” ;;;;;;;;;;;;;;;;;;;;; php.ini Options ;;;;;;;;;;;;;;;;;;;;;; Name for user-defined php.ini (.htaccess) files. Default is “.user.ini”;user_ini.filename &#x3D; “.user.ini” ; To disable this feature set this option to empty value;user_ini.filename &#x3D; ; TTL for user-defined php.ini files (time-to-live) in seconds. Default is 300 seconds (5 minutes);user_ini.cache_ttl &#x3D; 300 ;;;;;;;;;;;;;;;;;;;;; Language Options ;;;;;;;;;;;;;;;;;;;;; ; Enable the PHP scripting language engine under Apache.; http://php.net/engineengine &#x3D; On ; This directive determines whether or not PHP will recognize code between; tags as PHP source which should be processed as such. It’s been; recommended for several years that you not use the short tag “short cut” and; instead to use the full tag combination. With the wide spread use; of XML and use of these tags by other languages, the server can become easily; confused and end up parsing the wrong code in the wrong context. But because; this short cut has been a feature for such a long time, it’s currently still; supported for backwards compatibility, but we recommend you don’t use them.; Default Value: On; Development Value: Off; Production Value: Off; http://php.net/short-open-tagshort_open_tag &#x3D; On ; Allow ASP-style &lt;% %&gt; tags.; http://php.net/asp-tagsasp_tags &#x3D; Off ; The number of significant digits displayed in floating point numbers.; http://php.net/precisionprecision &#x3D; 14 ; Enforce year 2000 compliance (will cause problems with non-compliant browsers); http://php.net/y2k-compliancey2k_compliance &#x3D; On ; Output buffering is a mechanism for controlling how much output data; (excluding headers and cookies) PHP should keep internally before pushing that; data to the client. If your application’s output exceeds this setting, PHP; will send that data in chunks of roughly the size you specify.; Turning on this setting and managing its maximum buffer size can yield some; interesting side-effects depending on your application and web server.; You may be able to send headers and cookies after you’ve already sent output; through print or echo. You also may see performance benefits if your server is; emitting less packets due to buffered output versus PHP streaming the output; as it gets it. On production servers, 4096 bytes is a good setting for performance; reasons.; Note: Output buffering can also be controlled via Output Buffering Control; functions.; Possible Values:; On &#x3D; Enabled and buffer is unlimited. (Use with caution); Off &#x3D; Disabled; Integer &#x3D; Enables the buffer and sets its maximum size in bytes.; Note: This directive is hardcoded to Off for the CLI SAPI; Default Value: Off; Development Value: 4096; Production Value: 4096; http://php.net/output-bufferingoutput_buffering &#x3D; 4096 ; You can redirect all of the output of your scripts to a function. For; example, if you set output_handler to “mb_output_handler”, character; encoding will be transparently converted to the specified encoding.; Setting any output handler automatically turns on output buffering.; Note: People who wrote portable scripts should not depend on this ini; directive. Instead, explicitly set the output handler using ob_start().; Using this ini directive may cause problems unless you know what script; is doing.; Note: You cannot use both “mb_output_handler” with “ob_iconv_handler”; and you cannot use both “ob_gzhandler” and “zlib.output_compression”.; Note: output_handler must be empty if this is set ‘On’ !!!!; Instead you must use zlib.output_handler.; http://php.net/output-handler;output_handler &#x3D; ; Transparent output compression using the zlib library; Valid values for this option are ‘off’, ‘on’, or a specific buffer size; to be used for compression (default is 4KB); Note: Resulting chunk size may vary due to nature of compression. PHP; outputs chunks that are few hundreds bytes each as a result of; compression. If you prefer a larger chunk size for better; performance, enable output_buffering in addition.; Note: You need to use zlib.output_handler instead of the standard; output_handler, or otherwise the output will be corrupted.; http://php.net/zlib.output-compressionzlib.output_compression &#x3D; Off ; http://php.net/zlib.output-compression-level;zlib.output_compression_level &#x3D; -1 ; You cannot specify additional output handlers if zlib.output_compression; is activated here. This setting does the same as output_handler but in; a different order.; http://php.net/zlib.output-handler;zlib.output_handler &#x3D; ; Implicit flush tells PHP to tell the output layer to flush itself; automatically after every output block. This is equivalent to calling the; PHP function flush() after each and every call to print() or echo() and each; and every HTML block. Turning this option on has serious performance; implications and is generally recommended for debugging purposes only.; http://php.net/implicit-flush; Note: This directive is hardcoded to On for the CLI SAPIimplicit_flush &#x3D; Off ; The unserialize callback function will be called (with the undefined class’; name as parameter), if the unserializer finds an undefined class; which should be instantiated. A warning appears if the specified function is; not defined, or if the function doesn’t include&#x2F;implement the missing class.; So only set this entry, if you really want to implement such a; callback-function.unserialize_callback_func &#x3D; ; When floats &amp; doubles are serialized store serialize_precision significant; digits after the floating point. The default value ensures that when floats; are decoded with unserialize, the data will remain the same.serialize_precision &#x3D; 17 ; This directive allows you to enable and disable warnings which PHP will issue; if you pass a value by reference at function call time. Passing values by; reference at function call time is a deprecated feature which will be removed; from PHP at some point in the near future. The acceptable method for passing a; value by reference to a function is by declaring the reference in the functions; definition, not at call time. This directive does not disable this feature, it; only determines whether PHP will warn you about it or not. These warnings; should enabled in development environments only.; Default Value: On (Suppress warnings); Development Value: Off (Issue warnings); Production Value: Off (Issue warnings); http://php.net/allow-call-time-pass-referenceallow_call_time_pass_reference &#x3D; Off ; Safe Mode; http://php.net/safe-modesafe_mode &#x3D; Off ; By default, Safe Mode does a UID compare check when; opening files. If you want to relax this to a GID compare,; then turn on safe_mode_gid.; http://php.net/safe-mode-gidsafe_mode_gid &#x3D; Off ; When safe_mode is on, UID&#x2F;GID checks are bypassed when; including files from this directory and its subdirectories.; (directory must also be in include_path or full path must; be used when including); http://php.net/safe-mode-include-dirsafe_mode_include_dir &#x3D; ; When safe_mode is on, only executables located in the safe_mode_exec_dir; will be allowed to be executed via the exec family of functions.; http://php.net/safe-mode-exec-dirsafe_mode_exec_dir &#x3D; ; Setting certain environment variables may be a potential security breach.; This directive contains a comma-delimited list of prefixes. In Safe Mode,; the user may only alter environment variables whose names begin with the; prefixes supplied here. By default, users will only be able to set; environment variables that begin with PHP_ (e.g. PHP_FOO&#x3D;BAR).; Note: If this directive is empty, PHP will let the user modify ANY; environment variable!; http://php.net/safe-mode-allowed-env-varssafe_mode_allowed_env_vars &#x3D; PHP_ ; This directive contains a comma-delimited list of environment variables that; the end user won’t be able to change using putenv(). These variables will be; protected even if safe_mode_allowed_env_vars is set to allow to change them.; http://php.net/safe-mode-protected-env-varssafe_mode_protected_env_vars &#x3D; LD_LIBRARY_PATH ; open_basedir, if set, limits all file operations to the defined directory; and below. This directive makes most sense if used in a per-directory; or per-virtualhost web server configuration file. This directive is; NOT affected by whether Safe Mode is turned On or Off.; http://php.net/open-basedir;open_basedir &#x3D; ; This directive allows you to disable certain functions for security reasons.; It receives a comma-delimited list of function names. This directive is; NOT affected by whether Safe Mode is turned On or Off.; http://php.net/disable-functionsdisable_functions &#x3D; phpinfo,passthru,system,chroot,scandir,chgrp,chown,proc_open,proc_get_status,ini_alter,ini_alter,ini_restore,dl,pfsockopen,openlog,syslog,readlink,symlink,popepassthru,stream_socket_server,putenv,exec,shell_exec ; This directive allows you to disable certain classes for security reasons.; It receives a comma-delimited list of class names. This directive is; NOT affected by whether Safe Mode is turned On or Off.; http://php.net/disable-classesdisable_classes &#x3D; ; Colors for Syntax Highlighting mode. Anything that’s acceptable in; would work.; http://php.net/syntax-highlighting;highlight.string &#x3D; #DD0000;highlight.comment &#x3D; #FF9900;highlight.keyword &#x3D; #007700;highlight.bg &#x3D; #FFFFFF;highlight.default &#x3D; #0000BB;highlight.html &#x3D; #000000 ; If enabled, the request will be allowed to complete even if the user aborts; the request. Consider enabling it if executing long requests, which may end up; being interrupted by the user or a browser timing out. PHP’s default behavior; is to disable this feature.; http://php.net/ignore-user-abort;ignore_user_abort &#x3D; On ; Determines the size of the realpath cache to be used by PHP. This value should; be increased on systems where PHP opens many files to reflect the quantity of; the file operations performed.; http://php.net/realpath-cache-size;realpath_cache_size &#x3D; 16k ; Duration of time, in seconds for which to cache realpath information for a given; file or directory. For systems with rarely changing files, consider increasing this; value.; http://php.net/realpath-cache-ttl;realpath_cache_ttl &#x3D; 120 ;;;;;;;;;;;;;;;;;; Miscellaneous ;;;;;;;;;;;;;;;;;; ; Decides whether PHP may expose the fact that it is installed on the server; (e.g. by adding its signature to the Web server header). It is no security; threat in any way, but it makes it possible to determine whether you use PHP; on your server or not.; http://php.net/expose-phpexpose_php &#x3D; Off ;;;;;;;;;;;;;;;;;;;; Resource Limits ;;;;;;;;;;;;;;;;;;;; ; Maximum execution time of each script, in seconds; http://php.net/max-execution-time; Note: This directive is hardcoded to 0 for the CLI SAPImax_execution_time &#x3D; 30 ; Maximum amount of time each script may spend parsing request data. It’s a good; idea to limit this time on productions servers in order to eliminate unexpectedly; long running scripts.; Note: This directive is hardcoded to -1 for the CLI SAPI; Default Value: -1 (Unlimited); Development Value: 60 (60 seconds); Production Value: 60 (60 seconds); http://php.net/max-input-timemax_input_time &#x3D; 60 ; Maximum input variable nesting level; http://php.net/max-input-nesting-level;max_input_nesting_level &#x3D; 64 ; Maximum amount of memory a script may consume (128MB); http://php.net/memory-limitmemory_limit &#x3D; 128M ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; Error handling and logging ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; This directive informs PHP of which errors, warnings and notices you would like; it to take action for. The recommended way of setting values for this; directive is through the use of the error level constants and bitwise; operators. The error level constants are below here for convenience as well as; some common settings and their meanings.; By default, PHP is set to take action on all errors, notices and warnings EXCEPT; those related to E_NOTICE and E_STRICT, which together cover best practices and; recommended coding standards in PHP. For performance reasons, this is the; recommend error reporting setting. Your production server shouldn’t be wasting; resources complaining about best practices and coding standards. That’s what; development servers and development settings are for.; Note: The php.ini-development file has this setting as E_ALL | E_STRICT. This; means it pretty much reports everything which is exactly what you want during; development and early testing.;; Error Level Constants:; E_ALL - All errors and warnings (includes E_STRICT as of PHP 6.0.0); E_ERROR - fatal run-time errors; E_RECOVERABLE_ERROR - almost fatal run-time errors; E_WARNING - run-time warnings (non-fatal errors); E_PARSE - compile-time parse errors; E_NOTICE - run-time notices (these are warnings which often result; from a bug in your code, but it’s possible that it was; intentional (e.g., using an uninitialized variable and; relying on the fact it’s automatically initialized to an; empty string); E_STRICT - run-time notices, enable to have PHP suggest changes; to your code which will ensure the best interoperability; and forward compatibility of your code; E_CORE_ERROR - fatal errors that occur during PHP’s initial startup; E_CORE_WARNING - warnings (non-fatal errors) that occur during PHP’s; initial startup; E_COMPILE_ERROR - fatal compile-time errors; E_COMPILE_WARNING - compile-time warnings (non-fatal errors); E_USER_ERROR - user-generated error message; E_USER_WARNING - user-generated warning message; E_USER_NOTICE - user-generated notice message; E_DEPRECATED - warn about code that will not work in future versions; of PHP; E_USER_DEPRECATED - user-generated deprecation warnings;; Common Values:; E_ALL &amp; ~E_NOTICE (Show all errors, except for notices and coding standards warnings.); E_ALL &amp; ~E_NOTICE | E_STRICT (Show all errors, except for notices); E_COMPILE_ERROR|E_RECOVERABLE_ERROR|E_ERROR|E_CORE_ERROR (Show only errors); E_ALL | E_STRICT (Show all errors, warnings and notices including coding standards.); Default Value: E_ALL &amp; ~E_NOTICE; Development Value: E_ALL | E_STRICT; Production Value: E_ALL &amp; ~E_DEPRECATED; http://php.net/error-reportingerror_reporting &#x3D; E_ALL &amp; ~E_DEPRECATED ; This directive controls whether or not and where PHP will output errors,; notices and warnings too. Error output is very useful during development, but; it could be very dangerous in production environments. Depending on the code; which is triggering the error, sensitive information could potentially leak; out of your application such as database usernames and passwords or worse.; It’s recommended that errors be logged on production servers rather than; having the errors sent to STDOUT.; Possible Values:; Off &#x3D; Do not display any errors; stderr &#x3D; Display errors to STDERR (affects only CGI&#x2F;CLI binaries!); On or stdout &#x3D; Display errors to STDOUT; Default Value: On; Development Value: On; Production Value: Off; http://php.net/display-errorsdisplay_errors &#x3D; Off ; The display of errors which occur during PHP’s startup sequence are handled; separately from display_errors. PHP’s default behavior is to suppress those; errors from clients. Turning the display of startup errors on can be useful in; debugging configuration problems. But, it’s strongly recommended that you; leave this setting off on production servers.; Default Value: Off; Development Value: On; Production Value: Off; http://php.net/display-startup-errorsdisplay_startup_errors &#x3D; Off ; Besides displaying errors, PHP can also log errors to locations such as a; server-specific log, STDERR, or a location specified by the error_log; directive found below. While errors should not be displayed on productions; servers they should still be monitored and logging is a great way to do that.; Default Value: Off; Development Value: On; Production Value: On; http://php.net/log-errorslog_errors &#x3D; On ; Set maximum length of log_errors. In error_log information about the source is; added. The default is 1024 and 0 allows to not apply any maximum length at all.; http://php.net/log-errors-max-lenlog_errors_max_len &#x3D; 1024 ; Do not log repeated messages. Repeated errors must occur in same file on same; line unless ignore_repeated_source is set true.; http://php.net/ignore-repeated-errorsignore_repeated_errors &#x3D; Off ; Ignore source of message when ignoring repeated messages. When this setting; is On you will not log errors with repeated messages from different files or; source lines.; http://php.net/ignore-repeated-sourceignore_repeated_source &#x3D; Off ; If this parameter is set to Off, then memory leaks will not be shown (on; stdout or in the log). This has only effect in a debug compile, and if; error reporting includes E_WARNING in the allowed list; http://php.net/report-memleaksreport_memleaks &#x3D; On ; This setting is on by default.;report_zend_debug &#x3D; 0 ; Store the last error&#x2F;warning message in $php_errormsg (boolean). Setting this value; to On can assist in debugging and is appropriate for development servers. It should; however be disabled on production servers.; Default Value: Off; Development Value: On; Production Value: Off; http://php.net/track-errorstrack_errors &#x3D; Off ; Turn off normal error reporting and emit XML-RPC error XML; http://php.net/xmlrpc-errors;xmlrpc_errors &#x3D; 0 ; An XML-RPC faultCode;xmlrpc_error_number &#x3D; 0 ; When PHP displays or logs an error, it has the capability of inserting html; links to documentation related to that error. This directive controls whether; those HTML links appear in error messages or not. For performance and security; reasons, it’s recommended you disable this on production servers.; Note: This directive is hardcoded to Off for the CLI SAPI; Default Value: On; Development Value: On; Production value: Off; http://php.net/html-errorshtml_errors &#x3D; Off ; If html_errors is set On PHP produces clickable error messages that direct; to a page describing the error or function causing the error in detail.; You can download a copy of the PHP manual from http://php.net/docs; and change docref_root to the base URL of your local copy including the; leading ‘&#x2F;‘. You must also specify the file extension being used including; the dot. PHP’s default behavior is to leave these settings empty.; Note: Never use this feature for production boxes.; http://php.net/docref-root; Examples;docref_root &#x3D; “&#x2F;phpmanual&#x2F;“ ; http://php.net/docref-ext;docref_ext &#x3D; .html ; String to output before an error message. PHP’s default behavior is to leave; this setting blank.; http://php.net/error-prepend-string; Example:;error_prepend_string &#x3D; ““ ; String to output after an error message. PHP’s default behavior is to leave; this setting blank.; http://php.net/error-append-string; Example:;error_append_string &#x3D; ““ ; Log errors to specified file. PHP’s default behavior is to leave this value; empty.; http://php.net/error-log; Example:error_log &#x3D; &#x2F;data&#x2F;logs&#x2F;php&#x2F;php_errors.log; Log errors to syslog (Event Log on NT, not valid in Windows 95).;error_log &#x3D; syslog ;;;;;;;;;;;;;;;;;; Data Handling ;;;;;;;;;;;;;;;;;; ; The separator used in PHP generated URLs to separate arguments.; PHP’s default setting is “&amp;”.; http://php.net/arg-separator.output; Example:;arg_separator.output &#x3D; “&amp;” ; List of separator(s) used by PHP to parse input URLs into variables.; PHP’s default setting is “&amp;”.; NOTE: Every character in this directive is considered as separator!; http://php.net/arg-separator.input; Example:;arg_separator.input &#x3D; “;&amp;” ; This directive determines which super global arrays are registered when PHP; starts up. If the register_globals directive is enabled, it also determines; what order variables are populated into the global space. G,P,C,E &amp; S are; abbreviations for the following respective super globals: GET, POST, COOKIE,; ENV and SERVER. There is a performance penalty paid for the registration of; these arrays and because ENV is not as commonly used as the others, ENV is; is not recommended on productions servers. You can still get access to; the environment variables through getenv() should you need to.; Default Value: “EGPCS”; Development Value: “GPCS”; Production Value: “GPCS”;; http://php.net/variables-ordervariables_order &#x3D; “GPCS” ; This directive determines which super global data (G,P,C,E &amp; S) should; be registered into the super global array REQUEST. If so, it also determines; the order in which that data is registered. The values for this directive are; specified in the same manner as the variables_order directive, EXCEPT one.; Leaving this value empty will cause PHP to use the value set in the; variables_order directive. It does not mean it will leave the super globals; array REQUEST empty.; Default Value: None; Development Value: “GP”; Production Value: “GP”; http://php.net/request-orderrequest_order &#x3D; “GP” ; Whether or not to register the EGPCS variables as global variables. You may; want to turn this off if you don’t want to clutter your scripts’ global scope; with user data.; You should do your best to write your scripts so that they do not require; register_globals to be on; Using form variables as globals can easily lead; to possible security problems, if the code is not very well thought of.; http://php.net/register-globalsregister_globals &#x3D; Off ; Determines whether the deprecated long $HTTP_*_VARS type predefined variables; are registered by PHP or not. As they are deprecated, we obviously don’t; recommend you use them. They are on by default for compatibility reasons but; they are not recommended on production servers.; Default Value: On; Development Value: Off; Production Value: Off; http://php.net/register-long-arraysregister_long_arrays &#x3D; Off ; This directive determines whether PHP registers $argv &amp; $argc each time it; runs. $argv contains an array of all the arguments passed to PHP when a script; is invoked. $argc contains an integer representing the number of arguments; that were passed when the script was invoked. These arrays are extremely; useful when running scripts from the command line. When this directive is; enabled, registering these variables consumes CPU cycles and memory each time; a script is executed. For performance reasons, this feature should be disabled; on production servers.; Note: This directive is hardcoded to On for the CLI SAPI; Default Value: On; Development Value: Off; Production Value: Off; http://php.net/register-argc-argvregister_argc_argv &#x3D; Off ; When enabled, the SERVER and ENV variables are created when they’re first; used (Just In Time) instead of when the script starts. If these variables; are not used within a script, having this directive on will result in a; performance gain. The PHP directives register_globals, register_long_arrays,; and register_argc_argv must be disabled for this directive to have any affect.; http://php.net/auto-globals-jitauto_globals_jit &#x3D; On ; Maximum size of POST data that PHP will accept.; http://php.net/post-max-sizepost_max_size &#x3D; 8M ; Magic quotes are a preprocessing feature of PHP where PHP will attempt to; escape any character sequences in GET, POST, COOKIE and ENV data which might; otherwise corrupt data being placed in resources such as databases before; making that data available to you. Because of character encoding issues and; non-standard SQL implementations across many databases, it’s not currently; possible for this feature to be 100% accurate. PHP’s default behavior is to; enable the feature. We strongly recommend you use the escaping mechanisms; designed specifically for the database your using instead of relying on this; feature. Also note, this feature has been deprecated as of PHP 5.3.0 and is; scheduled for removal in PHP 6.; Default Value: On; Development Value: Off; Production Value: Off; http://php.net/magic-quotes-gpcmagic_quotes_gpc &#x3D; Off ; Magic quotes for runtime-generated data, e.g. data from SQL, from exec(), etc.; http://php.net/magic-quotes-runtimemagic_quotes_runtime &#x3D; Off ; Use Sybase-style magic quotes (escape ‘ with ‘’ instead of &#39;).; http://php.net/magic-quotes-sybasemagic_quotes_sybase &#x3D; Off ; Automatically add files before PHP document.; http://php.net/auto-prepend-fileauto_prepend_file &#x3D; ; Automatically add files after PHP document.; http://php.net/auto-append-fileauto_append_file &#x3D; ; By default, PHP will output a character encoding using; the Content-type: header. To disable sending of the charset, simply; set it to be empty.;; PHP’s built-in default is text&#x2F;html; http://php.net/default-mimetypedefault_mimetype &#x3D; “text&#x2F;html” ; PHP’s default character set is set to empty.; http://php.net/default-charset;default_charset &#x3D; “iso-8859-1” ; Always populate the $HTTP_RAW_POST_DATA variable. PHP’s default behavior is; to disable this feature.; http://php.net/always-populate-raw-post-data;always_populate_raw_post_data &#x3D; On ;;;;;;;;;;;;;;;;;;;;;;;;;; Paths and Directories ;;;;;;;;;;;;;;;;;;;;;;;;;; ; UNIX: “&#x2F;path1:&#x2F;path2”;include_path &#x3D; “.:&#x2F;php&#x2F;includes”;; Windows: “\\path1;\\path2”;include_path &#x3D; “.;c:\\php\\includes”;; PHP’s default setting for include_path is “.;&#x2F;path&#x2F;to&#x2F;php&#x2F;pear”; http://php.net/include-path ; The root of the PHP pages, used only if nonempty.; if PHP was not compiled with FORCE_REDIRECT, you SHOULD set doc_root; if you are running php as a CGI under any web server (other than IIS); see documentation for security issues. The alternate is to use the; cgi.force_redirect configuration below; http://php.net/doc-rootdoc_root &#x3D; ; The directory under which PHP opens the script using &#x2F;~username used only; if nonempty.; http://php.net/user-diruser_dir &#x3D; ; Directory in which the loadable extensions (modules) reside.; http://php.net/extension-dirextension_dir &#x3D; “&#x2F;usr&#x2F;local&#x2F;php&#x2F;ext”extension&#x3D;memcache.so; On windows:; extension_dir &#x3D; “ext” ; Whether or not to enable the dl() function. The dl() function does NOT work; properly in multithreaded servers, such as IIS or Zeus, and is automatically; disabled on them.; http://php.net/enable-dlenable_dl &#x3D; Off ; cgi.force_redirect is necessary to provide security running PHP as a CGI under; most web servers. Left undefined, PHP turns this on by default. You can; turn it off here AT YOUR OWN RISK; You CAN safely turn this off for IIS, in fact, you MUST.; http://php.net/cgi.force-redirect;cgi.force_redirect &#x3D; 1 ; if cgi.nph is enabled it will force cgi to always sent Status: 200 with; every request. PHP’s default behavior is to disable this feature.;cgi.nph &#x3D; 1 ; if cgi.force_redirect is turned on, and you are not running under Apache or Netscape; (iPlanet) web servers, you MAY need to set an environment variable name that PHP; will look for to know it is OK to continue execution. Setting this variable MAY; cause security issues, KNOW WHAT YOU ARE DOING FIRST.; http://php.net/cgi.redirect-status-env;cgi.redirect_status_env &#x3D; ; ; cgi.fix_pathinfo provides real PATH_INFO&#x2F;PATH_TRANSLATED support for CGI. PHP’s; previous behaviour was to set PATH_TRANSLATED to SCRIPT_FILENAME, and to not grok; what PATH_INFO is. For more information on PATH_INFO, see the cgi specs. Setting; this to 1 will cause PHP CGI to fix its paths to conform to the spec. A setting; of zero causes PHP to behave as before. Default is 1. You should fix your scripts; to use SCRIPT_FILENAME rather than PATH_TRANSLATED.; http://php.net/cgi.fix-pathinfocgi.fix_pathinfo&#x3D;0 ; FastCGI under IIS (on WINNT based OS) supports the ability to impersonate; security tokens of the calling client. This allows IIS to define the; security context that the request runs under. mod_fastcgi under Apache; does not currently support this feature (03&#x2F;17&#x2F;2002); Set to 1 if running under IIS. Default is zero.; http://php.net/fastcgi.impersonate;fastcgi.impersonate &#x3D; 1; ; Disable logging through FastCGI connection. PHP’s default behavior is to enable; this feature.;fastcgi.logging &#x3D; 0 ; cgi.rfc2616_headers configuration option tells PHP what type of headers to; use when sending HTTP response code. If it’s set 0 PHP sends Status: header that; is supported by Apache. When this option is set to 1 PHP will send; RFC2616 compliant header.; Default is zero.; http://php.net/cgi.rfc2616-headers;cgi.rfc2616_headers &#x3D; 0 ;;;;;;;;;;;;;;;;; File Uploads ;;;;;;;;;;;;;;;;; ; Whether to allow HTTP file uploads.; http://php.net/file-uploadsfile_uploads &#x3D; On ; Temporary directory for HTTP uploaded files (will use system default if not; specified).; http://php.net/upload-tmp-dir;upload_tmp_dir &#x3D; ; Maximum allowed size for uploaded files.; http://php.net/upload-max-filesizeupload_max_filesize &#x3D; 2M ; Maximum number of files that can be uploaded via a single requestmax_file_uploads &#x3D; 20 ;;;;;;;;;;;;;;;;;;; Fopen wrappers ;;;;;;;;;;;;;;;;;;; ; Whether to allow the treatment of URLs (like http:&#x2F;&#x2F; or ftp:&#x2F;&#x2F;) as files.; http://php.net/allow-url-fopenallow_url_fopen &#x3D; On ; Whether to allow include&#x2F;require to open URLs (like http:&#x2F;&#x2F; or ftp:&#x2F;&#x2F;) as files.; http://php.net/allow-url-includeallow_url_include &#x3D; Off ; Define the anonymous ftp password (your email address). PHP’s default setting; for this is empty.; http://php.net/from;from&#x3D;”&#x6a;&#x6f;&#104;&#110;&#64;&#x64;&#x6f;&#101;&#46;&#x63;&#111;&#109;“ ; Define the User-Agent string. PHP’s default setting for this is empty.; http://php.net/user-agent;user_agent&#x3D;”PHP” ; Default timeout for socket based streams (seconds); http://php.net/default-socket-timeoutdefault_socket_timeout &#x3D; 60 ; If your scripts have to deal with files from Macintosh systems,; or you are running on a Mac and need to deal with files from; unix or win32 systems, setting this flag will cause PHP to; automatically detect the EOL character in those files so that; fgets() and file() will work regardless of the source of the file.; http://php.net/auto-detect-line-endings;auto_detect_line_endings &#x3D; Off ;;;;;;;;;;;;;;;;;;;;;;; Dynamic Extensions ;;;;;;;;;;;;;;;;;;;;;;; ; If you wish to have an extension loaded automatically, use the following; syntax:;; extension&#x3D;modulename.extension;; For example, on Windows:;; extension&#x3D;msql.dll;; … or under UNIX:;; extension&#x3D;msql.so;; … or with a path:;; extension&#x3D;&#x2F;path&#x2F;to&#x2F;extension&#x2F;msql.so;; If you only provide the name of the extension, PHP will look for it in its; default extension directory.;; Windows Extensions; Note that ODBC support is built in, so no dll is needed for it.; Note that many DLL files are located in the extensions&#x2F; (PHP 4) ext&#x2F; (PHP 5); extension folders as well as the separate PECL DLL download (PHP 5).; Be sure to appropriately set the extension_dir directive.;;extension&#x3D;php_bz2.dll;extension&#x3D;php_curl.dll;extension&#x3D;php_fileinfo.dll;extension&#x3D;php_gd2.dll;extension&#x3D;php_gettext.dll;extension&#x3D;php_gmp.dll;extension&#x3D;php_intl.dll;extension&#x3D;php_imap.dll;extension&#x3D;php_interbase.dll;extension&#x3D;php_ldap.dll;extension&#x3D;php_mbstring.dll;extension&#x3D;php_exif.dll ; Must be after mbstring as it depends on it;extension&#x3D;php_mysql.dll;extension&#x3D;php_mysqli.dll;extension&#x3D;php_oci8.dll ; Use with Oracle 10gR2 Instant Client;extension&#x3D;php_oci8_11g.dll ; Use with Oracle 11g Instant Client;extension&#x3D;php_openssl.dll;extension&#x3D;php_pdo_firebird.dll;extension&#x3D;php_pdo_mssql.dll;extension&#x3D;php_pdo_mysql.dll;extension&#x3D;php_pdo_oci.dll;extension&#x3D;php_pdo_odbc.dll;extension&#x3D;php_pdo_pgsql.dll;extension&#x3D;php_pdo_sqlite.dll;extension&#x3D;php_pgsql.dll;extension&#x3D;php_pspell.dll;extension&#x3D;php_shmop.dll ; The MIBS data available in the PHP distribution must be installed.; See http://www.php.net/manual/en/snmp.installation.php;extension&#x3D;php_snmp.dll ;extension&#x3D;php_soap.dll;extension&#x3D;php_sockets.dll;extension&#x3D;php_sqlite.dll;extension&#x3D;php_sqlite3.dll;extension&#x3D;php_sybase_ct.dll;extension&#x3D;php_tidy.dll;extension&#x3D;php_xmlrpc.dll;extension&#x3D;php_xsl.dll;extension&#x3D;php_zip.dll ;;;;;;;;;;;;;;;;;;;; Module Settings ;;;;;;;;;;;;;;;;;;;; [Date]; Defines the default timezone used by the date functions; http://php.net/date.timezonedate.timezone &#x3D; Asia&#x2F;ShangHai ; http://php.net/date.default-latitude;date.default_latitude &#x3D; 31.7667 ; http://php.net/date.default-longitude;date.default_longitude &#x3D; 35.2333 ; http://php.net/date.sunrise-zenith;date.sunrise_zenith &#x3D; 90.583333 ; http://php.net/date.sunset-zenith;date.sunset_zenith &#x3D; 90.583333 [filter]; http://php.net/filter.default;filter.default &#x3D; unsafe_raw ; http://php.net/filter.default-flags;filter.default_flags &#x3D; [iconv];iconv.input_encoding &#x3D; ISO-8859-1;iconv.internal_encoding &#x3D; ISO-8859-1;iconv.output_encoding &#x3D; ISO-8859-1 [intl];intl.default_locale &#x3D;; This directive allows you to produce PHP errors when some error; happens within intl functions. The value is the level of the error produced.; Default is 0, which does not produce any errors.;intl.error_level &#x3D; E_WARNING [sqlite]; http://php.net/sqlite.assoc-case;sqlite.assoc_case &#x3D; 0 [sqlite3];sqlite3.extension_dir &#x3D; [Pcre];PCRE library backtracking limit.; http://php.net/pcre.backtrack-limit;pcre.backtrack_limit&#x3D;100000 ;PCRE library recursion limit.;Please note that if you set this value to a high number you may consume all;the available process stack and eventually crash PHP (due to reaching the;stack size limit imposed by the Operating System).; http://php.net/pcre.recursion-limit;pcre.recursion_limit&#x3D;100000 [Pdo]; Whether to pool ODBC connections. Can be one of “strict”, “relaxed” or “off”; http://php.net/pdo-odbc.connection-pooling;pdo_odbc.connection_pooling&#x3D;strict ;pdo_odbc.db2_instance_name [Pdo_mysql]; If mysqlnd is used: Number of cache slots for the internal result set cache; http://php.net/pdo_mysql.cache_sizepdo_mysql.cache_size &#x3D; 2000 ; Default socket name for local MySQL connects. If empty, uses the built-in; MySQL defaults.; http://php.net/pdo_mysql.default-socketpdo_mysql.default_socket&#x3D; [Phar]; http://php.net/phar.readonly;phar.readonly &#x3D; On ; http://php.net/phar.require-hash;phar.require_hash &#x3D; On ;phar.cache_list &#x3D; [Syslog]; Whether or not to define the various syslog variables (e.g. $LOG_PID,; $LOG_CRON, etc.). Turning it off is a good idea performance-wise. In; runtime, you can define these variables by calling define_syslog_variables().; http://php.net/define-syslog-variablesdefine_syslog_variables &#x3D; Off [mail function]; For Win32 only.; http://php.net/smtpSMTP &#x3D; localhost; http://php.net/smtp-portsmtp_port &#x3D; 25 ; For Win32 only.; http://php.net/sendmail-from;sendmail_from &#x3D; &#109;&#101;&#64;&#101;&#x78;&#97;&#109;&#112;&#108;&#101;&#x2e;&#99;&#111;&#109; ; For Unix only. You may supply arguments as well (default: “sendmail -t -i”).; http://php.net/sendmail-path;sendmail_path &#x3D; ; Force the addition of the specified parameters to be passed as extra parameters; to the sendmail binary. These parameters will always replace the value of; the 5th parameter to mail(), even in safe mode.;mail.force_extra_parameters &#x3D; ; Add X-PHP-Originating-Script: that will include uid of the script followed by the filenamemail.add_x_header &#x3D; On ; The path to a log file that will log all mail() calls. Log entries include; the full path of the script, line number, To address and headers.;mail.log &#x3D; [SQL]; http://php.net/sql.safe-modesql.safe_mode &#x3D; Off [ODBC]; http://php.net/odbc.default-db;odbc.default_db &#x3D; Not yet implemented ; http://php.net/odbc.default-user;odbc.default_user &#x3D; Not yet implemented ; http://php.net/odbc.default-pw;odbc.default_pw &#x3D; Not yet implemented ; Controls the ODBC cursor model.; Default: SQL_CURSOR_STATIC (default).;odbc.default_cursortype ; Allow or prevent persistent links.; http://php.net/odbc.allow-persistentodbc.allow_persistent &#x3D; On ; Check that a connection is still valid before reuse.; http://php.net/odbc.check-persistentodbc.check_persistent &#x3D; On ; Maximum number of persistent links. -1 means no limit.; http://php.net/odbc.max-persistentodbc.max_persistent &#x3D; -1 ; Maximum number of links (persistent + non-persistent). -1 means no limit.; http://php.net/odbc.max-linksodbc.max_links &#x3D; -1 ; Handling of LONG fields. Returns number of bytes to variables. 0 means; passthru.; http://php.net/odbc.defaultlrlodbc.defaultlrl &#x3D; 4096 ; Handling of binary data. 0 means passthru, 1 return as is, 2 convert to char.; See the documentation on odbc_binmode and odbc_longreadlen for an explanation; of odbc.defaultlrl and odbc.defaultbinmode; http://php.net/odbc.defaultbinmodeodbc.defaultbinmode &#x3D; 1 ;birdstep.max_links &#x3D; -1 [Interbase]; Allow or prevent persistent links.ibase.allow_persistent &#x3D; 1 ; Maximum number of persistent links. -1 means no limit.ibase.max_persistent &#x3D; -1 ; Maximum number of links (persistent + non-persistent). -1 means no limit.ibase.max_links &#x3D; -1 ; Default database name for ibase_connect().;ibase.default_db &#x3D; ; Default username for ibase_connect().;ibase.default_user &#x3D; ; Default password for ibase_connect().;ibase.default_password &#x3D; ; Default charset for ibase_connect().;ibase.default_charset &#x3D; ; Default timestamp format.ibase.timestampformat &#x3D; “%Y-%m-%d %H:%M:%S” ; Default date format.ibase.dateformat &#x3D; “%Y-%m-%d” ; Default time format.ibase.timeformat &#x3D; “%H:%M:%S” [MySQL]; Allow accessing, from PHP’s perspective, local files with LOAD DATA statements; http://php.net/mysql.allow_local_infilemysql.allow_local_infile &#x3D; On ; Allow or prevent persistent links.; http://php.net/mysql.allow-persistentmysql.allow_persistent &#x3D; On ; If mysqlnd is used: Number of cache slots for the internal result set cache; http://php.net/mysql.cache_sizemysql.cache_size &#x3D; 2000 ; Maximum number of persistent links. -1 means no limit.; http://php.net/mysql.max-persistentmysql.max_persistent &#x3D; -1 ; Maximum number of links (persistent + non-persistent). -1 means no limit.; http://php.net/mysql.max-linksmysql.max_links &#x3D; -1 ; Default port number for mysql_connect(). If unset, mysql_connect() will use; the $MYSQL_TCP_PORT or the mysql-tcp entry in &#x2F;etc&#x2F;services or the; compile-time value defined MYSQL_PORT (in that order). Win32 will only look; at MYSQL_PORT.; http://php.net/mysql.default-portmysql.default_port &#x3D; ; Default socket name for local MySQL connects. If empty, uses the built-in; MySQL defaults.; http://php.net/mysql.default-socketmysql.default_socket &#x3D; ; Default host for mysql_connect() (doesn’t apply in safe mode).; http://php.net/mysql.default-hostmysql.default_host &#x3D; ; Default user for mysql_connect() (doesn’t apply in safe mode).; http://php.net/mysql.default-usermysql.default_user &#x3D; ; Default password for mysql_connect() (doesn’t apply in safe mode).; Note that this is generally a bad idea to store passwords in this file.; Any user with PHP access can run ‘echo get_cfg_var(“mysql.default_password”); and reveal this password! And of course, any users with read access to this; file will be able to reveal the password as well.; http://php.net/mysql.default-passwordmysql.default_password &#x3D; ; Maximum time (in seconds) for connect timeout. -1 means no limit; http://php.net/mysql.connect-timeoutmysql.connect_timeout &#x3D; 60 ; Trace mode. When trace_mode is active (&#x3D;On), warnings for table&#x2F;index scans and; SQL-Errors will be displayed.; http://php.net/mysql.trace-modemysql.trace_mode &#x3D; Off [MySQLi] ; Maximum number of persistent links. -1 means no limit.; http://php.net/mysqli.max-persistentmysqli.max_persistent &#x3D; -1 ; Allow accessing, from PHP’s perspective, local files with LOAD DATA statements; http://php.net/mysqli.allow_local_infile;mysqli.allow_local_infile &#x3D; On ; Allow or prevent persistent links.; http://php.net/mysqli.allow-persistentmysqli.allow_persistent &#x3D; On ; Maximum number of links. -1 means no limit.; http://php.net/mysqli.max-linksmysqli.max_links &#x3D; -1 ; If mysqlnd is used: Number of cache slots for the internal result set cache; http://php.net/mysqli.cache_sizemysqli.cache_size &#x3D; 2000 ; Default port number for mysqli_connect(). If unset, mysqli_connect() will use; the $MYSQL_TCP_PORT or the mysql-tcp entry in &#x2F;etc&#x2F;services or the; compile-time value defined MYSQL_PORT (in that order). Win32 will only look; at MYSQL_PORT.; http://php.net/mysqli.default-portmysqli.default_port &#x3D; 3306 ; Default socket name for local MySQL connects. If empty, uses the built-in; MySQL defaults.; http://php.net/mysqli.default-socketmysqli.default_socket &#x3D; ; Default host for mysql_connect() (doesn’t apply in safe mode).; http://php.net/mysqli.default-hostmysqli.default_host &#x3D; ; Default user for mysql_connect() (doesn’t apply in safe mode).; http://php.net/mysqli.default-usermysqli.default_user &#x3D; ; Default password for mysqli_connect() (doesn’t apply in safe mode).; Note that this is generally a bad idea to store passwords in this file.; Any user with PHP access can run ‘echo get_cfg_var(“mysqli.default_pw”); and reveal this password! And of course, any users with read access to this; file will be able to reveal the password as well.; http://php.net/mysqli.default-pwmysqli.default_pw &#x3D; ; Allow or prevent reconnectmysqli.reconnect &#x3D; Off [mysqlnd]; Enable &#x2F; Disable collection of general statstics by mysqlnd which can be; used to tune and monitor MySQL operations.; http://php.net/mysqlnd.collect_statisticsmysqlnd.collect_statistics &#x3D; On ; Enable &#x2F; Disable collection of memory usage statstics by mysqlnd which can be; used to tune and monitor MySQL operations.; http://php.net/mysqlnd.collect_memory_statisticsmysqlnd.collect_memory_statistics &#x3D; Off ; Size of a pre-allocated buffer used when sending commands to MySQL in bytes.; http://php.net/mysqlnd.net_cmd_buffer_size;mysqlnd.net_cmd_buffer_size &#x3D; 2048 ; Size of a pre-allocated buffer used for reading data sent by the server in; bytes.; http://php.net/mysqlnd.net_read_buffer_size;mysqlnd.net_read_buffer_size &#x3D; 32768 [OCI8] ; Connection: Enables privileged connections using external; credentials (OCI_SYSOPER, OCI_SYSDBA); http://php.net/oci8.privileged-connect;oci8.privileged_connect &#x3D; Off ; Connection: The maximum number of persistent OCI8 connections per; process. Using -1 means no limit.; http://php.net/oci8.max-persistent;oci8.max_persistent &#x3D; -1 ; Connection: The maximum number of seconds a process is allowed to; maintain an idle persistent connection. Using -1 means idle; persistent connections will be maintained forever.; http://php.net/oci8.persistent-timeout;oci8.persistent_timeout &#x3D; -1 ; Connection: The number of seconds that must pass before issuing a; ping during oci_pconnect() to check the connection validity. When; set to 0, each oci_pconnect() will cause a ping. Using -1 disables; pings completely.; http://php.net/oci8.ping-interval;oci8.ping_interval &#x3D; 60 ; Connection: Set this to a user chosen connection class to be used; for all pooled server requests with Oracle 11g Database Resident; Connection Pooling (DRCP). To use DRCP, this value should be set to; the same string for all web servers running the same application,; the database pool must be configured, and the connection string must; specify to use a pooled server.;oci8.connection_class &#x3D; ; High Availability: Using On lets PHP receive Fast Application; Notification (FAN) events generated when a database node fails. The; database must also be configured to post FAN events.;oci8.events &#x3D; Off ; Tuning: This option enables statement caching, and specifies how; many statements to cache. Using 0 disables statement caching.; http://php.net/oci8.statement-cache-size;oci8.statement_cache_size &#x3D; 20 ; Tuning: Enables statement prefetching and sets the default number of; rows that will be fetched automatically after statement execution.; http://php.net/oci8.default-prefetch;oci8.default_prefetch &#x3D; 100 ; Compatibility. Using On means oci_close() will not close; oci_connect() and oci_new_connect() connections.; http://php.net/oci8.old-oci-close-semantics;oci8.old_oci_close_semantics &#x3D; Off [PostgresSQL]; Allow or prevent persistent links.; http://php.net/pgsql.allow-persistentpgsql.allow_persistent &#x3D; On ; Detect broken persistent links always with pg_pconnect().; Auto reset feature requires a little overheads.; http://php.net/pgsql.auto-reset-persistentpgsql.auto_reset_persistent &#x3D; Off ; Maximum number of persistent links. -1 means no limit.; http://php.net/pgsql.max-persistentpgsql.max_persistent &#x3D; -1 ; Maximum number of links (persistent+non persistent). -1 means no limit.; http://php.net/pgsql.max-linkspgsql.max_links &#x3D; -1 ; Ignore PostgreSQL backends Notice message or not.; Notice message logging require a little overheads.; http://php.net/pgsql.ignore-noticepgsql.ignore_notice &#x3D; 0 ; Log PostgreSQL backends Notice message or not.; Unless pgsql.ignore_notice&#x3D;0, module cannot log notice message.; http://php.net/pgsql.log-noticepgsql.log_notice &#x3D; 0 [Sybase-CT]; Allow or prevent persistent links.; http://php.net/sybct.allow-persistentsybct.allow_persistent &#x3D; On ; Maximum number of persistent links. -1 means no limit.; http://php.net/sybct.max-persistentsybct.max_persistent &#x3D; -1 ; Maximum number of links (persistent + non-persistent). -1 means no limit.; http://php.net/sybct.max-linkssybct.max_links &#x3D; -1 ; Minimum server message severity to display.; http://php.net/sybct.min-server-severitysybct.min_server_severity &#x3D; 10 ; Minimum client message severity to display.; http://php.net/sybct.min-client-severitysybct.min_client_severity &#x3D; 10 ; Set per-context timeout; http://php.net/sybct.timeout;sybct.timeout&#x3D; ;sybct.packet_size ; The maximum time in seconds to wait for a connection attempt to succeed before returning failure.; Default: one minute;sybct.login_timeout&#x3D; ; The name of the host you claim to be connecting from, for display by sp_who.; Default: none;sybct.hostname&#x3D; ; Allows you to define how often deadlocks are to be retried. -1 means “forever”.; Default: 0;sybct.deadlock_retry_count&#x3D; [bcmath]; Number of decimal digits for all bcmath functions.; http://php.net/bcmath.scalebcmath.scale &#x3D; 0 [browscap]; http://php.net/browscap;browscap &#x3D; extra&#x2F;browscap.ini [Session]; Handler used to store&#x2F;retrieve data.; http://php.net/session.save-handlersession.save_handler &#x3D; files ; Argument passed to save_handler. In the case of files, this is the path; where data files are stored. Note: Windows users have to change this; variable in order to use PHP’s session functions.;; The path can be defined as:;; session.save_path &#x3D; “N;&#x2F;path”;; where N is an integer. Instead of storing all the session files in; &#x2F;path, what this will do is use subdirectories N-levels deep, and; store the session data in those directories. This is useful if you; or your OS have problems with lots of files in one directory, and is; a more efficient layout for servers that handle lots of sessions.;; NOTE 1: PHP will not create this directory structure automatically.; You can use the script in the ext&#x2F;session dir for that purpose.; NOTE 2: See the section on garbage collection below if you choose to; use subdirectories for session storage;; The file storage module creates files using mode 600 by default.; You can change that by using;; session.save_path &#x3D; “N;MODE;&#x2F;path”;; where MODE is the octal representation of the mode. Note that this; does not overwrite the process’s umask.; http://php.net/session.save-path;session.save_path &#x3D; “&#x2F;tmp” ; Whether to use cookies.; http://php.net/session.use-cookiessession.use_cookies &#x3D; 1 ; http://php.net/session.cookie-secure;session.cookie_secure &#x3D; ; This option forces PHP to fetch and use a cookie for storing and maintaining; the session id. We encourage this operation as it’s very helpful in combatting; session hijacking when not specifying and managing your own session id. It is; not the end all be all of session hijacking defense, but it’s a good start.; http://php.net/session.use-only-cookiessession.use_only_cookies &#x3D; 1 ; Name of the session (used as cookie name).; http://php.net/session.namesession.name &#x3D; PHPSESSID ; Initialize session on request startup.; http://php.net/session.auto-startsession.auto_start &#x3D; 0 ; Lifetime in seconds of cookie or, if 0, until browser is restarted.; http://php.net/session.cookie-lifetimesession.cookie_lifetime &#x3D; 0 ; The path for which the cookie is valid.; http://php.net/session.cookie-pathsession.cookie_path &#x3D; &#x2F; ; The domain for which the cookie is valid.; http://php.net/session.cookie-domainsession.cookie_domain &#x3D; ; Whether or not to add the httpOnly flag to the cookie, which makes it inaccessible to browser scripting languages such as JavaScript.; http://php.net/session.cookie-httponlysession.cookie_httponly &#x3D; ; Handler used to serialize data. php is the standard serializer of PHP.; http://php.net/session.serialize-handlersession.serialize_handler &#x3D; php ; Defines the probability that the ‘garbage collection’ process is started; on every session initialization. The probability is calculated by using; gc_probability&#x2F;gc_divisor. Where session.gc_probability is the numerator; and gc_divisor is the denominator in the equation. Setting this value to 1; when the session.gc_divisor value is 100 will give you approximately a 1% chance; the gc will run on any give request.; Default Value: 1; Development Value: 1; Production Value: 1; http://php.net/session.gc-probabilitysession.gc_probability &#x3D; 1 ; Defines the probability that the ‘garbage collection’ process is started on every; session initialization. The probability is calculated by using the following equation:; gc_probability&#x2F;gc_divisor. Where session.gc_probability is the numerator and; session.gc_divisor is the denominator in the equation. Setting this value to 1; when the session.gc_divisor value is 100 will give you approximately a 1% chance; the gc will run on any give request. Increasing this value to 1000 will give you; a 0.1% chance the gc will run on any give request. For high volume production servers,; this is a more efficient approach.; Default Value: 100; Development Value: 1000; Production Value: 1000; http://php.net/session.gc-divisorsession.gc_divisor &#x3D; 1000 ; After this number of seconds, stored data will be seen as ‘garbage’ and; cleaned up by the garbage collection process.; http://php.net/session.gc-maxlifetimesession.gc_maxlifetime &#x3D; 1440 ; NOTE: If you are using the subdirectory option for storing session files; (see session.save_path above), then garbage collection does not; happen automatically. You will need to do your own garbage; collection through a shell script, cron entry, or some other method.; For example, the following script would is the equivalent of; setting session.gc_maxlifetime to 1440 (1440 seconds &#x3D; 24 minutes):; find &#x2F;path&#x2F;to&#x2F;sessions -cmin +24 | xargs rm ; PHP 4.2 and less have an undocumented feature&#x2F;bug that allows you to; to initialize a session variable in the global scope, even when register_globals; is disabled. PHP 4.3 and later will warn you, if this feature is used.; You can disable the feature and the warning separately. At this time,; the warning is only displayed, if bug_compat_42 is enabled. This feature; introduces some serious security problems if not handled correctly. It’s; recommended that you do not use this feature on production servers. But you; should enable this on development servers and enable the warning as well. If you; do not enable the feature on development servers, you won’t be warned when it’s; used and debugging errors caused by this can be difficult to track down.; Default Value: On; Development Value: On; Production Value: Off; http://php.net/session.bug-compat-42session.bug_compat_42 &#x3D; Off ; This setting controls whether or not you are warned by PHP when initializing a; session value into the global space. session.bug_compat_42 must be enabled before; these warnings can be issued by PHP. See the directive above for more information.; Default Value: On; Development Value: On; Production Value: Off; http://php.net/session.bug-compat-warnsession.bug_compat_warn &#x3D; Off ; Check HTTP Referer to invalidate externally stored URLs containing ids.; HTTP_REFERER has to contain this substring for the session to be; considered as valid.; http://php.net/session.referer-checksession.referer_check &#x3D; ; How many bytes to read from the file.; http://php.net/session.entropy-lengthsession.entropy_length &#x3D; 0 ; Specified here to create the session id.; http://php.net/session.entropy-file; On systems that don’t have &#x2F;dev&#x2F;urandom &#x2F;dev&#x2F;arandom can be used; On windows, setting the entropy_length setting will activate the; Windows random source (using the CryptoAPI);session.entropy_file &#x3D; &#x2F;dev&#x2F;urandom ; Set to {nocache,private,public,} to determine HTTP caching aspects; or leave this empty to avoid sending anti-caching headers.; http://php.net/session.cache-limitersession.cache_limiter &#x3D; nocache ; Document expires after n minutes.; http://php.net/session.cache-expiresession.cache_expire &#x3D; 180 ; trans sid support is disabled by default.; Use of trans sid may risk your users security.; Use this option with caution.; - User may send URL contains active session ID; to other person via. email&#x2F;irc&#x2F;etc.; - URL that contains active session ID may be stored; in publically accessible computer.; - User may access your site with the same session ID; always using URL stored in browser’s history or bookmarks.; http://php.net/session.use-trans-sidsession.use_trans_sid &#x3D; 0 ; Select a hash function for use in generating session ids.; Possible Values; 0 (MD5 128 bits); 1 (SHA-1 160 bits); This option may also be set to the name of any hash function supported by; the hash extension. A list of available hashes is returned by the hash_algos(); function.; http://php.net/session.hash-functionsession.hash_function &#x3D; 0 ; Define how many bits are stored in each character when converting; the binary hash data to something readable.; Possible values:; 4 (4 bits: 0-9, a-f); 5 (5 bits: 0-9, a-v); 6 (6 bits: 0-9, a-z, A-Z, “-“, “,”); Default Value: 4; Development Value: 5; Production Value: 5; http://php.net/session.hash-bits-per-charactersession.hash_bits_per_character &#x3D; 5 ; The URL rewriter will look for URLs in a defined set of HTML tags.; form&#x2F;fieldset are special; if you include them here, the rewriter will; add a hidden field with the info which is otherwise appended; to URLs. If you want XHTML conformity, remove the form entry.; Note that all valid entries require a “&#x3D;”, even if no value follows.; Default Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,form&#x3D;,fieldset&#x3D;”; Development Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,input&#x3D;src,form&#x3D;fakeentry”; Production Value: “a&#x3D;href,area&#x3D;href,frame&#x3D;src,input&#x3D;src,form&#x3D;fakeentry”; http://php.net/url-rewriter.tagsurl_rewriter.tags &#x3D; “a&#x3D;href,area&#x3D;href,frame&#x3D;src,input&#x3D;src,form&#x3D;fakeentry” [MSSQL]; Allow or prevent persistent links.mssql.allow_persistent &#x3D; On ; Maximum number of persistent links. -1 means no limit.mssql.max_persistent &#x3D; -1 ; Maximum number of links (persistent+non persistent). -1 means no limit.mssql.max_links &#x3D; -1 ; Minimum error severity to display.mssql.min_error_severity &#x3D; 10 ; Minimum message severity to display.mssql.min_message_severity &#x3D; 10 ; Compatibility mode with old versions of PHP 3.0.mssql.compatability_mode &#x3D; Off ; Connect timeout;mssql.connect_timeout &#x3D; 5 ; Query timeout;mssql.timeout &#x3D; 60 ; Valid range 0 - 2147483647. Default &#x3D; 4096.;mssql.textlimit &#x3D; 4096 ; Valid range 0 - 2147483647. Default &#x3D; 4096.;mssql.textsize &#x3D; 4096 ; Limits the number of records in each batch. 0 &#x3D; all records in one batch.;mssql.batchsize &#x3D; 0 ; Specify how datetime and datetim4 columns are returned; On &#x3D;&gt; Returns data converted to SQL server settings; Off &#x3D;&gt; Returns values as YYYY-MM-DD hh:mm:ss;mssql.datetimeconvert &#x3D; On ; Use NT authentication when connecting to the servermssql.secure_connection &#x3D; Off ; Specify max number of processes. -1 &#x3D; library default; msdlib defaults to 25; FreeTDS defaults to 4096;mssql.max_procs &#x3D; -1 ; Specify client character set.; If empty or not set the client charset from freetds.comf is used; This is only used when compiled with FreeTDS;mssql.charset &#x3D; “ISO-8859-1” [Assertion]; Assert(expr); active by default.; http://php.net/assert.active;assert.active &#x3D; On ; Issue a PHP warning for each failed assertion.; http://php.net/assert.warning;assert.warning &#x3D; On ; Don’t bail out by default.; http://php.net/assert.bail;assert.bail &#x3D; Off ; User-function to be called if an assertion fails.; http://php.net/assert.callback;assert.callback &#x3D; 0 ; Eval the expression with current error_reporting(). Set to true if you want; error_reporting(0) around the eval().; http://php.net/assert.quiet-eval;assert.quiet_eval &#x3D; 0 [COM]; path to a file containing GUIDs, IIDs or filenames of files with TypeLibs; http://php.net/com.typelib-file;com.typelib_file &#x3D; ; allow Distributed-COM calls; http://php.net/com.allow-dcom;com.allow_dcom &#x3D; true ; autoregister constants of a components typlib on com_load(); http://php.net/com.autoregister-typelib;com.autoregister_typelib &#x3D; true ; register constants casesensitive; http://php.net/com.autoregister-casesensitive;com.autoregister_casesensitive &#x3D; false ; show warnings on duplicate constant registrations; http://php.net/com.autoregister-verbose;com.autoregister_verbose &#x3D; true ; The default character set code-page to use when passing strings to and from COM objects.; Default: system ANSI code page;com.code_page&#x3D; [mbstring]; language for internal character representation.; http://php.net/mbstring.language;mbstring.language &#x3D; Japanese ; internal&#x2F;script encoding.; Some encoding cannot work as internal encoding.; (e.g. SJIS, BIG5, ISO-2022-*); http://php.net/mbstring.internal-encoding;mbstring.internal_encoding &#x3D; EUC-JP ; http input encoding.; http://php.net/mbstring.http-input;mbstring.http_input &#x3D; auto ; http output encoding. mb_output_handler must be; registered as output buffer to function; http://php.net/mbstring.http-output;mbstring.http_output &#x3D; SJIS ; enable automatic encoding translation according to; mbstring.internal_encoding setting. Input chars are; converted to internal encoding by setting this to On.; Note: Do not use automatic encoding translation for; portable libs&#x2F;applications.; http://php.net/mbstring.encoding-translation;mbstring.encoding_translation &#x3D; Off ; automatic encoding detection order.; auto means; http://php.net/mbstring.detect-order;mbstring.detect_order &#x3D; auto ; substitute_character used when character cannot be converted; one from another; http://php.net/mbstring.substitute-character;mbstring.substitute_character &#x3D; none; ; overload(replace) single byte functions by mbstring functions.; mail(), ereg(), etc are overloaded by mb_send_mail(), mb_ereg(),; etc. Possible values are 0,1,2,4 or combination of them.; For example, 7 for overload everything.; 0: No overload; 1: Overload mail() function; 2: Overload str*() functions; 4: Overload ereg*() functions; http://php.net/mbstring.func-overload;mbstring.func_overload &#x3D; 0 ; enable strict encoding detection.;mbstring.strict_detection &#x3D; Off ; This directive specifies the regex pattern of content types for which mb_output_handler(); is activated.; Default: mbstring.http_output_conv_mimetype&#x3D;^(text&#x2F;|application&#x2F;xhtml+xml);mbstring.http_output_conv_mimetype&#x3D; ; Allows to set script encoding. Only affects if PHP is compiled with –enable-zend-multibyte; Default: “”;mbstring.script_encoding&#x3D; [gd]; Tell the jpeg decode to ignore warnings and try to create; a gd image. The warning will then be displayed as notices; disabled by default; http://php.net/gd.jpeg-ignore-warning;gd.jpeg_ignore_warning &#x3D; 0 [exif]; Exif UNICODE user comments are handled as UCS-2BE&#x2F;UCS-2LE and JIS as JIS.; With mbstring support this will automatically be converted into the encoding; given by corresponding encode setting. When empty mbstring.internal_encoding; is used. For the decode settings you can distinguish between motorola and; intel byte order. A decode setting cannot be empty.; http://php.net/exif.encode-unicode;exif.encode_unicode &#x3D; ISO-8859-15 ; http://php.net/exif.decode-unicode-motorola;exif.decode_unicode_motorola &#x3D; UCS-2BE ; http://php.net/exif.decode-unicode-intel;exif.decode_unicode_intel &#x3D; UCS-2LE ; http://php.net/exif.encode-jis;exif.encode_jis &#x3D; ; http://php.net/exif.decode-jis-motorola;exif.decode_jis_motorola &#x3D; JIS ; http://php.net/exif.decode-jis-intel;exif.decode_jis_intel &#x3D; JIS [Tidy]; The path to a default tidy configuration file to use when using tidy; http://php.net/tidy.default-config;tidy.default_config &#x3D; &#x2F;usr&#x2F;local&#x2F;lib&#x2F;php&#x2F;default.tcfg ; Should tidy clean and repair output automatically?; WARNING: Do not use this option if you are generating non-html content; such as dynamic images; http://php.net/tidy.clean-outputtidy.clean_output &#x3D; Off [soap]; Enables or disables WSDL caching feature.; http://php.net/soap.wsdl-cache-enabledsoap.wsdl_cache_enabled&#x3D;1 ; Sets the directory name where SOAP extension will put cache files.; http://php.net/soap.wsdl-cache-dirsoap.wsdl_cache_dir&#x3D;”&#x2F;tmp” ; (time to live) Sets the number of second while cached file will be used; instead of original one.; http://php.net/soap.wsdl-cache-ttlsoap.wsdl_cache_ttl&#x3D;86400 ; Sets the size of the cache limit. (Max. number of WSDL files to cache)soap.wsdl_cache_limit &#x3D; 5 [sysvshm]; A default size of the shared memory segment;sysvshm.init_mem &#x3D; 10000 [ldap]; Sets the maximum number of open links or -1 for unlimited.ldap.max_links &#x3D; -1 [mcrypt]; For more information about mcrypt settings see http://php.net/mcrypt-module-open ; Directory where to load mcrypt algorithms; Default: Compiled in into libmcrypt (usually &#x2F;usr&#x2F;local&#x2F;lib&#x2F;libmcrypt);mcrypt.algorithms_dir&#x3D; ; Directory where to load mcrypt modes; Default: Compiled in into libmcrypt (usually &#x2F;usr&#x2F;local&#x2F;lib&#x2F;libmcrypt);mcrypt.modes_dir&#x3D; [dba];dba.default_handler&#x3D;; Local Variables:; tab-width: 4[APC]extension &#x3D; “apc.so”apc.enabled &#x3D; 1apc.cache_by_default &#x3D; onapc.shm_size &#x3D; 32Mapc.ttl &#x3D; 600apc.user_ttl &#x3D; 600apc.write_lock &#x3D; on; End:","categories":["Linux配置文件","lamp"]},{"title":"docker-cheat-sheet","path":"/2023/09/28/Linux配置文件/docker/docker-cheat-sheet/","content":"Docker Cheat Sheet 内容主要搬迁自：Docker Cheat Sheet 为何使用 Docker 运维 容器(Container) 镜像(Images) 网络(Networks) 仓管中心和仓库(Registry &amp; Repository) Dockerfile 层(Layers) 链接(Links) 卷标(Volumes) 暴露端口(Exposing ports) 最佳实践 安全(Security) 小贴士 参考资料 为何使用 Docker「通过 Docker，开发者可以使用任何语言任何工具创建任何应用。“Dockerized” 的应用是完全可移植的，能在任何地方运行 - 不管是同事的 OS X 和 Windows 笔记本，或是在云端运行的 Ubuntu QA 服务，还是在虚拟机运行的 Red Hat 产品数据中心。 Docker Hub 上有 13000+ 的应用，开发者可以从中选取一个进行快速扩展开发。Docker 跟踪管理变更和依赖关系，让系统管理员能更容易理解开发人员是如何让应用运转起来的。而开发者可以通过 Docker Hub 的共有&#x2F;私有仓库，构建他们的自动化编译，与其他合作者共享成果。 Docker 帮助开发者更快地构建和发布高质量的应用。」—— 什么是 Docker 运维安装Docker 是一个开源的商业产品，有两个版本：社区版（Community Edition，缩写为 CE）和企业版（Enterprise Edition，缩写为 EE）。企业版包含了一些收费服务，个人开发者一般用不到。 Docker CE 的安装请参考官方文档。 Mac Windows Ubuntu Debian CentOS Fedora 其他 Linux 发行版 检查版本docker version 查看你正在运行的 Docker 版本。 获取 Docker 服务版本： 1docker version --format &#x27;&#123;&#123;.Server.Version&#125;&#125;&#x27; 你也可以输出原始的 JSON 数据： 1docker version --format &#x27;&#123;&#123;json .&#125;&#125;&#x27; Docker 加速国内访问 Docker Hub 很慢，所以，推荐配置 Docker 镜像仓库来提速。 镜像仓库清单： 镜像仓库 镜像仓库地址 说明 DaoCloud 镜像站 http://f1361db2.m.daocloud.io 开发者需要开通 DaoCloud 账户，然后可以得到专属加速器。 阿里云 https://yourcode.mirror.aliyuncs.com 开发者需要开通阿里开发者帐户，再使用阿里的加速服务。登录后阿里开发者帐户后，https://cr.console.aliyun.com/undefined/instances/mirrors 中查看你的您的专属加速器地址。 网易云 https://hub-mirror.c.163.com 直接配置即可，亲测较为稳定。 配置镜像仓库方法（以 CentOS 为例）： 下面的示例为在 CentOS 环境中，指定镜像仓库为 https://hub-mirror.c.163.com （1）修改配置文件 修改 /etc/docker/daemon.json ，如果不存在则新建。执行以下 Shell： 12345678sudo mkdir -p /etc/dockercat &gt;&gt; /etc/docker/daemon.json &lt;&lt; EOF&#123; &quot;registry-mirrors&quot;: [ &quot;https://hub-mirror.c.163.com&quot; ]&#125;EOF 重启 docker 以生效： 12sudo systemctl daemon-reloadsudo systemctl restart docker 执行 docker info 命令，查看 Registry Mirrors 是否已被改为 https://hub-mirror.c.163.com ，如果是，则表示配置成功。 容器(Container)关于 Docker 进程隔离的基础。容器 (Container) 之于虚拟机 (Virtual Machine) 就好比线程之于进程。或者你可以把他们想成是「吃了类固醇的 chroots」。 生命周期 docker create 创建容器但不启动它。 docker rename 用于重命名容器。 docker run 一键创建并同时启动该容器。 docker rm 删除容器。 如果要删除一个运行中的容器，可以添加 -f 参数。Docker 会发送 SIGKILL 信号给容器。 docker update 调整容器的资源限制。 清理掉所有处于终止状态的容器。 通常情况下，不使用任何命令行选项启动一个容器，该容器将会立即启动并停止。若需保持其运行，你可以使用 docker run -td container_id 命令。选项 -t 表示分配一个 pseudo-TTY 会话，-d 表示自动将容器与终端分离（也就是说在后台运行容器，并输出容器 ID）。 如果你需要一个临时容器，可使用 docker run --rm 会在容器停止之后删除它。 如果你需要映射宿主机 (host) 的目录到 Docker 容器内，可使用 docker run -v $HOSTDIR:$DOCKERDIR。详见 卷标(Volumes) 一节。 如果你想同时删除与容器相关联的卷标，那么在删除容器的时候必须包含 -v 选项，像这样 docker rm -v。 从 Docker 1.10 起，其内置一套各容器独立的 日志引擎，每个容器可以独立使用。你可以使用 docker run --log-driver=syslog 来自定义日志引擎（例如以上的 syslog）。 启动和停止 docker start 启动已存在的容器。 docker stop 停止运行中的容器。 docker restart 重启容器。 docker pause 暂停运行中的容器，将其「冻结」在当前状态。 docker unpause 结束容器暂停状态。 docker wait 阻塞地等待某个运行中的容器直到停止。 docker kill 向运行中的容器发送 SIGKILL 指令。 docker attach 连接到运行中的容器。 如果你想将容器的端口 (ports) 暴露至宿主机，请见 暴露端口 一节。 关于 Docker 实例崩溃后的重启策略，详见 本文。 CPU 限制你可以限制 CPU 资源占用，无论是指定百分比，或是特定核心数。 例如，你可以设置 cpu-shares。该配置看起来有点奇怪 – 1024 表示 100% CPU，因此如果你希望容器使用所有 CPU 内核的 50%，应将其设置为 512： 1docker run -ti --c 512 agileek/cpuset-test 更多信息请参阅 https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/#_cpu。 通过 cpuset-cpus 可使用特定 CPU 内核。 1docker run -ti --cpuset-cpus=0,4,6 agileek/cpuset-test 请参阅 https://agileek.github.io/docker/2014/08/06/docker-cpuset/ 获取更多细节以及一些不错的视频。 注意，Docker 在容器内仍然能够 看到 全部 CPU – 它仅仅是不使用全部而已。请参阅 https://github.com/docker/docker/issues/20770 获取更多细节。 内存限制同样，亦可给 Docker 设置 内存限制： 1docker run -it -m 300M ubuntu:14.04 /bin/bash 能力(Capabilities)Linux 的 Capability 可以通过使用 cap-add 和 cap-drop 设置。请参阅 https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities 获取更多细节。这有助于提高安全性。 如需要挂载基于 FUSE 的文件系统，你需要结合 --cap-add 和 --device 使用： 1docker run --rm -it --cap-add SYS_ADMIN --device /dev/fuse sshfs 授予对某个设备的访问权限： 1docker run -it --device=/dev/ttyUSB0 debian bash 授予对所有设备的访问权限： 1docker run -it --privileged -v /dev/bus/usb:/dev/bus/usb debian bash 有关容器特权的更多信息请参阅 本文。 信息 docker ps 查看运行中的所有容器。 docker logs 从容器中读取日志。（你也可以使用自定义日志驱动，不过在 1.10 中，它只支持 json-file 和 journald）。 docker inspect 查看某个容器的所有信息（包括 IP 地址）。 docker events 从容器中获取事件 (events)。 docker port 查看容器的公开端口。 docker top 查看容器中活动进程。 docker stats 查看容器的资源使用量统计信息。 docker diff 查看容器文件系统中存在改动的文件。 docker ps -a 将显示所有容器，包括运行中和已停止的。 docker stats --all 同样将显示所有容器，默认仅显示运行中的容器。 导入 &#x2F; 导出 docker cp 在容器和本地文件系统之间复制文件或目录。 docker export 将容器的文件系统打包为归档文件流 (tarball archive stream) 并输出至标准输出 (STDOUT)。 执行命令 docker exec 在容器内执行命令。 例如，进入正在运行的 foo 容器，并连接 (attach) 到一个新的 Shell 进程：docker exec -it foo /bin/bash。 镜像(Images)镜像是 Docker 容器的模板。 生命周期 docker images 查看所有镜像。 docker import 从归档文件创建镜像。 docker build 从 Dockerfile 创建镜像。 docker commit 为容器创建镜像，如果容器正在运行则会临时暂停。 docker rmi 删除镜像。 docker load 从标准输入 (STDIN) 加载归档包 (tar archive) 作为镜像，包括镜像本身和标签 (tags, 0.7 起)。 docker save 将镜像打包为归档包，并输出至标准输出 (STDOUT)，包括所有的父层、标签和版本 (parent layers, tags, versions, 0.7 起)。 其它信息 docker history 查看镜像的历史记录。 docker tag 给镜像打标签命名（本地或者仓库均可）。 清理虽然你可以用 docker rmi 命令来删除指定的镜像，不过有个名为 docker-gc 的工具，它可以以一种安全的方式，清理掉那些不再被任何容器使用的镜像。Docker 1.13 起，使用 docker image prune 亦可删除未使用的镜像。参见 清理。 加载 &#x2F; 保存镜像从文件中加载镜像： 1docker load &lt; my_image.tar.gz 保存既有镜像： 1docker save my_image:my_tag | gzip &gt; my_image.tar.gz 导入 &#x2F; 导出容器从文件中导入容器镜像： 1cat my_container.tar.gz | docker import - my_image:my_tag 导出既有容器： 1docker export my_container | gzip &gt; my_container.tar.gz 加载已保存的镜像 与 导入已导出为镜像的容器 的不同通过 load 命令来加载镜像，会创建一个新的镜像，并继承原镜像的所有历史。 通过 import 将容器作为镜像导入，也会创建一个新的镜像，但并不包含原镜像的历史，因此会比使用 load 方式生成的镜像更小。 网络(Networks)Docker 具备 网络 功能。我并不是很了解它，所以这是一个扩展本文的好地方。文档 使用网络 指出，这是一种无需暴露端口即可实现 Docker 容器间通信的好方法。 生命周期 docker network create docker network rm 其它信息 docker network ls docker network inspect 建立连接 docker network connect docker network disconnect 你可以 为容器指定 IP 地址： 12345678# 使用你自己的子网和网关创建一个桥接网络docker network create --subnet 203.0.113.0/24 --gateway 203.0.113.254 iptastic# 基于以上创建的网络，运行一个 Nginx 容器并指定 IP$ docker run --rm -it --net iptastic --ip 203.0.113.2 nginx# 在其他地方使用 CURL 访问这个 IP（假设该 IP 为公网）$ curl 203.0.113.2 暴露端口(Exposing ports)通过宿主容器暴露输入端口相当 繁琐但有效的。 例如使用 -p 将容器端口映射到宿主端口上（只使用本地主机 (localhost) 接口）： 1docker run -p 127.0.0.1:$HOSTPORT:$CONTAINERPORT --name CONTAINER -t someimage 你可以使用 EXPOSE 告知 Docker，该容器在运行时监听指定的端口： 1EXPOSE &lt;CONTAINERPORT&gt; 但是注意 EXPOSE 并不会直接暴露端口，你需要用参数 -p 。比如说你要在 localhost 上暴露容器的端口: 1iptables -t nat -A DOCKER -p tcp --dport &lt;LOCALHOSTPORT&gt; -j DNAT --to-destination &lt;CONTAINERIP&gt;:&lt;PORT&gt; 如果你是在 Virtualbox 中运行 Docker，那么你需要配置端口转发 (forward the port)。使用 forwarded_port 在 Vagrantfile 上配置暴露的端口范围，这样你就可以动态地映射了： 123456789Vagrant.configure(VAGRANTFILE_API_VERSION) do |config| ... (49000..49900).each do |port| config.vm.network :forwarded_port, :host =&gt; port, :guest =&gt; port end ...end 如果你忘记了将什么端口映射到宿主机上的话，可使用 docker port 查看： 1docker port CONTAINER $CONTAINERPORT 仓管中心和仓库(Registry &amp; Repository)仓库 (repository) 是 被托管(hosted) 的已命名镜像 (tagged images) 的集合，这组镜像用于构建容器文件系统。 仓管中心 (registry) 则是 托管服务(host) – 用于存储仓库并提供 HTTP API，以便 管理仓库的上传和下载。 Docker 官方托管着自己的 仓管中心，包含着数量众多的仓库。不过话虽如此，这个仓管中心 并没有很好地验证镜像，所以如果你担心安全问题的话，请尽量避免使用它。 docker login 登入仓管中心。 docker logout 登出仓管中心。 docker search 从仓管中心检索镜像。 docker pull 从仓管中心拉取镜像到本地。 docker push 从本地推送镜像到仓管中心。 本地仓管中心你可以使用 docker distribution 项目搭建本地的仓管中心，详情参阅 本地发布 (local deploy) 的介绍。 科学上网后，也可以看看 Google+ Group。 Dockerfile当你执行 docker build 时，Docker 将会根据 配置文件 启动 Docker 容器。远优于使用 docker commit。 以下是一些编写 Dockerfile 的常用编辑器，并链接到适配的语法高亮模块︰ 如果你在使用 jEdit，你可以使用我开发的 Dockerfile 语法高亮模块。 [Sublime Text 2](https://packagecontrol.io/packages/Dockerfile Syntax Highlighting) Atom Vim Emacs TextMate 更多信息请参阅 Docker 遇上 IDE 指令 .dockerignore FROM 为其他指令设置基础镜像 (Base Image)。 MAINTAINER (deprecated - use LABEL instead) 为生成的镜像设置作者字段。 RUN 在当前镜像的基础上生成一个新层并执行命令。 CMD 设置容器默认执行命令。 EXPOSE 告知 Docker 容器在运行时所要监听的网络端口。注意：并没有实际上将端口设置为可访问。 ENV 设置环境变量。 ADD 将文件、目录或远程文件复制到容器中。缓存无效。请尽量用 COPY 代替 ADD。 COPY 将文件或文件夹复制到容器中。注意：将使用 ROOT 用户复制文件，故无论 USER &#x2F; WORKDIR 指令如何配置，你都需要手动修改其所有者（chown），ADD 也是一样。 ENTRYPOINT 将容器设为可执行的。 VOLUME 在容器内部创建挂载点 (mount point) 指向外部挂载的卷标或其他容器。 USER 设置随后执行 RUN &#x2F; CMD &#x2F; ENTRYPOINT 命令的用户名。 WORKDIR 设置工作目录 (working directory)。 ARG 定义编译时 (build-time) 变量。 ONBUILD 添加触发指令，当该镜像被作为其他镜像的基础镜像时该指令会被触发。 STOPSIGNAL 设置停止容器时，向容器内发送的系统调用信号 (system call signal)。 LABEL 将键值对元数据 (key&#x2F;value metadata) 应用到镜像、容器或是守护进程。 教程 Flux7’s Dockerfile Tutorial 例子 Examples Best practices for writing Dockerfiles Michael Crosby 还有更多的 Dockerfiles best practices &#x2F; take 2 Building Good Docker Images &#x2F; Building Better Docker Images Managing Container Configuration with Metadata 层(Layers)Docker 的版本化文件系统是基于层的。就像 Git 的提交或文件变更系统 一样。 链接(Links)链接 (links) 通过 TCP&#x2F;IP 端口 实现 Docker 容器之间的通讯。Atlassian 展示了可用的例子。你还可以 通过主机名 (hostname) 链接。 在某种意义上来说，该特性已经被 自定义网络 所替代。 注意: 如果你希望容器之间只通过链接进行通讯，在启动 Docker 守护进程时，请使用 -icc=false 来禁用内部进程通讯。 假设你有一个名为 CONTAINER 的容器（通过 docker run --name CONTAINER 指定）并且在 Dockerfile 中，暴露了一个端口: 1EXPOSE 1337 然后，我们创建另外一个名为 LINKED 的容器: 1docker run -d --link CONTAINER:ALIAS --name LINKED user/wordpress 然后 CONTAINER 暴露的端口和别名将会以如下的环境变量出现在 LINKED 中: 12$ALIAS_PORT_1337_TCP_PORT$ALIAS_PORT_1337_TCP_ADDR 那么你便可以通过这种方式来连接它了。 使用 docker rm --link 即可删除链接。 通常，Docker 容器（亦可理解为「服务」）之间的链接，是「服务发现」的一个子集。如果你打算在生产中大规模使用 Docker，这将是一个很大的问题。请参阅The Docker Ecosystem: Service Discovery and Distributed Configuration Stores 获取更多信息。 卷标(Volumes)和挂载卷标Docker 的卷标 (volumes) 是 独立的文件系统。它们并非必须连接到特定的容器上。 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性： 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 卷标相关命令： docker volume create - 创建卷标 docker volume rm - 删除卷标 docker volume ls - 查看卷标 docker volume inspect - 查看数据卷的具体信息 docker volume prune - 清理无主的数据卷 卷标在不能使用链接（只有 TCP&#x2F;IP）的情况下非常有用。例如，如果你有两个 Docker 实例需要通讯并在文件系统上留下记录。 你可以一次性将其挂载到多个 docker 容器上，通过 docker run --volumes-from。 因为卷标是独立的文件系统，它们通常被用于存储各容器之间的瞬时状态。也就是说，你可以配置一个无状态临时容器，关掉之后，当你有第二个这种临时容器实例的时候，你可以从上一次保存的状态继续执行。 查看 卷标进阶 来获取更多细节。Container42 非常有用。 你可以 将宿主 MacOS 的文件夹映射为 Docker 卷标： 1docker run -v /Users/wsargent/myapp/src:/src 你也可以用远程 NFS 卷标，如果你觉得你 有足够勇气。 还可以考虑运行一个纯数据容器，像 这里 所说的那样，提供可移植数据。 记得，文件也可以被挂载为卷标。 挂载使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。 在用 docker run 命令的时候，使用 --mount 标记来将 数据卷 挂载到容器里。在一次 docker run 中可以挂载多个 数据卷。 最佳实践这里有一些最佳实践，以及争论焦点： The Rabbit Hole of Using Docker in Automated Tests Bridget Kromhout has a useful blog post on running Docker in production at Dramafever. There’s also a best practices blog post from Lyst. A Docker Dev Environment in 24 Hours! Building a Development Environment With Docker Discourse in a Docker Container 安全(Security)这节准备讨论一些关于 Docker 安全性的问题。Docker 官方文档 安全 页面讲述了更多细节。 首先第一件事：Docker 是有 root 权限的。如果你在 docker 组，那么你就有 root 权限。如果你将 Docker 的 Unix Socket 暴露给容器，意味着你赋予了容器 宿主机 root 权限。 Docker 不应当作为唯一的防御措施。你应当使其更加安全可靠。 为了更好地理解容器暴露了什么，可参阅由 Aaron Grattafiori 编写的 Understanding and Hardening Linux Containers。这是一个完整全面且包含大量链接和脚注的容器问题指南，介绍了许多有用的内容。即使你已经加固过容器，以下的安全提示依然十分有帮助，但并不能代替理解的过程。 安全提示为了最大的安全性，你应当考虑在虚拟机上运行 Docker。这是直接从 Docker 安全团队拿来的资料 – slides &#x2F; notes。之后，可使用 AppArmor、seccomp、SELinux、grsec 等来 限制容器的权限。更多细节，请查阅 Docker 1.10 security features。 Docker 镜像 ID 属于 敏感信息 所以它不应该向外界公开。请将它们当作密码来对待。 阅读由 Thomas Sjögren 编写的 Docker Security Cheat Sheet：关于加固容器的不错的建议。 查看 Docker 安全测试脚本，下载 最佳实践白皮书。 你应当远离使用非稳定版本 grsecurity &#x2F; pax 的内核，比如 Alpine Linux。如果在产品中用了 grsecurity，那么你应该考虑使用有 商业支持 的 稳定版本，就像你对待 RedHat 那样。虽然要 $200 每月，但对于你的运维预算来说不值一提。 从 Docker 1.11 开始，你可以轻松的限制在容器中可用的进程数，以防止 fork 炸弹。 这要求 Linux 内核 &gt;&#x3D; 4.3，并且要在内核配置中打开 CGROUP_PIDS&#x3D;y。 1docker run --pids-limit=64 同时，你也可以限制进程再获取新权限。该功能是 Linux 内核从 3.5 版本开始就拥有的。你可以从 这篇博客 中阅读到更多关于这方面的内容。 1docker run --security-opt=no-new-privileges 以下内容摘选自 Container Solutions 的 Docker Security Cheat Sheet（PDF 版本，难以使用，故复制至此）： 关闭内部进程通讯： 1docker -d --icc=false --iptables 设置容器为只读： 1docker run --read-only 通过 hashsum 来验证卷标： 1docker pull debian@sha256:a25306f3850e1bd44541976aa7b5fd0a29be 设置卷标为只读： 1docker run -v $(pwd)/secrets:/secrets:ro debian 在 Dockerfile 中定义用户并以该用户运行，避免在容器中以 ROOT 身份操作： 12RUN groupadd -r user &amp;&amp; useradd -r -g user userUSER user 用户命名空间(User Namespaces)还可以通过使用 用户命名空间 – 自 1.10 版本起已内置，但默认并未启用。 要在 Ubuntu 15.10 中启用用户命名空间 (remap the userns)，请 跟着这篇博客的例子 来做。 安全相关视频 Using Docker Safely Securing your applications using Docker Container security: Do containers actually contain? Linux Containers: Future or Fantasy? 安全路线图Docker 的路线图提到关于 seccomp 的支持。 一个名为 bane 的 AppArmor 策略生成器正在实现 安全配置文件。 小贴士链接： 15 Docker Tips in 5 minutes CodeFresh Everyday Hacks Docker 清理最新的 数据管理命令 已在 Docker 1.13 实现： docker system prune docker volume prune docker network prune docker container prune docker image prune df 命令docker system df 将显示当前 Docker 各部分占用的磁盘空间。 Heredoc 声明 Docker 容器1234docker build -t htop - &lt;&lt; EOFFROM alpineRUN apk --no-cache add htopEOF 最近一次的容器 ID123alias dl=&#x27;docker ps -l -q&#x27;docker run ubuntu echo hello worlddocker commit $(dl) helloworld 带命令的提交（需要 Dockerfile）1docker commit -run=&#x27;&#123;&quot;Cmd&quot;:[&quot;postgres&quot;, &quot;-too -many -opts&quot;]&#125;&#x27; $(dl) postgres 获取 IP 地址1docker inspect $(dl) | grep -wm1 IPAddress | cut -d &#x27;&quot;&#x27; -f 4 或使用 jq: 1docker inspect $(dl) | jq -r &#x27;.[0].NetworkSettings.IPAddress&#x27; 或使用 go 模板： 1docker inspect -f &#x27;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&#x27; &lt;container_name&gt; 或在通过 Dockerfile 构建镜像时，通过构建参数 (build argument) 传入： 123456DOCKER_HOST_IP=`ifconfig | grep -E &quot;([0-9]&#123;1,3&#125;\\.)&#123;3&#125;[0-9]&#123;1,3&#125;&quot; | grep -v 127.0.0.1 | awk &#x27;&#123; print $2 &#125;&#x27; | cut -f2 -d: | head -n1`echo DOCKER_HOST_IP = $DOCKER_HOST_IPdocker build \\ --build-arg ARTIFACTORY_ADDRESS=$DOCKER_HOST_IP -t sometag \\ some-directory/ 获取端口映射1docker inspect -f &#x27;&#123;&#123;range $p, $conf := .NetworkSettings.Ports&#125;&#125; &#123;&#123;$p&#125;&#125; -&gt; &#123;&#123;(index $conf 0).HostPort&#125;&#125; &#123;&#123;end&#125;&#125;&#x27; &lt;containername&gt; 通过正则匹配容器1for i in $(docker ps -a | grep &quot;REGEXP_PATTERN&quot; | cut -f1 -d&quot; &quot;); do echo $i; done` 获取环境变量配置1docker run --rm ubuntu env 强行终止运行中的容器1docker kill $(docker ps -q) 删除所有容器（强行删除！无论容器运行或停止）1docker rm -f $(docker ps -qa) 删除旧容器1docker ps -a | grep &#x27;weeks ago&#x27; | awk &#x27;&#123;print $1&#125;&#x27; | xargs docker rm 删除已停止的容器1docker rm -v `docker ps -a -q -f status=exited` 停止并删除容器1docker stop $(docker ps -aq) &amp;&amp; docker rm -v $(docker ps -aq) 删除无用 (dangling) 的镜像1docker rmi $(docker images -q -f dangling=true) 删除所有镜像1docker rmi $(docker images -q) 删除无用 (dangling) 的卷标Docker 1.9 版本起： 1docker volume rm $(docker volume ls -q -f dangling=true) 1.9.0 中，参数 dangling=false 居然 没 用 - 它会被忽略然后列出所有的卷标。 查看镜像依赖1docker images -viz | dot -Tpng -o docker.png Docker 容器瘦身 在某层 (RUN layer) 清理 APT 这应当和其他 apt 命令在同一层中完成。 否则，前面的层将会保持原有信息，而你的镜像则依旧臃肿。 123RUN &#123;apt commands&#125; \\ &amp;&amp; apt-get clean \\ &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* 压缩镜像 12ID=$(docker run -d image-name /bin/bash)docker export $ID | docker import – flat-image-name 备份 123ID=$(docker run -d image-name /bin/bash)(docker export $ID | gzip -c &gt; image.tgz)gzip -dc image.tgz | docker import - flat-image-name 监视运行中容器的系统资源利用率检查某个容器的 CPU、内存以及网络 I&#x2F;O 使用情况，你可以： 1docker stats &lt;container&gt; 按 ID 列出所有容器： 1docker stats $(docker ps -q) 按名称列出所有容器： 1docker stats $(docker ps --format &#x27;&#123;&#123;.Names&#125;&#125;&#x27;) 按指定镜像名称列出所有容器： 1docker ps -a -f ancestor=ubuntu 删除所有未标签命名 (untagged) 的容器： 1docker rmi $(docker images | grep “^” | awk &#x27;&#123;split($0,a,&quot; &quot;); print a[3]&#125;&#x27;) 通过正则匹配删除指定容器： 1docker ps -a | grep wildfly | awk &#x27;&#123;print $1&#125;&#x27; | xargs docker rm -f 删除所有已退出 (exited) 的容器： 1docker rm -f $(docker ps -a | grep Exit | awk &#x27;&#123; print $1 &#125;&#x27;) 将文件挂载为卷标文件也可以被挂载为卷标。例如你可以仅仅注入单个配置文件： 12345678# 从容器复制文件docker run --rm httpd cat /usr/local/apache2/conf/httpd.conf &gt; httpd.conf# 编辑文件vim httpd.conf# 挂载修改后的配置启动容器docker run --rm -ti -v &quot;$PWD/httpd.conf:/usr/local/apache2/conf/httpd.conf:ro&quot; -p &quot;80:80&quot; httpd 参考资料 Docker Cheat Sheet","categories":["Linux配置文件","docker"]},{"title":"docker-dockerfile","path":"/2023/09/28/Linux配置文件/docker/docker-dockerfile/","content":"Dockerfile 最佳实践 一、Dockerfile 指令 FROM(指定基础镜像) RUN(执行命令) COPY(复制文件) ADD(更高级的复制文件) CMD(容器启动命令) ENTRYPOINT(入口点) ENV(设置环境变量) ARG(构建参数) VOLUME(定义匿名卷) EXPOSE(暴露端口) WORKDIR(指定工作目录) USER(指定当前用户) HEALTHCHECK(健康检查) ONBUILD(为他人作嫁衣裳) 参考资料 一、Dockerfile 简介Docker 镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。 Dockerfile 是一个文本文件，其内包含了一条条的 **指令(Instruction)**，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 使用 Dockerfile 构建镜像二、Dockerfile 指令详解FROM(指定基础镜像) 作用：**FROM 指令用于指定基础镜像**。 所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 nginx 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 FROM 就是指定基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。 在 Docker Store 上有非常多的高质量的官方镜像，有可以直接拿来使用的服务类的镜像，如 nginx、redis、mongo、mysql、httpd、php、tomcat 等；也有一些方便开发、构建、运行各种语言应用的镜像，如 node、openjdk、python、ruby、golang 等。可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制。 如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的操作系统镜像，如 ubuntu、debian、centos、fedora、alpine 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。 除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。 12FROM scratch... 如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。 不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 swarm、coreos/etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。 RUN(执行命令) RUN 指令是用来执行命令行命令的。由于命令行的强大能力，RUN 指令在定制镜像时是最常用的指令之一。其格式有两种： shell 格式：RUN &lt;命令&gt;，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 RUN 指令就是这种格式。 1RUN echo &#x27;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&#x27; &gt; /usr/share/nginx/html/index.html exec 格式：RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]，这更像是函数调用中的格式。 既然 RUN 就像 Shell 脚本一样可以执行命令，那么我们是否就可以像 Shell 脚本一样把每个命令对应一个 RUN 呢？比如这样： 123456789FROM debian:jessieRUN apt-get updateRUN apt-get install -y gcc libc6-dev makeRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install 之前说过，Dockerfile 中每一个指令都会建立一层，RUN 也不例外。每一个 RUN 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，commit 这一层的修改，构成新的镜像。 而上面的这种写法，创建了 7 层镜像。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。 这是很多初学 Docker 的人常犯的一个错误。 Union FS 是有最大层数限制的，比如 AUFS，曾经是最大不得超过 42 层，现在是不得超过 127 层。 上面的 Dockerfile 正确的写法应该是这样： 1234567891011121314FROM debian:jessieRUN buildDeps=&#x27;gcc libc6-dev make&#x27; \\ &amp;&amp; apt-get update \\ &amp;&amp; apt-get install -y $buildDeps \\ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; \\ &amp;&amp; mkdir -p /usr/src/redis \\ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\ &amp;&amp; make -C /usr/src/redis \\ &amp;&amp; make -C /usr/src/redis install \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; rm redis.tar.gz \\ &amp;&amp; rm -r /usr/src/redis \\ &amp;&amp; apt-get purge -y --auto-remove $buildDeps 首先，之前所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 RUN 对一一对应不同的命令，而是仅仅使用一个 RUN 指令，并使用 &amp;&amp; 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。 并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加 \\ 的命令换行方式，以及行首 # 进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。 此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 apt 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。 很多人初学 Docker 制作出了很臃肿的镜像的原因之一，就是忘记了每一层构建的最后一定要清理掉无关文件。 COPY(复制文件) COPY 指令将从构建上下文目录中 &lt;源路径&gt; 的文件&#x2F;目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置。 格式： COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径&gt;... &lt;目标路径&gt; COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 示例： 1COPY package.json /usr/src/app/ &lt;源路径&gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则，如： 12COPY hom* /mydir/COPY hom?.txt /mydir/ &lt;目标路径&gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。 此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。 在使用该指令的时候还可以加上 --chown=&lt;user&gt;:&lt;group&gt; 选项来改变文件的所属用户及所属组。 1234COPY --chown=55:mygroup files* /mydir/COPY --chown=bin files* /mydir/COPY --chown=1 files* /mydir/COPY --chown=10:11 files* /mydir/ ADD(更高级的复制文件) ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。 比如 &lt;源路径&gt; 可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 &lt;目标路径&gt;去。下载后的文件权限自动设置为 600，如果这并不是想要的权限，那么还需要增加额外的一层 RUN 进行权限调整，另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 RUN 指令进行解压缩。所以不如直接使用 RUN 指令，然后使用 wget 或者 curl 工具下载，处理权限、解压缩、然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。 如果 &lt;源路径&gt; 为一个 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，ADD 指令将会自动解压缩这个压缩文件到 &lt;目标路径&gt; 去。 在某些情况下，这个自动解压缩的功能非常有用，比如官方镜像 ubuntu 中： 123FROM scratchADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /... 但在某些情况下，如果我们真的是希望复制个压缩文件进去，而不解压缩，这时就不可以使用 ADD 命令了。 在 Docker 官方的 Dockerfile 最佳实践文档 中要求，尽可能的使用 COPY，因为 COPY 的语义很明确，就是复制文件而已，而 ADD 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 ADD 的场合，就是所提及的需要自动解压缩的场合。 另外需要注意的是，ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。 因此在 COPY 和 ADD 指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADD。 在使用该指令的时候还可以加上 --chown=&lt;user&gt;:&lt;group&gt; 选项来改变文件的所属用户及所属组。 1234ADD --chown=55:mygroup files* /mydir/ADD --chown=bin files* /mydir/ADD --chown=1 files* /mydir/ADD --chown=10:11 files* /mydir/ CMD(容器启动命令) 之前介绍容器的时候曾经说过，Docker 不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD 指令就是用于指定默认的容器主进程的启动命令的。 CMD 指令的格式和 RUN 相似，也是两种格式： shell 格式：CMD &lt;命令&gt; exec 格式：CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...] 参数列表格式：CMD [&quot;参数1&quot;, &quot;参数2&quot;...]。在指定了 ENTRYPOINT 指令后，用 CMD 指定具体的参数。 在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，ubuntu 镜像默认的 CMD 是 /bin/bash，如果我们直接 docker run -it ubuntu 的话，会直接进入 bash。我们也可以在运行时指定运行别的命令，如 docker run -it ubuntu cat /etc/os-release。这就是用 cat /etc/os-release 命令替换了默认的 /bin/bash 命令了，输出了系统版本信息。 在指令格式上，一般推荐使用 exec 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 &quot;，而不要使用单引号。 如果使用 shell 格式的话，实际的命令会被包装为 sh -c 的参数的形式进行执行。比如： 1CMD echo $HOME 在实际执行中，会将其变更为： 1CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ] 这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理。 提到 CMD 就不得不提容器中应用在前台执行和后台执行的问题。这是初学者常出现的一个混淆。 Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 upstart&#x2F;systemd 去启动后台服务，容器内没有后台服务的概念。 一些初学者将 CMD 写为： 1CMD service nginx start 然后发现容器执行后就立即退出了。甚至在容器内去使用 systemctl 命令结果却发现根本执行不了。这就是因为没有搞明白前台、后台的概念，没有区分容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。 对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 而使用 service nginx start 命令，则是希望 upstart 来以后台守护进程形式启动 nginx 服务。而刚才说了 CMD service nginx start 会被理解为 CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;]，因此主进程实际上是 sh。那么当 service nginx start 命令结束后，sh 也就结束了，sh 作为主进程退出了，自然就会令容器退出。 正确的做法是直接执行 nginx 可执行文件，并且要求以前台形式运行。比如： 1CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] ENTRYPOINT(入口点)ENTRYPOINT 的格式和 RUN 指令格式一样，分为 exec 格式和 shell 格式。 ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 --entrypoint 来指定。 当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为： 1&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 那么有了 CMD 后，为什么还要有 ENTRYPOINT 呢？这种 &lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 有什么好处么？让我们来看几个场景。 场景一：让镜像变成像命令一样使用假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 CMD 来实现： 12345FROM ubuntu:18.04RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lib/apt/lists/*CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;https://ip.cn&quot; ] 假如我们使用 docker build -t myip . 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行： 12$ docker run myip当前 IP：61.148.226.66 来自：北京市 联通 嗯，这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 CMD 中可以看到实质的命令是 curl，那么如果我们希望显示 HTTP 头信息，就需要加上 -i 参数。那么我们可以直接加 -i 参数给 docker run myip 么？ 12$ docker run myip -idocker: Error response from daemon: invalid header field value &quot;oci runtime error: container_linux.go:247: starting container process caused \\&quot;exec: \\\\\\&quot;-i\\\\\\&quot;: executable file not found in $PATH\\&quot; &quot;. 我们可以看到可执行文件找不到的报错，executable file not found。之前我们说过，跟在镜像名后面的是 command，运行时会替换 CMD 的默认值。因此这里的 -i 替换了原来的 CMD，而不是添加在原来的 curl -s https://ip.cn 后面。而 -i 根本不是命令，所以自然找不到。 那么如果我们希望加入 -i 这参数，我们就必须重新完整的输入这个命令： 1$ docker run myip curl -s https://ip.cn -i 这显然不是很好的解决方案，而使用 ENTRYPOINT 就可以解决这个问题。现在我们重新用 ENTRYPOINT 来实现这个镜像： 12345FROM ubuntu:18.04RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lib/apt/lists/*ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;https://ip.cn&quot; ] 这次我们再来尝试直接使用 docker run myip -i： 123456789101112131415161718$ docker run myip当前 IP：61.148.226.66 来自：北京市 联通$ docker run myip -iHTTP/1.1 200 OKServer: nginx/1.8.0Date: Tue, 22 Nov 2016 05:12:40 GMTContent-Type: text/html; charset=UTF-8Vary: Accept-EncodingX-Powered-By: PHP/5.6.24-1~dotdeb+7.1X-Cache: MISS from cache-2X-Cache-Lookup: MISS from cache-2:80X-Cache: MISS from proxy-2_6Transfer-Encoding: chunkedVia: 1.1 cache-2:80, 1.1 proxy-2_6:8006Connection: keep-alive当前 IP：61.148.226.66 来自：北京市 联通 可以看到，这次成功了。这是因为当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给 ENTRYPOINT，而这里 -i 就是新的 CMD，因此会作为参数传给 curl，从而达到了我们预期的效果。 场景二：应用运行前的准备工作启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。 比如 mysql 类的数据库，可能需要一些数据库配置、初始化的工作，这些工作要在最终的 mysql 服务器运行之前解决。 此外，可能希望避免使用 root 用户去启动服务，从而提高安全性，而在启动服务前还需要以 root 身份执行一些必要的准备工作，最后切换到服务用户身份启动服务。或者除了服务外，其它命令依旧可以使用 root 身份执行，方便调试等。 这些准备工作是和容器 CMD 无关的，无论 CMD 为什么，都需要事先进行一个预处理的工作。这种情况下，可以写一个脚本，然后放入 ENTRYPOINT 中去执行，而这个脚本会将接到的参数（也就是 &lt;CMD&gt;）作为命令，在脚本最后执行。比如官方镜像 redis 中就是这么做的： 12345678FROM alpine:3.4...RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis...ENTRYPOINT [&quot;docker-entrypoint.sh&quot;]EXPOSE 6379CMD [ &quot;redis-server&quot; ] 可以看到其中为了 redis 服务创建了 redis 用户，并在最后指定了 ENTRYPOINT 为 docker-entrypoint.sh 脚本。 123456789#!/bin/sh...# allow the container to be started with `--user`if [ &quot;$1&quot; = &#x27;redis-server&#x27; -a &quot;$(id -u)&quot; = &#x27;0&#x27; ]; then chown -R redis . exec su-exec redis &quot;$0&quot; &quot;$@&quot;fiexec &quot;$@&quot; 该脚本的内容就是根据 CMD 的内容来判断，如果是 redis-server 的话，则切换到 redis 用户身份启动服务器，否则依旧使用 root 身份执行。比如： 12$ docker run -it redis iduid=0(root) gid=0(root) groups=0(root) ENV(设置环境变量) ENV 指令用于设置环境变量。无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 格式： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 示例 1： 12ENV VERSION=1.0 DEBUG=on \\ NAME=&quot;Happy Feet&quot; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。 示例 2： 定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。比如在官方 node 镜像 Dockerfile 中，就有类似这样的代码： 123456789ENV NODE_VERSION 7.2.0RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \\ &amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; \\ &amp;&amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \\ &amp;&amp; grep &quot; node-v$NODE_VERSION-linux-x64.tar.xz\\$&quot; SHASUMS256.txt | sha256sum -c - \\ &amp;&amp; tar -xJf &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; -C /usr/local --strip-components=1 \\ &amp;&amp; rm &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; SHASUMS256.txt.asc SHASUMS256.txt \\ &amp;&amp; ln -s /usr/local/bin/node /usr/local/bin/nodejs 在这里先定义了环境变量 NODE_VERSION，其后的 RUN 这层里，多次使用 $NODE_VERSION 来进行操作定制。可以看到，将来升级镜像构建版本的时候，只需要更新 7.2.0 即可，Dockerfile 构建维护变得更轻松了。 下列指令可以支持环境变量展开： ADD、COPY、ENV、EXPOSE、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBUILD。 可以从这个指令列表里感觉到，环境变量可以使用的地方很多，很强大。通过环境变量，我们可以让一份 Dockerfile 制作更多的镜像，只需使用不同的环境变量即可。 ARG(构建参数) Dockerfile 中的 ARG 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 docker build 中用 --build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。 构建参数和 ENV 的效果一样，都是设置环境变量。所不同的是，ARG 所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用 ARG 保存密码之类的信息，因为 docker history 还是可以看到所有值的。 格式：ARG &lt;参数名&gt;[=&lt;默认值&gt;] 在 1.13 之前的版本，要求 --build-arg 中的参数名，必须在 Dockerfile 中用 ARG 定义过了，换句话说，就是 --build-arg 指定的参数，必须在 Dockerfile 中使用了。如果对应参数没有被使用，则会报错退出构建。从 1.13 开始，这种严格的限制被放开，不再报错退出，而是显示警告信息，并继续构建。这对于使用 CI 系统，用同样的构建流程构建不同的 Dockerfile 的时候比较有帮助，避免构建命令必须根据每个 Dockerfile 的内容修改。 VOLUME(定义匿名卷)格式： VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...] VOLUME &lt;路径&gt; 之前我们说过，容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中，后面的章节我们会进一步介绍 Docker 卷的概念。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。 1VOLUME /data 这里的 /data 目录就会在运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如： 1docker run -d -v mydata:/data xxxx 在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代了 Dockerfile 中定义的匿名卷的挂载配置。 EXPOSE(暴露端口) EXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 要将 EXPOSE 和在运行时使用 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 区分开来。-p，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。 格式：EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]。 WORKDIR(指定工作目录) 使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。 格式：WORKDIR &lt;工作目录路径&gt;。 示例 1： 之前提到一些初学者常犯的错误是把 Dockerfile 等同于 Shell 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误： 12RUN cd /appRUN echo &quot;hello&quot; &gt; world.txt 如果将这个 Dockerfile 进行构建镜像运行后，会发现找不到 /app/world.txt 文件，或者其内容不是 hello。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。 之前说过每一个 RUN 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 RUN cd /app 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。 因此如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR 指令。 LABELLABEL用于为镜像添加元数据，元数以键值对的形式指定： 1LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ... 使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。 如，通过LABEL指定一些元数据： 1LABEL version=&quot;1.0&quot; description=&quot;这是一个Web服务器&quot; by=&quot;IT笔录&quot; 指定后可以通过docker inspect查看： 123456$sudo docker inspect itbilu/test&quot;Labels&quot;: &#123; &quot;version&quot;: &quot;1.0&quot;, &quot;description&quot;: &quot;这是一个Web服务器&quot;, &quot;by&quot;: &quot;IT笔录&quot;&#125;, 注意；Dockerfile中还有个MAINTAINER命令，该命令用于指定镜像作者。但MAINTAINER并不推荐使用，更推荐使用LABEL来指定镜像作者。如： 1LABEL maintainer=&quot;itbilu.com&quot; USER(指定当前用户) USER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER 则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份。 当然，和 WORKDIR 一样，USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。 格式：USER &lt;用户名&gt;[:&lt;用户组&gt;] 示例 1： 123RUN groupadd -r redis &amp;&amp; useradd -r -g redis redisUSER redisRUN [ &quot;redis-server&quot; ] 如果以 root 执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程，不要使用 su或者 sudo，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用 gosu。 12345678# 建立 redis 用户，并使用 gosu 换另一个用户执行命令RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis# 下载 gosuRUN wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/1.7/gosu-amd64&quot; \\ &amp;&amp; chmod +x /usr/local/bin/gosu \\ &amp;&amp; gosu nobody true# 设置 CMD，并以另外的用户执行CMD [ &quot;exec&quot;, &quot;gosu&quot;, &quot;redis&quot;, &quot;redis-server&quot; ] HEALTHCHECK(健康检查)格式： HEALTHCHECK [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令 HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令 HEALTHCHECK 指令是告诉 Docker 应该如何进行判断容器的状态是否正常，这是 Docker 1.12 引入的新指令。 在没有 HEALTHCHECK 指令前，Docker 引擎只可以通过容器内主进程是否退出来判断容器是否状态异常。很多情况下这没问题，但是如果程序进入死锁状态，或者死循环状态，应用进程并不退出，但是该容器已经无法提供服务了。在 1.12 以前，Docker 不会检测到容器的这种状态，从而不会重新调度，导致可能会有部分容器已经无法提供服务了却还在接受用户请求。 而自 1.12 之后，Docker 提供了 HEALTHCHECK 指令，通过该指令指定一行命令，用这行命令来判断容器主进程的服务状态是否还正常，从而比较真实的反应容器实际状态。 当在一个镜像指定了 HEALTHCHECK 指令后，用其启动容器，初始状态会为 starting，在 HEALTHCHECK 指令检查成功后变为 healthy，如果连续一定次数失败，则会变为 unhealthy。 HEALTHCHECK 支持下列选项： --interval=&lt;间隔&gt;：两次健康检查的间隔，默认为 30 秒； --timeout=&lt;时长&gt;：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒； --retries=&lt;次数&gt;：当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。 和 CMD, ENTRYPOINT 一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 在 HEALTHCHECK [选项] CMD 后面的命令，格式和 ENTRYPOINT 一样，分为 shell 格式，和 exec 格式。命令的返回值决定了该次健康检查的成功与否：0：成功；1：失败；2：保留，不要使用这个值。 假设我们有个镜像是个最简单的 Web 服务，我们希望增加健康检查来判断其 Web 服务是否在正常工作，我们可以用 curl 来帮助判断，其 Dockerfile 的 HEALTHCHECK 可以这么写： 1234FROM nginxRUN apt-get update &amp;&amp; apt-get install -y curl &amp;&amp; rm -rf /var/lib/apt/lists/*HEALTHCHECK --interval=5s --timeout=3s \\ CMD curl -fs http://localhost/ || exit 1 这里我们设置了每 5 秒检查一次（这里为了试验所以间隔非常短，实际应该相对较长），如果健康检查命令超过 3 秒没响应就视为失败，并且使用 curl -fs http://localhost/ || exit 1 作为健康检查命令。 使用 docker build 来构建这个镜像： 1$ docker build -t myweb:v1 . 构建好了后，我们启动一个容器： 1$ docker run -d --name web -p 80:80 myweb:v1 当运行该镜像后，可以通过 docker container ls 看到最初的状态为 (health: starting)： 123$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES03e28eb00bd0 myweb:v1 &quot;nginx -g &#x27;daemon off&quot; 3 seconds ago Up 2 seconds (health: starting) 80/tcp, 443/tcp web 在等待几秒钟后，再次 docker container ls，就会看到健康状态变化为了 (healthy)： 123$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES03e28eb00bd0 myweb:v1 &quot;nginx -g &#x27;daemon off&quot; 18 seconds ago Up 16 seconds (healthy) 80/tcp, 443/tcp web 如果健康检查连续失败超过了重试次数，状态就会变为 (unhealthy)。 为了帮助排障，健康检查命令的输出（包括 stdout 以及 stderr）都会被存储于健康状态里，可以用 docker inspect 来查看。 12345678910111213$ docker inspect --format &#x27;&#123;&#123;json .State.Health&#125;&#125;&#x27; web | python -m json.tool&#123; &quot;FailingStreak&quot;: 0, &quot;Log&quot;: [ &#123; &quot;End&quot;: &quot;2016-11-25T14:35:37.940957051Z&quot;, &quot;ExitCode&quot;: 0, &quot;Output&quot;: &quot;&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Welcome to nginx!&lt;/title&gt; &lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Welcome to nginx!&lt;/h1&gt; &lt;p&gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.&lt;/p&gt; &lt;p&gt;For online documentation and support please refer to &lt;a href=\\&quot;http://nginx.org/\\&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt; Commercial support is available at &lt;a href=\\&quot;http://nginx.com/\\&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; &quot;, &quot;Start&quot;: &quot;2016-11-25T14:35:37.780192565Z&quot; &#125; ], &quot;Status&quot;: &quot;healthy&quot;&#125; ONBUILD(为他人作嫁衣裳)格式：ONBUILD &lt;其它指令&gt;。 ONBUILD 是一个特殊的指令，它后面跟的是其它指令，比如 RUN, COPY 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。 Dockerfile 中的其它指令都是为了定制当前镜像而准备的，唯有 ONBUILD 是为了帮助别人定制自己而准备的。 假设我们要制作 Node.js 所写的应用的镜像。我们都知道 Node.js 使用 npm 进行包管理，所有依赖、配置、启动信息等会放到 package.json 文件里。在拿到程序代码后，需要先进行 npm install 才可以获得所有需要的依赖。然后就可以通过 npm start来启动应用。因此，一般来说会这样写 Dockerfile： 1234567FROM node:slimRUN mkdir /appWORKDIR /appCOPY ./package.json /appRUN [ &quot;npm&quot;, &quot;install&quot; ]COPY . /app/CMD [ &quot;npm&quot;, &quot;start&quot; ] 把这个 Dockerfile 放到 Node.js 项目的根目录，构建好镜像后，就可以直接拿来启动容器运行。但是如果我们还有第二个 Node.js 项目也差不多呢？好吧，那就再把这个 Dockerfile 复制到第二个项目里。那如果有第三个项目呢？再复制么？文件的副本越多，版本控制就越困难，让我们继续看这样的场景维护的问题。 如果第一个 Node.js 项目在开发过程中，发现这个 Dockerfile 里存在问题，比如敲错字了、或者需要安装额外的包，然后开发人员修复了这个 Dockerfile，再次构建，问题解决。第一个项目没问题了，但是第二个项目呢？虽然最初 Dockerfile 是复制、粘贴自第一个项目的，但是并不会因为第一个项目修复了他们的 Dockerfile，而第二个项目的 Dockerfile 就会被自动修复。 那么我们可不可以做一个基础镜像，然后各个项目使用这个基础镜像呢？这样基础镜像更新，各个项目不用同步 Dockerfile的变化，重新构建后就继承了基础镜像的更新？好吧，可以，让我们看看这样的结果。那么上面的这个 Dockerfile 就会变为： 1234FROM node:slimRUN mkdir /appWORKDIR /appCMD [ &quot;npm&quot;, &quot;start&quot; ] 这里我们把项目相关的构建指令拿出来，放到子项目里去。假设这个基础镜像的名字为 my-node 的话，各个项目内的自己的 Dockerfile 就变为： 1234FROM my-nodeCOPY ./package.json /appRUN [ &quot;npm&quot;, &quot;install&quot; ]COPY . /app/ 基础镜像变化后，各个项目都用这个 Dockerfile 重新构建镜像，会继承基础镜像的更新。 那么，问题解决了么？没有。准确说，只解决了一半。如果这个 Dockerfile 里面有些东西需要调整呢？比如 npm install 都需要加一些参数，那怎么办？这一行 RUN 是不可能放入基础镜像的，因为涉及到了当前项目的 ./package.json，难道又要一个个修改么？所以说，这样制作基础镜像，只解决了原来的 Dockerfile 的前 4 条指令的变化问题，而后面三条指令的变化则完全没办法处理。 ONBUILD 可以解决这个问题。让我们用 ONBUILD 重新写一下基础镜像的 Dockerfile: 1234567FROM node:slimRUN mkdir /appWORKDIR /appONBUILD COPY ./package.json /appONBUILD RUN [ &quot;npm&quot;, &quot;install&quot; ]ONBUILD COPY . /app/CMD [ &quot;npm&quot;, &quot;start&quot; ] 这次我们回到原始的 Dockerfile，但是这次将项目相关的指令加上 ONBUILD，这样在构建基础镜像的时候，这三行并不会被执行。然后各个项目的 Dockerfile 就变成了简单地： 1FROM my-node 是的，只有这么一行。当在各个项目目录中，用这个只有一行的 Dockerfile 构建镜像时，之前基础镜像的那三行 ONBUILD 就会开始执行，成功的将当前项目的代码复制进镜像、并且针对本项目执行 npm install，生成应用镜像。 二、最佳实践有任何的问题或建议，欢迎给我留言 :laughing: 参考资料 Dockerfie 官方文档 Best practices for writing Dockerfiles Docker 官方镜像 Dockerfile Dockerfile 指令详解","categories":["Linux配置文件","docker"]},{"title":"docker-compose","path":"/2023/09/28/Linux配置文件/docker/docker-compose/","content":"Docker Compose compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。 一、Compose 简介Compose 的定位是：定义和运行多个 Docker 容器的应用。 使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： **服务 (service)**：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 **项目 (project)**：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 二、安装卸载Compose 支持 Linux、macOS、Windows10 三大平台。 Linux 安装方式： 12sudo curl -L https://github.com/docker/compose/releases/download/1.24.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose :bell: 详情请参考：Install Docker Compose 三、快速入门web 应用新建文件夹，在该目录中编写 app.py 文件 12345678910111213from flask import Flaskfrom redis import Redisapp = Flask(__name__)redis = Redis(host=&#x27;redis&#x27;, port=6379)@app.route(&#x27;/&#x27;)def hello(): count = redis.incr(&#x27;hits&#x27;) return &#x27;Hello World! 该页面已被访问 &#123;&#125; 次。 &#x27;.format(count)if __name__ == &quot;__main__&quot;: app.run(host=&quot;0.0.0.0&quot;, debug=True) Dockerfile编写 Dockerfile 文件，内容为 12345FROM python:3.6-alpineADD . /codeWORKDIR /codeRUN pip install redis flaskCMD [&quot;python&quot;, &quot;app.py&quot;] docker-compose.yml编写 docker-compose.yml 文件，这个是 Compose 使用的主模板文件。 12345678910version: &#x27;3&#x27;services: web: build: . ports: - &quot;5000:5000&quot; redis: image: &quot;redis:alpine&quot; 运行 compose 项目1$ docker-compose up 此时访问本地 5000 端口，每次刷新页面，计数就会加 1。 四、命令 :bell: 请参考： Compose 官方命令说明文档 Compose 命令说明中文文档 五、模板文件 docker-compose.yml 文件是 Docker Compose 的模板文件，其作用类似于 Dockerfile 和 Docker。 docker-compose.yml 支持的默认环境变量官方文档 参考资料 官方 Docker Compose Github Docker Compose 官方文档 教程 Docker — 从入门到实践 - Docker Compose 项目","categories":["Linux配置文件","docker"]},{"title":"kubernetes","path":"/2023/09/28/Linux配置文件/docker/kubernetes/","content":"Kubernetes 应用指南 Kubernetes 是谷歌开源的容器集群管理系统 是用于自动部署，扩展和管理 Docker 应用程序的开源系统，简称 K8S。 关键词： docker 一、K8S 简介 二、K8S 命令 参考资料 一、K8S 简介K8S 主控组件（Master） 包含三个进程，都运行在集群中的某个节上，通常这个节点被称为 master 节点。这些进程包括：kube-apiserver、kube-controller-manager 和 kube-scheduler。 集群中的每个非 master 节点都运行两个进程： kubelet，和 master 节点进行通信。 kube-proxy，一种网络代理，将 Kubernetes 的网络服务代理到每个节点上。 K8S 功能 基于容器的应用部署、维护和滚动升级 负载均衡和服务发现 跨机器和跨地区的集群调度 自动伸缩 无状态服务和有状态服务 广泛的 Volume 支持 插件机制保证扩展性 K8S 核心组件Kubernetes 主要由以下几个核心组件组成： etcd 保存了整个集群的状态； apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制； controller manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等； scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上； kubelet 负责维护容器的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理； Container runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI）； kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡 img K8S 核心概念K8S 包含若干抽象用来表示系统状态，包括：已部署的容器化应用和负载、与它们相关的网络和磁盘资源以及有关集群正在运行的其他操作的信息。 img Pod - K8S 使用 Pod 来管理容器，每个 Pod 可以包含一个或多个紧密关联的容器。Pod 是一组紧密关联的容器集合，它们共享 PID、IPC、Network 和 UTS namespace，是 K8S 调度的基本单位。Pod 内的多个容器共享网络和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。 Node - Node 是 Pod 真正运行的主机，可以是物理机，也可以是虚拟机。为了管理 Pod，每个 Node 节点上至少要运行 container runtime（比如 docker 或者 rkt）、kubelet 和 kube-proxy 服务。 Namespace - Namespace 是对一组资源和对象的抽象集合，比如可以用来将系统内部的对象划分为不同的项目组或用户组。常见的 pods, services, replication controllers 和 deployments 等都是属于某一个 namespace 的（默认是 default），而 node, persistentVolumes 等则不属于任何 namespace。 Service - Service 是应用服务的抽象，通过 labels 为应用提供负载均衡和服务发现。匹配 labels 的 Pod IP 和端口列表组成 endpoints，由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints 上。每个 Service 都会自动分配一个 cluster IP（仅在集群内部可访问的虚拟地址）和 DNS 名，其他容器可以通过该地址或 DNS 来访问服务，而不需要了解后端容器的运行。 Label - Label 是识别 K8S 对象的标签，以 key&#x2F;value 的方式附加到对象上（key 最长不能超过 63 字节，value 可以为空，也可以是不超过 253 字节的字符串）。Label 不提供唯一性，并且实际上经常是很多对象（如 Pods）都使用相同的 label 来标志具体的应用。Label 定义好后其他对象可以使用 Label Selector 来选择一组相同 label 的对象（比如 ReplicaSet 和 Service 用 label 来选择一组 Pod）。Label Selector 支持以下几种方式： 等式，如 app=nginx 和 env!=production 集合，如 env in (production, qa) 多个 label（它们之间是 AND 关系），如 app=nginx,env=test Annotations - Annotations 是 key&#x2F;value 形式附加于对象的注解。不同于 Labels 用于标志和选择对象，Annotations 则是用来记录一些附加信息，用来辅助应用部署、安全策略以及调度策略等。比如 deployment 使用 annotations 来记录 rolling update 的状态。 二、K8S 命令客户端配置1234567891011# Setup autocomplete in bash; bash-completion package should be installed firstsource &lt;(kubectl completion bash)# View Kubernetes configkubectl config view# View specific config items by json pathkubectl config view -o jsonpath=&#x27;&#123;.users[?(@.name == &quot;k8s&quot;)].user.password&#125;&#x27;# Set credentials for foo.kuberntes.comkubectl config set-credentials kubeuser/foo.kubernetes.com --username=kubeuser --password=kubepassword 查找资源1234567891011121314151617181920212223242526272829# List all services in the namespacekubectl get services# List all pods in all namespaces in wide formatkubectl get pods -o wide --all-namespaces# List all pods in json (or yaml) formatkubectl get pods -o json# Describe resource details (node, pod, svc)kubectl describe nodes my-node# List services sorted by namekubectl get services --sort-by=.metadata.name# List pods sorted by restart countkubectl get pods --sort-by=&#x27;.status.containerStatuses[0].restartCount&#x27;# Rolling update pods for frontend-v1kubectl rolling-update frontend-v1 -f frontend-v2.json# Scale a replicaset named &#x27;foo&#x27; to 3kubectl scale --replicas=3 rs/foo# Scale a resource specified in &quot;foo.yaml&quot; to 3kubectl scale --replicas=3 -f foo.yaml# Execute a command in every pod / replicafor i in 0 1; do kubectl exec foo-$i -- sh -c &#x27;echo $(hostname) &gt; /usr/share/nginx/html/index.html&#x27;; done 资源管理1234567891011121314151617181920212223242526# Get documentation for pod or servicekubectl explain pods,svc# Create resource(s) like pods, services or daemonsetskubectl create -f ./my-manifest.yaml# Apply a configuration to a resourcekubectl apply -f ./my-manifest.yaml# Start a single instance of Nginxkubectl run nginx --image=nginx# Create a secret with several keyscat &lt;&lt;EOF | kubectl create -f -apiVersion: v1kind: Secretmetadata: name: mysecrettype: Opaquedata: password: $(echo &quot;s33msi4&quot; | base64) username: $(echo &quot;jane&quot;| base64)EOF# Delete a resourcekubectl delete -f ./my-manifest.yaml 监控和日志1234567891011121314151617# Deploy Heapster from Github repositorykubectl create -f deploy/kube-config/standalone/# Show metrics for nodeskubectl top node# Show metrics for podskubectl top pod# Show metrics for a given pod and its containerskubectl top pod pod_name --containers# Dump pod logs (stdout)kubectl logs pod_name# Stream pod container logs (stdout, multi-container case)kubectl logs -f pod_name -c my-container 参考资料 官方 Kubernetes Github Kubernetes 官网 教程 Kubernetes 中文指南 kubernetes-handbook 文章 https://github.com/LeCoupa/awesome-cheatsheets/blob/master/tools/kubernetes.sh 更多资源 awesome-kubernetes","categories":["Linux配置文件","docker"]},{"title":"docker-quickstart","path":"/2023/09/28/Linux配置文件/docker/docker-quickstart/","content":"Docker 快速入门 一、Docker 的简介 二、Docker 的运维 三、hello world 实例 四、制作 Docker 容器 参考资料 一、Docker 的简介什么是 Docker Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。 它是目前最流行的 Linux 容器解决方案。 Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 为什么需要 Docker 更高效的利用系统资源 - 由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间 - 传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境 - 开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署 - 对开发和运维（DevOps）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合 持续集成(Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery&#x2F;Deployment) 系统进行自动部署。而且使用 Dockerfile 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。 更轻松的迁移 - 由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展 - Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的 官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 img Docker 的主要用途Docker 提供了被称为容器的松散隔离环境，在环境中可以打包和运行应用程序。隔离和安全性允许您在给定主机上同时运行多个容器。容器是轻量级的，因为它们不需要管理程序的额外负载，而是直接在主机的内核中运行。这意味着您可以在给定的硬件组合上运行更多容器，而不是使用虚拟机。你甚至可以在实际上是虚拟机的主机中运行 Docker 容器！ Docker 的主要用途，目前有三大类。 提供一次性的环境。比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。 提供弹性的云服务。因为 Docker 容器可以随开随关，很适合动态扩容和缩容。 组建微服务架构。通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。 Docker 的核心概念镜像Docker 把应用程序及其依赖，打包在镜像（Image）文件里面。 我们都知道，操作系统分为内核和用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:18.04 就包含了完整的一套 Ubuntu 18.04 最小系统的 root 文件系统。 Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 分层存储 因为镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。 镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。 分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 容器镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。 前面讲过镜像使用的是分层存储，容器也是如此。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。 仓库镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。 一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，16.04, 18.04。我们可以通过 ubuntu:14.04，或者 ubuntu:18.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。 仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。 二、Docker 的运维不同操作系统环境下安装 Docker 的方式有所不同，详情可以参： Docker 官方安装指南 安装 Docker（中文） 国内访问 Docker 比较慢，如果需要提速，可以参考 镜像加速器 安装完成后，运行下面的命令，验证是否安装成功。 docker version docker info Docker 需要用户具有 sudo 权限，为了避免每次命令都输入sudo，可以把用户加入 Docker 用户组（官方文档）。 1$ sudo usermod -aG docker $USER Docker 是服务器—-客户端架构。命令行运行docker命令的时候，需要本机有 Docker 服务。如果这项服务没有启动，可以用下面的命令启动（官方文档）。 12345# service 命令的用法$ sudo service docker start# systemctl 命令的用法$ sudo systemctl start docker 三、Hello World 实例下面，我们通过最简单的 image 文件”hello world”，感受一下 Docker。 需要说明的是，国内连接 Docker 的官方仓库很慢，还会断线，需要将默认仓库改成国内的镜像网站，具体的修改方法在下一篇文章的第一节。有需要的朋友，可以先看一下。 首先，运行下面的命令，将 image 文件从仓库抓取到本地。 1$ docker image pull library/hello-world 上面代码中，docker image pull是抓取 image 文件的命令。library/hello-world是 image 文件在仓库里面的位置，其中library是 image 文件所在的组，hello-world是 image 文件的名字。 由于 Docker 官方提供的 image 文件，都放在library组里面，所以它的是默认组，可以省略。因此，上面的命令可以写成下面这样。 1$ docker image pull hello-world 抓取成功以后，就可以在本机看到这个 image 文件了。 1$ docker image ls 现在，运行这个 image 文件。 1$ docker container run hello-world docker container run命令会从 image 文件，生成一个正在运行的容器实例。 注意，docker container run命令具有自动抓取 image 文件的功能。如果发现本地没有指定的 image 文件，就会从仓库自动抓取。因此，前面的docker image pull命令并不是必需的步骤。 如果运行成功，你会在屏幕上读到下面的输出。 123456$ docker container run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.... ... 输出这段提示以后，hello world就会停止运行，容器自动终止。 有些容器不会自动终止，因为提供的是服务。比如，安装运行 Ubuntu 的 image，就可以在命令行体验 Ubuntu 系统。 1$ docker container run -it ubuntu bash 对于那些不会自动终止的容器，必须使用docker container kill 命令手动终止。 1$ docker container kill [containID] 四、制作 Docker 容器下面我以 koa-demos 项目为例，介绍怎么写 Dockerfile 文件，实现让用户在 Docker 容器里面运行 Koa 框架。 作为准备工作，请先下载源码。 12$ git clone https://github.com/ruanyf/koa-demos.git$ cd koa-demos 编写 Dockerfile 文件首先，在项目的根目录下，新建一个文本文件.dockerignore，写入下面的内容。 123.gitnode_modulesnpm-debug.log 上面代码表示，这三个路径要排除，不要打包进入 image 文件。如果你没有路径要排除，这个文件可以不新建。 然后，在项目的根目录下，新建一个文本文件 Dockerfile，写入下面的内容。 12345FROM node:8.4COPY . /appWORKDIR /appRUN npm install --registry=https://registry.npm.taobao.orgEXPOSE 3000 上面代码一共五行，含义如下。 FROM node:8.4：该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即 8.4 版本的 node。 COPY . /app：将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。 WORKDIR /app：指定接下来的工作路径为/app。 RUN npm install：在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。 EXPOSE 3000：将容器 3000 端口暴露出来， 允许外部连接这个端口。 创建 image 文件有了 Dockerfile 文件以后，就可以使用docker image build命令创建 image 文件了。 123$ docker image build -t koa-demo .# 或者$ docker image build -t koa-demo:0.0.1 . 上面代码中，-t参数用来指定 image 文件的名字，后面还可以用冒号指定标签。如果不指定，默认的标签就是latest。最后的那个点表示 Dockerfile 文件所在的路径，上例是当前路径，所以是一个点。 如果运行成功，就可以看到新生成的 image 文件koa-demo了。 1$ docker image ls 生成容器docker container run命令会从 image 文件生成容器。 123$ docker container run -p 8000:3000 -it koa-demo /bin/bash# 或者$ docker container run -p 8000:3000 -it koa-demo:0.0.1 /bin/bash 上面命令的各个参数含义如下： -p参数：容器的 3000 端口映射到本机的 8000 端口。 -it参数：容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器。 koa-demo:0.0.1：image 文件的名字（如果有标签，还需要提供标签，默认是 latest 标签）。 /bin/bash：容器启动以后，内部第一个执行的命令。这里是启动 Bash，保证用户可以使用 Shell。 如果一切正常，运行上面的命令以后，就会返回一个命令行提示符。 1root@66d80f4aaf1e:/app# 这表示你已经在容器里面了，返回的提示符就是容器内部的 Shell 提示符。执行下面的命令。 1root@66d80f4aaf1e:/app# node demos/01.js 这时，Koa 框架已经运行起来了。打开本机的浏览器，访问","categories":["Linux配置文件","docker"]},{"title":"apache+tomcat+jk","path":"/2023/09/28/Linux配置文件/apache+tomcat+jk/apache+tomcat+jk/","content":"apache&#x2F;tomcat安装过程略一些变量##apache安装目录 APACHE_PREFIX&#x3D;&#x2F;Data&#x2F;app&#x2F;apache apache配置文件 APACHE_CONF&#x3D;&#x2F;etc&#x2F;httpd&#x2F;httpd.conf tomcat 安装目录 TOMCAT1_PREFIX&#x3D;&#x2F;Data&#x2F;app&#x2F;tomcat1 TOMCAT2_PREFIX&#x3D;&#x2F;Data&#x2F;app&#x2F;tomcat2 tomcat根目录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177TOMCAT_ROOT=/Data/code# 为tomcat添加项目，也就是配置tomcat根目录,修改$TOMCAT_PREFIX/conf/server.xml# 在&lt;Host&gt;&lt;/Host&gt;段添加Context,这里设置为/Data/code/&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;&lt;Context path=&quot;&quot; docBase=&quot;/Data/code&quot;&gt;&lt;/Context&gt;..........&lt;/Host&gt;# jk安装（apache tomcat 连接器）wget http://archive.apache.org/dist/tomcat/tomcat-connectors/jk/tomcat-connectors-1.2.39-src.tar.gztar zxvf tomcat-connectors-1.2.39-src.tar.gz &amp;&amp; cd tomcat-connectors-1.2.39-src/native./configure --with-apxs=/Data/app/apache/bin/apxs --with-java-home=/Data/app/jdkmake # mod_jk.so会生成在apache安装目录下的modules目录# 安装tomcat native，否则在tomcat启动日志中会有关于libnative的报错cd /Data/app/tomcat/bin # tomcat 安装目录下的bin目录tar zxvf tomcat-native.tar.gz &amp;&amp; cd tomcat-native-1.1.29-src/jni/native./configure --with-apr=/Data/app/apr/bin/apr-1-config --with-ssl=/usr/local/ssl/make &amp;&amp; make installcp /usr/local/apr/lib/libtcnative* /usr/lib # 拷贝到/usr/lib /usr/lib64等位置都可，参考tomcat启动日志# 启动多个tomcat，本机启动多个tomcat，要注意修改tomcat端口，server.xml的8080,8005,8009端口都要避免冲突，不然无法启动多个tomcat# 假设本机安装的两个tomcat分别为$TOMCAT1_PREFIX和$TOMCAT2_PREFIX,确认端口无冲突后启动$TOMCAT1_PREFIX/bin/catalina.sh start$TOMCAT2_PREFIX/bin/catalina.sh start# 配置apache作为前端，将请求转发给后端tomcat集群# 在/etc/httpd/extra目录下创建mod_jk.conf,文件内容为：LoadModule jk_module modules/mod_jk.so # 加载mod_jk模块JkWorkersFile /etc/httpd/extra/workers.properties # 这个文件里配置的是tomcat集群及负载均衡JkMountFile /etc/httpd/extra/uriworkermap.properties # 这里配置的是转发规则，即哪些由apache自己处理，哪些交给tomcatJkLogFile logs/mod_jk.logJkLogLevel info# 在extra下创建workers.properties和uriworkermap.properties## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## file name workers.properties## ## worker.list=tomcatserver,status # tomcatserver为均衡器名称，自定义# localhost server 1# ------------------------worker.s1.port=8009 # s1是为tomcat定义的名称，多个tomcat不得冲突worker.s1.host=localhostworker.s1.type=ajp13worker.s1.lbfactor = 1 # 在集群中的权重# localhost server 2# ------------------------worker.s2.port=8010 # s2的意义同s1worker.s2.host=localhostworker.s2.type=ajp13worker.s2.lbfactor = 1# -----------------------------worker.tomcatserver.type=lb # 负载均衡类型，worker.retries=3worker.tomcatserver.balance_workers=s1,s2 # s1,s2就是上边定义的名称worker.tomcatserver.sticky_session=false # 启用session复制，该选项必须为false,如果为true，则表示同一用户的请求不会在多个tomcat之间移动，固定由一个tomcat处理worker.tomcatserver.sticky_session_force=1 # 默认tomcat 无反应，是否将请求转到其他tomcatworker.status.type=status## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## # file name uriworkermap.properties## ## /*=tomcatserver # 所有请求都由controller这个server处理/jkstatus=status # 所有包含jkstatus请求的都由status这个server处理!/*.gif=tomcatserver # 所有以.gif结尾的请求都不由tomcatserver这个server处理，以下几个都是一样的意思!/*.jpg=tomcatserver!/*.png=tomcatserver!/*.css=tomcatserver!/*.js=tomcatserver!/*.htm=tomcatserver!/*.html=tomcatserver# 修改$APACHE_CONF，Include /etc/httpd/extra/mod_jk.conf# 重启httpd# 现在apache已经可以使用jk方式与tomcat通信，并且将请求平均分发给s1,s2两个tomcat.不安装jk的话,apache可以使用proxy方式与tomcat通信# 多个tomcat session复制,保持客户端会话# 修改$TOMCAT1_PREFIX/conf/server.xml和$TOMCAT2_PREFIX/conf/server.xml## ## # TOMCAT1_PREFIX/conf/server.xml## ## ## &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot; jvmRoute=&quot;s1&quot;&gt; # jvmRoute必须设置，s1与workers.properties中设置的名称一致，另一个为jvmRoute=&quot;s2&quot; &lt;!--For clustering, please take a look at documentation at: /docs/cluster-howto.html (simple how to) /docs/config/cluster.html (reference documentation) --&gt; &lt;!-- &lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot;/&gt; --&gt; &lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot; channelSendOptions=&quot;8&quot;&gt; &lt;Manager className=&quot;org.apache.catalina.ha.session.DeltaManager&quot; expireSessionsOnShutdown=&quot;false&quot; notifyListenersOnReplication=&quot;true&quot;/&gt; &lt;Channel className=&quot;org.apache.catalina.tribes.group.GroupChannel&quot;&gt; &lt;Membership className=&quot;org.apache.catalina.tribes.membership.McastService&quot; address=&quot;228.0.0.4&quot; port=&quot;45564&quot; frequency=&quot;500&quot; dropTime=&quot;3000&quot;/&gt;&lt;Receiver className=&quot;org.apache.catalina.tribes.transport.nio.NioReceiver&quot; address=&quot;auto&quot; # auto的话，会绑定在127.0.0.1上 port=&quot;4000&quot; # 这个端口号两个tomcat必须不一致，不得冲突 autoBind=&quot;100&quot; selectorTimeout=&quot;5000&quot; maxThreads=&quot;6&quot;/&gt; &lt;Sender className=&quot;org.apache.catalina.tribes.transport.ReplicationTransmitter&quot;&gt; &lt;Transport className=&quot;org.apache.catalina.tribes.transport.nio.PooledParallelSender&quot;/&gt; &lt;/Sender&gt; &lt;Interceptor className=&quot;org.apache.catalina.tribes.group.interceptors.TcpFailureDetector&quot;/&gt; &lt;Interceptor className=&quot;org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor&quot;/&gt; &lt;/Channel&gt; &lt;Valve className=&quot;org.apache.catalina.ha.tcp.ReplicationValve&quot; filter=&quot;&quot;/&gt; &lt;Valve className=&quot;org.apache.catalina.ha.session.JvmRouteBinderValve&quot;/&gt; &lt;Deployer className=&quot;org.apache.catalina.ha.deploy.FarmWarDeployer&quot; tempDir=&quot;/tmp/war-temp/&quot; deployDir=&quot;/tmp/war-deploy/&quot; watchDir=&quot;/tmp/war-listen/&quot; watchEnabled=&quot;false&quot;/&gt; &lt;ClusterListener className=&quot;org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener&quot;/&gt; &lt;ClusterListener className=&quot;org.apache.catalina.ha.session.ClusterSessionListener&quot;/&gt; &lt;/Cluster&gt;# 在$TOMCAT_ROOT下创建WEB-INF目录，WEB-INF目录下创建web.xml&lt;web-app xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot; version=&quot;3.0&quot; metadata-complete=&quot;true&quot;&gt; &lt;display-name&gt;Welcome to Tomcat&lt;/display-name&gt; &lt;description&gt; Welcome to Tomcat &lt;/description&gt;&lt;distributable/&gt; # 必须添加这个标签&lt;/web-app&gt;# 启动两个tomcat route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0","categories":["Linux配置文件","apache+tomcat+jk"]},{"title":"DNS配置","path":"/2023/09/27/Linux配置文件/dns/DNS配置/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148./configure --prefix=/usr/local/bind/ --with-openssl=/usr/ --sysconfdir=/etc/ --with-libtool --enable-threads--prefix=/usr/local/bind #指定bind9的安装目录,默认是/usr/local--enable-threads #开启多线程的支持；如果你的系统有多个CPU，那么可以使用这个选项--disable-openssl-version-check #关闭openssl的检查--with-openssl=/usr/local/openssl #指定openssl的安装路径--sysconfdir=/etc/ #设置named.conf配置文件放置的目录，默认是--prefix选项指定的目录下的/etc下--localstatdir=/var #设置 run/named.pid 放置的目录，默认是--prefix选项指定的目录下的/var下--with-libtool #BIND的库文件编译为动态共享库文件，这个选项默认是未选择的。 如果不选这个选项，那么编译后的named命令会比较大，lib目录 中的库文件都是.a后缀的 --disable-chroot #禁用chroot，不建议使用，默认开启此功能make &amp;&amp; make install#添加系统变量vi ~/.bash_profilePATH=$PATH:$HOME/bin:/usr/local/bind/bin:/usr/local/bind/bin:/usr/local/bind/sbin #修改本行source ~/.bash_profile #使修改生效 #添加运行用户useradd -r named # -r 添加系统用户#启用chrootmkdir -p /var/named/chroot/&#123;var,etc,dev&#125;mkdir /var/named/chroot/var/run#创建虚拟设备cd /var/named/chroot/devmknod random c 1 8 mknod zero c 1 5 mknod null c 1 3#修改run目录属主chown -R named:named /var/named/chroot/var/run #named 要向run目录写入pid文件#生成rndc.conf ，以便使用rndc命令管理bindrndc-confgen将生成的内容分别写入/etc/named.conf和/etc/rndc.conf #这里在测试中，named.conf是写入chroot之后的etc而rndc.conf写如chroot之后的etc却提示找不到，写入真实的/etc下则正常#创建配置文件vi /var/named/chroot/etc/named.confkey &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;BM+rI8Ra3mpKKtIlYpGEAQ==&quot;; &#125;;controls &#123; inet 127.0.0.1 port 953 allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;options &#123; directory &quot;/var&quot;; pid-file &quot;/var/run/named.pid&quot;; version &quot;bind 9.9.3&quot;; allow-query &#123;any;&#125;; forwarders &#123; #如果想让dns同时可以解析外网，可使用forward功能； 192.168.1.253; &#125;;&#125;;zone &quot;.&quot; IN &#123; type hint; file &quot;named.root&quot;;&#125;;zone &quot;lxy.com&quot; IN &#123; type master; file &quot;named.lxy.com&quot;;&#125;;vi /etc/rndc.confkey &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;BM+rI8Ra3mpKKtIlYpGEAQ==&quot;;&#125;;options &#123; default-key &quot;rndc-key&quot;; default-server 127.0.0.1; default-port 953;&#125;;#ZONE文件内容：vi /var/named/chroot/var/named.lxy.kk #正解析的zone，如果想让dns可以解析外网，就不要包含.com等合法域，不然在试图解析合法域名的时候服务器会在本地寻找记录，当然是找 不到的，它会告诉你找不到，而不会去向forward请求。$TTL 86400@ IN SOA lxy.kk. root.lxy.kk. ( 2008080804 ; 28800 ; 14400 ; 3600000 ; 86400 ) ;@ IN NS dns.lxy.kk.@ IN MX 10 mail.lxy.kk.dns IN A 192.168.127.129mail IN A 192.168.127.130www IN A 192.168.127.129vi /var/named/chroot/named.127.0.0 #反向解析的zone$TTL 86400@ IN SOA dns.lxy.kk. root.lxy.kk. ( 2008080804 ; 28800 ; 14400 ; 3600000 ; 86400 ) ;@ IN NS dns.lxy.kk.1 IN PTR localhost.#启动服务named -c /etc/named.conf -t /var/named/chroot -u named #注意这里的/etc/实际指的是chroot下的etc,因为已经使用-t指定了chroot到的目录，named将视chroot为根目录#rndcrndc reload | status等","categories":["Linux","DNS配置"]},{"title":"Ansible-command模块和shell模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-command模块和shell模块/","content":"ansible command与shell模块 两个模块都是用于执行linux命令的,这对于命令熟悉的工程师来说，用起来非常high。 shell模块与command模块差不多（command模块不能执行一些类似$HOME,&gt;,&lt;,|等符号，但shell可以) https://docs.ansible.com/ansible/latest/modules/command_module.html https://docs.ansible.com/ansible/latest/modules/shell_module.html 一、shell模块1234567891011121314151617181920212223242526[root@manage01 ~]# ansible -m shell 192.168.98.201 -a &quot;ls /root&quot;192.168.98.201 | CHANGED | rc=0 &gt;&gt;公共模板视频图片文档下载音乐桌面anaconda-ks.cfginitial-setup-ks.cfgnginx.servicenginx_study[root@manage01 ~]# ansible -m shell 192.168.98.201 -a &quot;echo &#x27;hello world&#x27; &gt; /tmp/baishuming&quot;192.168.98.201 | CHANGED | rc=0 &gt;&gt;[root@manage01 ~]# ansible -m shell 192.168.98.201 -a &quot;cat /tmp/baishuming&quot;192.168.98.201 | CHANGED | rc=0 &gt;&gt;hello world注意shell模块不是什么命令都能使用，比如vim这样的交互命令,不建议大家去记忆哪些命令不可以，大家只要养成任何在生产环境里的命令都要先在测试环境里测试一下的习惯就好。 二、command模块1234567891011121314151617181920212223242526[root@manage01 ~]# ansible -m command 192.168.98.201 -a &quot;ls /root&quot;192.168.98.201 | CHANGED | rc=0 &gt;&gt;公共模板视频图片文档下载音乐桌面anaconda-ks.cfginitial-setup-ks.cfgnginx.servicenginx_study[root@manage01 ~]# ansible -m command 192.168.98.201 -a &quot;echo &#x27;baism hello&#x27; &gt; /tmp/baism_123&quot;192.168.98.201 | CHANGED | rc=0 &gt;&gt;baism hello &gt; /tmp/baism_123[root@manage01 ~]# ansible -m command 192.168.98.201 -a &quot;cat /tmp/baism_123&quot;192.168.98.201 | FAILED | rc=1 &gt;&gt;cat: /tmp/baism_123: 没有那个文件或目录non-zero return code发现没有/tmp/baism_123 证明上一条命令未能执行成功 三、学习视频视频： command与shell模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-fetch模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-fetch模块/","content":"一、fetch模块fetch模块与copy模块类似，但作用相反。用于把远程机器的文件拷贝到本地。 https://docs.ansible.com/ansible/latest/modules/fetch_module.html#fetch-module 将group1组机器的&#x2F;opt&#x2F;readme 拷贝到manage01的&#x2F;opt目录 注意:不管是拷贝多个机器还是一个机器的文件，在管理机本地目录都会按照 IP&#x2F;路径&#x2F;文件名 的方式命名，防止冲突 12345678910111213141516171819202122232425[root@manage01 ~]# ansible -m fetch group1 -a &quot;src=/opt/readme dest=/opt&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;f8182e9ccdbe6efd13eb36a056a7db203fe66e40&quot;, &quot;dest&quot;: &quot;/opt/192.168.98.203/opt/readme&quot;, &quot;md5sum&quot;: &quot;f8c2686842f9fa79361e8928867a1983&quot;, &quot;remote_checksum&quot;: &quot;f8182e9ccdbe6efd13eb36a056a7db203fe66e40&quot;, &quot;remote_md5sum&quot;: null&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;f8182e9ccdbe6efd13eb36a056a7db203fe66e40&quot;, &quot;dest&quot;: &quot;/opt/192.168.98.202/opt/readme&quot;, &quot;md5sum&quot;: &quot;f8c2686842f9fa79361e8928867a1983&quot;, &quot;remote_checksum&quot;: &quot;f8182e9ccdbe6efd13eb36a056a7db203fe66e40&quot;, &quot;remote_md5sum&quot;: null&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;f8182e9ccdbe6efd13eb36a056a7db203fe66e40&quot;, &quot;dest&quot;: &quot;/opt/192.168.98.201/opt/readme&quot;, &quot;md5sum&quot;: &quot;f8c2686842f9fa79361e8928867a1983&quot;, &quot;remote_checksum&quot;: &quot;f8182e9ccdbe6efd13eb36a056a7db203fe66e40&quot;, &quot;remote_md5sum&quot;: null&#125; 二、学习视频视频：fetch模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-copy模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-copy模块/","content":"一、copy模块(重点)copy模块用于对文件的远程拷贝操作（如把本地的文件拷贝到远程的机器上) https://docs.ansible.com/ansible/latest/modules/copy_module.html#copy-module 参数 说明 src 文件源路径 dest 目标路径 content 往目标文件输入内容 force 强制 yes or no backup 是否备份有冲突的源文件[文件名相同，内容不同] yes or no checksum 拷贝完整性校验，使用sha1sum生成校验码 owner 目标文件所有者 group 目标文件所属组 mode 目标文件权限 拷贝manage01机器&#x2F;root&#x2F;readme文件到group1组的机器。 要求校验完整性，注意[checksum 是根据sha1算法做校验的] 所有者、所属组都是sko 权限0400 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[root@manage01 ~]# sha1sum readme f8182e9ccdbe6efd13eb36a056a7db203fe66e40 readme[root@manage01 ~]# ansible -m copy group1 -a &quot;src=/root/readme dest=/opt checksum=f8182e9ccdbe6efd13eb36a056a7db203fe66e40 owner=sko group=sko mode=0400&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;f8182e9ccdbe6efd13eb36a056a7db203fe66e40&quot;, &quot;dest&quot;: &quot;/opt/readme&quot;, &quot;gid&quot;: 1000, &quot;group&quot;: &quot;sko&quot;, &quot;md5sum&quot;: &quot;f8c2686842f9fa79361e8928867a1983&quot;, &quot;mode&quot;: &quot;0400&quot;, &quot;owner&quot;: &quot;sko&quot;, &quot;size&quot;: 1214, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1571366236.6664524-201027506158575/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 1000&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;f8182e9ccdbe6efd13eb36a056a7db203fe66e40&quot;, &quot;dest&quot;: &quot;/opt/readme&quot;, &quot;gid&quot;: 1001, &quot;group&quot;: &quot;sko&quot;, &quot;md5sum&quot;: &quot;f8c2686842f9fa79361e8928867a1983&quot;, &quot;mode&quot;: &quot;0400&quot;, &quot;owner&quot;: &quot;sko&quot;, &quot;size&quot;: 1214, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1571366236.6522918-97522631781022/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 1001&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;f8182e9ccdbe6efd13eb36a056a7db203fe66e40&quot;, &quot;dest&quot;: &quot;/opt/readme&quot;, &quot;gid&quot;: 1001, &quot;group&quot;: &quot;sko&quot;, &quot;md5sum&quot;: &quot;f8c2686842f9fa79361e8928867a1983&quot;, &quot;mode&quot;: &quot;0400&quot;, &quot;owner&quot;: &quot;sko&quot;, &quot;size&quot;: 1214, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1571366236.6274443-88161541412737/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 1001&#125; copy模块拷贝时要注意拷贝目录后面是否带”&#x2F;“符号 1234/etc/yum.repos.d后面不带/符号，则表示把/etc/yum.repos.d整个目录拷贝到/tmp/目录下[root@manage01 ~]# ansible group1 -m copy -a &#x27;src=/etc/yum.repos.d dest=/tmp/&#x27;/etc/yum.repos.d/后面带/符号，则表示把/etc/yum.repos.d/目录里的所有文件拷贝到/tmp/目录下[root@manage01 ~]# ansible group1 -m copy -a &#x27;src=/etc/yum.repos.d/ dest=/tmp/&#x27; 使用content参数直接往远程文件里写内容（会覆盖原内容） 1234[root@manage01 ~]# ansible -m file group1 -a &quot;path=/tmp/zutuanxue_333 state=touch&quot;[root@manage01 ~]# ansible -m copy group1 -a &quot;content=&#x27;baism hello world &#x27; dest=/tmp/zutuanxue_333&quot;注意:ansible中-a后面的参数里也有引号时，记得要单引双引交叉使用，如果都为双引会出现问题 使用force参数控制是否强制覆盖 1234如果目标文件已经存在，则不覆盖[root@manage01 ~]# ansible group1 -m copy -a &quot;src=/tmp/zutuanxue_222 dest=/tmp/zutuanxue_333 force=no&quot;如果目标文件已经存在，则会强制覆盖[root@manage01 ~]# ansible group1 -m copy -a &quot;src=/tmp/zutuanxue_222 dest=/tmp/zutuanxue_333 force=yes&quot; 使用backup参数控制是否备份文件 1234backup=yes表示如果拷贝的文件内容与原内容不一样，则会备份一份如果拷贝过来的文件本机存在，group1的机器上会将/tmp/333备份一份（备份文件命名加上时间），再远程拷贝新的文件为/tmp/333[root@manage01 ~]# ansible group1 -m copy -a &quot;src=/etc/fstab dest=/tmp/zutuanxue_333 backup=yes&quot; 二、学习视频视频：copy模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-cron模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-cron模块/","content":"一、cron模块cron模块用于管理周期性时间任务。 https://docs.ansible.com/ansible/latest/modules/cron_module.html#cron-module 参数 说明 name 计划任务的名称 user 执行计划任务的用户 job 计划任务命令 minute 执行计划任务的分 默认为* hour 执行计划任务的时 默认为* day 执行计划任务的日 默认为* month 执行计划任务的月 默认为* week 执行计划任务的周 默认为* state absent 删除计划任务 创建一个cron任务,不指定user的话,默认就是root（因为我这里是用root操作的)。如果minute,hour,day,month,week不指定的话，默认都为* 每天14:23 执行echo “haha”&gt;&#x2F;tmp&#x2F;test 12345678910111213141516171819202122232425262728293031[root@manage01 ~]# ansible -m cron group1 -a &#x27;name=&quot;cron test&quot; user=root job=&quot;echo haha &gt; /tmp/test&quot; minute=23 hour=12&#x27;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;cron test&quot; ]&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;cron test&quot; ]&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;cron test&quot; ]&#125; 删除cron任务 12345678910111213141516171819202122232425[root@manage01 ~]# ansible -m cron group1 -a &#x27;name=&quot;cron test&quot; state=absent&#x27;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: []&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: []&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: []&#125; 二、学习视频视频：cron模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-file模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-file模块/","content":"一、file模块(重点)file模块用于对文件或文件夹相关的操作，主要用来设置文件、链接、目录的属性，或者移除文件、链接、目录，很多其他的模块也会包含这种作用，例如copy，assemble和template。 https://docs.ansible.com/ansible/latest/modules/file_module.html#file-module 参数 说明 path 文件绝对路径 state 操作(touch文件新建、absent删除、link软连接、hard硬链接、directory目录创建) owner 设置所有者 group 设置所属的组 mode 权限 0000 recurse 递归 yes or no 文件的创建 在所有的业务机器的&#x2F;tmp下创建一个文件：zutuanxue 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@manage01 ~]# ansible -m file group1 -a &quot;path=/tmp/zutuanxue state=touch&quot;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;dest&quot;: &quot;/tmp/zutuanxue&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 0, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;dest&quot;: &quot;/tmp/zutuanxue&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 0, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;dest&quot;: &quot;/tmp/zutuanxue&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 0, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125; 文件的删除 将node1(192.168.98.201)机器的&#x2F;tmp&#x2F;zutuanxue文件删除 123456789[root@manage01 ~]# ansible -m file 192.168.98.201 -a &quot;path=/tmp/zutuanxue state=absent&quot;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;path&quot;: &quot;/tmp/zutuanxue&quot;, &quot;state&quot;: &quot;absent&quot;&#125; 文件权限 修改node2机器文件&#x2F;tmp&#x2F;zutuanxue: 所有者:sko 所属组:nobody 权限:600 1234567891011121314151617[root@manage01 ~]# ansible -m file 192.168.98.202 -a &quot;path=/tmp/zutuanxue owner=sko group=nobody mode=0600&quot;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;gid&quot;: 65534, &quot;group&quot;: &quot;nobody&quot;, &quot;mode&quot;: &quot;0600&quot;, &quot;owner&quot;: &quot;sko&quot;, &quot;path&quot;: &quot;/tmp/zutuanxue&quot;, &quot;size&quot;: 0, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 1001&#125;###执行前提:192.168.98.202 有sko用户 创建链接文件[软连接、硬链接] 为node2机器的&#x2F;tmp&#x2F;zutuanxue文件创建以下链接 软连接 &#x2F;tmp&#x2F;zutuanxue_com 硬链接 &#x2F;tmp&#x2F;zutuanxue_com_cn 1234567891011121314151617181920212223242526272829303132333435#软连接[root@manage01 ~]# ansible -m file 192.168.98.202 -a &quot;src=/tmp/zutuanxue path=/tmp/zutuanxue_com state=link&quot;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;dest&quot;: &quot;/tmp/zutuanxue_com&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0777&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 13, &quot;src&quot;: &quot;/tmp/zutuanxue&quot;, &quot;state&quot;: &quot;link&quot;, &quot;uid&quot;: 0&#125;#硬链接[root@manage01 ~]# ansible -m file 192.168.98.202 -a &quot;src=/tmp/zutuanxue path=/tmp/zutuanxue_com_cn state=hard&quot;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;dest&quot;: &quot;/tmp/zutuanxue_com_cn&quot;, &quot;gid&quot;: 65534, &quot;group&quot;: &quot;nobody&quot;, &quot;mode&quot;: &quot;0600&quot;, &quot;owner&quot;: &quot;sko&quot;, &quot;size&quot;: 0, &quot;src&quot;: &quot;/tmp/zutuanxue&quot;, &quot;state&quot;: &quot;hard&quot;, &quot;uid&quot;: 1001&#125; 创建一个目录 为所有的业务机器创建一个目录: &#x2F;tmp&#x2F;zutuanxue123 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@manage01 ~]# ansible -m file group1 -a &quot;path=/tmp/zutuanxue123 state=directory&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0755&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;path&quot;: &quot;/tmp/zutuanxue123&quot;, &quot;size&quot;: 6, &quot;state&quot;: &quot;directory&quot;, &quot;uid&quot;: 0&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0755&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;path&quot;: &quot;/tmp/zutuanxue123&quot;, &quot;size&quot;: 6, &quot;state&quot;: &quot;directory&quot;, &quot;uid&quot;: 0&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0755&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;path&quot;: &quot;/tmp/zutuanxue123&quot;, &quot;size&quot;: 6, &quot;state&quot;: &quot;directory&quot;, &quot;uid&quot;: 0&#125; 修改目录及子文件权限 设置业务机器的&#x2F;tmp&#x2F;zutuanxue123目录及子文件的权限 所有者设置为sko 权限为2775 123456789101112131415161718192021222324252627282930313233343536373839404142[root@manage01 ~]# ansible -m file group1 -a &quot;path=/tmp/zutuanxue123 owner=sko mode=2755 recurse=yes&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;02755&quot;, &quot;owner&quot;: &quot;sko&quot;, &quot;path&quot;: &quot;/tmp/zutuanxue123&quot;, &quot;size&quot;: 19, &quot;state&quot;: &quot;directory&quot;, &quot;uid&quot;: 1000192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;02755&quot;, &quot;owner&quot;: &quot;sko&quot;, &quot;path&quot;: &quot;/tmp/zutuanxue123&quot;, &quot;size&quot;: 19, &quot;state&quot;: &quot;directory&quot;, &quot;uid&quot;: 1001&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;02755&quot;, &quot;owner&quot;: &quot;sko&quot;, &quot;path&quot;: &quot;/tmp/zutuanxue123&quot;, &quot;size&quot;: 19, &quot;state&quot;: &quot;directory&quot;, &quot;uid&quot;: 1001&#125; 删除一个目录[包括子文件全部删除] 删除所有业务机器的&#x2F;tmp&#x2F;zutuanxue123目录 12345678910111213141516171819202122232425[root@manage01 ~]# ansible -m file group1 -a &quot;path=/tmp/zutuanxue123 state=absent&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;path&quot;: &quot;/tmp/zutuanxue123&quot;, &quot;state&quot;: &quot;absent&quot;&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;path&quot;: &quot;/tmp/zutuanxue123&quot;, &quot;state&quot;: &quot;absent&quot;&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;path&quot;: &quot;/tmp/zutuanxue123&quot;, &quot;state&quot;: &quot;absent&quot;&#125; 二、学习视频视频：file模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-hostname模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-hostname模块/","content":"一、hostname模块hostname模块用于修改主机名（注意: 它不能修改&#x2F;etc&#x2F;hosts文件) https://docs.ansible.com/ansible/latest/modules/hostname_module.html#hostname-module 1234567891011121314151617将192.168.98.203机器的主机名修改为zutuanxue_node3[root@manage01 ~]# ansible -m hostname -a &quot;name=zutuanxue_node3&quot; 192.168.98.203192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_domain&quot;: &quot;&quot;, &quot;ansible_fqdn&quot;: &quot;zutuanxue_node3&quot;, &quot;ansible_hostname&quot;: &quot;zutuanxue_node3&quot;, &quot;ansible_nodename&quot;: &quot;zutuanxue_node3&quot;, &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;name&quot;: &quot;zutuanxue_node3&quot;&#125;备注：批量修改需要使用playbook剧本 二、学习视频视频：hostname模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-playbook剧本","path":"/2023/09/27/Ansible自动化运维平台/Ansible-playbook剧本/","content":"一、playbook介绍playbook(剧本): 是ansible用于配置,部署,和管理被控节点的剧本。 参考:https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html 使用的格式为yaml格式（saltstack,elk,docker等也都会用到yaml格式) 1234567891011121314树明的理解：playbook：ansible格式的脚本。将所有需要执行的操作按照ansible的编程语法，放到文件中执行。playbook替代方案1)、完全可以用shell脚本来替代playbook 将所有的ansible命令放入脚本 shell脚本中写的是ansible指令#!/bin/bashfor IP in `seq 201 203` do ansible -m hostname 192.168.98.$IP -a &quot;name=node$&#123;IP&#125;&quot;done 2)、ansible+shell脚本 使用script模块ansible -m script group2 &#x27;/etc/ansible/srcipts/nginx_install.sh&#x27; 1.1、YAML格式规则 文件的第一行以 “—“开始，表明YMAL文件的开始. 以#号开头为注释 列表中的所有成员都开始于相同的缩进级别, 并且使用一个 &quot;- &quot; 作为开头(一个横杠和一个空格) 一个字典是由一个简单的 键: 值 的形式组成(这个冒号后面必须是一个空格) 注意: 写这种文件不要使用tab键，都使用空格 参考: https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html#yaml-syntax 下面看一个官方的示例感受一下 123456789101112131415---# 一位职工记录name: Example Developerjob: Developerskill: Eliteemployed: Truefoods: - Apple - Orange - Strawberry - Mangolanguages: ruby: Elite python: Elite dotnet: Lame playbook实例先直接来看一个实例 apache安装及业务初始化 第1步: 创建一个存放playbook的目录(路径自定义) 1[root@manage01 ~]# mkdir -p /etc/ansible/playbook/web 第2步: 准备httpd配置文件,并修改成你想要的配置 1234[root@manage01 ~]# yum install httpd -y按需要修改你想要的配置(为了测试可以随意改动标记一下)[root@manage01 ~]# vim /etc/httpd/conf/httpd.conf 第3步: 写一个playbook文件(后缀为.yml或.yaml) 123456789101112131415161718192021222324252627282930313233343536[root@manage01 web]# cat apache.yaml ---- hosts: group1 remote_user: root vars: - user: zutuanxue tasks: - name: create user use variable user: user=zutuanxue state=present - name: install httpd server yum: name=&#123;&#123;item&#125;&#125; state=latest with_items: - httpd - httpd-devel - name: start httpd service service: name=httpd state=started enabled=yes - name: copy httpd.conf to group1:/etc/httpd/conf/ copy: src=/etc/ansible/playbook/web/httpd.conf dest=/etc/httpd/conf notify: - restart httpd service handlers: - name: restart httpd service service: name=httpd state=restarted #tasks#1、创建apache管理用户#2、安装httpd#3、服务启动管理#4、拷贝配置文件，业务初始化 #5、触发重启服务httpd 第4步: 执行写好的palybook 会显示出执行的过程，并且执行的每一步都有ok,changed,failed等标识 执行如果有错误(failed)会回滚，解决问题后，直接再执行这条命令即可,并会把failed改为changed（幂等性) 1[root@manage01 web]# ansible-playbook /etc/ansible/playbook/web/apache.yaml 1.2、Playbook常见语法hosts: 用于指定要执行任务的主机，其可以是一个或多个由冒号分隔主机组. remote_user: 用于指定远程主机上的执行任务的用户. 12- hosts: group1 remote_user: root tasks: 任务列表, 按顺序执行任务. 如果一个host执行task失败, 整个tasks都会回滚, 修正playbook 中的错误, 然后重新执行即可. 12345678910111213tasks: - name: create user use variable user: name=&#123;&#123;user&#125;&#125; state=present - name: install httpd server yum: name=httpd state=latest name=httpd-devel state=latest - name: start httpd service service: name=httpd state=started enabled=yes - name: copy httpd.conf to group1:/etc/httpd/conf/ copy: src=/opt/httpd.conf dest=/etc/httpd/conf/ handlers: 类似task，但需要使用notify通知调用，实现按需调用。 不管有多少个通知者进行了notify，等到play中的所有task执行完成之后，handlers也只会被执行一次. handlers最佳的应用场景是用来重启服务,或者触发系统重启操作.除此以外很少用到了. 12345678 notify: - restart httpd service handlers: - name: restart httpd service service: name=httpd state=restarted #注意: handlers 需要notify调用，他和tasks不同的是 tasks每次都会调用，heandlers触发才调用，比如配置文件修改了，在执行playbook的时候，就会将管理机上的新改的copy到被管理机，那么就会触发headlers重启服务，否则不会执行heanlers 练习: 修改httpd的端口为8080,再执行playbook测试 variables: 变量 定义变量可以被多次方便调用 12vars: - user: zutuanxue with_items: 迭代列表 其使用格式为将需要迭代的内容定义为item变量引用，并通过with_items语句指明迭代的元素列表即可。 例如安装多个软件包 1234yum: name=&#123;&#123;item&#125;&#125; state=latestwith_items: - httpd - httpd-devel 执行后有如下警告 警告.png 解决方法: 在&#x2F;etc&#x2F;ansible&#x2F;ansible.cfg配置文件里的[default]配置段下面加上deprecation_warnings&#x3D;False参数即可 二、练习案例写一个playbook实现 配置yum 安装vsftpd包 修改配置文件(要求拒绝匿名用户登录) 启动服务并实现vsftpd服务开机自动启动 12345678910111213141516171819202122232425---- hosts: group1 remote_user: root tasks: - name: rm yum repository file: path=/etc/yum.repos.d/ state=absent - name: 同步master上的yum源到group1 copy: src=/etc/yum.repos.d dest=/etc/ - name: ensure vsftpd is at the latest version yum: name=vsftpd state=latest - name: write the apache config file copy: src=/etc/vsftpd/vsftpd.conf dest=/etc/vsftpd/vsftpd.conf notify: - restart vsftpd - name: ensure vsftpd is running (and enable it at boot) service: name=vsftpd state=started enabled=yes handlers: - name: restart vsftpd service: name=vsftpd state=restarted","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-role","path":"/2023/09/27/Ansible自动化运维平台/Ansible-role/","content":"假设我们要写一个playbook来安装管理lamp环境，那么这个playbook就会写很长。所以我们希望把这个很大的文件分成多个功能拆分, 分成apache管理,php管理,mysql管理，然后在需要使用的时候直接调用就可以了，以免重复写。就类似编程里的模块化的概念，以达到代码复用的效果。 一、roles介绍roles： ansible模块，类似于函数，完成一个任务的指令。每一个roles都有自己特定的目录结构，就是通过分别将variables, tasks及handlers等放置于单独的目录中,并可以便捷地调用它们的一种机制。 roles优点： 1）模块中指令较少，方便编写 2）重复调用方便 3）排错方便 二、创建roles的目录结构123456files：用来存放由copy模块或script模块调用的文件。tasks：至少有一个main.yml文件，定义各tasks。handlers:有一个main.yml文件，定义各handlers。templates：用来存放jinjia2模板。vars：有一个main.yml文件，定义变量。meta：有一个main.yml文件，定义此角色的特殊设定及其依赖关系。 注意: 在每个角色的目录中分别创建files, tasks,handlers,templates,vars和meta目录，用不到的目录可以创建为空目录. 三、案例：通过roles实现lamp分析：需定制三个角色: httpd,mysql,php 3.1） 创建roles目录及文件,并确认目录结构roles&#x2F;├── httpd│ ├── files│ ├── handlers│ │ └── main.yml│ ├── meta│ │ └── main.yml│ ├── tasks│ │ └── main.yml│ ├── templates│ └── vars│ └── main.yml├── mysql│ ├── files│ ├── handlers│ │ └── main.yml│ ├── meta│ │ └── main.yml│ ├── tasks│ │ └── main.yml│ ├── templates│ └── vars│ └── main.yml└── php├── files├── handlers│ └── main.yml├── meta│ └── main.yml├── tasks│ └── main.yml├── templates└── vars└── main.yml 123456789101112131415161718192021222324252627282930313233343536373839[root@manage01 ansible]# mkdir -p roles/&#123;httpd,mysql,php&#125;/&#123;files,tasks,handlers,templates,vars,meta&#125;[root@manage01 ansible]# touch roles/&#123;httpd,mysql,php&#125;/&#123;tasks,handlers,vars,meta&#125;/main.yml[root@manage01 ansible]# tree roles/roles/├── httpd│ ├── files│ ├── handlers│ │ └── main.yml│ ├── meta│ │ └── main.yml│ ├── tasks│ │ └── main.yml│ ├── templates│ └── vars│ └── main.yml├── mysql│ ├── files│ ├── handlers│ │ └── main.yml│ ├── meta│ │ └── main.yml│ ├── tasks│ │ └── main.yml│ ├── templates│ └── vars│ └── main.yml└── php ├── files ├── handlers │ └── main.yml ├── meta │ └── main.yml ├── tasks │ └── main.yml ├── templates └── vars └── main.yml21 directories, 12 files 3.2）准备httpd服务器的主页文件,php测试页和配置文件等12[root@manage01 files]# lshttpd.conf phpinfo.php 3.3）编写httpd角色的main.yml文件12345678910111213141516171819202122232425262728293031[root@manage01 roles]# cat httpd/tasks/main.yml - name: httpd httpd-devel httpd-manual软件包安装 yum: name=&#123;&#123;item&#125;&#125; state=latest with_items: - httpd - httpd-devel - httpd-manual- name: 创建apache管理用户 www user: name=&#123;&#123;user&#125;&#125; state=present- name: 设置apache开机启动，并启动服务 service: name=httpd enabled=yes state=started- name: 拷贝配置文件，初始化业务 copy: src=/etc/ansible/roles/httpd/files/httpd.conf dest=/etc/httpd/conf/httpd.conf #定义通知调用，当配置文件更新,需要重启服务 notify: - restart apache- name: 拷贝php测试页面 copy: src=/etc/ansible/roles/httpd/files/phpinfo.php dest=/var/www/html/[root@manage01 roles]# cat httpd/vars/main.ymluser: www[root@manage01 roles]# cat httpd/handlers/main.yml - name: restart apache service: name=httpd state=restarted 3.4）编写mysql角色的main.yml文件12345678910111213141516171819202122[root@manage01 ansible]# ls roles/php/files/www.conf[root@manage01 roles]# cat mysql/tasks/main.yml - name: mysql 用户创建 user: name=&#123;&#123;user&#125;&#125; state=present- name: mysql 软件安装 yum: name=&#123;&#123;item&#125;&#125; state=latest with_items: - mariadb - mariadb-server- name: 启动服务，并设置开机启动 service: name=mariadb enabled=yes state=started- name: 改变mysql文件的所有者为mysql file: path=&#x27;/usr/lib/mysql&#x27; owner=&#123;&#123;user&#125;&#125; group=&#123;&#123;user&#125;&#125; recurse=yes[root@manage01 roles]# cat mysql/vars/main.yml user: mysql 3.5）:编写php角色的main.yml文件123456789101112131415161718192021222324252627282930[root@manage01 ansible]# cat roles/php/tasks/main.yml - name: 安装php yum: name=&#123;&#123;item&#125;&#125; state=latest with_items: - php - php-mysqlnd - php-gd - php-ldap - php-odbc - php-pear - php-xml - php-xmlrpc - php-mbstring - php-snmp - php-soap - curl - curl-devel - php-bcmath - php-fpm- name: copy www.conf to /etc/php-fpm.d copy: src=/etc/ansible/roles/php/files/www.conf dest=/etc/php-fpm.d force=yes notify: - restart php-fpm[root@manage01 ansible]# cat roles/php/handlers/main.yml - name: restart php-fpm service: name=php-fpm state=restarted 3.6）编写lamp的playbook文件调用前面定义好的三个角色12345678[root@manage01 yaml]# cat lamp.yml ---- hosts: group1 remote_user: root roles: - httpd - mysql - php 3.7） 执行lamp的playbook文件12[root@manage01 yaml]# ansible-playbook -C lamp.yml[root@manage01 yaml]# ansible-playbook lamp.yml 3.8） 测试业务机器lamp_test.png","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-group模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-group模块/","content":"一、group模块group模块用于管理用户组和用户组属性。 https://docs.ansible.com/ansible/latest/modules/group_module.html#group-module 参数 说明 name&#x3D; 组名 state&#x3D; persent|absent 创建|删除 system&#x3D; yes|no 是否为系统组 gid gid 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#组创建[root@manage01 ~]# ansible -m group group1 -a &quot;name=admin gid=4444 state=present&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;gid&quot;: 4444, &quot;name&quot;: &quot;admin&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: false&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;gid&quot;: 4444, &quot;name&quot;: &quot;admin&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: false&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;gid&quot;: 4444, &quot;name&quot;: &quot;admin&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: false&#125;#删除组[root@manage01 ~]# ansible -m group group1 -a &quot;name=admin state=absent&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;name&quot;: &quot;admin&quot;, &quot;state&quot;: &quot;absent&quot;&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;name&quot;: &quot;admin&quot;, &quot;state&quot;: &quot;absent&quot;&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;name&quot;: &quot;admin&quot;, &quot;state&quot;: &quot;absent&quot;&#125; 二、学习视频视频：group模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-script模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-script模块/","content":"一、script模块如何通过ansible执行一个脚本：lamp安装脚本 script模块：用于在远程机器上执行本地脚本。 https://docs.ansible.com/ansible/latest/modules/script_module.html#script-module 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146在manage01上创建脚本，通过ansible将脚本分发到被管理端[root@manage01 ~]# cat ansible_test.sh #!/bin/bash#ansible script module test scriptmkdir /opt/logfind / -name &quot;*.log&quot; -exec cp -rpf &#123;&#125; /opt/log \\;#脚本不用给执行权限[root@manage01 ~]# ansible -m script group1 -a &quot;/root/ansible_test.sh&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;changed&quot;: true, &quot;rc&quot;: 0, &quot;stderr&quot;: &quot;Shared connection to 192.168.98.203 closed.\\r &quot;, &quot;stderr_lines&quot;: [ &quot;Shared connection to 192.168.98.203 closed.&quot; ], &quot;stdout&quot;: &quot;cp: &#x27;/opt/log/sssd.log&#x27; 与&#x27;/opt/log/sssd.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/sssd_implicit_files.log&#x27; 与&#x27;/opt/log/sssd_implicit_files.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/sssd_nss.log&#x27; 与&#x27;/opt/log/sssd_nss.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/tuned.log&#x27; 与&#x27;/opt/log/tuned.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/audit.log&#x27; 与&#x27;/opt/log/audit.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/anaconda.log&#x27; 与&#x27;/opt/log/anaconda.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/X.log&#x27; 与&#x27;/opt/log/X.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/program.log&#x27; 与&#x27;/opt/log/program.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/packaging.log&#x27; 与&#x27;/opt/log/packaging.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/storage.log&#x27; 与&#x27;/opt/log/storage.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/ifcfg.log&#x27; 与&#x27;/opt/log/ifcfg.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/lvm.log&#x27; 与&#x27;/opt/log/lvm.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dnf.librepo.log&#x27; 与&#x27;/opt/log/dnf.librepo.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/hawkey.log&#x27; 与&#x27;/opt/log/hawkey.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dbus.log&#x27; 与&#x27;/opt/log/dbus.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/ks-script-5r3m4old.log&#x27; 与&#x27;/opt/log/ks-script-5r3m4old.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/ks-script-h97m_bc_.log&#x27; 与&#x27;/opt/log/ks-script-h97m_bc_.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/journal.log&#x27; 与&#x27;/opt/log/journal.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/boot.log&#x27; 与&#x27;/opt/log/boot.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-vmsvc.log&#x27; 与&#x27;/opt/log/vmware-vmsvc.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dnf.log&#x27; 与&#x27;/opt/log/dnf.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dnf.rpm.log&#x27; 与&#x27;/opt/log/dnf.rpm.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.3.log&#x27; 与&#x27;/opt/log/vmware-network.3.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.2.log&#x27; 与&#x27;/opt/log/vmware-network.2.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.1.log&#x27; 与&#x27;/opt/log/vmware-network.1.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.log&#x27; 与&#x27;/opt/log/vmware-network.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/rpm.log&#x27; 与&#x27;/opt/log/rpm.log&#x27; 为同一文件\\r &quot;, &quot;stdout_lines&quot;: [ &quot;cp: &#x27;/opt/log/sssd.log&#x27; 与&#x27;/opt/log/sssd.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/sssd_implicit_files.log&#x27; 与&#x27;/opt/log/sssd_implicit_files.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/sssd_nss.log&#x27; 与&#x27;/opt/log/sssd_nss.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/tuned.log&#x27; 与&#x27;/opt/log/tuned.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/audit.log&#x27; 与&#x27;/opt/log/audit.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/anaconda.log&#x27; 与&#x27;/opt/log/anaconda.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/X.log&#x27; 与&#x27;/opt/log/X.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/program.log&#x27; 与&#x27;/opt/log/program.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/packaging.log&#x27; 与&#x27;/opt/log/packaging.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/storage.log&#x27; 与&#x27;/opt/log/storage.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/ifcfg.log&#x27; 与&#x27;/opt/log/ifcfg.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/lvm.log&#x27; 与&#x27;/opt/log/lvm.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dnf.librepo.log&#x27; 与&#x27;/opt/log/dnf.librepo.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/hawkey.log&#x27; 与&#x27;/opt/log/hawkey.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dbus.log&#x27; 与&#x27;/opt/log/dbus.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/ks-script-5r3m4old.log&#x27; 与&#x27;/opt/log/ks-script-5r3m4old.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/ks-script-h97m_bc_.log&#x27; 与&#x27;/opt/log/ks-script-h97m_bc_.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/journal.log&#x27; 与&#x27;/opt/log/journal.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/boot.log&#x27; 与&#x27;/opt/log/boot.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-vmsvc.log&#x27; 与&#x27;/opt/log/vmware-vmsvc.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dnf.log&#x27; 与&#x27;/opt/log/dnf.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dnf.rpm.log&#x27; 与&#x27;/opt/log/dnf.rpm.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.3.log&#x27; 与&#x27;/opt/log/vmware-network.3.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.2.log&#x27; 与&#x27;/opt/log/vmware-network.2.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.1.log&#x27; 与&#x27;/opt/log/vmware-network.1.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.log&#x27; 与&#x27;/opt/log/vmware-network.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/rpm.log&#x27; 与&#x27;/opt/log/rpm.log&#x27; 为同一文件&quot; ]&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;changed&quot;: true, &quot;rc&quot;: 0, &quot;stderr&quot;: &quot;Shared connection to 192.168.98.202 closed.\\r &quot;, &quot;stderr_lines&quot;: [ &quot;Shared connection to 192.168.98.202 closed.&quot; ], &quot;stdout&quot;: &quot;cp: &#x27;/opt/log/home-75a175cb.log&#x27; 与&#x27;/opt/log/home-75a175cb.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/root-648d48b0.log&#x27; 与&#x27;/opt/log/root-648d48b0.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/audit.log&#x27; 与&#x27;/opt/log/audit.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/sssd.log&#x27; 与&#x27;/opt/log/sssd.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/sssd_implicit_files.log&#x27; 与&#x27;/opt/log/sssd_implicit_files.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/sssd_nss.log&#x27; 与&#x27;/opt/log/sssd_nss.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/sssd_kcm.log&#x27; 与&#x27;/opt/log/sssd_kcm.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/tuned.log&#x27; 与&#x27;/opt/log/tuned.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/anaconda.log&#x27; 与&#x27;/opt/log/anaconda.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/X.log&#x27; 与&#x27;/opt/log/X.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/program.log&#x27; 与&#x27;/opt/log/program.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/packaging.log&#x27; 与&#x27;/opt/log/packaging.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/storage.log&#x27; 与&#x27;/opt/log/storage.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/ifcfg.log&#x27; 与&#x27;/opt/log/ifcfg.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/lvm.log&#x27; 与&#x27;/opt/log/lvm.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dnf.librepo.log&#x27; 与&#x27;/opt/log/dnf.librepo.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/hawkey.log&#x27; 与&#x27;/opt/log/hawkey.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dbus.log&#x27; 与&#x27;/opt/log/dbus.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/ks-script-fx6j2w7d.log&#x27; 与&#x27;/opt/log/ks-script-fx6j2w7d.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/ks-script-igqtd8i1.log&#x27; 与&#x27;/opt/log/ks-script-igqtd8i1.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/journal.log&#x27; 与&#x27;/opt/log/journal.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/boot.log&#x27; 与&#x27;/opt/log/boot.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-vmsvc.log&#x27; 与&#x27;/opt/log/vmware-vmsvc.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/Xorg.9.log&#x27; 与&#x27;/opt/log/Xorg.9.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-vmusr.log&#x27; 与&#x27;/opt/log/vmware-vmusr.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dnf.log&#x27; 与&#x27;/opt/log/dnf.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dnf.rpm.log&#x27; 与&#x27;/opt/log/dnf.rpm.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.3.log&#x27; 与&#x27;/opt/log/vmware-network.3.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.2.log&#x27; 与&#x27;/opt/log/vmware-network.2.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.1.log&#x27; 与&#x27;/opt/log/vmware-network.1.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.log&#x27; 与&#x27;/opt/log/vmware-network.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/rpm.log&#x27; 与&#x27;/opt/log/rpm.log&#x27; 为同一文件\\r &quot;, &quot;stdout_lines&quot;: [ &quot;cp: &#x27;/opt/log/home-75a175cb.log&#x27; 与&#x27;/opt/log/home-75a175cb.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/root-648d48b0.log&#x27; 与&#x27;/opt/log/root-648d48b0.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/audit.log&#x27; 与&#x27;/opt/log/audit.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/sssd.log&#x27; 与&#x27;/opt/log/sssd.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/sssd_implicit_files.log&#x27; 与&#x27;/opt/log/sssd_implicit_files.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/sssd_nss.log&#x27; 与&#x27;/opt/log/sssd_nss.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/sssd_kcm.log&#x27; 与&#x27;/opt/log/sssd_kcm.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/tuned.log&#x27; 与&#x27;/opt/log/tuned.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/anaconda.log&#x27; 与&#x27;/opt/log/anaconda.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/X.log&#x27; 与&#x27;/opt/log/X.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/program.log&#x27; 与&#x27;/opt/log/program.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/packaging.log&#x27; 与&#x27;/opt/log/packaging.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/storage.log&#x27; 与&#x27;/opt/log/storage.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/ifcfg.log&#x27; 与&#x27;/opt/log/ifcfg.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/lvm.log&#x27; 与&#x27;/opt/log/lvm.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dnf.librepo.log&#x27; 与&#x27;/opt/log/dnf.librepo.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/hawkey.log&#x27; 与&#x27;/opt/log/hawkey.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dbus.log&#x27; 与&#x27;/opt/log/dbus.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/ks-script-fx6j2w7d.log&#x27; 与&#x27;/opt/log/ks-script-fx6j2w7d.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/ks-script-igqtd8i1.log&#x27; 与&#x27;/opt/log/ks-script-igqtd8i1.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/journal.log&#x27; 与&#x27;/opt/log/journal.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/boot.log&#x27; 与&#x27;/opt/log/boot.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-vmsvc.log&#x27; 与&#x27;/opt/log/vmware-vmsvc.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/Xorg.9.log&#x27; 与&#x27;/opt/log/Xorg.9.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-vmusr.log&#x27; 与&#x27;/opt/log/vmware-vmusr.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dnf.log&#x27; 与&#x27;/opt/log/dnf.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dnf.rpm.log&#x27; 与&#x27;/opt/log/dnf.rpm.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.3.log&#x27; 与&#x27;/opt/log/vmware-network.3.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.2.log&#x27; 与&#x27;/opt/log/vmware-network.2.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.1.log&#x27; 与&#x27;/opt/log/vmware-network.1.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.log&#x27; 与&#x27;/opt/log/vmware-network.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/rpm.log&#x27; 与&#x27;/opt/log/rpm.log&#x27; 为同一文件&quot; ]&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;changed&quot;: true, &quot;rc&quot;: 0, &quot;stderr&quot;: &quot;Shared connection to 192.168.98.201 closed.\\r &quot;, &quot;stderr_lines&quot;: [ &quot;Shared connection to 192.168.98.201 closed.&quot; ], &quot;stdout&quot;: &quot;cp: &#x27;/opt/log/home-2b167fc1.log&#x27; 与&#x27;/opt/log/home-2b167fc1.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/root-836d3cf3.log&#x27; 与&#x27;/opt/log/root-836d3cf3.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/audit.log&#x27; 与&#x27;/opt/log/audit.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/sssd_implicit_files.log&#x27; 与&#x27;/opt/log/sssd_implicit_files.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/sssd_kcm.log&#x27; 与&#x27;/opt/log/sssd_kcm.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/sssd_nss.log&#x27; 与&#x27;/opt/log/sssd_nss.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/sssd.log&#x27; 与&#x27;/opt/log/sssd.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/tuned.log&#x27; 与&#x27;/opt/log/tuned.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/anaconda.log&#x27; 与&#x27;/opt/log/anaconda.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/X.log&#x27; 与&#x27;/opt/log/X.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/program.log&#x27; 与&#x27;/opt/log/program.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/packaging.log&#x27; 与&#x27;/opt/log/packaging.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/storage.log&#x27; 与&#x27;/opt/log/storage.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/ifcfg.log&#x27; 与&#x27;/opt/log/ifcfg.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/lvm.log&#x27; 与&#x27;/opt/log/lvm.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dnf.librepo.log&#x27; 与&#x27;/opt/log/dnf.librepo.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/hawkey.log&#x27; 与&#x27;/opt/log/hawkey.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dbus.log&#x27; 与&#x27;/opt/log/dbus.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/ks-script-ai28ecf4.log&#x27; 与&#x27;/opt/log/ks-script-ai28ecf4.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/ks-script-k4vgo8wr.log&#x27; 与&#x27;/opt/log/ks-script-k4vgo8wr.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/journal.log&#x27; 与&#x27;/opt/log/journal.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/boot.log&#x27; 与&#x27;/opt/log/boot.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-vmsvc.log&#x27; 与&#x27;/opt/log/vmware-vmsvc.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/Xorg.9.log&#x27; 与&#x27;/opt/log/Xorg.9.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-vmusr.log&#x27; 与&#x27;/opt/log/vmware-vmusr.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dnf.log&#x27; 与&#x27;/opt/log/dnf.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/dnf.rpm.log&#x27; 与&#x27;/opt/log/dnf.rpm.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.6.log&#x27; 与&#x27;/opt/log/vmware-network.6.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.5.log&#x27; 与&#x27;/opt/log/vmware-network.5.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.4.log&#x27; 与&#x27;/opt/log/vmware-network.4.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.3.log&#x27; 与&#x27;/opt/log/vmware-network.3.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.2.log&#x27; 与&#x27;/opt/log/vmware-network.2.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.1.log&#x27; 与&#x27;/opt/log/vmware-network.1.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/vmware-network.log&#x27; 与&#x27;/opt/log/vmware-network.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/rpm.log&#x27; 与&#x27;/opt/log/rpm.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/error.log&#x27; 与&#x27;/opt/log/error.log&#x27; 为同一文件\\r cp: &#x27;/opt/log/access.log&#x27; 与&#x27;/opt/log/access.log&#x27; 为同一文件\\r &quot;, &quot;stdout_lines&quot;: [ &quot;cp: &#x27;/opt/log/home-2b167fc1.log&#x27; 与&#x27;/opt/log/home-2b167fc1.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/root-836d3cf3.log&#x27; 与&#x27;/opt/log/root-836d3cf3.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/audit.log&#x27; 与&#x27;/opt/log/audit.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/sssd_implicit_files.log&#x27; 与&#x27;/opt/log/sssd_implicit_files.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/sssd_kcm.log&#x27; 与&#x27;/opt/log/sssd_kcm.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/sssd_nss.log&#x27; 与&#x27;/opt/log/sssd_nss.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/sssd.log&#x27; 与&#x27;/opt/log/sssd.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/tuned.log&#x27; 与&#x27;/opt/log/tuned.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/anaconda.log&#x27; 与&#x27;/opt/log/anaconda.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/X.log&#x27; 与&#x27;/opt/log/X.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/program.log&#x27; 与&#x27;/opt/log/program.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/packaging.log&#x27; 与&#x27;/opt/log/packaging.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/storage.log&#x27; 与&#x27;/opt/log/storage.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/ifcfg.log&#x27; 与&#x27;/opt/log/ifcfg.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/lvm.log&#x27; 与&#x27;/opt/log/lvm.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dnf.librepo.log&#x27; 与&#x27;/opt/log/dnf.librepo.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/hawkey.log&#x27; 与&#x27;/opt/log/hawkey.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dbus.log&#x27; 与&#x27;/opt/log/dbus.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/ks-script-ai28ecf4.log&#x27; 与&#x27;/opt/log/ks-script-ai28ecf4.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/ks-script-k4vgo8wr.log&#x27; 与&#x27;/opt/log/ks-script-k4vgo8wr.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/journal.log&#x27; 与&#x27;/opt/log/journal.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/boot.log&#x27; 与&#x27;/opt/log/boot.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-vmsvc.log&#x27; 与&#x27;/opt/log/vmware-vmsvc.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/Xorg.9.log&#x27; 与&#x27;/opt/log/Xorg.9.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-vmusr.log&#x27; 与&#x27;/opt/log/vmware-vmusr.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dnf.log&#x27; 与&#x27;/opt/log/dnf.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/dnf.rpm.log&#x27; 与&#x27;/opt/log/dnf.rpm.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.6.log&#x27; 与&#x27;/opt/log/vmware-network.6.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.5.log&#x27; 与&#x27;/opt/log/vmware-network.5.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.4.log&#x27; 与&#x27;/opt/log/vmware-network.4.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.3.log&#x27; 与&#x27;/opt/log/vmware-network.3.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.2.log&#x27; 与&#x27;/opt/log/vmware-network.2.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.1.log&#x27; 与&#x27;/opt/log/vmware-network.1.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/vmware-network.log&#x27; 与&#x27;/opt/log/vmware-network.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/rpm.log&#x27; 与&#x27;/opt/log/rpm.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/error.log&#x27; 与&#x27;/opt/log/error.log&#x27; 为同一文件&quot;, &quot;cp: &#x27;/opt/log/access.log&#x27; 与&#x27;/opt/log/access.log&#x27; 为同一文件&quot; ]&#125; 二、学习视频视频：script模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-setup模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-setup模块/","content":"一、setup模块setup模块用于收集远程主机的基本信息（如操作系统类型,主机名,ip,cpu信息,内存信息等） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157#打印192.168.98.201机器的所有信息[root@manage01 ~]# ansible -m setup 192.168.98.201#使用filter过滤输出#打印192.168.98.201机器的CPU信息[root@manage01 ~]# ansible -m setup 192.168.98.201 -a &quot;filter=&#x27;ansible_processor&#x27;&quot;192.168.98.201 | SUCCESS =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_processor&quot;: [ &quot;0&quot;, &quot;GenuineIntel&quot;, &quot;Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz&quot;, &quot;1&quot;, &quot;GenuineIntel&quot;, &quot;Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz&quot;, &quot;2&quot;, &quot;GenuineIntel&quot;, &quot;Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz&quot;, &quot;3&quot;, &quot;GenuineIntel&quot;, &quot;Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz&quot; ], &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: false&#125;#打印192.168.98.201机器的内核信息[root@manage01 ~]# ansible -m setup 192.168.98.201 -a &quot;filter=&#x27;ansible_kernel&#x27;&quot;192.168.98.201 | SUCCESS =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_kernel&quot;: &quot;4.18.0-80.el8.x86_64&quot;, &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: false&#125;#打印192.168.98.201机器的主机名[root@manage01 ~]# ansible -m setup 192.168.98.201 -a &quot;filter=&#x27;ansible_hostname&#x27;&quot;192.168.98.201 | SUCCESS =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_hostname&quot;: &quot;node1&quot;, &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: false&#125;#打印192.168.98.201机器的网卡信息[root@manage01 ~]# ansible -m setup 192.168.98.201 -a &quot;filter=&#x27;ansible_ens*&#x27;&quot;192.168.98.201 | SUCCESS =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_ens33&quot;: &#123; &quot;active&quot;: true, &quot;device&quot;: &quot;ens33&quot;, &quot;features&quot;: &#123; &quot;esp_hw_offload&quot;: &quot;off [fixed]&quot;, &quot;esp_tx_csum_hw_offload&quot;: &quot;off [fixed]&quot;, &quot;fcoe_mtu&quot;: &quot;off [fixed]&quot;, &quot;generic_receive_offload&quot;: &quot;on&quot;, &quot;generic_segmentation_offload&quot;: &quot;on&quot;, &quot;highdma&quot;: &quot;off [fixed]&quot;, &quot;hw_tc_offload&quot;: &quot;off [fixed]&quot;, &quot;l2_fwd_offload&quot;: &quot;off [fixed]&quot;, &quot;large_receive_offload&quot;: &quot;off [fixed]&quot;, &quot;loopback&quot;: &quot;off [fixed]&quot;, &quot;netns_local&quot;: &quot;off [fixed]&quot;, &quot;ntuple_filters&quot;: &quot;off [fixed]&quot;, &quot;receive_hashing&quot;: &quot;off [fixed]&quot;, &quot;rx_all&quot;: &quot;off&quot;, &quot;rx_checksumming&quot;: &quot;off&quot;, &quot;rx_fcs&quot;: &quot;off&quot;, &quot;rx_gro_hw&quot;: &quot;off [fixed]&quot;, &quot;rx_udp_tunnel_port_offload&quot;: &quot;off [fixed]&quot;, &quot;rx_vlan_filter&quot;: &quot;on [fixed]&quot;, &quot;rx_vlan_offload&quot;: &quot;on&quot;, &quot;rx_vlan_stag_filter&quot;: &quot;off [fixed]&quot;, &quot;rx_vlan_stag_hw_parse&quot;: &quot;off [fixed]&quot;, &quot;scatter_gather&quot;: &quot;on&quot;, &quot;tcp_segmentation_offload&quot;: &quot;on&quot;, &quot;tls_hw_record&quot;: &quot;off [fixed]&quot;, &quot;tls_hw_tx_offload&quot;: &quot;off [fixed]&quot;, &quot;tx_checksum_fcoe_crc&quot;: &quot;off [fixed]&quot;, &quot;tx_checksum_ip_generic&quot;: &quot;on&quot;, &quot;tx_checksum_ipv4&quot;: &quot;off [fixed]&quot;, &quot;tx_checksum_ipv6&quot;: &quot;off [fixed]&quot;, &quot;tx_checksum_sctp&quot;: &quot;off [fixed]&quot;, &quot;tx_checksumming&quot;: &quot;on&quot;, &quot;tx_esp_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_fcoe_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_gre_csum_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_gre_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_gso_partial&quot;: &quot;off [fixed]&quot;, &quot;tx_gso_robust&quot;: &quot;off [fixed]&quot;, &quot;tx_ipxip4_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_ipxip6_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_lockless&quot;: &quot;off [fixed]&quot;, &quot;tx_nocache_copy&quot;: &quot;off&quot;, &quot;tx_scatter_gather&quot;: &quot;on&quot;, &quot;tx_scatter_gather_fraglist&quot;: &quot;off [fixed]&quot;, &quot;tx_sctp_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_tcp6_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_tcp_ecn_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_tcp_mangleid_segmentation&quot;: &quot;off&quot;, &quot;tx_tcp_segmentation&quot;: &quot;on&quot;, &quot;tx_udp_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_udp_tnl_csum_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_udp_tnl_segmentation&quot;: &quot;off [fixed]&quot;, &quot;tx_vlan_offload&quot;: &quot;on [fixed]&quot;, &quot;tx_vlan_stag_hw_insert&quot;: &quot;off [fixed]&quot;, &quot;udp_fragmentation_offload&quot;: &quot;off&quot;, &quot;vlan_challenged&quot;: &quot;off [fixed]&quot; &#125;, &quot;hw_timestamp_filters&quot;: [], &quot;ipv4&quot;: &#123; &quot;address&quot;: &quot;192.168.98.201&quot;, &quot;broadcast&quot;: &quot;192.168.98.255&quot;, &quot;netmask&quot;: &quot;255.255.255.0&quot;, &quot;network&quot;: &quot;192.168.98.0&quot; &#125;, &quot;ipv6&quot;: [ &#123; &quot;address&quot;: &quot;fe80::357b:9443:2232:f0c0&quot;, &quot;prefix&quot;: &quot;64&quot;, &quot;scope&quot;: &quot;link&quot; &#125; ], &quot;macaddress&quot;: &quot;00:0c:29:b8:d0:45&quot;, &quot;module&quot;: &quot;e1000&quot;, &quot;mtu&quot;: 1500, &quot;pciid&quot;: &quot;0000:02:01.0&quot;, &quot;promisc&quot;: false, &quot;speed&quot;: 1000, &quot;timestamping&quot;: [ &quot;tx_software&quot;, &quot;rx_software&quot;, &quot;software&quot; ], &quot;type&quot;: &quot;ether&quot; &#125;, &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: false&#125;其它常见的过滤条件ansible_all_ipv4_addresses：显示ipv4的信息。ansible_devices：显示磁盘设备信息。ansible_distribution_major_version：显示是系统主版本。ansible_distribution_version：仅显示系统版本。ansible_machine：显示系统类型，例：32位，还是64位。ansible_lvm：显示lvm相关信息。ansible_memtotal_mb：显示系统总内存。ansible_memfree_mb：显示可用系统内存。ansible_memory_mb：详细显示内存情况。ansible_swaptotal_mb：显示总的swap内存。ansible_swapfree_mb：显示swap内存的可用内存。ansible_mounts：显示系统磁盘挂载情况。ansible_processor：显示cpu个数(具体显示每个cpu的型号)。ansible_processor_vcpus：显示cpu个数(只显示总的个数)。 二、学习视频视频：setup模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-service模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-service模块/","content":"一、service模块service模块：用于控制服务的启动,关闭,开机自启动等。 https://docs.ansible.com/ansible/latest/modules/service_module.html#service-module 参数 说明 name 服务名称 state reloaded, restarted, started, stopped 服务管理 enabled yes|no 开启是否启动 启动vsftpd服务，并设为开机自动启动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207[root@manage01 ~]# ansible -m service 192.168.98.202 -a &quot;name=vsftpd state=started enabled=on&quot;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;enabled&quot;: true, &quot;name&quot;: &quot;vsftpd&quot;, &quot;state&quot;: &quot;started&quot;, &quot;status&quot;: &#123; &quot;ActiveEnterTimestampMonotonic&quot;: &quot;0&quot;, &quot;ActiveExitTimestampMonotonic&quot;: &quot;0&quot;, &quot;ActiveState&quot;: &quot;inactive&quot;, &quot;After&quot;: &quot;network.target systemd-journald.socket system.slice basic.target sysinit.target&quot;, &quot;AllowIsolate&quot;: &quot;no&quot;, &quot;AmbientCapabilities&quot;: &quot;&quot;, &quot;AssertResult&quot;: &quot;no&quot;, &quot;AssertTimestampMonotonic&quot;: &quot;0&quot;, &quot;Before&quot;: &quot;shutdown.target&quot;, &quot;BlockIOAccounting&quot;: &quot;no&quot;, &quot;BlockIOWeight&quot;: &quot;[not set]&quot;, &quot;CPUAccounting&quot;: &quot;no&quot;, &quot;CPUQuotaPerSecUSec&quot;: &quot;infinity&quot;, &quot;CPUSchedulingPolicy&quot;: &quot;0&quot;, &quot;CPUSchedulingPriority&quot;: &quot;0&quot;, &quot;CPUSchedulingResetOnFork&quot;: &quot;no&quot;, &quot;CPUShares&quot;: &quot;[not set]&quot;, &quot;CPUUsageNSec&quot;: &quot;[not set]&quot;, &quot;CPUWeight&quot;: &quot;[not set]&quot;, &quot;CacheDirectoryMode&quot;: &quot;0755&quot;, &quot;CanIsolate&quot;: &quot;no&quot;, &quot;CanReload&quot;: &quot;no&quot;, &quot;CanStart&quot;: &quot;yes&quot;, &quot;CanStop&quot;: &quot;yes&quot;, &quot;CapabilityBoundingSet&quot;: &quot;cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend&quot;, &quot;CollectMode&quot;: &quot;inactive&quot;, &quot;ConditionResult&quot;: &quot;no&quot;, &quot;ConditionTimestampMonotonic&quot;: &quot;0&quot;, &quot;ConfigurationDirectoryMode&quot;: &quot;0755&quot;, &quot;Conflicts&quot;: &quot;shutdown.target&quot;, &quot;ControlPID&quot;: &quot;0&quot;, &quot;DefaultDependencies&quot;: &quot;yes&quot;, &quot;Delegate&quot;: &quot;no&quot;, &quot;Description&quot;: &quot;Vsftpd ftp daemon&quot;, &quot;DevicePolicy&quot;: &quot;auto&quot;, &quot;DynamicUser&quot;: &quot;no&quot;, &quot;ExecMainCode&quot;: &quot;0&quot;, &quot;ExecMainExitTimestampMonotonic&quot;: &quot;0&quot;, &quot;ExecMainPID&quot;: &quot;0&quot;, &quot;ExecMainStartTimestampMonotonic&quot;: &quot;0&quot;, &quot;ExecMainStatus&quot;: &quot;0&quot;, &quot;ExecStart&quot;: &quot;&#123; path=/usr/sbin/vsftpd ; argv[]=/usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 &#125;&quot;, &quot;FailureAction&quot;: &quot;none&quot;, &quot;FileDescriptorStoreMax&quot;: &quot;0&quot;, &quot;FragmentPath&quot;: &quot;/usr/lib/systemd/system/vsftpd.service&quot;, &quot;GID&quot;: &quot;[not set]&quot;, &quot;GuessMainPID&quot;: &quot;yes&quot;, &quot;IOAccounting&quot;: &quot;no&quot;, &quot;IOSchedulingClass&quot;: &quot;0&quot;, &quot;IOSchedulingPriority&quot;: &quot;0&quot;, &quot;IOWeight&quot;: &quot;[not set]&quot;, &quot;IPAccounting&quot;: &quot;no&quot;, &quot;IPEgressBytes&quot;: &quot;18446744073709551615&quot;, &quot;IPEgressPackets&quot;: &quot;18446744073709551615&quot;, &quot;IPIngressBytes&quot;: &quot;18446744073709551615&quot;, &quot;IPIngressPackets&quot;: &quot;18446744073709551615&quot;, &quot;Id&quot;: &quot;vsftpd.service&quot;, &quot;IgnoreOnIsolate&quot;: &quot;no&quot;, &quot;IgnoreSIGPIPE&quot;: &quot;yes&quot;, &quot;InactiveEnterTimestampMonotonic&quot;: &quot;0&quot;, &quot;InactiveExitTimestampMonotonic&quot;: &quot;0&quot;, &quot;JobRunningTimeoutUSec&quot;: &quot;infinity&quot;, &quot;JobTimeoutAction&quot;: &quot;none&quot;, &quot;JobTimeoutUSec&quot;: &quot;infinity&quot;, &quot;KeyringMode&quot;: &quot;private&quot;, &quot;KillMode&quot;: &quot;control-group&quot;, &quot;KillSignal&quot;: &quot;15&quot;, &quot;LimitAS&quot;: &quot;infinity&quot;, &quot;LimitASSoft&quot;: &quot;infinity&quot;, &quot;LimitCORE&quot;: &quot;infinity&quot;, &quot;LimitCORESoft&quot;: &quot;infinity&quot;, &quot;LimitCPU&quot;: &quot;infinity&quot;, &quot;LimitCPUSoft&quot;: &quot;infinity&quot;, &quot;LimitDATA&quot;: &quot;infinity&quot;, &quot;LimitDATASoft&quot;: &quot;infinity&quot;, &quot;LimitFSIZE&quot;: &quot;infinity&quot;, &quot;LimitFSIZESoft&quot;: &quot;infinity&quot;, &quot;LimitLOCKS&quot;: &quot;infinity&quot;, &quot;LimitLOCKSSoft&quot;: &quot;infinity&quot;, &quot;LimitMEMLOCK&quot;: &quot;16777216&quot;, &quot;LimitMEMLOCKSoft&quot;: &quot;16777216&quot;, &quot;LimitMSGQUEUE&quot;: &quot;819200&quot;, &quot;LimitMSGQUEUESoft&quot;: &quot;819200&quot;, &quot;LimitNICE&quot;: &quot;0&quot;, &quot;LimitNICESoft&quot;: &quot;0&quot;, &quot;LimitNOFILE&quot;: &quot;4096&quot;, &quot;LimitNOFILESoft&quot;: &quot;1024&quot;, &quot;LimitNPROC&quot;: &quot;7741&quot;, &quot;LimitNPROCSoft&quot;: &quot;7741&quot;, &quot;LimitRSS&quot;: &quot;infinity&quot;, &quot;LimitRSSSoft&quot;: &quot;infinity&quot;, &quot;LimitRTPRIO&quot;: &quot;0&quot;, &quot;LimitRTPRIOSoft&quot;: &quot;0&quot;, &quot;LimitRTTIME&quot;: &quot;infinity&quot;, &quot;LimitRTTIMESoft&quot;: &quot;infinity&quot;, &quot;LimitSIGPENDING&quot;: &quot;7741&quot;, &quot;LimitSIGPENDINGSoft&quot;: &quot;7741&quot;, &quot;LimitSTACK&quot;: &quot;infinity&quot;, &quot;LimitSTACKSoft&quot;: &quot;8388608&quot;, &quot;LoadState&quot;: &quot;loaded&quot;, &quot;LockPersonality&quot;: &quot;no&quot;, &quot;LogLevelMax&quot;: &quot;-1&quot;, &quot;LogsDirectoryMode&quot;: &quot;0755&quot;, &quot;MainPID&quot;: &quot;0&quot;, &quot;MemoryAccounting&quot;: &quot;yes&quot;, &quot;MemoryCurrent&quot;: &quot;[not set]&quot;, &quot;MemoryDenyWriteExecute&quot;: &quot;no&quot;, &quot;MemoryHigh&quot;: &quot;infinity&quot;, &quot;MemoryLimit&quot;: &quot;infinity&quot;, &quot;MemoryLow&quot;: &quot;0&quot;, &quot;MemoryMax&quot;: &quot;infinity&quot;, &quot;MemorySwapMax&quot;: &quot;infinity&quot;, &quot;MountAPIVFS&quot;: &quot;no&quot;, &quot;MountFlags&quot;: &quot;&quot;, &quot;NFileDescriptorStore&quot;: &quot;0&quot;, &quot;NRestarts&quot;: &quot;0&quot;, &quot;Names&quot;: &quot;vsftpd.service&quot;, &quot;NeedDaemonReload&quot;: &quot;no&quot;, &quot;Nice&quot;: &quot;0&quot;, &quot;NoNewPrivileges&quot;: &quot;no&quot;, &quot;NonBlocking&quot;: &quot;no&quot;, &quot;NotifyAccess&quot;: &quot;none&quot;, &quot;OOMScoreAdjust&quot;: &quot;0&quot;, &quot;OnFailureJobMode&quot;: &quot;replace&quot;, &quot;PermissionsStartOnly&quot;: &quot;no&quot;, &quot;Perpetual&quot;: &quot;no&quot;, &quot;PrivateDevices&quot;: &quot;no&quot;, &quot;PrivateMounts&quot;: &quot;no&quot;, &quot;PrivateNetwork&quot;: &quot;no&quot;, &quot;PrivateTmp&quot;: &quot;no&quot;, &quot;PrivateUsers&quot;: &quot;no&quot;, &quot;ProtectControlGroups&quot;: &quot;no&quot;, &quot;ProtectHome&quot;: &quot;no&quot;, &quot;ProtectKernelModules&quot;: &quot;no&quot;, &quot;ProtectKernelTunables&quot;: &quot;no&quot;, &quot;ProtectSystem&quot;: &quot;no&quot;, &quot;RefuseManualStart&quot;: &quot;no&quot;, &quot;RefuseManualStop&quot;: &quot;no&quot;, &quot;RemainAfterExit&quot;: &quot;no&quot;, &quot;RemoveIPC&quot;: &quot;no&quot;, &quot;Requires&quot;: &quot;sysinit.target system.slice&quot;, &quot;Restart&quot;: &quot;no&quot;, &quot;RestartUSec&quot;: &quot;100ms&quot;, &quot;RestrictNamespaces&quot;: &quot;no&quot;, &quot;RestrictRealtime&quot;: &quot;no&quot;, &quot;Result&quot;: &quot;success&quot;, &quot;RootDirectoryStartOnly&quot;: &quot;no&quot;, &quot;RuntimeDirectoryMode&quot;: &quot;0755&quot;, &quot;RuntimeDirectoryPreserve&quot;: &quot;no&quot;, &quot;RuntimeMaxUSec&quot;: &quot;infinity&quot;, &quot;SameProcessGroup&quot;: &quot;no&quot;, &quot;SecureBits&quot;: &quot;0&quot;, &quot;SendSIGHUP&quot;: &quot;no&quot;, &quot;SendSIGKILL&quot;: &quot;yes&quot;, &quot;Slice&quot;: &quot;system.slice&quot;, &quot;StandardError&quot;: &quot;inherit&quot;, &quot;StandardInput&quot;: &quot;null&quot;, &quot;StandardInputData&quot;: &quot;&quot;, &quot;StandardOutput&quot;: &quot;journal&quot;, &quot;StartLimitAction&quot;: &quot;none&quot;, &quot;StartLimitBurst&quot;: &quot;5&quot;, &quot;StartLimitIntervalUSec&quot;: &quot;10s&quot;, &quot;StartupBlockIOWeight&quot;: &quot;[not set]&quot;, &quot;StartupCPUShares&quot;: &quot;[not set]&quot;, &quot;StartupCPUWeight&quot;: &quot;[not set]&quot;, &quot;StartupIOWeight&quot;: &quot;[not set]&quot;, &quot;StateChangeTimestampMonotonic&quot;: &quot;0&quot;, &quot;StateDirectoryMode&quot;: &quot;0755&quot;, &quot;StatusErrno&quot;: &quot;0&quot;, &quot;StopWhenUnneeded&quot;: &quot;no&quot;, &quot;SubState&quot;: &quot;dead&quot;, &quot;SuccessAction&quot;: &quot;none&quot;, &quot;SyslogFacility&quot;: &quot;3&quot;, &quot;SyslogLevel&quot;: &quot;6&quot;, &quot;SyslogLevelPrefix&quot;: &quot;yes&quot;, &quot;SyslogPriority&quot;: &quot;30&quot;, &quot;SystemCallErrorNumber&quot;: &quot;0&quot;, &quot;TTYReset&quot;: &quot;no&quot;, &quot;TTYVHangup&quot;: &quot;no&quot;, &quot;TTYVTDisallocate&quot;: &quot;no&quot;, &quot;TasksAccounting&quot;: &quot;yes&quot;, &quot;TasksCurrent&quot;: &quot;[not set]&quot;, &quot;TasksMax&quot;: &quot;12386&quot;, &quot;TimeoutStartUSec&quot;: &quot;1min 30s&quot;, &quot;TimeoutStopUSec&quot;: &quot;1min 30s&quot;, &quot;TimerSlackNSec&quot;: &quot;50000&quot;, &quot;Transient&quot;: &quot;no&quot;, &quot;Type&quot;: &quot;forking&quot;, &quot;UID&quot;: &quot;[not set]&quot;, &quot;UMask&quot;: &quot;0022&quot;, &quot;UnitFilePreset&quot;: &quot;disabled&quot;, &quot;UnitFileState&quot;: &quot;disabled&quot;, &quot;UtmpMode&quot;: &quot;init&quot;, &quot;WatchdogTimestampMonotonic&quot;: &quot;0&quot;, &quot;WatchdogUSec&quot;: &quot;0&quot; &#125;&#125; 关闭vsftpd服务，并设为开机不自动启动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217[root@manage01 ~]# ansible -m service 192.168.98.202 -a &quot;name=vsftpd state=stopped enabled=false&quot;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;enabled&quot;: false, &quot;name&quot;: &quot;vsftpd&quot;, &quot;state&quot;: &quot;stopped&quot;, &quot;status&quot;: &#123; &quot;ActiveEnterTimestamp&quot;: &quot;Fri 2019-10-18 04:13:19 EDT&quot;, &quot;ActiveEnterTimestampMonotonic&quot;: &quot;89286681247&quot;, &quot;ActiveExitTimestampMonotonic&quot;: &quot;0&quot;, &quot;ActiveState&quot;: &quot;active&quot;, &quot;After&quot;: &quot;systemd-journald.socket sysinit.target basic.target system.slice network.target&quot;, &quot;AllowIsolate&quot;: &quot;no&quot;, &quot;AmbientCapabilities&quot;: &quot;&quot;, &quot;AssertResult&quot;: &quot;yes&quot;, &quot;AssertTimestamp&quot;: &quot;Fri 2019-10-18 04:13:19 EDT&quot;, &quot;AssertTimestampMonotonic&quot;: &quot;89286676375&quot;, &quot;Before&quot;: &quot;multi-user.target shutdown.target&quot;, &quot;BlockIOAccounting&quot;: &quot;no&quot;, &quot;BlockIOWeight&quot;: &quot;[not set]&quot;, &quot;CPUAccounting&quot;: &quot;no&quot;, &quot;CPUQuotaPerSecUSec&quot;: &quot;infinity&quot;, &quot;CPUSchedulingPolicy&quot;: &quot;0&quot;, &quot;CPUSchedulingPriority&quot;: &quot;0&quot;, &quot;CPUSchedulingResetOnFork&quot;: &quot;no&quot;, &quot;CPUShares&quot;: &quot;[not set]&quot;, &quot;CPUUsageNSec&quot;: &quot;[not set]&quot;, &quot;CPUWeight&quot;: &quot;[not set]&quot;, &quot;CacheDirectoryMode&quot;: &quot;0755&quot;, &quot;CanIsolate&quot;: &quot;no&quot;, &quot;CanReload&quot;: &quot;no&quot;, &quot;CanStart&quot;: &quot;yes&quot;, &quot;CanStop&quot;: &quot;yes&quot;, &quot;CapabilityBoundingSet&quot;: &quot;cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend&quot;, &quot;CollectMode&quot;: &quot;inactive&quot;, &quot;ConditionResult&quot;: &quot;yes&quot;, &quot;ConditionTimestamp&quot;: &quot;Fri 2019-10-18 04:13:19 EDT&quot;, &quot;ConditionTimestampMonotonic&quot;: &quot;89286676375&quot;, &quot;ConfigurationDirectoryMode&quot;: &quot;0755&quot;, &quot;Conflicts&quot;: &quot;shutdown.target&quot;, &quot;ControlGroup&quot;: &quot;/system.slice/vsftpd.service&quot;, &quot;ControlPID&quot;: &quot;0&quot;, &quot;DefaultDependencies&quot;: &quot;yes&quot;, &quot;Delegate&quot;: &quot;no&quot;, &quot;Description&quot;: &quot;Vsftpd ftp daemon&quot;, &quot;DevicePolicy&quot;: &quot;auto&quot;, &quot;DynamicUser&quot;: &quot;no&quot;, &quot;ExecMainCode&quot;: &quot;0&quot;, &quot;ExecMainExitTimestampMonotonic&quot;: &quot;0&quot;, &quot;ExecMainPID&quot;: &quot;51752&quot;, &quot;ExecMainStartTimestamp&quot;: &quot;Fri 2019-10-18 04:13:19 EDT&quot;, &quot;ExecMainStartTimestampMonotonic&quot;: &quot;89286681239&quot;, &quot;ExecMainStatus&quot;: &quot;0&quot;, &quot;ExecStart&quot;: &quot;&#123; path=/usr/sbin/vsftpd ; argv[]=/usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf ; ignore_errors=no ; start_time=[Fri 2019-10-18 04:13:19 EDT] ; stop_time=[Fri 2019-10-18 04:13:19 EDT] ; pid=51751 ; code=exited ; status=0 &#125;&quot;, &quot;FailureAction&quot;: &quot;none&quot;, &quot;FileDescriptorStoreMax&quot;: &quot;0&quot;, &quot;FragmentPath&quot;: &quot;/usr/lib/systemd/system/vsftpd.service&quot;, &quot;GID&quot;: &quot;[not set]&quot;, &quot;GuessMainPID&quot;: &quot;yes&quot;, &quot;IOAccounting&quot;: &quot;no&quot;, &quot;IOSchedulingClass&quot;: &quot;0&quot;, &quot;IOSchedulingPriority&quot;: &quot;0&quot;, &quot;IOWeight&quot;: &quot;[not set]&quot;, &quot;IPAccounting&quot;: &quot;no&quot;, &quot;IPEgressBytes&quot;: &quot;18446744073709551615&quot;, &quot;IPEgressPackets&quot;: &quot;18446744073709551615&quot;, &quot;IPIngressBytes&quot;: &quot;18446744073709551615&quot;, &quot;IPIngressPackets&quot;: &quot;18446744073709551615&quot;, &quot;Id&quot;: &quot;vsftpd.service&quot;, &quot;IgnoreOnIsolate&quot;: &quot;no&quot;, &quot;IgnoreSIGPIPE&quot;: &quot;yes&quot;, &quot;InactiveEnterTimestampMonotonic&quot;: &quot;0&quot;, &quot;InactiveExitTimestamp&quot;: &quot;Fri 2019-10-18 04:13:19 EDT&quot;, &quot;InactiveExitTimestampMonotonic&quot;: &quot;89286677130&quot;, &quot;InvocationID&quot;: &quot;e326c69c138b430880f883b0bdb05f83&quot;, &quot;JobRunningTimeoutUSec&quot;: &quot;infinity&quot;, &quot;JobTimeoutAction&quot;: &quot;none&quot;, &quot;JobTimeoutUSec&quot;: &quot;infinity&quot;, &quot;KeyringMode&quot;: &quot;private&quot;, &quot;KillMode&quot;: &quot;control-group&quot;, &quot;KillSignal&quot;: &quot;15&quot;, &quot;LimitAS&quot;: &quot;infinity&quot;, &quot;LimitASSoft&quot;: &quot;infinity&quot;, &quot;LimitCORE&quot;: &quot;infinity&quot;, &quot;LimitCORESoft&quot;: &quot;infinity&quot;, &quot;LimitCPU&quot;: &quot;infinity&quot;, &quot;LimitCPUSoft&quot;: &quot;infinity&quot;, &quot;LimitDATA&quot;: &quot;infinity&quot;, &quot;LimitDATASoft&quot;: &quot;infinity&quot;, &quot;LimitFSIZE&quot;: &quot;infinity&quot;, &quot;LimitFSIZESoft&quot;: &quot;infinity&quot;, &quot;LimitLOCKS&quot;: &quot;infinity&quot;, &quot;LimitLOCKSSoft&quot;: &quot;infinity&quot;, &quot;LimitMEMLOCK&quot;: &quot;16777216&quot;, &quot;LimitMEMLOCKSoft&quot;: &quot;16777216&quot;, &quot;LimitMSGQUEUE&quot;: &quot;819200&quot;, &quot;LimitMSGQUEUESoft&quot;: &quot;819200&quot;, &quot;LimitNICE&quot;: &quot;0&quot;, &quot;LimitNICESoft&quot;: &quot;0&quot;, &quot;LimitNOFILE&quot;: &quot;4096&quot;, &quot;LimitNOFILESoft&quot;: &quot;1024&quot;, &quot;LimitNPROC&quot;: &quot;7741&quot;, &quot;LimitNPROCSoft&quot;: &quot;7741&quot;, &quot;LimitRSS&quot;: &quot;infinity&quot;, &quot;LimitRSSSoft&quot;: &quot;infinity&quot;, &quot;LimitRTPRIO&quot;: &quot;0&quot;, &quot;LimitRTPRIOSoft&quot;: &quot;0&quot;, &quot;LimitRTTIME&quot;: &quot;infinity&quot;, &quot;LimitRTTIMESoft&quot;: &quot;infinity&quot;, &quot;LimitSIGPENDING&quot;: &quot;7741&quot;, &quot;LimitSIGPENDINGSoft&quot;: &quot;7741&quot;, &quot;LimitSTACK&quot;: &quot;infinity&quot;, &quot;LimitSTACKSoft&quot;: &quot;8388608&quot;, &quot;LoadState&quot;: &quot;loaded&quot;, &quot;LockPersonality&quot;: &quot;no&quot;, &quot;LogLevelMax&quot;: &quot;-1&quot;, &quot;LogsDirectoryMode&quot;: &quot;0755&quot;, &quot;MainPID&quot;: &quot;51752&quot;, &quot;MemoryAccounting&quot;: &quot;yes&quot;, &quot;MemoryCurrent&quot;: &quot;577536&quot;, &quot;MemoryDenyWriteExecute&quot;: &quot;no&quot;, &quot;MemoryHigh&quot;: &quot;infinity&quot;, &quot;MemoryLimit&quot;: &quot;infinity&quot;, &quot;MemoryLow&quot;: &quot;0&quot;, &quot;MemoryMax&quot;: &quot;infinity&quot;, &quot;MemorySwapMax&quot;: &quot;infinity&quot;, &quot;MountAPIVFS&quot;: &quot;no&quot;, &quot;MountFlags&quot;: &quot;&quot;, &quot;NFileDescriptorStore&quot;: &quot;0&quot;, &quot;NRestarts&quot;: &quot;0&quot;, &quot;Names&quot;: &quot;vsftpd.service&quot;, &quot;NeedDaemonReload&quot;: &quot;no&quot;, &quot;Nice&quot;: &quot;0&quot;, &quot;NoNewPrivileges&quot;: &quot;no&quot;, &quot;NonBlocking&quot;: &quot;no&quot;, &quot;NotifyAccess&quot;: &quot;none&quot;, &quot;OOMScoreAdjust&quot;: &quot;0&quot;, &quot;OnFailureJobMode&quot;: &quot;replace&quot;, &quot;PermissionsStartOnly&quot;: &quot;no&quot;, &quot;Perpetual&quot;: &quot;no&quot;, &quot;PrivateDevices&quot;: &quot;no&quot;, &quot;PrivateMounts&quot;: &quot;no&quot;, &quot;PrivateNetwork&quot;: &quot;no&quot;, &quot;PrivateTmp&quot;: &quot;no&quot;, &quot;PrivateUsers&quot;: &quot;no&quot;, &quot;ProtectControlGroups&quot;: &quot;no&quot;, &quot;ProtectHome&quot;: &quot;no&quot;, &quot;ProtectKernelModules&quot;: &quot;no&quot;, &quot;ProtectKernelTunables&quot;: &quot;no&quot;, &quot;ProtectSystem&quot;: &quot;no&quot;, &quot;RefuseManualStart&quot;: &quot;no&quot;, &quot;RefuseManualStop&quot;: &quot;no&quot;, &quot;RemainAfterExit&quot;: &quot;no&quot;, &quot;RemoveIPC&quot;: &quot;no&quot;, &quot;Requires&quot;: &quot;system.slice sysinit.target&quot;, &quot;Restart&quot;: &quot;no&quot;, &quot;RestartUSec&quot;: &quot;100ms&quot;, &quot;RestrictNamespaces&quot;: &quot;no&quot;, &quot;RestrictRealtime&quot;: &quot;no&quot;, &quot;Result&quot;: &quot;success&quot;, &quot;RootDirectoryStartOnly&quot;: &quot;no&quot;, &quot;RuntimeDirectoryMode&quot;: &quot;0755&quot;, &quot;RuntimeDirectoryPreserve&quot;: &quot;no&quot;, &quot;RuntimeMaxUSec&quot;: &quot;infinity&quot;, &quot;SameProcessGroup&quot;: &quot;no&quot;, &quot;SecureBits&quot;: &quot;0&quot;, &quot;SendSIGHUP&quot;: &quot;no&quot;, &quot;SendSIGKILL&quot;: &quot;yes&quot;, &quot;Slice&quot;: &quot;system.slice&quot;, &quot;StandardError&quot;: &quot;inherit&quot;, &quot;StandardInput&quot;: &quot;null&quot;, &quot;StandardInputData&quot;: &quot;&quot;, &quot;StandardOutput&quot;: &quot;journal&quot;, &quot;StartLimitAction&quot;: &quot;none&quot;, &quot;StartLimitBurst&quot;: &quot;5&quot;, &quot;StartLimitIntervalUSec&quot;: &quot;10s&quot;, &quot;StartupBlockIOWeight&quot;: &quot;[not set]&quot;, &quot;StartupCPUShares&quot;: &quot;[not set]&quot;, &quot;StartupCPUWeight&quot;: &quot;[not set]&quot;, &quot;StartupIOWeight&quot;: &quot;[not set]&quot;, &quot;StateChangeTimestamp&quot;: &quot;Fri 2019-10-18 04:13:19 EDT&quot;, &quot;StateChangeTimestampMonotonic&quot;: &quot;89286681247&quot;, &quot;StateDirectoryMode&quot;: &quot;0755&quot;, &quot;StatusErrno&quot;: &quot;0&quot;, &quot;StopWhenUnneeded&quot;: &quot;no&quot;, &quot;SubState&quot;: &quot;running&quot;, &quot;SuccessAction&quot;: &quot;none&quot;, &quot;SyslogFacility&quot;: &quot;3&quot;, &quot;SyslogLevel&quot;: &quot;6&quot;, &quot;SyslogLevelPrefix&quot;: &quot;yes&quot;, &quot;SyslogPriority&quot;: &quot;30&quot;, &quot;SystemCallErrorNumber&quot;: &quot;0&quot;, &quot;TTYReset&quot;: &quot;no&quot;, &quot;TTYVHangup&quot;: &quot;no&quot;, &quot;TTYVTDisallocate&quot;: &quot;no&quot;, &quot;TasksAccounting&quot;: &quot;yes&quot;, &quot;TasksCurrent&quot;: &quot;1&quot;, &quot;TasksMax&quot;: &quot;12386&quot;, &quot;TimeoutStartUSec&quot;: &quot;1min 30s&quot;, &quot;TimeoutStopUSec&quot;: &quot;1min 30s&quot;, &quot;TimerSlackNSec&quot;: &quot;50000&quot;, &quot;Transient&quot;: &quot;no&quot;, &quot;Type&quot;: &quot;forking&quot;, &quot;UID&quot;: &quot;[not set]&quot;, &quot;UMask&quot;: &quot;0022&quot;, &quot;UnitFilePreset&quot;: &quot;disabled&quot;, &quot;UnitFileState&quot;: &quot;enabled&quot;, &quot;UtmpMode&quot;: &quot;init&quot;, &quot;WantedBy&quot;: &quot;multi-user.target&quot;, &quot;WatchdogTimestamp&quot;: &quot;Fri 2019-10-18 04:13:19 EDT&quot;, &quot;WatchdogTimestampMonotonic&quot;: &quot;89286681246&quot;, &quot;WatchdogUSec&quot;: &quot;0&quot; &#125;&#125; 二、学习视频视频：service模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-stat模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-stat模块/","content":"一、stat模块stat模块类似linux的stat命令，用于获取文件的状态信息。 https://docs.ansible.com/ansible/latest/modules/stat_module.html#stat-module 获取&#x2F;etc&#x2F;fstab文件的状态信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@manage01 ~]# ansible -m stat 192.168.98.201 -a &quot;path=/etc/fstab&quot;192.168.98.201 | SUCCESS =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: false, &quot;stat&quot;: &#123; &quot;atime&quot;: 1571386074.1020715, &quot;attr_flags&quot;: &quot;&quot;, &quot;attributes&quot;: [], &quot;block_size&quot;: 4096, &quot;blocks&quot;: 8, &quot;charset&quot;: &quot;us-ascii&quot;, &quot;checksum&quot;: &quot;554e387b5bde93c05baa689312e9a8db5579629e&quot;, &quot;ctime&quot;: 1570636725.1020045, &quot;dev&quot;: 64768, &quot;device_type&quot;: 0, &quot;executable&quot;: false, &quot;exists&quot;: true, &quot;gid&quot;: 0, &quot;gr_name&quot;: &quot;root&quot;, &quot;inode&quot;: 16777347, &quot;isblk&quot;: false, &quot;ischr&quot;: false, &quot;isdir&quot;: false, &quot;isfifo&quot;: false, &quot;isgid&quot;: false, &quot;islnk&quot;: false, &quot;isreg&quot;: true, &quot;issock&quot;: false, &quot;isuid&quot;: false, &quot;mimetype&quot;: &quot;text/plain&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;mtime&quot;: 1570636308.3990006, &quot;nlink&quot;: 1, &quot;path&quot;: &quot;/etc/fstab&quot;, &quot;pw_name&quot;: &quot;root&quot;, &quot;readable&quot;: true, &quot;rgrp&quot;: true, &quot;roth&quot;: true, &quot;rusr&quot;: true, &quot;size&quot;: 579, &quot;uid&quot;: 0, &quot;version&quot;: &quot;1364475400&quot;, &quot;wgrp&quot;: false, &quot;woth&quot;: false, &quot;writeable&quot;: true, &quot;wusr&quot;: true, &quot;xgrp&quot;: false, &quot;xoth&quot;: false, &quot;xusr&quot;: false &#125;&#125; 二、学习视频视频：ansible常用模块知识图谱","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-user模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-user模块/","content":"一、user模块user模块用于管理用户账号和用户属性 https://docs.ansible.com/ansible/latest/modules/user_module.html#user-module 常用参数 说明 name&#x3D;”” 指定用户名 password&#x3D;”” 指定密码,必须是密文 state&#x3D; absent|present 删除|创建 system&#x3D; yes|no 是否为系统用户 shell&#x3D;”” 指定登陆shell generate_ssh_key&#x3D; yes|no 是否创建秘钥对 uid&#x3D; 指定用户的uid append&#x3D; yes|no 用户是否追加到其他组 group&#x3D; 用户属组 groups&#x3D; 将现有用户加入到某个组，空值就会把该用户从所有所属组中删除 create_home&#x3D; yes|no 是否建立家目录 remove&#x3D; yes|no 删除家目录 创建一个用户sky，密码是123 要求是系统用户 非交互式登陆 要求生成自己的秘钥对 不创建家目录 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#密码必须是密文，所以先要把明文转换一下，生成md5密文[root@manage01 ~]# echo 123|openssl passwd -1 -stdin$1$5V.qzSEd$Yr08MU8K.vXeBZcmavypk1[root@manage01 ~]# ansible -m user group1 -a &#x27;name=sky password=&quot;$1$5V.qzSEd$Yr08MU8K.vXeBZcmavypk1&quot; state=present system=yes shell=/sbin/nologin generate_ssh_key=yes&#x27;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;create_home&quot;: true, &quot;group&quot;: 991, &quot;home&quot;: &quot;/home/sky&quot;, &quot;name&quot;: &quot;sky&quot;, &quot;password&quot;: &quot;NOT_LOGGING_PASSWORD&quot;, &quot;shell&quot;: &quot;/sbin/nologin&quot;, &quot;ssh_fingerprint&quot;: &quot;2048 SHA256:b2umG0XfPW0cGAFBFDBNBNbtgaY+s1X4cM334JCGGOo ansible-generated on node3 (RSA)&quot;, &quot;ssh_key_file&quot;: &quot;/home/sky/.ssh/id_rsa&quot;, &quot;ssh_public_key&quot;: &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDIvVcTDxT4GotFYolpPPJUS2XYEmgaxCj/YLXfW2vllXJSfa3TwBLN6kJnPBabVFSYCiGRzci28f/rx4chm9TuVsNx6TozzUpolD+T3vzO/rcLdaIEzw+JYXGtqpaTapuuhm6pdQBx04TLmO3pVWBCdbJum0paMIXwPDcGPGz6JwGXWTdA5AXfvWmOZ5ChwwLDUau84R47FHfj9EisclYM3Yt3WfcVp+waSd23BBRj86jh+veL9BR7OnDmmj7YZkOxAqnU/TjuOW1uiGCB91Flgku7fPR3jmbXXrd+Ql9vWlGe22+xgYYjT4KVzlHAr3lE/HZQu49Vz/N78ZnJ1rX3 ansible-generated on node3&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: true, &quot;uid&quot;: 994&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;create_home&quot;: true, &quot;group&quot;: 974, &quot;home&quot;: &quot;/home/sky&quot;, &quot;name&quot;: &quot;sky&quot;, &quot;password&quot;: &quot;NOT_LOGGING_PASSWORD&quot;, &quot;shell&quot;: &quot;/sbin/nologin&quot;, &quot;ssh_fingerprint&quot;: &quot;2048 SHA256:D2ZhPJV9bdFMtf7EBo3Y5w023xqxDppZxqoe5Z3NVus ansible-generated on node1 (RSA)&quot;, &quot;ssh_key_file&quot;: &quot;/home/sky/.ssh/id_rsa&quot;, &quot;ssh_public_key&quot;: &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQD1swS5MAox4o2f3rxe9TPz+AFDnB5Jt+X6Yygpphfetfds37SHSP5K4QcAd1SO6OlHopB3x9FQklS3z6C4bfz5trbK/PR9RCzkkzLamC5BKhNXEV2ozj1m2J/F10umZLSvd3ElEJubkyzV383x7sVi5VtQycemoDLiJiWjHTEcKu/I0bSCliODe57nqgM9+5V+nfeih56Vs+vhTGIxqZ/6FZXKGM9iDiI8VokUlMjhOJz5MuFRr4XsgBvtGNyu/bCbjr8QPdDNX/Wl8IZDjLJNHDno8ixc7Bp6ME2hEr9pnpe+DuKJmsAwl+A52E7eAlm/0pp573mZ4ObHRTQwdgQT ansible-generated on node1&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: true, &quot;uid&quot;: 976&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;create_home&quot;: true, &quot;group&quot;: 975, &quot;home&quot;: &quot;/home/sky&quot;, &quot;name&quot;: &quot;sky&quot;, &quot;password&quot;: &quot;NOT_LOGGING_PASSWORD&quot;, &quot;shell&quot;: &quot;/sbin/nologin&quot;, &quot;ssh_fingerprint&quot;: &quot;2048 SHA256:/VBzZUWcHnLOpMNxq9OXIwD/5IkI9r7smp50s6lByZs ansible-generated on node2 (RSA)&quot;, &quot;ssh_key_file&quot;: &quot;/home/sky/.ssh/id_rsa&quot;, &quot;ssh_public_key&quot;: &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDT/+8y3omHiWSOS9dX1AYcADRp7ZUszOBqZV0/77TZ7mV5X1/T+cdZrsnwAiNbXosjDQjKj0qtIJQR3rLuCv08DV6gjlP4bzDodSekfh1mbGu9EkDu0HD+qmW0/y5Mb4lJbBCMHCVJFrwBnH2+AfVezTVgcf4NHh4zJvASnSfmecmyfFEDEVZIozd0z8hw8NcgcYn8MeDrMhVN+y3xj0IXKwg6E0NindBuxkMYbwehcQo6Sscx9YdCv05SXVU+FjyPOQNzZZUQkmp+5GDy1dib1m5GJ5yIf8IzOh1FISoKz8/FqORRIEp55NRgrGw3ZU/weK0RL9SkXhUc29gcN1ON ansible-generated on node2&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: true, &quot;uid&quot;: 977&#125;创建用户baishuming 密码为123456[root@manage01 ~]# echo &quot;123456&quot;|openssl passwd -1 -stdin$1$BMPgiHeV$GskMFnvqBL17gTe/us5yK.[root@manage01 ~]# ansible -m user group1 -a &#x27;name=baishuming password=&quot;$1$BMPgiHeV$GskMFnvqBL17gTe/us5yK.&quot; uid=4423&#x27;不创建家目录[root@manage01 ~]# ansible -m user 192.168.98.201 -a &quot;name=baism create_home=no&quot;要求属组为root附加组为sko 用户删除 1234567891011[root@manage01 ~]# ansible -m user 192.168.98.201 -a &quot;name=baishuming1 state=absent remove=yes&quot;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot; &#125;, &quot;changed&quot;: true, &quot;force&quot;: false, &quot;name&quot;: &quot;baishuming1&quot;, &quot;remove&quot;: true, &quot;state&quot;: &quot;absent&quot;&#125; 二、学习视频视频：user模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible命令用法","path":"/2023/09/27/Ansible自动化运维平台/Ansible命令用法/","content":"ansible是基于模块工作的，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。 ansible支持的模块非常的多，我们并不需要把每个模块都记住，而只需要熟悉一些常见的模块，其它的模块在需要用到时再查询即可。 一、ansible命令用法12ansible 机器 -m 模块名称 -a &#x27;模块参数&#x27;基本格式为: ansible 操作的机器名或组名 -m 模块名 -a &quot;参数1=值1 参数2=值2&quot; 查看所有支持的模块 12345678910# ansible-doc -l a10_server Manage A10 Networks AX/SoftAX...a10_server_axapi3 Manage A10 Networks AX/SoftAX...a10_service_group Manage A10 Networks AX/SoftAX...a10_virtual_server Manage A10 Networks AX/SoftAX...aci_aaa_user Manage AAA users (aaa:User).......如果要查看ping模块的用法，使用下面命令（其它模块以此类推)# ansible-doc ping 官网模块文档地址: https://docs.ansible.com/ansible/latest/modules/list_of_all_modules.html 二、ansible常见模块 hostname模块 file模块 copy模块 fetch模块 user模块 group模块 cron模块 yum_repository模块 yum模块 service模块 script模块 command模块 shell模块 setup模块 stat模块 三、学习视频视频：ansible 命令语法与常见模块介绍","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-yum_repository模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-yum_repository模块/","content":"一、yum_repository模块yum_repository模块用于配置yum仓库。 https://docs.ansible.com/ansible/latest/modules/yum_repository_module.html 参数 说明 name 仓库名 name.repo 源的名称 [name] description 描述 baseurl 包下载路径 gpgcheck&#x3D; 1 or 0 包gpg验证 enabled &#x3D; yes|no 是否开启本源 state&#x3D; absent 删除源 增加一个&#x2F;etc&#x2F;yum.repos.d&#x2F;dvd.repo配置文件 12345678910111213141516171819202122232425[root@manage01 ~]# ansible -m yum_repository group1 -a &quot;name=dvd description=BaseOS baseurl=file:///mnt/BaseOS gpgcheck=0 enabled=yes&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;repo&quot;: &quot;dvd&quot;, &quot;state&quot;: &quot;present&quot;&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;repo&quot;: &quot;dvd&quot;, &quot;state&quot;: &quot;present&quot;&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;repo&quot;: &quot;dvd&quot;, &quot;state&quot;: &quot;present&quot;&#125; 删除某个yum源 12345678910111213141516171819202122232425[root@manage01 ~]# ansible -m yum_repository group1 -a &quot;name=dvd state=absent&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;repo&quot;: &quot;dvd&quot;, &quot;state&quot;: &quot;absent&quot;&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;repo&quot;: &quot;dvd&quot;, &quot;state&quot;: &quot;absent&quot;&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;repo&quot;: &quot;dvd&quot;, &quot;state&quot;: &quot;absent&quot;&#125; 二、学习视频视频：yum_repository模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible自动化运维平台部署","path":"/2023/09/27/Ansible自动化运维平台/Ansible自动化运维平台部署/","content":"一、部署前准备 部署机器准备 计算机名解析 关闭防火墙、selinux 时间同步 软件包获得 ssh免密登陆 约定事项： 所有服务器全部采用静态ip 主机名称 IP地址 manage01 192.168.98.200&#x2F;24 node1 192.168.98.201&#x2F;24 node2 192.168.98.202&#x2F;24 node3 192.168.98.203&#x2F;24 主机名及主机名互相绑定 123456789[root@manage01 ~]# cat /etc/hosts127.0.0.1 localhost::1 localhost 192.168.98.200\tmanage01192.168.98.201\tnode1192.168.98.202\tnode2192.168.98.203\tnode3其他机器同理 关闭防火墙, selinux 123456[root@manage01 ~]# systemctl disable firewalld[root@manage01 ~]# sed -i -r &#x27;/SELINUX=/c\\SELINUX=disabled&#x27; /etc/selinux/config[root@manage01 ~]# reboot其他机器同理 采用时间服务器，时间同步 1234567891011121314151617181920212223242526272829301、修改配置文件，配置时间服务器为阿里云的时间服务器[root@manage01 ~]# egrep &quot;^server&quot; /etc/chrony.conf server ntp1.aliyun.comserver ntp2.aliyun.comserver ntp3.aliyun.comserver ntp4.aliyun.com#注释# pool 2.centos.pool.ntp.org iburst2、重启服务chronyd[root@manage01 ~]# systemctl restart chronyd.service 3、查看源信息#chronyc chrony的命令行客户端[root@manage01 ~]# chronyc sources -v210 Number of sources = 2 .-- Source mode &#x27;^&#x27; = server, &#x27;=&#x27; = peer, &#x27;#&#x27; = local clock. / .- Source state &#x27;*&#x27; = current synced, &#x27;+&#x27; = combined , &#x27;-&#x27; = not combined,| / &#x27;?&#x27; = unreachable, &#x27;x&#x27; = time may be in error, &#x27;~&#x27; = time too variable.|| .- xxxx [ yyyy ] +/- zzzz|| Reachability register (octal) -. | xxxx = adjusted offset,|| Log2(Polling interval) --. | | yyyy = measured offset,|| \\ | | zzzz = estimated error.|| | | \\MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^? 120.25.115.20 2 6 1 3 +663us[ +663us] +/- 23ms^? 203.107.6.88 2 6 1 2 -1326us[-1326us] +/- 17ms 确认和配置yum源(需要epel源) 1[root@manage01 ~]# yum -y install epel-* 6.ssh远程连接 管理端和被管理端连接时基于ssh的，所以有两种连接方式 1）基于ssh口令 2）基于ssh证书（重点讲解） 如果想不需要运维人员干预，被管理端必须允许管理端证书免密登陆。 #管理端manage01生成ssh公私钥 [root@manage01 ~]# ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: SHA256:aufJno2QjPK/V63/PVW13h5oWlKu0jk7HesXYTho0gM root@manage01 The key&#39;s randomart image is: +---[RSA 2048]----+ | | | E .| | o . . o| | . = + +.| | S o.+ = +| | o o ...* +o| | . . * ....O o.+| | o . =.*.B o +.| | ..o+B oo*oo o| +----[SHA256]-----+ #将公钥传给node1 [root@manage01 ~]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.98.201 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;.ssh/id_rsa.pub&quot; The authenticity of host &#39;192.168.98.201 (192.168.98.201)&#39; can&#39;t be established. ECDSA key fingerprint is SHA256:u+yOQz+E+eF7Oixdz/vClLXlAEu/7K8jy783gzk20dQ. ECDSA key fingerprint is MD5:c0:80:1b:ae:93:32:c2:66:f5:da:2f:1c:26:1e:7e:f8. Are you sure you want to continue connecting (yes/no)? yes /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@192.168.98.201&#39;s password: Number of key(s) added: 1 Now try logging into the machine, with: &quot;ssh &#39;root@192.168.98.201&#39;&quot; and check to make sure that only the key(s) you wanted were added. #将公钥传给node2 [root@manage01 ~]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.98.202 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;.ssh/id_rsa.pub&quot; The authenticity of host &#39;192.168.98.202 (192.168.98.202)&#39; can&#39;t be established. ECDSA key fingerprint is SHA256:X4JeiiFuwV0cja81veAyGCosriEfZm/zv34cfYkuxmU. ECDSA key fingerprint is MD5:7d:17:0f:80:d5:2b:30:ec:2c:62:f9:79:6b:fb:5f:bc. Are you sure you want to continue connecting (yes/no)? yes /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@192.168.98.202&#39;s password: Number of key(s) added: 1 Now try logging into the machine, with: &quot;ssh &#39;root@192.168.98.202&#39;&quot; and check to make sure that only the key(s) you wanted were added. #将公钥传给node3 [root@manage01 ~]# ssh-copy-id -i .ssh/id_rsa.pub root@192.168.98.203 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;.ssh/id_rsa.pub&quot; The authenticity of host &#39;192.168.98.203 (192.168.98.203)&#39; can&#39;t be established. ECDSA key fingerprint is SHA256:PtpsYBjaXkE+o3j8QYU5Ju8uPgcW2lVW8wsx4X1PV/c. ECDSA key fingerprint is MD5:50:a1:63:a0:ef:e7:61:26:11:25:ae:06:ec:93:cb:18. Are you sure you want to continue connecting (yes/no)? yes /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@192.168.98.203&#39;s password: Number of key(s) added: 1 Now try logging into the machine, with: &quot;ssh &#39;root@192.168.98.203&#39;&quot; and check to make sure that only the key(s) you wanted were added. 小窍门 免交互创建公私钥 [root@manage01 ansible]# ssh-keygen -f /root/.ssh/id_rsa -N &quot;&quot; -f 指定密钥存放路径 -N &quot;&quot; 新密码设置问空 -P &quot;&quot; 老密码是什么 如何可以非交互式传公钥呢 [root@manage01 ansible]# yum -y install sshpass [root@manage01 ansible]# sshpass -p111111 ssh-copy-id -o StrictHostKeyChecking=no -i /root/.ssh/id_rsa.pub root@192.168.98.202 StrictHostKeyChecking 严厉的主机监测=no 就不会问你yes|no了 sshpass 非交互式传密码 测试证书是否生效 [root@manage01 ~]# for i in `seq 201 203`;do &gt; ssh root@192.168.98.$i &quot;hostname&quot; &gt; done node1 node2 node3 看到返回客户端的计算机名称 123456789## 二、ansible管理端部署### 2.1）管理端安装ansible安装方式:1）yum [root@manage01 ~]# yum -y install ansible[root@manage01 ~]# ansible –versionansible 2.8.5 config file &#x3D; &#x2F;etc&#x2F;ansible&#x2F;ansible.cfg configured module search path &#x3D; [‘&#x2F;root&#x2F;.ansible&#x2F;plugins&#x2F;modules’, ‘&#x2F;usr&#x2F;share&#x2F;ansible&#x2F;plugins&#x2F;modules’] ansible python module location &#x3D; &#x2F;usr&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;ansible executable location &#x3D; &#x2F;usr&#x2F;bin&#x2F;ansible python version &#x3D; 3.6.8 (default, May 21 2019, 23:51:36) [GCC 8.2.1 20180905 (Red Hat 8.2.1-3)] 1232） 源码 1、官网下载地址：https://releases.ansible.com/ansible[root@manage01 ~]# wget https://releases.ansible.com/ansible/ansible-2.9.3.tar.gz2、安装ansible[root@manage01 ~]# tar xf ansible-2.9.3.tar.gz[root@manage01 ~]# mv ansible-2.9.3 &#x2F;opt&#x2F;ansible[root@manage01 ~]# cd &#x2F;opt&#x2F;ansible-2.9.3#python软件包安装–1、安装依赖[root@manage01 ansible-2.9.0rc3]# pip3 install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/[root@manage01 ansible]# ln -s &#x2F;usr&#x2F;bin&#x2F;pip3 &#x2F;usr&#x2F;bin&#x2F;pip#python软件包安装–2、安装软件[root@manage01 ansible-2.9.0rc3]# pip install –user ansible -i https://pypi.tuna.tsinghua.edu.cn/simple/ #安装后设置[root@manage01 ~]# ln -s &#x2F;usr&#x2F;bin&#x2F;python3 &#x2F;usr&#x2F;bin&#x2F;python[root@manage01 ~]# ln -s &#x2F;opt&#x2F;ansible&#x2F;bin&#x2F;* &#x2F;usr&#x2F;bin&#x2F;[root@manage01 ~]# cp &#x2F;opt&#x2F;ansible&#x2F;examples&#x2F;ansible.cfg &#x2F;etc&#x2F;ansible&#x2F;[root@manage01 ~]# cp &#x2F;opt&#x2F;ansible&#x2F;examples&#x2F;hosts &#x2F;etc&#x2F;ansible&#x2F; 123**FAQ1** [root@manage01 ansible-2.9.0rc3]# .&#x2F;bin&#x2F;ansible -m ping 192.168.98.201 [WARNING]: No inventory was parsed, only implicit localhost is available [WARNING]: provided hosts list is empty, only localhost is available. Note thatthe implicit localhost does not match ‘all’ [WARNING]: Could not match supplied host pattern, ignoring: 192.168.98.201 触发原因 执行ansible的时候回去读取客户端文件hosts，如果没有把客户端加入到hosts文件，就说明无法ansible无法管理。 解决方案 [root@manage01 ansible]# mkdir &#x2F;etc&#x2F;ansible [root@manage01 ansible]# cp examples&#x2F;hosts &#x2F;etc&#x2F;ansible&#x2F; #将需要管理的客户端IP地址写入hosts文件,可以分组或者直接写 [root@manage01 ~]# cat &#x2F;etc&#x2F;ansible&#x2F;hosts 192.168.98.[201:203] 分组 [group1]192.168.98.[201:203] 12345### 2.2）ansible管理服务器部署管理端ansible目录：/etc/ansible [root@manage01 ansible]# tree.├── ansible.cfg #ansible配置文件,不需要配置├── hosts #主机列表└── roles #角色列表 1 directory, 2 files 123### 2.3）部署主机列表，定义被监控机 [root@manage01 ansible]# egrep -v “(^#|^$)” &#x2F;etc&#x2F;ansible&#x2F;hosts[group1] #名字可以随便起 后面跟上业务机器的IP地址或者域名192.168.98.201192.168.98.202192.168.98.203 123**关于业务机器分组** 分组中使用范围[nginx] 组名apache[1:10].aaa.com\t表示apache1.aaa.com到apache10.aaa.com这10台机器nginx[a:z].aaa.com 表示nginxa.aaa.com到nginxz.aaa.com共26台机器10.1.1.[11:15] 表示10.1.1.11到10.1.1.15这5台机器 如果业务机器的SSH端口不是2210.1.1.13:2222 表示10.1.1.13这台，但ssh端口为2222 指定业务机器别名，未做免密登陆的机器可以通过下面的机器设置账号密码nginx1 ansible_ssh_host&#x3D;10.1.1.13 ansible_ssh_port&#x3D;2222 ansible_ssh_user&#x3D;root ansible_ssh_pass&#x3D;”123456” ansible_ssh_host 指定业务机器的IP或域名ansible_ssh_port 指定业务机器的ssh端口ansible_ssh_user 指定业务机器的ssh用户名ansible_ssh_pass 指定业务机器的ssh用户名密码 利用机器别名分组nginx1 ansible_ssh_host&#x3D;10.1.1.13 ansible_ssh_port&#x3D;2222 ansible_ssh_user&#x3D;root ansible_ssh_pass&#x3D;”123456”nginx2 ansible_ssh_host&#x3D;10.1.1.12 [nginx]nginx1 #写服务器别名nginx2 [root@manage01 ansible]# egrep -v “(^#|^$)” &#x2F;etc&#x2F;ansible&#x2F;hosts#别名定义web1 ansible_ssh_host&#x3D;192.168.98.203 ansible_ssh_port&#x3D;12121 #分组[group1]192.168.98.201#未做免密登陆机器192.168.98.202:12121 ansible_ssh_user&#x3D;sko ansible_ssh_pass&#x3D;’123’#别名机器web1 ansible_ssh_user&#x3D;sko ansible_ssh_pass&#x3D;’123’ 123### 2.4）测试管理机和业务机器的联通性 我们可以使用ansible通过调用ping模块来测试分组机器或某个机器-m 指定使用的模块 group1 业务机器分组#测试单个机器#测试主机列表中的机器 #测试单个机器方法[root@manage01 ~]# ansible -m ping 192.168.98.201192.168.98.201 | SUCCESS &#x3D;&gt; { “ansible_facts”: { “discovered_interpreter_python”: “&#x2F;usr&#x2F;libexec&#x2F;platform-python” }, “changed”: false, “ping”: “pong”} #测试主机列表中的机器方法[root@manage01 ~]# ansible -m ping group1192.168.98.201 | SUCCESS &#x3D;&gt; { “ansible_facts”: { “discovered_interpreter_python”: “&#x2F;usr&#x2F;libexec&#x2F;platform-python” }, “changed”: false, “ping”: “pong”}192.168.98.203 | SUCCESS &#x3D;&gt; { “ansible_facts”: { “discovered_interpreter_python”: “&#x2F;usr&#x2F;libexec&#x2F;platform-python” }, “changed”: false, “ping”: “pong”}192.168.98.202 | SUCCESS &#x3D;&gt; { “ansible_facts”: { “discovered_interpreter_python”: “&#x2F;usr&#x2F;libexec&#x2F;platform-python” }, “changed”: false, “ping”: “pong”} ## 三、学习视频 [视频：部署前准备](https://www.bilibili.com/video/BV19J41167sM?p=6) [视频：ssh证书互信设置](https://www.bilibili.com/video/BV19J41167sM?p=7) [视频：ansible平台部署](https://www.bilibili.com/video/BV19J41167sM?p=8) [视频：主机列表文件hosts文件](https://www.bilibili.com/video/BV19J41167sM?p=9) [视频：ansible自动化平台部署知识图谱](https://www.bilibili.com/video/BV19J41167sM?p=10)","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible-yum模块","path":"/2023/09/27/Ansible自动化运维平台/Ansible-yum模块/","content":"一、yum模块yum模块用于使用yum命令来实现软件包的安装与卸载。 https://docs.ansible.com/ansible/latest/modules/yum_module.html#yum-module 参数 说明 name 需要安装软件包的名称 list&#x3D; installed, updates, available and repos 列出已安装 需要更新 可获得的 和 yum源 state&#x3D; absent removed installed present latest 删除、删除、安装确认、安装确认、安装最新版本 list:列出包信息 12345678910111213[root@manage01 ~]# ansible -m yum group1 -a &quot;list=repos&quot;192.168.98.201 | FAILED! =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: false, &quot;msg&quot;: &quot;同步仓库 &#x27;dvd&#x27; 缓存失败&quot;, &quot;rc&quot;: 1, &quot;results&quot;: []&#125;原因就是源不好用，这里是cdrom没有挂载光盘 使用yum安装一个软件（前提:group1的机器上的yum配置都已经OK） 12345678910111213141516171819202122232425262728293031323334353637[root@manage01 ~]# ansible -m yum group1 -a &quot;name=vsftpd&quot;192.168.98.203 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;msg&quot;: &quot;&quot;, &quot;rc&quot;: 0, &quot;results&quot;: [ &quot;Installed: vsftpd&quot;, &quot;Installed: vsftpd-3.0.3-28.el8.x86_64&quot; ]&#125;192.168.98.202 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;msg&quot;: &quot;&quot;, &quot;rc&quot;: 0, &quot;results&quot;: [ &quot;Installed: vsftpd&quot;, &quot;Installed: vsftpd-3.0.3-28.el8.x86_64&quot; ]&#125;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;msg&quot;: &quot;&quot;, &quot;rc&quot;: 0, &quot;results&quot;: [ &quot;Installed: vsftpd&quot;, &quot;Installed: vsftpd-3.0.3-28.el8.x86_64&quot; ]&#125; 删除软件包 123456789101112[root@manage01 ~]# ansible -m yum 192.168.98.201 -a &quot;state=absent name=vsftpd&quot;192.168.98.201 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;msg&quot;: &quot;&quot;, &quot;rc&quot;: 0, &quot;results&quot;: [ &quot;Removed: vsftpd-3.0.3-28.el8.x86_64&quot; ]&#125; 二、学习视频视频：yum模块","categories":["Linux","Ansible自动化运维平台"]},{"title":"Ansible运维自动化平台初识","path":"/2023/09/27/Ansible自动化运维平台/Ansible运维自动化平台初识/","content":"一、运维自动化平台介绍1.1、自动化运维平台介绍运维自动化平台是由管理机器[S]和业务机器[C]组成的,C&#x2F;S。 管理机器：任务定制及发布； 业务机器：接收任务并执行任务。 运维自动化平台组成.png 1.2、运维自动化平台的优势： 一次性任务定制：任务一次性发布给所有机器 节省任务执行时间：任务主机并发完成任务，节省部署时间 错误率低：避免重复，保证一次任务定制准确即可 二、常见的自动化运维工具2.1、常见的运维自动化工具 Puppet Ansible SaltStack 12345678puppet：基于Ruby开发，有产品线已经在用，优点是历史悠久，比较成熟，在可远程可本地，功能强劲，批量执行需要写专门的配置文件，费力费时。而且有客户端在，和授权系统结合比较麻烦。saltstack:saltstack和ansible都是python流的，而且就功能上来讲，两者也极为相似，不同之处是salt stack是有客户端的，并且execution模块还用0MQ实现了pub-sub，命令和执行结果因此可以高效并行传输，不过成也萧何败也萧何，第一个sub阶段（将querystring下发到所有机器，然后收集机器响应的阶段）太依赖与客户端返回了，如果客户端未能及时返回或未响应的话，playbook执行阶段可能会直接漏掉这部分机器而没有任何提示，这对于运维来说是不可接受的。ansible:与前两者比起来，在特性上似乎并不抢眼，配置管理方面（playbook）绝对比不过老大哥puppet，批量执行方面也只是多线程，不像saltstack那么高大上，不过ansible搜索热度高出saltstack三倍多，显然靠的不是吹牛，至少，ansible至少不会悄悄的丢机器，这给了我们一个定心丸，而且仅依赖ssh，与登录授权管理系统天然集成，简单即有效，没有比这更美妙的事情了。 2.2、ansible介绍ansible是一种由Python开发的自动化运维工具，集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。ansible是基于模块工作的，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。主要包括： 连接插件connection plugins：负责和被监控端实现通信；ansible管理端和客户端基于ssh协议通信 host inventory：指定操作的主机，是一个配置文件里面定义监控的主机；提供主机管理列表，定义管理谁 各种模块核心模块、command模块、自定义模块；提供了日常模块 借助于插件完成记录日志邮件等功能； 根据需求后续添加模块，邮件、日志模块 playbook：剧本执行多个任务时，非必需可以让节点一次性运行多个任务。一次发布多条指令给客户端 特性 no agents：不需要在被管控主机上安装任何客户端； no server：无服务器端，使用时直接运行命令即可； modules in any languages：基于模块工作，可使用任意语言开发模块； yaml，not code：使用yaml语言定制剧本playbook； ssh by default：基于SSH工作； strong multi-tier solution：可实现多级指挥。 优点 轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可； 批量任务执行可以写成脚本，而且不用分发到远程就可以执行； 使用python编写，维护更简单，ruby语法过于复杂； 支持sudo 基本架构 ansible3.png 123456789· 核心引擎：即ansible· 核心模块（core modules）：这些都是ansible自带的模块，ansible模块资源分发到远程节点使其执行特定任务或匹配一个特定的状态。· 自定义模块（custom modules）：如果核心模块不足以完成某种功能，可以添加自定义模块。· 插件（plugins）：完成模块功能的补充，借助于插件完成记录日志、邮件等功能· 剧本（playbook）：定义ansible任务的配置文件，可以将多个任务定义在一个剧本中，由ansible自动执行，剧本执行支持多个任务，可以由控制主机运行多个任务，同时对多台远程主机进行管理。· playbook是ansible的配置、部署和编排语言，可以描述一个你想要的远程系统执行策略，或一组步骤的一般过程。如果ansible模块作为你的工作室工具，playbook就是设计方案。在基本层面上，剧本可以用于管理配置和部署远程机器。在更高级的应用中，可以序列多层应用及滚动更新，并可以把动作委托给其他主机，与监控服务器和负载平衡器交互。· 连接插件（connection plugins）：ansible基于连接插件连接到各个主机上，负责和被管理节点实现通信。虽然ansible是使用ssh连接到各被管理节点，但它还支持其他的连接方法，所以需要有连接插件。· 主机清单（host inventory）：定义ansible管理的主机策略，默认是在ansible的hosts配置文件中定义被管节点，同时也支持自定义动态主机清单和指定配置文件路径。 ansible采用paramiko协议库（Fabric也使用这个，基于python开发，支持SSHV2），通过ssh或者ZeroMQ等连接主机。ansible在控制主机主机将ansible模块通过ssh协议（或者Kerberos、LDAP）推送到被管节点执行，执行完之后自动删除。控制主机与被管理节点之间支持local、SSH、ZeroMQ三种连接方式，默认使用基于SSH的连接。在规模较大的情况下使用ZeroMQ连接方式会明显改善执行速度。 三、ansible运行原理ansible是如何工作的呢？我们通过一个图片来说明一下 ansible工作原理1132928.png 1234567891011121314工作原理：1、用户登录管理机器：通过ansible剧本或者单行命令针对业务机器组或者单个机器部署任务2、管理机器读取用户的部署任务：根据自己hosts文件中定义的业务机器组查找对应的机器地址(ip或者域名)3、管理机下发任务：管理机通过ssh免密连接业务机器，下发任务给业务机器4、业务机器执行任务5、业务机器将执行结果发送给ansible管理机器\t反馈字体颜色\t绿色 未发生变化\t黄色 更改生效\t红色 执行错误 四、学习视频视频：ansible课程介绍视频：自动化运维平台课程介绍视频：自动化运维平台介绍视频：ansible介绍视频：ansible工作原理","categories":["Linux","Ansible自动化运维平台"]},{"title":"ELK-Logstash日志收集","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK-Logstash日志收集/","content":"ES负责存储、分析数据，但是这一切前提是需要有数据，ES本身是不能够收集数据的，数据的收集如何来做呢？我们可以通过两个软件来实现数据的收集，那就是： Logstash:收集、处理数据然后交给ES Beats:收集数据交给ES 两者不同点在于Logstash能够更像一个数据中转站，它能够收集数据，并且对收集的数据进行处理，所以logstash消耗的计算机资源也是比较大的。Beats只负责收集数据，将数据收集后交给ES，和logstash相比其消耗的计算机资源更少，可以忽略。 一、logstash介绍logstash是一个开源的数据采集工具,通过数据源采集数据.然后进行过滤,并自定义格式输出到目的地。 数据分为: 结构化数据 如:mysql数据库里的表等 半结构化数据 如: xml,yaml,json等 非结构化数据 如:文档,图片,音频,视频等 logstash可以采集任何格式的数据,当然我们这里主要是讨论采集系统日志,服务日志等日志类型数据。 官方产品介绍:https://www.elastic.co/cn/products/logstash logstash工作流.png input插件: 用于导入日志源 (配置必须) https://www.elastic.co/guide/en/logstash/current/input-plugins.html filter插件: 用于过滤(不是配置必须的) https://www.elastic.co/guide/en/logstash/current/filter-plugins.html output插件: 用于导出(配置必须) https://www.elastic.co/guide/en/logstash/current/output-plugins.html 二、logstash安装部署a、安装前准备 机器准备：node3 静态IP(要求能上公网,最好用虚拟机的NAT网络类型上网) 主机名及主机名绑定 关闭防火墙和selinux 时间同步 yum源(centos安装完系统后的默认yum源就OK) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667安装前准备参考https://www.zutuanxue.com/home/4/52_138本文通过自定义脚本init_linux_os.sh脚本来完成# cat init_linux_os.sh#!/bin/bash#Description: initialize linux OS from ZUTUANXUE(http://www.zutuanxue.com)#Release: 1.0#Auther: www.zutuanxue.com#Email: #OS: Centos 8.X################hosts() &#123; echo &quot;&quot; &gt; /etc/hosts cat &gt;&gt; /etc/hosts&lt;&lt;EOF127.0.0.1 localhost::1 localhost 192.168.98.200 manage01192.168.98.201 node1192.168.98.202 node2192.168.98.203 node3192.168.98.204 node4EOF&#125;################cat &lt;&lt;EOF#Description: initialize linux OS from ZUTUANXUE(http://www.zutuanxue.com)#Release: 1.0#Auther: www.zutuanxue.com#Email: #OS: Centos 8.X#1、disable firewall#2、disable selinux#3、set chrony clientEOF#hosts#disable fireallsystemctl disable firewalldsystemctl stop firewalldiptables -Fiptables -t nat -F#disable selinuxsed -i -r &#x27;/SELINUX=/c\\SELINUX=disabled&#x27; /etc/selinux/config#set chrony clientsed -i.bak &#x27;/^pool 2.centos.pool.ntp.org iburst$/s//#/&#x27; /etc/chrony.conf cat &gt;&gt; /etc/chrony.conf &lt;&lt;EOFserver ntp1.aliyun.comserver ntp2.aliyun.comserver ntp3.aliyun.comserver ntp4.aliyun.comEOFif systemctl restart chronyd.service;then echo -e &quot;\\033[32m SUCCESS \\033[0m&quot;else echo -e &quot;\\033[31m FAIL \\033[0m&quot; exit 1fi b、安装部署 因为logstash也是基于java开发的，所以安装之前先要解决运行环境问题，需要安装jdk. 安装jdk 安装logstash 安装jdk-13.0.2 12345参考5.2.1本文通过自定义脚本elk_install.sh安装[root@node3 es_install]# sh elk_install.sh jdk警告：jdk-13.0.2_linux-x64_bin.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID ec551f03: NOKEYjdk-13.0.2 install success 安装logstash 安装方法： yum rpm 源码 我依然采用rpm安装，如果安装ES的时候设置过yum源，可以直接使用命令： yum -y install logstash 123456789101112[root@node3 ~]# rpm -i logstash-7.6.0.rpm 警告：logstash-7.6.0.rpm: 头V4 RSA/SHA512 Signature, 密钥 ID d88e42b4: NOKEYUsing provided startup.options file: /etc/logstash/startup.optionsJava HotSpot(TM) 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.Java HotSpot(TM) 64-Bit Server VM warning: Options -Xverify:none and -noverify were deprecated in JDK 13 and will likely be removed in a future release.WARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by com.headius.backport9.modules.Modules to method sun.nio.ch.NativeThread.signal(long)WARNING: Please consider reporting this to the maintainers of com.headius.backport9.modules.ModulesWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release/usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/pleaserun-0.0.30/lib/pleaserun/platform/base.rb:112: warning: constant ::Fixnum is deprecatedSuccessfully created system startup script for Logstash c、目录及文件 安装目录:&#x2F;usr&#x2F;share&#x2F;logstash 配置文件目录: &#x2F;etc&#x2F;logstash&#x2F; 1234567891011[root@node3 logstash]# tree .├── conf.d #业务配置文件，空目录 *.conf 从哪里采集日志，送到哪里去├── jvm.options├── log4j2.properties├── logstash-sample.conf\t#数据收集模板文件├── logstash.yml #配置文件├── pipelines.yml└── startup.options #启动参数1 directory, 6 files d、启动管理 1234567开机启动[root@node3 logstash]# systemctl enable logstashCreated symlink /etc/systemd/system/multi-user.target.wants/logstash.service → /etc/systemd/system/logstash.service.启动服务[root@node3 logstash]# systemctl start logstash注意第一次安装未配置是无法启动的，应为没有业务配置文件在conf.d下面 命令行启动验证 1234[root@node3 logstash]# /usr/share/logstash/bin/logstash -e &#x27;input &#123;stdin &#123;&#125;&#125; output &#123;stdout &#123;&#125;&#125;&#x27;#自己输给自己运行在前台，ctrl+C终止 24_logstash命令行启动.png 如图，看到启动成功就可以了 e、查看启动 启动成功后可以查看一下logstash启动情况，使用netstat命令。 1[root@node3 logstash]# netstat -ntpl 25_logstash启动查看.png 三、配置logstash服务监听地址为本机网卡IP[root@node3 ~]# vim &#x2F;etc&#x2F;logstash&#x2F;logstash.yml 12345678910# ------------ Metrics Settings --------------## Bind address for the metrics REST endpoint#http.host: &quot;0.0.0.0&quot; #删除#号，输入本机网卡地址或0.0.0.0,顶格写## Bind port for the metrics REST endpoint, this option also accept a range# (9600-9700) and logstash will pick up the first available ports.## http.port: 9600-9700 配置业务后启动查看 四、收集本机messages日志给ES业务架构 LEK.png 这里以&#x2F;var&#x2F;log&#x2F;messages为例,只定义input输入和output输出,不考虑过滤 配置业务文件存储在conf.d下 12345678910111213141516171819202122[root@node3 logstash]# cat /etc/logstash/conf.d/logstash_to_es_messages.conf#采集日志位置input &#123; file &#123; path =&gt; &quot;/var/log/messages&quot; #日志文件路径 start_position =&gt; &quot;beginning&quot; #收集日志开始的位置点 &#125;&#125;#输出给ESoutput &#123; elasticsearch&#123; hosts =&gt; [&quot;192.168.98.201:9200&quot;] #ES地址 #数据保存的索引名字 test-YYYY-MM-DD 按日期生成索引 index =&gt; &quot;test-%&#123;+YYYY.MM.dd&#125;&quot; &#125; #输出到屏幕一份，dubug使用,前台启动Logstash排错有用 #stdout &#123;# codec =&gt; rubydebug# &#125;&#125; 注意问题 设置&#x2F;var&#x2F;log&#x2F;messages文件权限，让logstash能读取 logstash进程管理用户 logstash &#x2F;var&#x2F;log&#x2F;messages文件权限400 123[root@node3 logstash]# ls /var/log/messages -l-rw------- 1 root root 374743 2月 15 05:08 /var/log/messages[root@node3 logstash]# chmod 644 /var/log/messages 启动logstash生效设置 1[root@node3 logstash]# systemctl restart logstash 查看启动日志 1[root@node3 ~]# tail -f /var/log/logstash/logstash-plain.log 26_logstash启动日志.png 看到上图选择的内容就说明成功了。 验证监听地址 1[root@node3 ~]# netstat -ntpl 27_logstash监听IP启动查看.png 验证ES数据，通过ES-head查看数据情况 通过浏览器登陆:http://192.168.98.201:9100 28_messages日志收集ES验证.png 看到数据索引，成功了。 五、logstash多日志收集实验注意: 清除上一个收集Messages的业务配置文件 清除ES的索引，方便查看，此条不是必须 案例：实验日志文件收集 &#x2F;var&#x2F;log&#x2F;messages 索引 message-%{+YYYY.MM.dd} &#x2F;var&#x2F;log&#x2F;dnf.rpm.log 索引 dnf-%{+YYYY.MM.dd} 思路 1、(input)收集日志同时给不同的日志打标签区别 2、(output)根据不同的数据标签将不同数据输出到ES不同索引 123456789101112131415161718192021222324252627282930313233[root@node3 ~]# cat /etc/logstash/conf.d/logstash_to_es_mutl_log.conf input &#123; file &#123; path =&gt; &quot;/var/log/messages&quot; start_position =&gt; &quot;beginning&quot; type =&gt; &quot;messages&quot; #给每条数据打标签 &#125; file &#123; path =&gt; &quot;/var/log/dnf.rpm.log&quot; start_position =&gt; &quot;beginning&quot; type =&gt; &quot;dnf&quot; &#125;&#125;output &#123; if [type] == &quot;messages&quot; &#123;\telasticsearch &#123; hosts =&gt; [&quot;192.168.98.201:9200&quot;] index =&gt; &quot;message-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; if [type] == &quot;dnf&quot; &#123;\telasticsearch &#123; hosts =&gt; [&quot;192.168.98.201:9200&quot;] index =&gt; &quot;dnf-%&#123;+YYYY.MM.dd&#125;&quot;\t&#125; &#125;&#125; 重启logstash验证ES数据 1[root@node3 logstash]# systemctl restart logstash 查看ES-head web页面概览标签，查看数据索引 29_多日志收集ES展示.png 通过数据浏览标签，查看原始数据我们自定义的标签。 30_查看数据定义的标签.png 完美，多日志收集成功。","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"ELK-kibana数据展示","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK-kibana数据展示/","content":"学习数据采集、数据分析的时候，我们一般验证都是通过ES-head来查看的，虽然解决了验证问题，但是界面友好度还是比较差，为了解决这个问题，我们可以通过学习kibana之后，通过kibana进行数据展示。 一、kibana部署1.1、kibana介绍Kibana是一个开源的可视化web平台,【是什么】 可以为ElasticSearch集群的管理提供友好的Web界面,帮助汇总,分析和搜索重要的日志数据。【干什么】 文档路径: https://www.elastic.co/guide/en/kibana/current/setup.html 1.2、kibana安装部署部署前准备 机器准备 初始化设置【参考4.2】 安装方法 yum rpm 源码包 kibana安装 123456[root@manage01 elk_7.6_soft]# rpm -ivh kibana-7.6.0-x86_64.rpm 警告：kibana-7.6.0-x86_64.rpm: 头V4 RSA/SHA512 Signature, 密钥 ID d88e42b4: NOKEYVerifying... ################################# [100%]准备中... ################################# [100%]正在升级/安装... 1:kibana-7.6.0-1 ################################# [100%] 相关目录 123安装目录:/usr/share/kibana配置文件目录:/etc/kibana配置文件：/etc/kibana/kibana.yml 1.3、kibana数据导入12345678910111213[root@manage01 ~]# egrep -v &quot;^#|^$&quot; /etc/kibana/kibana.yml #kibana监听端口server.port: 5601#kibana监听地址server.host: &quot;0.0.0.0&quot;#ES主机地址，用于取数据elasticsearch.hosts: [&quot;http://192.168.98.201:9200&quot;]#PID文件pid.file: /tmp/kibana.pid#日志文件路径logging.dest: /var/log/kibana.log#汉化中文i18n.locale: &quot;zh-CN&quot; 创建日志文件 123注意:日志文件kibana不会自己创建的，必须手动创建[root@manage01 ~]# touch /var/log/kibana.log[root@manage01 ~]# chown kibana.kibana /var/log/kibana.log kibana启动 123456[root@manage01 ~]# systemctl enable kibanaSynchronizing state of kibana.service with SysV service script with /usr/lib/systemd/systemd-sysv-install.Executing: /usr/lib/systemd/systemd-sysv-install enable kibanaCreated symlink /etc/systemd/system/multi-user.target.wants/kibana.service → /etc/systemd/system/kibana.service.[root@manage01 ~]# systemctl start kibana 启动验证 12[root@manage01 ~]# netstat -ntpltcp 0 0 0.0.0.0:5601 0.0.0.0:* LISTEN 2351/node 1.4、kibana web界面项目案例： 收集业务机器的messages日志,通过kibana数据分析，实时查看的数据增长量。 数据索引为zutuanxue-主机名-messages-YYYY-MM-DD.以node4为例。 实验架构 FEK1986104.png 1、filebeat设置，收集日志给ES 2、索引管理-通过鼠标流展示 登陆kibana:http://192.168.98.200:5601 索引添加 1、输入索引名称：xxxx-* 2、输入索引中筛选字段名 1注意：第一次登陆，必须设置索引数据后才能使用web工具栏上的工具 WEB界面介绍 33kibanaweb_ui.png 索引查看 34kibanaindex1992790.png 索引管理 35kibanaindex管理.png 1.5、kibana图表参考文档：https://www.elastic.co/guide/cn/kibana/current/createvis.html 发现工具：可以展示索引中的数据，以及按时间统计增长数量 36发现.png 图表管理 创建图表 37创建图表.png 选择图表样式(柱形图) 36创建图表1.png 选择索引数据 38创建图表索引选择.png 设置图形数据x-y轴 39创建图表xy轴1.png x轴添加及设置 40创建图表x轴.png 图形保存 41创建图形图形保存.png 可视化图表管理 42可视化管理图形.png 在可视化中可以对图表进行查看、修改、删除 我们再练习一个图表创建，说一下图表的选项设置。 仪表盘图形设置—创建仪表盘图形 43仪表盘图形创建.png 仪表盘图形索引选择 44仪表盘索引选择1995682.png 图形选项设置 46仪表盘图形选项设置.png 保存仪表盘图形 47仪表盘保存.png 仪表盘管理 将多个图表放在一个页面展示给用户 仪表盘-创建仪表盘 48仪表盘创建.png 添加图形 49添加图形到仪表盘.png 选择图形的同时，图表就会展示出来，选择完毕，点右上角叉号关闭即可 仪表盘内容查看 仪表盘查看.png 保存仪表盘 50仪表盘保存.png 仪表盘管理 51仪表盘管理.png 在本页面可以对仪表盘进行查看，修改，删除。","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"ELK-单机部署Elasticsearch","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK-单机部署Elasticsearch/","content":"一、Elasticsearch简介Elasticsearch(简称ES)是一个开源的分布式搜索引擎,Elasticsearch还是一个分布式文档数据库。所以它提供了大量数据的存储功能,快速的搜索与分析功能。 提到搜索,大家肯定就想到了百度,谷歌,必应等。当然也有如下的搜索场景。 github搜索界面.png 二、Elasticsearch部署方法 JDK安装并设置为默认java环境 Elasticsearch安装 配置elasticsearch监听ip地址 测试 1234567891011关于软件获得1、JDK 注意：下载页面，需要接受下载协议才能下载jdk13 https://download.oracle.com/otn-pub/java/jdk/13.0.2+8/d4173c853231432d94f001e99d882ca7/jdk-13.0.2_linux-x64_bin.rpm2、Elasticsearch https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.6.0-x86_64.rpm3、logstash https://artifacts.elastic.co/downloads/logstash/logstash-7.6.0.rpm4、kibana https://artifacts.elastic.co/downloads/kibana/kibana-7.6.0-x86_64.rpm5、filebeat https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.6.0-x86_64.rpm 2.1、JDK安装JDK介绍JDK的全称是Java Development Kit，是Sun公司免费提供的Java语言的软件开发工具包，其中包含Java虚拟机（JVM），java运行环境(JRE)。编写好的Java源程序经过编译可形成Java字节码，只要安装了JDK，就可以利用JVM解释这些字节码文件，从而保证了Java的跨平台性。 JDK安装方法 软件安装[本次安装jdk13.0.2] 设置环境变量，默认java环境为新安装环境 12345678910111213141516171819202122232425262728293031323334353637#1、软件安装 #默认安装路径/usr/java/jdk-13.0.2[root@node1 ~]# rpm -ivh jdk-13.0.2_linux-x64_bin.rpm 警告：jdk-13.0.2_linux-x64_bin.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID ec551f03: NOKEYVerifying... ################################# [100%]准备中... ################################# [100%]正在升级/安装... 1:jdk-13.0.2-2000:13.0.2-ga ################################ [100%]or如果有依赖，可以通过yum解决依赖[root@node1 elk_7.6_soft]# yum -y localinstall jdk-13.0.2_linux-x64_bin.rpm#2、设置环境变量，默认java环境为新安装环境 #注意 java环境给谁用#/etc/profile#~/.bash_profile#在/etc/profile文件中追加以下环境变量，并导出为全局变量[root@node1 ~]# tail -4 /etc/profile#JAVA安装路径JAVA_HOME=/usr/java/jdk-13.0.2/#JAVA命令输出PATH=$JAVA_HOME/bin:$PATH:$HOME/bin#JAVA库文件CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar#导出全局export PATH JAVA_HOME CLASSPATH CATALINA_HOME#重载/etc/profile文件到内存，生效变量[root@node1 ~]# source /etc/profile#3、测试java默认环境[root@node1 ~]# java --versionjava 13.0.2 2020-01-14 #看这里，看这里，完美！Java(TM) SE Runtime Environment (build 13.0.2+8)Java HotSpot(TM) 64-Bit Server VM (build 13.0.2+8, mixed mode, sharing) 2.2 Elasticsearch安装Elasticsearch安装方法 Elasticsearch RPM安装 yum源安装 源码安装 Elasticsearch安装方法对比 Elasticsearch RPM安装： 需要提前下好安装包，如果有依赖需要手动解决依赖，压力山大！ yum源安装 傻瓜式安装，做好yum源即可，网络很重要。 源码安装 源码自定义安装，可以优化软件功能，删减功能，高手的选择。 RPM安装方法 a、下载elasticsearch RPM包 b、安装elasticsearch 123456789101112131415161718192021222324252627a、下载elasticsearch RPM包[root@node1 ~]# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.6.0-x86_64.rpmb、安装elasticsearch[root@node1 ~]# rpm -ivh elasticsearch-7.6.0-x86_64.rpm 警告：elasticsearch-7.6.0-x86_64.rpm: 头V4 RSA/SHA512 Signature, 密钥 ID d88e42b4: NOKEYVerifying... ################################# [100%]准备中... ################################# [100%]Creating elasticsearch group... OKCreating elasticsearch user... OK正在升级/安装... 1:elasticsearch-0:7.6.0-1 ################################# [100%]### NOT starting on installation, please execute the following statements to configure elasticsearch service to start automatically using systemd 安装服务到systemd服务，方便使用systemctl管理服务 sudo systemctl daemon-reload sudo systemctl enable elasticsearch.service### You can start elasticsearch service by executing sudo systemctl start elasticsearch.service 服务启动方法Created elasticsearch keystore in /etc/elasticsearch[/usr/lib/tmpfiles.d/elasticsearch.conf:1] Line references path below legacy directory /var/run/, updating /var/run/elasticsearch → /run/elasticsearch; please update the tmpfiles.d/ drop-in file accordingly.[/usr/lib/tmpfiles.d/libstoragemgmt.conf:1] Line references path below legacy directory /var/run/, updating /var/run/lsm → /run/lsm; please update the tmpfiles.d/ drop-in file accordingly.[/usr/lib/tmpfiles.d/libstoragemgmt.conf:2] Line references path below legacy directory /var/run/, updating /var/run/lsm/ipc → /run/lsm/ipc; please update the tmpfiles.d/ drop-in file accordingly.[/usr/lib/tmpfiles.d/mdadm.conf:1] Line references path below legacy directory /var/run/, updating /var/run/mdadm → /run/mdadm; please update the tmpfiles.d/ drop-in file accordingly.[/usr/lib/tmpfiles.d/radvd.conf:1] Line references path below legacy directory /var/run/, updating /var/run/radvd → /run/radvd; please update the tmpfiles.d/ drop-in file accordingly.[/usr/lib/tmpfiles.d/spice-vdagentd.conf:2] Line references path below legacy directory /var/run/, updating /var/run/spice-vdagentd → /run/spice-vdagentd; please update the tmpfiles.d/ drop-in file accordingly.安装路径 /usr/share/elasticsearch/ yum源安装 a、安装elasticsearch gpg key b、设置yum源 c、安装elasticsearch 1234567891011121314151617a、=================安装elasticsearch key=================[root@node1 ~]# rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearchb、=================设置yum源=================[root@node1 ~]# cat &gt;&gt;/etc/yum.repos.d/elk.repo &lt;&lt;EOF&gt; [elasticsearch-7.x]&gt; name=Elasticsearch repository for 7.x packages&gt; baseurl=https://artifacts.elastic.co/packages/7.x/yum&gt; gpgcheck=1&gt; gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch&gt; enabled=1&gt; autorefresh=1&gt; type=rpm-md&gt; EOFc、=================安装elasticsearch=================[root@node1 ~]# yum install elasticsearch 源码安装 a、下载源码包 b、解压安装 c、启动测试 1234挑战自我，超越自我，you can you do!参考官方手册https://www.elastic.co/guide/en/elasticsearch/reference/7.6/targz.html Elasticsearch配置文件目录结构 12345678910111213141516elasticsearch安装目录：/usr/share/elasticsearch/elasticsearch配置文件目录：/etc/elasticsearch/[root@node1 ~]# cd /etc/elasticsearch/[root@node1 elasticsearch]# tree.├── elasticsearch.keystore\t#key存储├── elasticsearch.yml\t#主配置文件├── jvm.options #JVM虚拟机参数配置文件├── log4j2.properties\t#记录日志├── role_mapping.yml\t#空文件├── roles.yml #空文件，定义权限文件├── users #空文件，定义用户文件└── users_roles #空文件四个空文件是ES权限控制文件 Elasticsearch设置[拓展] 12345678910111213141516171819202122232425262728293031323334353637#堆内存设置jvm将内存逻辑分区，主要分为堆、栈、方法区java创建的对象放在堆内存中java创建的方法是放在栈内存执行，包括局部变量java源码编译后二进制文件执行要加载到方法区，常量池也存在方法区#详情可参考天易IT学院java课程数据结构JVM课程Elasticsearch 默认安装后设置的堆内存是 1 GB。对于任何一个业务部署来说， 这个设置都太小了。如果你正在使用这些默认堆内存配置，您的集群可能会出现问题。#建议不要超过32G官方解释在 Java 中，所有的对象都分配在堆上，并通过一个指针进行引用。 普通对象指针（OOP）指向这些对象，通常为 CPU 字长 的大小：32 位或 64 位，取决于你的处理器。指针引用的就是这个 OOP 值的字节位置。对于 32 位的系统，意味着堆内存大小最大为 4 GB。对于 64 位的系统， 可以使用更大的内存，但是 64 位的指针意味着更大的浪费，因为你的指针本身大了。更糟糕的是， 更大的指针在主内存和各级缓存（例如 LLC，L1 等）之间移动数据的时候，会占用更多的带宽。Java 使用一个叫作 内存指针压缩（compressed oops）的技术来解决这个问题。 它的指针不再表示对象在内存中的精确位置，而是表示 偏移量 。这意味着 32 位的指针可以引用 40 亿个 对象 ， 而不是 40 亿个字节。最终， 也就是说堆内存增长到 32 GB 的物理内存，也可以用 32 位的指针表示。一旦你越过那个神奇的 ~32 GB 的边界，指针就会切回普通对象的指针。 每个对象的指针都变长了，就会使用更多的 CPU 内存带宽，也就是说你实际上失去了更多的内存。事实上，当内存到达 40–50 GB 的时候，有效内存才相当于使用内存对象指针压缩技术时候的 32 GB 内存。这段描述的意思就是说：即便你有足够的内存，也尽量不要 超过 32 GB。因为它浪费了内存，降低了 CPU 的性能，还要让 GC 应对大内存。#GC，全称是 Garbage Collection （垃圾收集）或者 Garbage Collector(垃圾收集器)#参考文档https://www.elastic.co/guide/cn/elasticsearch/guide/current/heap-sizing.html#设置方法[root@node1 ~]#vim /etc/elasticsearch/jvm.options# Xms represents the initial size of total heap space# Xmx represents the maximum size of total heap space-Xms1g -Xmx1g Elasticsearch服务管理方法 a、开机启动服务 b、服务启动管理 12345678910111213141516a、开机启动服务[root@node1 ~]# systemctl enable elasticsearch.service Synchronizing state of elasticsearch.service with SysV service script with /usr/lib/systemd/systemd-sysv-install.Executing: /usr/lib/systemd/systemd-sysv-install enable elasticsearchCreated symlink /etc/systemd/system/multi-user.target.wants/elasticsearch.service → /usr/lib/systemd/system/elasticsearch.service.b、服务启动管理[root@node1 ~]# systemctl start elasticsearch.servicec、启动测试[root@node1 ~]# netstat -ntpl.....tcp6 0 0 127.0.0.1:9200 :::* LISTEN 2698/java tcp6 0 0 ::1:9200 :::* LISTEN 2698/java tcp6 0 0 127.0.0.1:9300 :::* LISTEN 2698/java tcp6 0 0 ::1:9300 :::* LISTEN 2698/java 2.3、配置Elasticsearch监听本地外网地址绑定ES监听地址为:192.168.98.201 1234567891011121314151617181920212223242526[root@node1 ~]# vim /etc/elasticsearch/elasticsearch.yml # ---------------------------------- Network --------------------------## Set the bind address to a specific IP (IPv4 or IPv6):#network.host: 192.168.98.201 #删除#号，设置本机某个公网地址或0.0.0.0## Set a custom port for HTTP:##http.port: 9200 ## For more information, consult the network module documentation.## --------------------------------- Discovery -------------------------## Pass an initial list of hosts to perform discovery when this node is started:# The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]##discovery.seed_hosts: [&quot;host1&quot;, &quot;host2&quot;]## Bootstrap the cluster using an initial set of master-eligible nodes:#如果ES设置公网地址，非localhost，那么它就会认为这是一个es集群，必须有一个master#所有开启下面这行，指定master可以是哪个node。cluster.initial_master_nodes: [&quot;192.168.98.201&quot;] #删除#号，写上自己本地地址## For more information, consult the discovery and cluster formation module documentation. 重启服务生效 1[root@node1 ~]# systemctl restart elasticsearch.service 2.4、测试验证端口及监听地址 02_elasticsearch_启动验证.png 通过浏览器访问ES 03_elasticsearch_web_启动验证.png","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"ELK-beats数据采集","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK-beats数据采集/","content":"一、beats介绍因为logstash太费内存了,如果在要采集的服务上都安装logstash,你可以想象这样这样资源消耗多高。所以我们要用轻量级的采集工具才更高效,更省资源。 beats是轻量级的日志收集处理工具，Beats占用资源少 - Packetbeat： 网络数据（收集网络流量数据） - Metricbeat： 指标 （收集系统、进程和文件系统级别的 CPU 和内存使用情况等数据） - Filebeat： 文件（收集日志文件数据） - Winlogbeat： windows事件日志（收集 Windows 事件日志数据） - Auditbeat：审计数据 （收集审计日志） - Heartbeat：运行时间监控 （收集系统运行时的数据） 我们这里主要是收集日志信息, 所以只讨论filebeat。 filebeat可以直接将采集的日志数据传输给ES集群（EFK ELKfilebeat架构.png, 也可以给logstash(**5044**端口接收)。 二、 filebeat准备工作 机器：node4(192.168.98.204) 1部署前准备参考https://www.zutuanxue.com/home/4/52_138 filebeat安装 a、yum安装 b、rpm安装 c、源码安装 a、yum安装 如果你安装ES的时候设置过yum源可以直接使用yum命令: 1# yum -y install filebeat b、rpm安装 1234[root@node4 ~]# rpm -i filebeat-7.6.0-x86_64.rpm 警告：filebeat-7.6.0-x86_64.rpm: 头V4 RSA/SHA512 Signature, 密钥 ID d88e42b4: NOKEY-i install c、源码安装 1参考官方手册 相关文件及目录 安装目录: &#x2F;usr&#x2F;share&#x2F;filebeat 配置文件目录: &#x2F;etc&#x2F;filebeat 配置文件:&#x2F;etc&#x2F;filebeat&#x2F;filebeat.yml 服务启动管理 1234567[root@node4 ~]# systemctl enable filebeatSynchronizing state of filebeat.service with SysV service script with /usr/lib/systemd/systemd-sysv-install.Executing: /usr/lib/systemd/systemd-sysv-install enable filebeatCreated symlink /etc/systemd/system/multi-user.target.wants/filebeat.service → /usr/lib/systemd/system/filebeat.service.#没有修改配置文件，起不来[root@node4 ~]# systemctl start filebeat 三、filebeat配置文件123456789101112131415161718192021[root@node4 ~]# cat /etc/filebeat/filebeat.yml |grep -v &#x27;#&#x27; |grep -v &#x27;^$&#x27;filebeat.inputs:- type: log enabled: false #默认false，修改为true paths: - /var/log/*.log #收集日志的路径filebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1#定义kibana地址setup.kibana:#定义ES地址接收数据output.elasticsearch: hosts: [&quot;192.168.98.201:9200&quot;] processors: - add_host_metadata: ~ - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ 四、收集日志给ES集群案例：filebeat收集本机messages日志到ES，通过ES-head查看 业务拓扑 FEK.png 1注意：每做下一个实验前，建议大家把之前的索引数据清除，通过es-head，这样没有干扰，也好验证效果。否则那么多索引信息，对前期学习的你来说，干扰太多了。 a、设置filebeat配置文件 123456789101112131415161718192021[root@node4 ~]# cat /etc/filebeat/filebeat.yml |grep -v &#x27;#&#x27; |grep -v &#x27;^$&#x27;filebeat.inputs:- type: log enabled: true #默认false，修改为true paths: - /var/log/messages #收集日志的路径filebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1#定义kibana地址setup.kibana:#定义ES地址接收数据output.elasticsearch: hosts: [&quot;192.168.98.201:9200&quot;] processors: - add_host_metadata: ~ - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ b、重启filebeat服务，生效配置 1[root@node4 ~]# systemctl restart filebeat c、通过ES-head验证日志收集 31_es-filebeat验证 拓展：关于filebeat设置数据索引 12345678910111213141516171819202122232425262728[root@node4 ~]# cat /etc/filebeat/filebeat.yml |grep -v &#x27;#&#x27; |grep -v &#x27;^$&#x27;filebeat.inputs:- type: log enabled: true paths: - /var/log/messagesfilebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1setup.kibana:#在output.*输出全局中插入这行插入，下面三行#禁用ilmsetup.ilm.enabled: false#设置索引模板名setup.template.name: &quot;node4_messages&quot;#索引前缀setup.template.pattern: &quot;node4_messages-*&quot;output.elasticsearch: hosts: [&quot;192.168.98.201:9200&quot;] #定义索引 index: &quot;node4_messages-%&#123;+yyyy.MM.dd&#125;&quot;processors: - add_host_metadata: ~ - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ 五、收集日志给logstash案例：收集本机messages日志到logstash，通过ES-head查看,要求索引为zutuanxue_node4_messages 业务拓扑： elk部署图3933846.png 案例分析： a、设置filebeat配置文件，将采集的日志发送给logstash b、logstash收到日志添加索引后给ES c、ES-head验证 a、设置filebeat配置文件，将采集的日志发送给logstash 1234567891011121314151617181920[root@node4 ~]# cat /etc/filebeat/filebeat.yml |grep -v &#x27;#&#x27; |grep -v &#x27;^$&#x27;filebeat.inputs:- type: log enabled: true paths: - /var/log/messagesfilebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1setup.kibana:#定义输出到logstashoutput.logstash: hosts: [&quot;192.168.98.203:5044&quot;]processors: - add_host_metadata: ~ - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ b、logstash收到日志添加索引后给ES 12345678910111213[root@node3 conf.d]# cat filebeat_to_logstash_es.conf input &#123; beats &#123; port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;192.168.98.201:9200&quot;] index =&gt; &quot;zutuanxue_node4-%&#123;+YYYY.MM.dd&#125;&quot; #定义索引 &#125;&#125; 重启filebeat、logstash服务生效配置 12[root@node4 ~]# systemctl restart filebeat[root@node3 ~]# systemctl restart logstash c、ES-head验证 32_esheadfilebeat_logstat验证.png 完美，实验完成","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"ELK-数据管理","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK-数据管理/","content":"一、elasticsearch基础概念主要的基础概念有: Index,Type,Document,Field,shard和replicas. Index(索引): 是具有相似特性的文档集合。 Type(类型): 在一个索引中可以定义一个或多个类型。 Documenet(文档): 索引信息的基本单位。 Field(字段): ES里更小的信息单位。 shard(分片)： 数据存储的方式 replicas(副本)：副本 数据备份 为了便于理解,我们和mysql这种关系型数据库做一个对比: 关系型数据库(如mysql,oracle等) elasticsearch database index table type row document column field ES是分布式搜索引擎，每个索引有一个或多个分片(shard)，索引的数据被分配到各个分片上。你可以看作是一份数据分成了多份给不同的节点。 二、elaticsearch基础API操作如果有ES集群,则为ES任意节点IP都可以 前面我们通过http://192.168.98.201:9200/_cluster/health?pretty查看ES集群状态,其实就是它的一种API操作。 12什么是API?API(Application Programming Interface)应用程序编程接口,就是无需访问程序源码或理解内部工作机制就能实现一些相关功能的接口。 elasticseearch的API很多, 我们运维人员主要用到以下几个要介绍的较简单的API。 更多API参考: https://www.elastic.co/guide/en/elasticsearch/reference/6.2/index.html 查看节点信息通过curl或浏览器访问http://192.168.98.202:9200/_cat/nodes?v ip为ES节点IP,如果有ES集群,则为ES任意节点IP都可以) 1234[root@node1 ~]# curl http://192.168.98.202:9200/_cat/nodes?v ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name192.168.98.201 9 94 0 0.09 0.06 0.06 dilm * node1192.168.98.202 15 92 4 0.12 0.14 0.11 dilm - node2 使用浏览器访问 05_api_查看节点信息.png 三、索引管理 文本界面API管理索引 web图形ES-head管理索引 文本界面管理索引 查看索引信息 通过curl或浏览器访问http://192.168.98.201:9200/_cat/indices?v 123[root@node1 ~]# curl http://192.168.98.201:9200/_cat/indices?vhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.size默认现在没有任何索引 新增索引 12345678910[root@node1 ~]# curl -X PUT http://192.168.98.201:9200/zutuanxue_com_access_log [root@node1 ~]#输出信息&#123;&quot;acknowledged&quot;:true,&quot;shards_acknowledged&quot;:true,&quot;index&quot;:&quot;zutuanxue_com_access_log&quot;&#125;[root@node1 ~]# curl http://192.168.98.201:9200/_cat/indices?vhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.sizegreen open zutuanxue_com_access_log A_keWJh4RSOUS3gKCX2AwA 1 1 0 0 460b 230b 06_api_查看索引.png green:表示每个index的shard和replica都是活跃状态的。 yellow:表示每个index的shard是活跃状态的，replica是不可用状态的。 red：表示索引中有些shard是不可用状态，导致数据丢失。 删除索引 12[root@node1 ~]# curl -X DELETE http://192.168.98.201:9200/zutuanxue_com_access_log &#123;&quot;acknowledged&quot;:true&#125; 当ES集群增加或删除节点时,shard会在多个节点中均衡分配。7.0之前，默认是5个primary shard(主分片)和1个replica shard(副本,用于容错)。7.x之后是1个主分片 1个副本分片","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"ELK-收集mysqlslow日志","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK-收集mysqlslow日志/","content":"案例分析开发和DBA为了能够实时掌握mysql的运行情况，需要对mysql中执行的sql指令大于1秒的统计出来，并且通过ELK分析，统计，实时查看。通过分析可以让DBA能够优化数据库，能够提升运行速度。 一、MySQL设置a、mysql安装 1安装脚本 mysql默认root密码更改 1[root@node4 mysql]# mysql_secure_installation b、mysql slow日志开启 1234567#开启slow logslow_query_log=1slow_query_log_file=/usr/local/mysql/mysql-slow.loglong-query-time=1#允许使用Load data命令secure_file_priv=&#x27;&#x27; 重启mysql生效 123[root@node4 mysql]# /etc/init.d/mysql.server restartShutting down MySQL.. SUCCESS! Starting MySQL. SUCCESS! c、生成测试数据 1[root@node4 mysql]# seq 1 10000000 &gt; /tmp/big 导入数据 1234mysql&gt; create table db1.t1(id int(11));mysql&gt; load data infile &#x27;/tmp/big&#x27; into table db1.t1;Query OK, 10000000 rows affected (21.73 sec)Records: 10000000 Deleted: 0 Skipped: 0 Warnings: 0 生成slow日志 1234567mysql&gt; select * from db1.t1 where id=8;+------+| id |+------+| 8 |+------+1 row in set (3.46 sec) 查看slow 日志 1234567891011121314151617181920212223242526272829303132[root@node4 mysql]# cat mysql-slow.log /usr/local/mysql/bin/mysqld, Version: 5.7.28-log (MySQL Community Server (GPL)). started with:Tcp port: 0 Unix socket: /tmp/mysql.sockTime Id Command Argument/usr/local/mysql/bin/mysqld, Version: 5.7.28-log (MySQL Community Server (GPL)). started with:Tcp port: 0 Unix socket: /tmp/mysql.sockTime Id Command Argument# Time: 2020-02-18T13:15:34.406907Z# User@Host: root[root] @ localhost [] Id: 2# Query_time: 21.729690 Lock_time: 0.005813 Rows_sent: 0 Rows_examined: 0SET timestamp=1582031734;load data infile &#x27;/tmp/big&#x27; into table db1.t1;# Time: 2020-02-18T13:16:03.022224Z# User@Host: root[root] @ localhost [] Id: 2# Query_time: 3.458640 Lock_time: 0.004334 Rows_sent: 1 Rows_examined: 10000000SET timestamp=1582031763;select * from db1.t1 where id=8;# Time: 2020-02-18T13:23:11.893639Z# User@Host: root[root] @ localhost [] Id: 3# Query_time: 3.583976 Lock_time: 0.000412 Rows_sent: 1 Rows_examined: 10000000SET timestamp=1582032191;select * from db1.t1 where id=88;# Time: 2020-02-18T13:23:17.347380Z# User@Host: root[root] @ localhost [] Id: 3# Query_time: 3.557843 Lock_time: 0.000113 Rows_sent: 1 Rows_examined: 10000000SET timestamp=1582032197;select * from db1.t1 where id=888;# Time: 2020-02-18T13:23:22.470483Z# User@Host: root[root] @ localhost [] Id: 3# Query_time: 3.498105 Lock_time: 0.000173 Rows_sent: 1 Rows_examined: 10000000SET timestamp=1582032202;select * from db1.t1 where id=8888; 二、数据收集###a、mysql slow日志格式整理收集 通过filebeat多行模式收集mysql slow日志 12345678910111213141516171819202122232425262728293031[root@node4 ~]# egrep -v &quot;^#|^$| #&quot; /etc/filebeat/filebeat.yml filebeat.inputs:- type: log enabled: true paths: - /usr/local/mysql/mysql-slow.log #开启多行收集 multiline.pattern: &quot;^# User@Host:&quot; multiline.negate: true multiline.match: after filebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1setup.kibana:output.logstash: hosts: [&quot;192.168.98.203:5044&quot;]processors: - add_host_metadata: ~ - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~参数说明multiline.pattern：正则表达式，去匹配指定的一行，这里去匹配的以“# User@Host:”开头的那一行；multiline.negate：取值true 或 false；默认是false，就是将multiline.pattern匹配到的那一行合并到上一行；如果配置是true，就是将除了multiline.pattern匹的那一行的其他所有行合并到其上一行；multiline.match：after 或 before，就是指定将要合并到上一行的内容，合并到上一行的末尾或开头； logstash中的数据是这样存储的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&#123; &quot;host&quot; =&gt; &#123; &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;name&quot; =&gt; &quot;node4&quot;, &quot;os&quot; =&gt; &#123; &quot;family&quot; =&gt; &quot;redhat&quot;, &quot;name&quot; =&gt; &quot;CentOS Linux&quot;, &quot;kernel&quot; =&gt; &quot;4.18.0-80.el8.x86_64&quot;, &quot;codename&quot; =&gt; &quot;Core&quot;, &quot;version&quot; =&gt; &quot;8 (Core)&quot;, &quot;platform&quot; =&gt; &quot;centos&quot; &#125;, &quot;containerized&quot; =&gt; false, &quot;id&quot; =&gt; &quot;d8100d9fc21041ae9364bbb1ca84da02&quot;, &quot;architecture&quot; =&gt; &quot;x86_64&quot; &#125;, &quot;log&quot; =&gt; &#123; &quot;offset&quot; =&gt; 4629, &quot;file&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/usr/local/mysql/mysql-slow.log&quot; &#125; &#125;, &quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot; ], &quot;@timestamp&quot; =&gt; 2020-02-19T02:50:06.763Z, &quot;input&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;log&quot; &#125;, #这里有一个message行，记录了时间 &quot;message&quot; =&gt; &quot;# Time: 2020-02-19T02:50:05.740090Z&quot;, &quot;ecs&quot; =&gt; &#123; &quot;version&quot; =&gt; &quot;1.4.0&quot; &#125;, &quot;agent&quot; =&gt; &#123; &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;type&quot; =&gt; &quot;filebeat&quot;, &quot;ephemeral_id&quot; =&gt; &quot;3736821d-5c17-429a-a8af-0a9b28ba87b7&quot;, &quot;version&quot; =&gt; &quot;7.6.0&quot;, &quot;id&quot; =&gt; &quot;060fdb52-cc79-463e-9cbf-f7d8fee5db89&quot; &#125;, &quot;@version&quot; =&gt; &quot;1&quot;&#125;&#123; &quot;log&quot; =&gt; &#123; &quot;file&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/usr/local/mysql/mysql-slow.log&quot; &#125;, &quot;offset&quot; =&gt; 4665, &quot;flags&quot; =&gt; [ [0] &quot;multiline&quot; ] &#125;, &quot;host&quot; =&gt; &#123; &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;name&quot; =&gt; &quot;node4&quot;, &quot;os&quot; =&gt; &#123; &quot;family&quot; =&gt; &quot;redhat&quot;, &quot;name&quot; =&gt; &quot;CentOS Linux&quot;, &quot;kernel&quot; =&gt; &quot;4.18.0-80.el8.x86_64&quot;, &quot;codename&quot; =&gt; &quot;Core&quot;, &quot;version&quot; =&gt; &quot;8 (Core)&quot;, &quot;platform&quot; =&gt; &quot;centos&quot; &#125;, &quot;containerized&quot; =&gt; false, &quot;id&quot; =&gt; &quot;d8100d9fc21041ae9364bbb1ca84da02&quot;, &quot;architecture&quot; =&gt; &quot;x86_64&quot; &#125;, &quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot; ], &quot;@timestamp&quot; =&gt; 2020-02-19T02:50:06.763Z, &quot;input&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;log&quot; &#125;, ####看这里message!mysql slow日志这样才的 &quot;message&quot; =&gt; &quot;# User@Host: root[root] @ localhost [] Id: 2 # Query_time: 4.764090 Lock_time: 0.001112 Rows_sent: 1 Rows_examined: 10000000 SET timestamp=1582080605; select * from db1.t1 where id=1;&quot;, &quot;ecs&quot; =&gt; &#123; &quot;version&quot; =&gt; &quot;1.4.0&quot; &#125;, &quot;agent&quot; =&gt; &#123; &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;type&quot; =&gt; &quot;filebeat&quot;, &quot;version&quot; =&gt; &quot;7.6.0&quot;, &quot;ephemeral_id&quot; =&gt; &quot;3736821d-5c17-429a-a8af-0a9b28ba87b7&quot;, &quot;id&quot; =&gt; &quot;060fdb52-cc79-463e-9cbf-f7d8fee5db89&quot; &#125;, &quot;@version&quot; =&gt; &quot;1&quot;&#125; b、使用grok插件格式化数据 grok是一种采用组合多个预定义的正则表达式，用来匹配分割文本并映射到关键字的工具。通常用来对日志数据进行预处理。logstash的filter模块中grok插件是其实现之一。 处理思路： 12341、第一个message数据行，没有用到，删除；2、第二个message数据行的数据做json格式；3、时间根据第二个message数据行中的时间戳转换；4、数据已经做成json格式了，自然第二个message也没用了，删除第二个message行； 通过不断测试，查看Logstash中的数据存储 1、第一个message数据行，没有用到，删除； 2、第二个message数据行的数据做json格式； 3、时间根据第二个message数据行中的时间戳转换； 12345678910111213141516171819202122232425262728293031filter &#123;#2、将第二个message数据格式化为json格斯grok &#123; match =&gt; [ &quot;message&quot;, &quot;(?m)^# User@Host: %&#123;USER:query_user&#125;\\[[^\\]]+\\] @ (?:(?&lt;query_host&gt;\\S*) )?\\[(?:%&#123;IP:query_ip&#125;)?\\]\\s+Id:\\s+%&#123;NUMBER:row_id:int&#125;\\s*# Query_time: %&#123;NUMBER:query_time:float&#125;\\s+Lock_time: %&#123;NUMBER:lock_time:float&#125;\\s+Rows_sent: %&#123;NUMBER:rows_sent:int&#125;\\s+Rows_examined: %&#123;NUMBER:rows_examined:int&#125;\\s*(?:use %&#123;DATA:database&#125;;\\s*)?SET timestamp=%&#123;NUMBER:timestamp&#125;;\\s*(?&lt;query&gt;(?&lt;action&gt;\\w+)\\s+.*)&quot; ] &#125;#1、匹配&quot;message&quot; =&gt; &quot;# Time: &quot;数据行[第一个message]，添加一个标签 dropgrok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;# Time: &quot; &#125; add_tag =&gt; [ &quot;drop&quot; ] tag_on_failure =&gt; [] &#125;#1、删除标签为drop的数据行 if &quot;drop&quot; in [tags] &#123; drop &#123;&#125; &#125;#3、匹配message中的时间戳，根据亚洲/上海的格式生成本地时间 date &#123; match =&gt; [&quot;mysql.slowlog.timestamp&quot;, &quot;UNIX&quot;, &quot;YYYY-MM-dd HH:mm:ss&quot;] target =&gt; &quot;@timestamp&quot; timezone =&gt; &quot;Asia/Shanghai&quot; &#125; ruby &#123; code =&gt; &quot;event.set(&#x27;[@metadata][today]&#x27;, Time.at(event.get(&#x27;@timestamp&#x27;).to_i).localtime.strftime(&#x27;%Y.%m.%d&#x27;))&quot; &#125;&#125; logstash中数据存储 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&#123; &quot;agent&quot; =&gt; &#123; &quot;ephemeral_id&quot; =&gt; &quot;3736821d-5c17-429a-a8af-0a9b28ba87b7&quot;, &quot;type&quot; =&gt; &quot;filebeat&quot;, &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;version&quot; =&gt; &quot;7.6.0&quot;, &quot;id&quot; =&gt; &quot;060fdb52-cc79-463e-9cbf-f7d8fee5db89&quot; &#125;, #看这里，根据时间戳生成的时间 &quot;@timestamp&quot; =&gt; 2020-02-19T03:01:46.833Z, &quot;input&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;log&quot; &#125;, &quot;query_host&quot; =&gt; &quot;localhost&quot;, &quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot; ], &quot;row_id&quot; =&gt; 2, ###看这里，第二个message数据 &quot;message&quot; =&gt; &quot;# User@Host: root[root] @ localhost [] Id: 2 # Query_time: 4.448631 Lock_time: 0.000213 Rows_sent: 1 Rows_examined: 10000000 SET timestamp=1582081300; select * from db1.t1 where id=1;&quot;, &quot;@version&quot; =&gt; &quot;1&quot;, ###从这往下看，能看到这里面夹杂这生成的json数据 #row_id query_time lock_time rows_examined query query_user等都是 &quot;query_time&quot; =&gt; 4.448631, &quot;lock_time&quot; =&gt; 0.000213, &quot;ecs&quot; =&gt; &#123; &quot;version&quot; =&gt; &quot;1.4.0&quot; &#125;, &quot;rows_examined&quot; =&gt; 10000000, &quot;query&quot; =&gt; &quot;select * from db1.t1 where id=1;&quot;, &quot;log&quot; =&gt; &#123; &quot;flags&quot; =&gt; [ [0] &quot;multiline&quot; ], &quot;offset&quot; =&gt; 5346, &quot;file&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/usr/local/mysql/mysql-slow.log&quot; &#125; &#125;, &quot;host&quot; =&gt; &#123; &quot;name&quot; =&gt; &quot;node4&quot;, &quot;os&quot; =&gt; &#123; &quot;codename&quot; =&gt; &quot;Core&quot;, &quot;name&quot; =&gt; &quot;CentOS Linux&quot;, &quot;family&quot; =&gt; &quot;redhat&quot;, &quot;version&quot; =&gt; &quot;8 (Core)&quot;, &quot;kernel&quot; =&gt; &quot;4.18.0-80.el8.x86_64&quot;, &quot;platform&quot; =&gt; &quot;centos&quot; &#125;, &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;architecture&quot; =&gt; &quot;x86_64&quot;, &quot;id&quot; =&gt; &quot;d8100d9fc21041ae9364bbb1ca84da02&quot;, &quot;containerized&quot; =&gt; false &#125;, &quot;action&quot; =&gt; &quot;select&quot;, &quot;rows_sent&quot; =&gt; 1, &quot;timestamp&quot; =&gt; &quot;1582081300&quot;, &quot;query_user&quot; =&gt; &quot;root&quot;&#125; 通过grok插件，实现日志过滤 关于正则表达式内容，参考shell脚本中的正则表达式一章 1234补充知识点空格匹配 \\s回车匹配 \\s*非空格匹配 \\S [大写] grok中的语法 123456789101112grok匹配规则%&#123;数据类型：变量名&#125;例如 5.12 可能是一个事件的持续时间,192.168.98.200可能是请求的client地址。所以这两个值可以用 %&#123;NUMBER:duration&#125; %&#123;IP:client&#125; 来匹配。自定义数据类型(?&lt;字段名&gt;表达式)例如，日志有一个student_id 为一个长度为10或11个字符的十六进制值。使用下列语法可以获取该片段，并把值赋予student_id(?&lt;student_id&gt;[0-9A-F]&#123;10,11&#125;)具体参考https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html 删除第二个message数据 1234567891011121314151617181920212223242526272829303132333435filter &#123;#1、将第二个message数据格式化为json格斯grok &#123; match =&gt; [ &quot;message&quot;, &quot;(?m)^# User@Host: %&#123;USER:query_user&#125;\\[[^\\]]+\\] @ (?:(?&lt;query_host&gt;\\S*) )?\\[(?:%&#123;IP:query_ip&#125;)?\\]\\s+Id:\\s+%&#123;NUMBER:row_id:int&#125;\\s*# Query_time: %&#123;NUMBER:query_time:float&#125;\\s+Lock_time: %&#123;NUMBER:lock_time:float&#125;\\s+Rows_sent: %&#123;NUMBER:rows_sent:int&#125;\\s+Rows_examined: %&#123;NUMBER:rows_examined:int&#125;\\s*(?:use %&#123;DATA:database&#125;;\\s*)?SET timestamp=%&#123;NUMBER:timestamp&#125;;\\s*(?&lt;query&gt;(?&lt;action&gt;\\w+)\\s+.*)&quot; ] &#125;#匹配&quot;message&quot; =&gt; &quot;# Time: &quot;数据行[第一个message]，添加一个标签 dropgrok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;# Time: &quot; &#125; add_tag =&gt; [ &quot;drop&quot; ] tag_on_failure =&gt; [] &#125;#删除标签为drop的数据行 if &quot;drop&quot; in [tags] &#123; drop &#123;&#125; &#125;#匹配message中的时间戳，根据亚洲/上海的格式生成本地时间 date &#123; match =&gt; [&quot;mysql.slowlog.timestamp&quot;, &quot;UNIX&quot;, &quot;YYYY-MM-dd HH:mm:ss&quot;] target =&gt; &quot;@timestamp&quot; timezone =&gt; &quot;Asia/Shanghai&quot; &#125; ruby &#123; code =&gt; &quot;event.set(&#x27;[@metadata][today]&#x27;, Time.at(event.get(&#x27;@timestamp&#x27;).to_i).localtime.strftime(&#x27;%Y.%m.%d&#x27;))&quot; &#125;#删除message字段 mutate &#123; remove_field =&gt; [ &quot;message&quot; ] &#125;&#125; 实现过滤后，logstash数据存储状态 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&#123; &quot;lock_time&quot; =&gt; 0.000226, &quot;host&quot; =&gt; &#123; &quot;name&quot; =&gt; &quot;node4&quot;, &quot;architecture&quot; =&gt; &quot;x86_64&quot;, &quot;os&quot; =&gt; &#123; &quot;name&quot; =&gt; &quot;CentOS Linux&quot;, &quot;family&quot; =&gt; &quot;redhat&quot;, &quot;platform&quot; =&gt; &quot;centos&quot;, &quot;kernel&quot; =&gt; &quot;4.18.0-80.el8.x86_64&quot;, &quot;version&quot; =&gt; &quot;8 (Core)&quot;, &quot;codename&quot; =&gt; &quot;Core&quot; &#125;, &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;id&quot; =&gt; &quot;d8100d9fc21041ae9364bbb1ca84da02&quot;, &quot;containerized&quot; =&gt; false &#125;, &quot;rows_examined&quot; =&gt; 10000000, &quot;action&quot; =&gt; &quot;select&quot;, &quot;rows_sent&quot; =&gt; 1, &quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot; ], &quot;row_id&quot; =&gt; 2, &quot;log&quot; =&gt; &#123; &quot;file&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/usr/local/mysql/mysql-slow.log&quot; &#125;, &quot;flags&quot; =&gt; [ [0] &quot;multiline&quot; ], &quot;offset&quot; =&gt; 5119 &#125;, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;ecs&quot; =&gt; &#123; &quot;version&quot; =&gt; &quot;1.4.0&quot; &#125;, &quot;input&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;log&quot; &#125;, ###看这里下面数据,数据已经被定义为json格式了， &quot;query_host&quot; =&gt; &quot;localhost&quot;, &quot;@timestamp&quot; =&gt; 2020-02-19T02:57:11.812Z, &quot;query_time&quot; =&gt; 4.377673, &quot;query_user&quot; =&gt; &quot;root&quot;, &quot;query&quot; =&gt; &quot;select * from db1.t1 where id=1;&quot;, &quot;timestamp&quot; =&gt; &quot;1582081027&quot;, &quot;agent&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;filebeat&quot;, &quot;version&quot; =&gt; &quot;7.6.0&quot;, &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;id&quot; =&gt; &quot;060fdb52-cc79-463e-9cbf-f7d8fee5db89&quot;, &quot;ephemeral_id&quot; =&gt; &quot;3736821d-5c17-429a-a8af-0a9b28ba87b7&quot; &#125;&#125; c、logstash将数据交给elasticsearch 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@node3 conf.d]# cat mysql_logstash_es.conf#采集数据input &#123;\tbeats &#123; port =&gt; 5044 &#125;&#125;#过滤filter &#123;grok &#123; match =&gt; [ &quot;message&quot;, &quot;(?m)^# User@Host: %&#123;USER:query_user&#125;\\[[^\\]]+\\] @ (?:(?&lt;query_host&gt;\\S*) )?\\[(?:%&#123;IP:query_ip&#125;)?\\]\\s+Id:\\s+%&#123;NUMBER:row_id:int&#125;\\s*# Query_time: %&#123;NUMBER:query_time:float&#125;\\s+Lock_time: %&#123;NUMBER:lock_time:float&#125;\\s+Rows_sent: %&#123;NUMBER:rows_sent:int&#125;\\s+Rows_examined: %&#123;NUMBER:rows_examined:int&#125;\\s*(?:use %&#123;DATA:database&#125;;\\s*)?SET timestamp=%&#123;NUMBER:timestamp&#125;;\\s*(?&lt;query&gt;(?&lt;action&gt;\\w+)\\s+.*)&quot; ] &#125; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;# Time: &quot; &#125; add_tag =&gt; [ &quot;drop&quot; ] tag_on_failure =&gt; [] &#125; if &quot;drop&quot; in [tags] &#123; drop &#123;&#125; &#125; date &#123; match =&gt; [&quot;mysql.slowlog.timestamp&quot;, &quot;UNIX&quot;, &quot;YYYY-MM-dd HH:mm:ss&quot;] target =&gt; &quot;@timestamp&quot; timezone =&gt; &quot;Asia/Shanghai&quot; &#125; ruby &#123; code =&gt; &quot;event.set(&#x27;[@metadata][today]&#x27;, Time.at(event.get(&#x27;@timestamp&#x27;).to_i).localtime.strftime(&#x27;%Y.%m.%d&#x27;))&quot; &#125; mutate &#123; remove_field =&gt; [ &quot;message&quot; ] &#125;&#125;#输出到esoutput &#123; elasticsearch&#123; hosts =&gt; [&quot;192.168.98.201:9200&quot;] index =&gt; &quot;zutuanxue_node4_mysql-%&#123;+YYYY.MM.dd&#125;&quot; &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 三、kibana展示绘制图表 query_time分布 统计slow日志数量","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"ELK-部署Elasticsearch集群","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK-部署Elasticsearch集群/","content":"单节点的ES需要在处理大量数据的时候需要消耗大量内存和CPU资源，数据量大到一定程度就会产生处理瓶颈，甚至会出现宕机。为了解决单节点ES的处理能力的瓶颈及单节点故障问题，我们考虑使用ES集群。 一、ES集群的优点：优化数据处理能力：通过多台ES共同处理数据，提升处理能力，节省时间。 容错能力增强：解决了ES单点故障问题，让架构更稳定。 数据安全：分布式数据存储，数据更安全 实验部署准备 两台ES机器：node1、node2 同步时间：chrony 静态IP：192.168.98.201 192.168.98.202 关闭防火墙、selinux 配置ES yum源 12准备工作参考https://www.zutuanxue.com/home/4/52_138 - ELK学习准备 二、集群部署部署步骤: node1、node2安装jdk、Elasticsearch软件包 node1、node2设置配置文件配置集群 启动ES验证集群 2.1、软件包安装12345678软件包安装,机器node1 node2以node1为例jdk安装通过rpm软件包[root@node1 ~]# rpm -ivh jdk-13.0.2_linux-x64_bin.rpmElasticsearch安装通过rpm软件包[root@node1 ~]# rpm -ivh elasticsearch-7.6.0-x86_64.rpm 2.2、node1、node2设置配置文件配置集群1234567891011121314151617181920212223242526272829配置文件修改[root@node1 ~]# egrep -v &quot;(^#|^$)&quot; /etc/elasticsearch/elasticsearch.yml cluster.name: zutuanxue_elk 集群名称,所有节点必须一样node.name: node1 节点名称#node.master: true 定义为主 path.data: /var/lib/elasticsearch 数据路径path.logs: /var/log/elasticsearch 日志路径network.host: 0.0.0.0 监听地址http.port: 9200 监听端口discovery.seed_hosts: [&quot;node1&quot;, &quot;node2&quot;] 可扫描监控的主机cluster.initial_master_nodes: [&quot;node1&quot;, &quot;node2&quot;] 开启服务的时候谁可以竞选为主[第一次启动集群]node2配置文件[root@node2 elasticsearch]# egrep -v &quot;(^#|^$)&quot; /etc/elasticsearch/elasticsearch.yml cluster.name: zutuanxue_elknode.name: node2path.data: /var/lib/elasticsearchpath.logs: /var/log/elasticsearchnetwork.host: 192.168.98.202discovery.seed_hosts: [&quot;node1&quot;, &quot;node2&quot;]cluster.initial_master_nodes: [&quot;node1&quot;, &quot;node2&quot;]拓展当您想要与其他主机上的节点组成群集时，你必须使用 discovery.seed_hosts 来提供群集中可以成为master ，可能存在并且可以连接到的其他节点的列表，使得 discovery process 能够发现节点)。此设置通常应包含群集中所有可以成为master节点的地址。需要注意的是，IPv6主机必须放在括号内。此设置的默认值为127.0.0.1，[::1]。cluster.initial_master_nodes当你第一次启动全新的Elasticsearch集群时，会有一个集群引导(cluster bootstrapping)步骤，这个步骤会确定一个在第一次选举中投票被计数的、并且可以成为master节点的集合。cluster.initial_master_nodes参数说明：es7 引用了 [Bootstrapping a cluster](https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-discovery-bootstrap-cluster.html) 后，首次启动Elasticsearch集群需要在集群中的一个或多个符合主节点的节点上显式定义初始的符合主节点的节点集。这称为群集自举，这仅在群集首次启动时才需要。 2.3 启动ES验证集群1234启动ES[root@node1 ~]# systemctl restart elasticsearch[root@node2 ~]# systemctl restart elasticsearch确保服务正常启动：端口正常打开 2.4 集群测试web站点测试方法：http://192.168.98.201:9200/_cluster/health?pretty 04_es_cluster.png 123456789101112131415161718页面输出介绍&#123; &quot;cluster_name&quot; : &quot;zutuanxue_elk&quot;, #集群名称 &quot;status&quot; : &quot;green&quot;, #集群状态 &quot;timed_out&quot; : false, #超时设置 &quot;number_of_nodes&quot; : 2, #集群节点数量 &quot;number_of_data_nodes&quot; : 2, #集群数据节点数量 &quot;active_primary_shards&quot; : 0, &quot;active_shards&quot; : 0, &quot;relocating_shards&quot; : 0, &quot;initializing_shards&quot; : 0, &quot;unassigned_shards&quot; : 0, &quot;delayed_unassigned_shards&quot; : 0, &quot;number_of_pending_tasks&quot; : 0, &quot;number_of_in_flight_fetch&quot; : 0, &quot;task_max_waiting_in_queue_millis&quot; : 0, &quot;active_shards_percent_as_number&quot; : 100.0&#125;","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"ELK介绍","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK介绍/","content":"一、项目背景运维人员需要对系统和业务日志进行精准把控，便于分析系统和业务状态。日志分布在不同的服务器上，传统的使用传统的方法依次登录每台服务器查看日志，既繁琐又效率低下。所以我们需要集中化的日志管理工具将位于不同服务器上的日志收集到一起, 然后进行分析,展示。 前面我们学习过rsyslog,它就可以实现集中化的日志管理，可是rsyslog集中后的日志实现统计与检索又成了一个问题。使用wc, grep, awk等相关命令可以实现统计与检索，但如果要求更高的场景，这些命令也会力不从心。所以我们需要一套专业的日志收集分析展示系统。 二、项目分析2.1、数据分析流程 数据收集 数据分析 数据展示 明确数据分析流程后，我们来看一下能够进行数据处理的软件-ELK ELK是一套开源的日志分析系统，由elasticsearch+logstash+Kibana组成。它可以实时的收集、处理、展示分析数据，可以让人通过图表直观的看到数据分析结果。 ELK一般应用数据分析领域比如： 日志分析处理 结合Hadoop实现大数据分析处理和展示 数据搜索 三、认识ELKELK介绍 ELK是一套开源的日志分析系统，由elasticsearch+logstash+Kibana组成。 官网说明:https://www.elastic.co/cn/products 首先: 先一句话简单了解E,L,K这三个软件 Elasticsearch 垃圾处理厂Elasticsearch 是基于 JSON 的分布式搜索和分析引擎，专为实现水平扩展、高可靠性和管理便捷性而设计 Elasticsearch 是一个分布式的 RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 Logstash 垃圾中转站 Logstash 是动态数据收集管道，拥有可扩展的插件生态系统，能够与 Elasticsearch 产生强大的协同作用。Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的 “存储库” 中。（我们的存储库当然是 Elasticsearch） Kibana 垃圾处理报表Kibana 能够以图表的形式呈现数据，并且具有可扩展的用户界面，供您全方位配置和管理 Elastic Stack。 Kibana 让您能够自由地选择如何呈现您的数据。或许您一开始并不知道自己想要什么。不过借助 Kibana 的交互式可视化，您可以先从一个问题出发，看看能够从中发现些什么。一张图片胜过千万行日志 Beats 垃圾桶 垃圾回收车Beats 是轻量型采集器的平台，从边缘机器向 Logstash 和 Elasticsearch 发送数据。 Beats 是数据采集的得力工具。将这些采集器安装在您的服务器中，它们就会把数据汇总到 Elasticsearch。如果需要更加强大的处理性能，Beats 还能将数据输送到 Logstash 进行转换和解析。 elk架构图.png ELK下载地址:https://www.elastic.co/cn/downloads elk_download_page.png 四、ELK学习准备4.1、实验拓扑图:elk部署图3933846.png 收集系统日志 F-E-K L-E-K F-L-E-K 收集web服务器access.log日志 收集mysql slow日志 4.2、部署前准备 静态IP(要求能上公网,最好用虚拟机的NAT网络类型上网) 主机名及IP绑定 关闭防火墙和selinux 时间同步 chrony yum源(centos安装完系统后的默认yum源就OK) 所有服务器全部采用静态ip 主机名称 IP地址 角色 manage01 192.168.98.200&#x2F;24 kibana数据展示 node1 192.168.98.201&#x2F;24 ES1 node2 192.168.98.202&#x2F;24 ES2 node3 192.168.98.203&#x2F;24 logstash或(业务机器) node4 192.168.98.204&#x2F;24 filebeat-业务机器 主机名及IP互相绑定 12345678910[root@manage01 ~]# cat /etc/hosts127.0.0.1 localhost::1 localhost 192.168.98.200\tmanage01192.168.98.201\tnode1192.168.98.202\tnode2192.168.98.203\tnode3192.168.98.204\tnode4其他机器同理 关闭防火墙, selinux 12345678[root@manage01 ~]# systemctl disable firewalld[root@manage01 ~]# iptables -F[root@manage01 ~]# iptables -t nat -F[root@manage01 ~]# sed -i -r &#x27;/SELINUX=/c\\SELINUX=disabled&#x27; /etc/selinux/config[root@manage01 ~]# reboot其他机器同理 采用时间服务器，时间同步 1234567891011121314151617181920212223242526272829301、修改配置文件，配置时间服务器为阿里云的时间服务器[root@manage01 ~]# egrep &quot;^server&quot; /etc/chrony.conf server ntp1.aliyun.comserver ntp2.aliyun.comserver ntp3.aliyun.comserver ntp4.aliyun.com#注释# pool 2.centos.pool.ntp.org iburst2、重启服务chronyd[root@manage01 ~]# systemctl restart chronyd.service 3、查看源信息#chronyc chrony的命令行客户端[root@manage01 ~]# chronyc sources -v210 Number of sources = 2 .-- Source mode &#x27;^&#x27; = server, &#x27;=&#x27; = peer, &#x27;#&#x27; = local clock. / .- Source state &#x27;*&#x27; = current synced, &#x27;+&#x27; = combined , &#x27;-&#x27; = not combined,| / &#x27;?&#x27; = unreachable, &#x27;x&#x27; = time may be in error, &#x27;~&#x27; = time too variable.|| .- xxxx [ yyyy ] +/- zzzz|| Reachability register (octal) -. | xxxx = adjusted offset,|| Log2(Polling interval) --. | | yyyy = measured offset,|| \\ | | zzzz = estimated error.|| | | \\MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^? 120.25.115.20 2 6 1 3 +663us[ +663us] +/- 23ms^? 203.107.6.88 2 6 1 2 -1326us[-1326us] +/- 17ms yum源设置 建议采用默认yum源就可以","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"ELK数据管理工具ES-Head应用","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK数据管理工具ES-Head应用/","content":"一、ES-head web UI界面ES-head web UI界面介绍http://ES-head_ip:9100 10_eshead_webUI.png 12345概览：显示ES集群及节点状态索引：索引管理数据浏览：查看某个索引中的数据基本查询：查询索引中的所有数据复合查询：数据管理[上传数据、查看数据、删除数据 doc] 索引管理 创建索引 管理索引 删除索引 a、创建索引 11_eshead_index创建1729565.png 选择索引标签–新建索引 12_eshead_index创建.png 123索引名称:根据业务起名字分片数：创建多少个shard分片副本数：需要多少个ES集群节点存储 b、查看索引 13_eshead_index创建.png 可以看到新创建的索引 zutuanxue_com_log 以及大小和文档数 也可以通过概述查看索引分片情况 14_eshead_index查看.png 主从分片有区分的，加粗的是主分片 c、索引管理 15_eshead_index管理.png d、索引删除 16_eshead_index删除.png 数据查询 符合查询 基本查询 a、复合查询 1）存储数据 2）查询数据 3）删除某条数据 1）存储数据 上传数据[提前创建好存储索引] 指定索引和type：zutuanxue_com_log&#x2F;test 1type是一个index中用来区分类似的数据的，但是可能有不同的fields，而且有不同的属性来控制索引建立、分词器。 17_eshead_复合查询_提交数据.png key是列Field(字段)的名字 2）查询数据 查询方法：index&#x2F;type&#x2F;id 123id获得方法：1）基本查询2）数据浏览 18_eshead_复合查询_查询数据.png 数据删除 通过复合查询删除指定数据 删除方法：删除数据的 索引&#x2F;类型&#x2F;id 删除方法:DELETE 21_eshead_复合查询_删除数据.png 查询结果 22_eshead_复合查询_删除数据1830276.png 基本查询 查询索引中的数据 19_eshead_基本查询_查询数据.png 显示数据 20_eshead_基本查询_数据显示.png 数据浏览 浏览索引中的所有数据 23_eshead数据浏览.png","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"ELK收集nginxaccess_log日志","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK收集nginxaccess_log日志/","content":"一、案例分析公司为了每天都能够随时看到公司WEB业务的实时运行情况，希望运维通过分析access.log日志信息，实时展示一下数据给公司的运营部门： 统计不同返回值的数量 统计访问前5名的IP地址 统计每日PV 统计每日UV ……. 二、nginx access_log定义json格式日志 部署nginx 设置nginx 访问日志为json格式 a、部署nginx服务 123456[root@node4 ~]# tar xf nginx-*.rpm[root@node4 ~]# cd nginx-*.rpm[root@node4 ~]# yum -y install pcre-devel zlib-devel gcc-*[root@node4 ~]# ./configure --prefix=/usr/local[root@node4 ~]# make[root@node4 ~]# make install b、设置nginx 访问日志为json格式 由于ES是基于json来处理数据的，所以给ES的数据就必须是JSON数据，只有这样才能通过json将数据进行分析、统计。为了能让ES能分析access.log日志，我们让nginx直接将该日志的格式设置为json格式。 1234567891011121314[root@node4 ~]# vim /usr/local/nginx/conf/nginx.conflog_format main_json &#x27;&#123;&quot;@timestamp&quot;:&quot;$time_local&quot;,&#x27;&#x27;&quot;N_client_ip&quot;: &quot;$remote_addr&quot;,&#x27;&#x27;&quot;N_request&quot;: &quot;$request&quot;,&#x27;&#x27;&quot;N_request_time&quot;: &quot;$request_time&quot;,&#x27;&#x27;&quot;N_status&quot;: &quot;$status&quot;,&#x27;&#x27;&quot;N_bytes&quot;: &quot;$body_bytes_sent&quot;,&#x27;&#x27;&quot;N_user_agent&quot;: &quot;$http_user_agent&quot;,&#x27;&#x27;&quot;N_x_forwarded&quot;: &quot;$http_x_forwarded_for&quot;,&#x27;&#x27;&quot;N_referer&quot;: &quot;$http_referer&quot;&#x27;&#x27;&#125;&#x27;; access_log logs/access.log main_json; 三、日志收集filebeat设置-修改配置文件定义日志收集 123456789101112131415161718192021[root@node4 ~]# egrep -v &quot;(#|^$)&quot; /etc/filebeat/filebeat.yml filebeat.inputs:- type: log enabled: true paths: - /usr/local/nginx/logs/access.log #添加以下两行，定义收集的是json日志 json.keys_under_root: true json.overwrite_keys: truefilebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1setup.kibana: host: &quot;192.168.98.200:5601&quot;output.logstash: hosts: [&quot;192.168.98.203:5044&quot;]processors: - add_host_metadata: ~ - add_cloud_metadata: ~ logstash设置-配置业务文件，接收Filebeat发送的数据，然后将数据发送给ES 12345678910111213141516[root@node3 conf.d]# cat f_to_e.conf input &#123; beats &#123; port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;192.168.98.202:9200&quot;] index =&gt; &quot;nginx-%&#123;+YYYY.MM.dd&#125;&quot; &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; kibana创建索引，添加nginx数据 四、kibana展示统计不同返回值的数量 饼图 统计访问前5名的IP地址 柱形图 统计每日PV 仪表盘 统计每日UV 计数 52nginx_access.png","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"ELK数据管理工具ES-Head部署","path":"/2023/09/27/构建可视化数据分析系统-ELK/ELK数据管理工具ES-Head部署/","content":"一、elasticsearch-head介绍elasticsearch-head是 ES集群管理、索引数据可视化、增删改查、查询语句可视化 工具。 ES集群管理 ES集群上的数据索引管理和查询 查看索引中的某条数据 从ES5版本后安装方式和ES2以上的版本有很大的不同,在ES2中可以直接在bin目录下执行plugin install xxxx 来进行安装,但是在ES5中这种安装方式变了,要想在ES5中安装Elasticsearch Head必须要安装NodeJs,然后通过NodeJS来启动Head。 官网下载地址:https://github.com/mobz/elasticsearch-head 安装机器:node1 集群机器，生产环境下建议两台或多天进行容灾 安装方法： nodejs es-head 二、elasticsearch-head部署2.1、安装依赖包-node.jsa、下载软件包 1[root@node1 ~]# wget https://nodejs.org/dist/v13.8.0/node-v13.8.0-linux-x64.tar.xz b、安装node.js 123456789101112131415161718192021222324252627[root@node1 ~]# tar xf node-v13.8.0-linux-x64.tar.xz [root@node1 ~]# mv node-v13.8.0-linux-x64 /usr/local/nodejs#可以看出是免安装版的软件[root@node1 ~]# cd /usr/local/nodejs/[root@node1 nodejs]# lsbin CHANGELOG.md include lib LICENSE README.md share#链接命令[root@node1 nodejs]# ln -sf /usr/local/nodejs/bin/* /usr/local/bin/#验证链接，确保正确[root@node1 nodejs]# ll /usr/local/bin/nodelrwxrwxrwx 1 root root 26 2月 14 12:01 /usr/local/bin/node -&gt; /usr/local/nodejs/bin/node[root@node1 nodejs]# ll /usr/local/bin/npm lrwxrwxrwx 1 root root 25 2月 14 12:01 /usr/local/bin/npm -&gt; /usr/local/nodejs/bin/npm#验证node版本[root@node1 nodejs]# node -vv13.8.0#升级npm为最新,npm是 Node.js 的包管理器，类似于yum[root@node1 nodejs]# npm update -g npm/usr/local/nodejs/bin/npm -&gt; /usr/local/nodejs/lib/node_modules/npm/bin/npm-cli.js/usr/local/nodejs/bin/npx -&gt; /usr/local/nodejs/lib/node_modules/npm/bin/npx-cli.js+ npm@6.13.7added 7 packages from 3 contributors, removed 3 packages and updated 11 packages in 7.6s 2.2、elasticsearch-head部署es-head是基于nodejs开发的一个前端网站 官网有安装说明,可以通过git安装,也可以下载zip包解压安装 这里去下载相应的软件包,并拷贝到ES集群的一个节点上(我这里拷贝到192.168.98.202这台,也就是node2上) a、下载ES-head 12345678[root@node1 ~]# git clone git://github.com/mobz/elasticsearch-head.git正克隆到 &#x27;elasticsearch-head&#x27;...remote: Enumerating objects: 77, done.remote: Counting objects: 100% (77/77), done.remote: Compressing objects: 100% (57/57), done.remote: Total 4337 (delta 38), reused 46 (delta 17), pack-reused 4260接收对象中: 100% (4337/4337), 2.51 MiB | 26.00 KiB/s, 完成.处理 delta 中: 100% (2411/2411), 完成. b、安装es-head 12345678安装grunt服务#grunt作为一个前端构建工具，有资源压缩，代码检查，文件合并等功能。#构建nodejs代码 es-head并发布代码[root@node1 ~]# cd elasticsearch-head/[root@node1 elasticsearch-head]# npm install -g grunt-cli/usr/local/nodejs/bin/grunt -&gt; /usr/local/nodejs/lib/node_modules/grunt-cli/bin/grunt+ grunt-cli@1.3.2added 150 packages from 121 contributors in 32.255s c、安装插件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222[root@node1 elasticsearch-head]# npm install#安装不成功的插件，手动在单独安装一下，依赖存在源码根目录package.json文件中npm WARN deprecated http2@3.3.7: Use the built-in module in node 9.0.0 or newer, insteadnpm WARN deprecated coffee-script@1.10.0: CoffeeScript on NPM has moved to &quot;coffeescript&quot; (no hyphen)npm WARN deprecated core-js@2.6.11: core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3.npm WARN deprecated phantomjs-prebuilt@2.1.16: this package is now deprecatednpm WARN deprecated request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142npm WARN deprecated json3@3.3.2: Please use the native JSON object instead of JSON 3npm WARN deprecated json3@3.2.6: Please use the native JSON object instead of JSON 3&gt; phantomjs-prebuilt@2.1.16 install /root/elasticsearch-head/node_modules/phantomjs-prebuilt&gt; node install.jsPhantomJS not found on PATHDownloading https://github.com/Medium/phantomjs/releases/download/v2.1.1/phantomjs-2.1.1-linux-x86_64.tar.bz2Saving to /tmp/phantomjs/phantomjs-2.1.1-linux-x86_64.tar.bz2Receiving... [==================================------] 84%Received 22866K total.Extracting tar contents (via spawned process)Removing /root/elasticsearch-head/node_modules/phantomjs-prebuilt/lib/phantomCopying extracted folder /tmp/phantomjs/phantomjs-2.1.1-linux-x86_64.tar.bz2-extract-1581725015606/phantomjs-2.1.1-linux-x86_64 -&gt; /root/elasticsearch-head/node_modules/phantomjs-prebuilt/lib/phantomPhantom installation failed [Error: EACCES: permission denied, link &#x27;/tmp/phantomjs/phantomjs-2.1.1-linux-x86_64.tar.bz2-extract-1581725015606/phantomjs-2.1.1-linux-x86_64&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/phantomjs-prebuilt/lib/phantom&#x27;] &#123; errno: -13, code: &#x27;EACCES&#x27;, syscall: &#x27;link&#x27;, path: &#x27;/tmp/phantomjs/phantomjs-2.1.1-linux-x86_64.tar.bz2-extract-1581725015606/phantomjs-2.1.1-linux-x86_64&#x27;, dest: &#x27;/root/elasticsearch-head/node_modules/phantomjs-prebuilt/lib/phantom&#x27;&#125; Error: EACCES: permission denied, link &#x27;/tmp/phantomjs/phantomjs-2.1.1-linux-x86_64.tar.bz2-extract-1581725015606/phantomjs-2.1.1-linux-x86_64&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/phantomjs-prebuilt/lib/phantom&#x27;npm WARN notsup Unsupported engine for karma@1.3.0: wanted: &#123;&quot;node&quot;:&quot;0.10 || 0.12 || 4 || 5 || 6&quot;&#125; (current: &#123;&quot;node&quot;:&quot;13.8.0&quot;,&quot;npm&quot;:&quot;6.13.6&quot;&#125;)npm WARN notsup Not compatible with your version of node/npm: karma@1.3.0npm WARN notsup Unsupported engine for http2@3.3.7: wanted: &#123;&quot;node&quot;:&quot;&gt;=0.12.0 &lt;9.0.0&quot;&#125; (current: &#123;&quot;node&quot;:&quot;13.8.0&quot;,&quot;npm&quot;:&quot;6.13.6&quot;&#125;)npm WARN notsup Not compatible with your version of node/npm: http2@3.3.7npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@^1.0.0 (node_modules/chokidar/node_modules/fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.11: wanted &#123;&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;&#125; (current: &#123;&quot;os&quot;:&quot;linux&quot;,&quot;arch&quot;:&quot;x64&quot;&#125;)npm WARN elasticsearch-head@0.0.0 license should be a valid SPDX license expressionnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: abbrev@1.1.1 (node_modules/fsevents/node_modules/abbrev):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/abbrev&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.abbrev.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: ansi-regex@2.1.1 (node_modules/fsevents/node_modules/ansi-regex):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/ansi-regex&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.ansi-regex.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: aproba@1.2.0 (node_modules/fsevents/node_modules/aproba):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/aproba&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.aproba.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: balanced-match@1.0.0 (node_modules/fsevents/node_modules/balanced-match):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/balanced-match&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.balanced-match.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: chownr@1.1.3 (node_modules/fsevents/node_modules/chownr):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/chownr&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.chownr.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: code-point-at@1.1.0 (node_modules/fsevents/node_modules/code-point-at):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/code-point-at&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.code-point-at.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: concat-map@0.0.1 (node_modules/fsevents/node_modules/concat-map):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/concat-map&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.concat-map.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: console-control-strings@1.1.0 (node_modules/fsevents/node_modules/console-control-strings):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/console-control-strings&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.console-control-strings.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: core-util-is@1.0.2 (node_modules/fsevents/node_modules/core-util-is):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/core-util-is&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.core-util-is.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: deep-extend@0.6.0 (node_modules/fsevents/node_modules/deep-extend):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/deep-extend&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.deep-extend.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: delegates@1.0.0 (node_modules/fsevents/node_modules/delegates):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/delegates&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.delegates.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: detect-libc@1.0.3 (node_modules/fsevents/node_modules/detect-libc):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/detect-libc&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.detect-libc.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fs.realpath@1.0.0 (node_modules/fsevents/node_modules/fs.realpath):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/fs.realpath&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.fs.realpath.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: has-unicode@2.0.1 (node_modules/fsevents/node_modules/has-unicode):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/has-unicode&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.has-unicode.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: inherits@2.0.4 (node_modules/fsevents/node_modules/inherits):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/inherits&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.inherits.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: ini@1.3.5 (node_modules/fsevents/node_modules/ini):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/ini&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.ini.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: isarray@1.0.0 (node_modules/fsevents/node_modules/isarray):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/isarray&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.isarray.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: minimist@0.0.8 (node_modules/fsevents/node_modules/minimist):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/minimist&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.minimist.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: ms@2.1.2 (node_modules/fsevents/node_modules/ms):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/ms&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.ms.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: npm-normalize-package-bin@1.0.1 (node_modules/fsevents/node_modules/npm-normalize-package-bin):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/npm-normalize-package-bin&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.npm-normalize-package-bin.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: number-is-nan@1.0.1 (node_modules/fsevents/node_modules/number-is-nan):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/number-is-nan&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.number-is-nan.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: object-assign@4.1.1 (node_modules/fsevents/node_modules/object-assign):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/object-assign&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.object-assign.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: os-homedir@1.0.2 (node_modules/fsevents/node_modules/os-homedir):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/os-homedir&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.os-homedir.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: os-tmpdir@1.0.2 (node_modules/fsevents/node_modules/os-tmpdir):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/os-tmpdir&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.os-tmpdir.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: path-is-absolute@1.0.1 (node_modules/fsevents/node_modules/path-is-absolute):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/path-is-absolute&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.path-is-absolute.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: process-nextick-args@2.0.1 (node_modules/fsevents/node_modules/process-nextick-args):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/process-nextick-args&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.process-nextick-args.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: minimist@1.2.0 (node_modules/fsevents/node_modules/rc/node_modules/minimist):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/rc/node_modules/minimist&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/rc/node_modules/.minimist.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: safe-buffer@5.1.2 (node_modules/fsevents/node_modules/safe-buffer):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/safe-buffer&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.safe-buffer.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: safer-buffer@2.1.2 (node_modules/fsevents/node_modules/safer-buffer):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/safer-buffer&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.safer-buffer.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: sax@1.2.4 (node_modules/fsevents/node_modules/sax):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/sax&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.sax.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: semver@5.7.1 (node_modules/fsevents/node_modules/semver):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/semver&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.semver.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: set-blocking@2.0.0 (node_modules/fsevents/node_modules/set-blocking):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/set-blocking&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.set-blocking.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: signal-exit@3.0.2 (node_modules/fsevents/node_modules/signal-exit):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/signal-exit&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.signal-exit.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: strip-json-comments@2.0.1 (node_modules/fsevents/node_modules/strip-json-comments):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/strip-json-comments&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.strip-json-comments.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: util-deprecate@1.0.2 (node_modules/fsevents/node_modules/util-deprecate):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/util-deprecate&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.util-deprecate.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: wrappy@1.0.2 (node_modules/fsevents/node_modules/wrappy):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/wrappy&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.wrappy.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: yallist@3.1.1 (node_modules/fsevents/node_modules/yallist):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/yallist&#x27; -&gt; &#x27;/root/elasticsearch-head/node_modules/fsevents/node_modules/.yallist.DELETE&#x27;#报错npm ERR! code ELIFECYCLEnpm ERR! errno 1npm ERR! phantomjs-prebuilt@2.1.16 install: `node install.js`npm ERR! Exit status 1npm ERR! #phantomjs-prebuilt@2.1.16 install script 安装脚本失败npm ERR! Failed at the phantomjs-prebuilt@2.1.16 install script.npm ERR! This is probably not a problem with npm. There is likely additional logging output above.npm ERR! A complete log of this run can be found in:npm ERR! /root/.npm/_logs/2020-02-14T23_45_53_948Z-debug.log#收到安装一下，忽略脚本[root@node1 elasticsearch-head]# npm install phantomjs-prebuilt@2.1.16 --ignore-scriptnpm WARN deprecated phantomjs-prebuilt@2.1.16: this package is now deprecatednpm WARN deprecated request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142npm notice created a lockfile as package-lock.json. You should commit this file.npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@^1.0.0 (node_modules/chokidar/node_modules/fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.11: wanted &#123;&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;&#125; (current: &#123;&quot;os&quot;:&quot;linux&quot;,&quot;arch&quot;:&quot;x64&quot;&#125;)npm WARN elasticsearch-head@0.0.0 license should be a valid SPDX license expressionnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: abbrev@1.1.1 (node_modules/chokidar/node_modules/fsevents/node_modules/abbrev):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/abbrev&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.abbrev.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: ansi-regex@2.1.1 (node_modules/chokidar/node_modules/fsevents/node_modules/ansi-regex):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/ansi-regex&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.ansi-regex.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: aproba@1.2.0 (node_modules/chokidar/node_modules/fsevents/node_modules/aproba):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/aproba&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.aproba.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: balanced-match@1.0.0 (node_modules/chokidar/node_modules/fsevents/node_modules/balanced-match):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/balanced-match&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.balanced-match.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: chownr@1.1.3 (node_modules/chokidar/node_modules/fsevents/node_modules/chownr):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/chownr&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.chownr.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: code-point-at@1.1.0 (node_modules/chokidar/node_modules/fsevents/node_modules/code-point-at):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/code-point-at&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.code-point-at.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: concat-map@0.0.1 (node_modules/chokidar/node_modules/fsevents/node_modules/concat-map):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/concat-map&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.concat-map.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: console-control-strings@1.1.0 (node_modules/chokidar/node_modules/fsevents/node_modules/console-control-strings):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/console-control-strings&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.console-control-strings.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: core-util-is@1.0.2 (node_modules/chokidar/node_modules/fsevents/node_modules/core-util-is):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/core-util-is&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.core-util-is.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: deep-extend@0.6.0 (node_modules/chokidar/node_modules/fsevents/node_modules/deep-extend):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/deep-extend&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.deep-extend.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: delegates@1.0.0 (node_modules/chokidar/node_modules/fsevents/node_modules/delegates):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/delegates&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.delegates.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: detect-libc@1.0.3 (node_modules/chokidar/node_modules/fsevents/node_modules/detect-libc):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/detect-libc&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.detect-libc.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fs.realpath@1.0.0 (node_modules/chokidar/node_modules/fsevents/node_modules/fs.realpath):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/fs.realpath&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.fs.realpath.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: has-unicode@2.0.1 (node_modules/chokidar/node_modules/fsevents/node_modules/has-unicode):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/has-unicode&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.has-unicode.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: inherits@2.0.4 (node_modules/chokidar/node_modules/fsevents/node_modules/inherits):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/inherits&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.inherits.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: ini@1.3.5 (node_modules/chokidar/node_modules/fsevents/node_modules/ini):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/ini&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.ini.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: isarray@1.0.0 (node_modules/chokidar/node_modules/fsevents/node_modules/isarray):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/isarray&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.isarray.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: minimist@0.0.8 (node_modules/chokidar/node_modules/fsevents/node_modules/minimist):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/minimist&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.minimist.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: ms@2.1.2 (node_modules/chokidar/node_modules/fsevents/node_modules/ms):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/ms&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.ms.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: npm-normalize-package-bin@1.0.1 (node_modules/chokidar/node_modules/fsevents/node_modules/npm-normalize-package-bin):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/npm-normalize-package-bin&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.npm-normalize-package-bin.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: number-is-nan@1.0.1 (node_modules/chokidar/node_modules/fsevents/node_modules/number-is-nan):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/number-is-nan&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.number-is-nan.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: object-assign@4.1.1 (node_modules/chokidar/node_modules/fsevents/node_modules/object-assign):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/object-assign&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.object-assign.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: os-homedir@1.0.2 (node_modules/chokidar/node_modules/fsevents/node_modules/os-homedir):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/os-homedir&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.os-homedir.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: os-tmpdir@1.0.2 (node_modules/chokidar/node_modules/fsevents/node_modules/os-tmpdir):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/os-tmpdir&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.os-tmpdir.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: path-is-absolute@1.0.1 (node_modules/chokidar/node_modules/fsevents/node_modules/path-is-absolute):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/path-is-absolute&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.path-is-absolute.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: process-nextick-args@2.0.1 (node_modules/chokidar/node_modules/fsevents/node_modules/process-nextick-args):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/process-nextick-args&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.process-nextick-args.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: minimist@1.2.0 (node_modules/chokidar/node_modules/fsevents/node_modules/rc/node_modules/minimist):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/rc/node_modules/minimist&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/rc/node_modules/.minimist.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: safe-buffer@5.1.2 (node_modules/chokidar/node_modules/fsevents/node_modules/safe-buffer):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/safe-buffer&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.safe-buffer.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: safer-buffer@2.1.2 (node_modules/chokidar/node_modules/fsevents/node_modules/safer-buffer):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/safer-buffer&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.safer-buffer.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: sax@1.2.4 (node_modules/chokidar/node_modules/fsevents/node_modules/sax):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/sax&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.sax.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: semver@5.7.1 (node_modules/chokidar/node_modules/fsevents/node_modules/semver):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/semver&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.semver.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: set-blocking@2.0.0 (node_modules/chokidar/node_modules/fsevents/node_modules/set-blocking):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/set-blocking&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.set-blocking.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: signal-exit@3.0.2 (node_modules/chokidar/node_modules/fsevents/node_modules/signal-exit):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/signal-exit&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.signal-exit.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: strip-json-comments@2.0.1 (node_modules/chokidar/node_modules/fsevents/node_modules/strip-json-comments):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/strip-json-comments&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.strip-json-comments.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: util-deprecate@1.0.2 (node_modules/chokidar/node_modules/fsevents/node_modules/util-deprecate):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/util-deprecate&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.util-deprecate.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: wrappy@1.0.2 (node_modules/chokidar/node_modules/fsevents/node_modules/wrappy):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/wrappy&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.wrappy.DELETE&#x27;npm WARN optional SKIPPING OPTIONAL DEPENDENCY: yallist@3.1.1 (node_modules/chokidar/node_modules/fsevents/node_modules/yallist):npm WARN enoent SKIPPING OPTIONAL DEPENDENCY: ENOENT: no such file or directory, rename &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/yallist&#x27; -&gt; &#x27;/usr/local/elasticsearch-head/node_modules/chokidar/node_modules/fsevents/node_modules/.yallist.DELETE&#x27;+ phantomjs-prebuilt@2.1.16added 61 packages from 63 contributors, removed 6 packages and audited 1736 packages in 10.371s3 packages are looking for funding run `npm fund` for detailsfound 40 vulnerabilities (18 low, 2 moderate, 20 high) run `npm audit fix` to fix them, or `npm audit` for details #安装完成，后台grunt启动，发布ES-head 前端web[root@node1 elasticsearch-head]# nohup npm run start &amp;[1] 38691[root@node1 elasticsearch-head]# nohup: 忽略输入并把输出追加到&#x27;nohup.out&#x27;[root@node1 elasticsearch-head]# jobs[1]+ 运行中 nohup npm run start &amp; 测试es-head发布 1[root@node1 ~]# netstat -ntpl 07_grunt_启动验证.png web测试 1浏览器中输入：http://192.168.98.201:9100/ 08_grunt_web启动验证.png FAQ：连接失败解决方法 ES安装成功后，从另外一个域的浏览器访问ES服务器数据，会出现跨域的问题。 解决方案 1）修改elasticsearch.yml末尾添加：跨域访问 123跨域访问http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 2）重启elasticsearch服务 1[root@node1 ~]# systemctl restart elasticsearch 再次测试 09_grunt_web启动验证成功.png","categories":["Linux","构建可视化数据分析系统-ELK"]},{"title":"gitlab备份与还原","path":"/2023/09/27/CI和CD代码管理平台/gitlab备份与还原/","content":"由于gitlab中存放的都是开发人员的工作成果，所以为了保证数据安全，我们会定期对数据进行备份，对gitlab进行备份将会创建一个包含所有库和附件的归档文件。对备份的恢复只能恢复到与备份时的gitlab相同的版本。将gitlab迁移到另一台服务器上的最佳方法就是通过备份和还原。gitlab提供了一个简单的命令行来备份整个gitlab ，并且能灵活的满足需求。 一、备份备份路径： 备份文件将保存在配置文件中定义的backup_path中 ，文件名为TIMESTAMP_gitlab_backup.tar,TIMESTAMP为备份时的时间戳。TIMESTAMP的格式为 ：EPOCH_YYYY_MM_DD_Gitlab‐version。 备份配置： 123456[root@zutuanxue git_data]# vim /etc/gitlab/gitlab.rb gitlab_rails[&#x27;backup_path&#x27;] = &quot;/opt/backups&quot;#备份路径gitlab_rails[&#x27;backup_keep_time&#x27;] = 604800#备份周期-秒（7x24x3600）[root@zutuanxue git_data]# gitlab-ctl reconfigure 手动备份： 1234[root@zutuanxue git_data]# gitlab-backup create或者[root@zutuanxue git_data]# gitlab-rake gitlab:backup:create[root@zutuanxue git_data]# ls /opt/backups/ 定时备份： 在定时任务里添加： 1230 2 * * * /opt/gitlab/bin/gitlab-rake gitlab:backup:create或0 2 * * * /opt/gitlab/bin/gitlab-backup create 二、还原操作只能还原到与备份文件相同的gitlab版本。执行恢复操作时，需要gitlab处于运行状态，备份文件位于gitlab_rails[‘backup_path’]。需要先停掉两个服务，停止连接到数据库的进程（也就是停止数据写入服务，如果是空主机，没有任何操作的话，可以不停止服务，停止相应服务的目的是为了保证数据移植），但是保持GitLab是运行的。 在web中删除项目 12[root@zutuanxue backups]# gitlab-ctl stop unicorn[root@zutuanxue backups]# gitlab-ctl stop sidekiq 指定时间戳你要从那个备份恢复： 123456789101112131415161718192021222324[root@zutuanxue git_data]# cd /opt/backups/[root@zutuanxue backups]# gitlab-ctl stop unicornok: down: unicorn: 0s, normally up[root@zutuanxue backups]# gitlab-ctl stop sidekiqok: down: sidekiq: 1s, normally up[root@zutuanxue backups]# gitlab-rake gitlab:backup:restore BACKUP=1586328114_2020_04_08_12.9.2（有的版本执行gitlab-rake gitlab:backup:restore BACKUP=1586328114即可）Unpacking backup ... doneBefore restoring the database, we will remove all existingtables to avoid future upgrade problems. Be aware that if you havecustom tables in the GitLab database these tables and all data will beremoved.Do you want to continue (yes/no)? yes#提示移除所有存在的表...This task will now rebuild the authorized_keys file.You will lose any data stored in the authorized_keys file.Do you want to continue (yes/no)? yes#提示移除所有验证秘钥[root@zutuanxue backups]# gitlab-ctl restart#重启gitlab注意：也可使用gitlab-rake gitlab:check SANITIZE=true验证下gitlab服务 浏览器重新打开gitlab页面，重新登录后查看到被还原的项目内容","categories":["Linux","CI和CD代码管理平台"]},{"title":"gitlab部署","path":"/2023/09/27/CI和CD代码管理平台/gitlab部署/","content":"一、GitLab简介GitLab 是一个用于仓库管理系统的开源项目。使用Git作为代码管理工具，并在此基础上搭建起来的web服务。可通过Web界面进行访问公开的或者私人项目。它拥有与Github类似的功能，能够浏览源代码，管理缺陷和注释。可以管理团队对仓库的访问，它非常易于浏览提交过的版本并提供一个文件历史库。团队成员可以利用内置的简单聊天程序(Wall)进行交流。它还提供一个代码片段收集功能可以轻松实现代码复用。 gitlab主要用于私用，github主要用于公网，都可看成web版的git Community Edition or Enterprise Edition，ce和ee分别指的是社区版和企业版，毫无疑问社区版已经能满足我们的需求了。 常用的网站 官网 ： https://about.gitlab.com/ https://packages.gitlab.com/gitlab/gitlab-ce CE版下载地址 https://packages.gitlab.com/gitlab/gitlab-ee EE版下载地址 国内镜像 ：https://mirrors.tuna.tsinghua.edu.cn/gitlab‐ce/yum/ image20200407140627737.png image20200407140745198.png 二、安装与配置 环境：CentOS 8 关闭selinux和防火墙 2.1、 安装依赖包 12345dnf install -y curl policycoreutils openssh-server postfixsystemctl enable sshdsystemctl start sshdsystemctl enable postfixsystemctl start postfix 2.2、 联网安装 1234567891011121314[root@zutuanxue ~]# vim /etc/yum.repos.d/gitlab-ce.repo [gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1[root@zutuanxue ~]# dnf install gitlab-ce -y（如果安装比较慢的话也可以从https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el8/下载rpm包到本地进行安装[root@zutuanxue ~]# yum localinstall gitlab-ce-12.9.2-ce.0.el8.x86_64.rpm ） 2.3、配置 123456789101112131415[root@zutuanxue ~]# vim /etc/gitlab/gitlab.rb external_url &#x27;http://192.168.2.100&#x27;#修改为本机的名称或者IP地址###(GitLab默认会占用80、8080和9090端口，如果服务器上还有tomcat、Jenkins等其他服务，可能会遇到端口冲突,如果想修改端口的话可以external_url &#x27;http://192.168.2.100:自定义端口&#x27;unicorn[&#x27;port&#x27;] = xxxprometheus[&#x27;listen_address&#x27;] = &#x27;localhost:xxx&#x27;将xxx更换成自己需要使用的端口###)[root@zutuanxue ~]# gitlab-ctl reconfigure#修改完成之后重新配置gitlab 命令和目录&#x2F;opt&#x2F;gitlab&#x2F; # gitlab的程序安装目录 &#x2F;var&#x2F;opt&#x2F;gitlab # gitlab数据目录 &#x2F;var&#x2F;opt&#x2F;gitlab&#x2F;git‐data # 存放仓库数据 命令 function start 启动所有服务 stop 关闭所有服务 restart 重启所有服务 status 查看所有服务状态 tail 查看日志信息 service-list 查看所有启动服务 graceful-kill 平稳停止一个服务 help 帮助 reconfigure 修改配置文件之后，重新加载 show-config 查看所有服务配置文件信息 uninstall 卸载这个软件 cleanse 清空gitlab数据 1234567[root@zutuanxue ~]# gitlab-ctl startok: run: alertmanager: (pid 1564) 3804sok: run: gitaly: (pid 1550) 3804s[root@zutuanxue ~]# gitlab-ctl start nginxok: run: nginx: (pid 1531) 3823s#这些操作指令，如果不指定名称的话，默认会操作所有 Gitlab的服务构成12345678910[root@zutuanxue ~]# gitlab-ctl service-listgitaly*\tgit RPC服务，用于处理gitlab发出的git调用gitlab-workhorse*\t轻量级的反向代理服务器logrotate*\t日志文件管理工具nginx*\t静态web服务postgresql*\t数据库redis*\t缓存数据库sidekiq*\t用于在后台执行队列任务unicorn*\t用Ruby编写的web server，GitLab Rails应用是托管在这个服务器上面alertmanager*，gitlab-exporter*，grafana*，node-exporter*，postgres-exporter*，prometheus*，redis-exporter*\t#与监控相关的插件 在浏览器中访问本机，就可以打开登录界面，初次登录必须修改密码（不能少于8位），更改完成后可以使用管理员账号登录，用户名为root 2.4、gitlab汉化 1、浏览器设置中文后重新打开 2、点击右上角头像，选择设置（settings） 3、左边选择preferences–&gt;languages—&gt;save 4、刷新页面 如果还是有问题 123[root@zutuanxue ~]# dnf groupinstall chinese-support#安装中文支持[root@zutuanxue ~]# dnf install ibus*\t#安装输入法#重启后在系统设置更改语言环境为中文 image20200407163323541.png","categories":["Linux","CI和CD代码管理平台"]},{"title":"git介绍","path":"/2023/09/27/CI和CD代码管理平台/git介绍/","content":"git介绍简单来说git就是一个分布式的版本控制软件，直接记录快照，而非差异比较Git 和其它版本控制系统(包括 Subversion 和近似工具)的主要差别在于 Git 对待数据的方法。 从概念上来说，其它大部分系统以文件变更列表的方式存储信息（基于差异的版本控制)。Git 不按照以上方式对待或保存数据。反之，Git 更像是把数据看作是对小型文件系统的一系列快照。 在 Git 中，每当你提交更新或保存项目状态时，它基本上就会对当时的全部文件创建一个快照并保存这个快照的索引。 为了效率，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个快照流。 git的优势近乎所有操作都是本地执行 在 Git 中的绝大多数操作都只需要访问本地文件和资源，一般不需要来自网络上其它计算机的信息。因为你在本地磁盘上就有项目的完整历史，所以大部分操作看起来瞬间完成。这也意味着你在离线或者没有 VPN 时，几乎可以进行任何操作， 直到有网络连接时再上传。 保证完整性 Git 中所有的数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 Git 不知情时更改任何文件 内容或目录内容。 这个功能建构在 Git 底层，是构成 Git 哲学不可或缺的部分。 若你在传送过程中丢失信息或损 坏文件，Git 就能发现。 很难丢失数据 你执行的 Git 操作，几乎只往 Git 数据库中添加数据。 你很难让 Git 执行任何不可逆操作，或者让它以任何方式清除数据。虽然未提交更新时有可能丢失或弄乱修改的内容。但是一旦你提交快照到 Git 中， 就难以再丢失数据，特别是如果你定期的推送数据库到其它仓库的话。 git的三种状态 已修改(modified) 表示修改了文件，但还没保存到数据库中。 已暂存(staged) 表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。 已提交(committed) 表示数据已经安全地保存在本地数据库中。 由于有这三种状态，所以Git 项目拥有三个阶段:工作区、暂存区以及 Git 目录。 image20200405153608934.png 工作区：是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。 暂存区：是一个文件，保存了下次将要提交的文件列表信息，一般在 Git 仓库目录中。 按照 Git 的术语叫做“索引”，不过一般说法还是叫“暂存区”。 Git 仓库目录：是 Git 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，复制的就是这里的数据。 基本的 Git 工作流程如下: 1231. 在工作区中修改文件。2. 将你想要下次提交的更改选择性地暂存，这样只会将更改的部分添加到暂存区。3. 提交更新，找到暂存区的文件，将快照永久性存储到 Git 目录。 如果Git目录中保存着特定版本的文件，就属于已提交状态。 如果文件已修改并放入暂存区，就属于已暂存状态。 如果作了修改但还没有放到暂存区域，就是已修改状态。","categories":["Linux","CI和CD代码管理平台"]},{"title":"git仓库配置及仓库特性","path":"/2023/09/27/CI和CD代码管理平台/git仓库配置及仓库特性/","content":"一、git仓库初始化123456789101112131415161718192021git init\t把当前所在目录变成git工作目录git config ‐‐global 使用全局配置文件\t‐‐system 使用系统级配置文件\t‐‐local 使用版本库级配置文件#定义git用户[root@zutuanxue ~]# git config --global user.name &quot;hello&quot;#定义git使用的邮箱[root@zutuanxue ~]# git config --global user.email &quot;hello@localhost#定义语法高亮[root@zutuanxue ~]# git config --global color.ui true#查看定义的信息[root@zutuanxue ~]# git config --listuser.name=hellouser.email=hello@localhostcolor.ui=true git 配置文件管理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354551、新建配置文件git config --global --add configName configValue解释:给指定的级别的指定config增加一个值示例:[root@zutuanxue git_data]# git config --global --add user.name test[root@zutuanxue git_data]# git config --global --listuser.name=hellouser.email=hello@localhostuser.name=testcolor.ui=true2、删除配置文件git config --global --unset configName (只针对存在唯一值的情况)为了测试先增加一个[root@zutuanxue git_data]# git config --global --add alias.test &quot;aaaaa&quot;[root@zutuanxue git_data]# git config --global --listuser.name=hellouser.email=hello@localhostuser.name=testcolor.ui=truealias.test=aaaaa删除这个唯一值,查看效果[root@zutuanxue git_data]# git config --global --unset alias.test [root@zutuanxue git_data]# git config --global --listuser.name=hellouser.email=hello@localhostuser.name=testcolor.ui=true3、修改配置文件git config --global configName configValue[root@zutuanxue git_data]# git config --global --listuser.name=hellouser.email=hello@localhostuser.name=testcolor.ui=true[root@zutuanxue git_data]# git config --global user.name aaawarning: user.name 有多个取值error: 无法用一个值覆盖多个值 使用一个正则表达式、--add 或 --replace-all 来修改 user.name。[root@zutuanxue git_data]# git config --global --replace-all user.name aaa[root@zutuanxue git_data]# git config --global --listuser.email=hello@localhostuser.name=aaacolor.ui=true4、查看配置文件git config --global configName查询指定级别下: 实际生效的配置值[root@zutuanxue git_data]# git config --global user.name aaa 二、git仓库数据管理机状态创建数据-提交数据 image20200405175817262.png 本地仓库可以理解为工作目录下.git&#x2F;objects git提交数据到仓库流程： 1231. 先git add把新文件提交到暂存区2. 再git commit 存到仓库3. 最后使用git push提交到远程仓库； 用户使用则通过以下命令拉取到本地 11. 使用git clone/git pull将数据同步到本地仓库，再使用相关命令进行操作 git四种状态 image20200405165323247.png untracked：未跟踪的，也就是一个文件没有被git管理、监控起来 unmodified：未修改的 modified：已修改的 staged：已暂存的 你工作目录下的每一个文件都不外乎这两种状态:已跟踪 或 未跟踪。 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后， 它们的状态可能是未修改，已修改或已放入暂存区。简而言之，已跟踪的文件就是 Git 已经知道的文件。 工作目录中除已跟踪文件外的其它所有文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有被放 入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态，因为 Git 刚刚检出了它们， 而你尚未编辑过它们。 编辑过某些文件之后，由于自上次提交后你对它们做了修改，Git 将它们标记为已修改文件。 在工作时，你可以 选择性地将这些修改过的文件放入暂存区，然后提交所有已暂存的修改，如此反复。 检查当前文件状态 我们可以使用git status检查文件的状态 123456[root@zutuanxue git]# git status 位于分支 master尚无提交无文件要提交（创建/拷贝文件并使用 &quot;git add&quot; 建立跟踪）#这说明你现在的工作目录相当干净。换句话说，所有已跟踪文件在上次提交后都未被更改过。 此外，上面的信 息还表明，当前目录下没有出现任何处于未跟踪状态的新文件，否则 Git 会在这里列出来。 在项目下创建一个新的 README 文件。 如果之前并不存在这个文件，使用 git status 命令，你将看到一个新的未跟踪文件: 12345678[root@zutuanxue git]# echo test &gt; README[root@zutuanxue git]# git status 位于分支 master尚无提交未跟踪的文件: （使用 &quot;git add &lt;文件&gt;...&quot; 以包含要提交的内容）\tREADME提交为空，但是存在尚未跟踪的文件（使用 &quot;git add&quot; 建立跟踪） 在状态报告中可以看到新建的 README 文件出现在 “未跟踪的文件” 下面。 未跟踪的文件意味着 Git 在之前 的快照(提交)中没有这些文件;Git 不会自动将之纳入跟踪范围，除非你明明白白地告诉它“我需要跟踪该文件”。 跟踪新文件 1234567[root@zutuanxue git]# git add README [root@zutuanxue git]# git status位于分支 master尚无提交要提交的变更： （使用 &quot;git rm --cached &lt;文件&gt;...&quot; 以取消暂存）\t新文件： README 只要在 Changes to be committed 或者“要提交的变更”这行下面的，就说明是已暂存状态。 如果此时提交，那么该文件在你运 行git add时的版本将被留存在后续的历史记录中。 暂存已修改的文件 1234567891011[root@zutuanxue git]# echo aaa &gt;&gt; README [root@zutuanxue git]# git status位于分支 master尚无提交要提交的变更： （使用 &quot;git rm --cached &lt;文件&gt;...&quot; 以取消暂存）\t新文件： README尚未暂存以备提交的变更： （使用 &quot;git add &lt;文件&gt;...&quot; 更新要提交的内容） （使用 &quot;git checkout -- &lt;文件&gt;...&quot; 丢弃工作区的改动）\t修改： README 现在我们来修改一个已被跟踪的文件。出现在Changes not staged for commit或者“尚未暂存以备提交的变更”这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。 要暂存这次更新，需要运行 git add 命令。 这是个多功能命令:可以用它开 始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。再次使用git status -s查看 123456[root@zutuanxue git]# git status -sA README################?? 新添加的未跟踪文件A\t新添加到暂存区中的文件M\t修改过的文件","categories":["Linux","CI和CD代码管理平台"]},{"title":"gitlab使用","path":"/2023/09/27/CI和CD代码管理平台/gitlab使用/","content":"一、外观image20200407163624225.png 设置完成后保存，返回登录页面查看 image20200407163659051.png 关于注册，有些公司是不允许打开的，，有些人数非常多的公司就需要打开注册的功能，让人员自己注册，我们来给他特定的权限就可以，毕竟人非常多的时候还由我们来给她们注册就非常不现实了，工作量会很大 二、自动注册image20200407163952391.png image20200407164026831.png 三、组&amp;用户&amp;项目创建组 image20200407164306707.png 设置组名称、描述等创建群组 image20200407164514878.png 创建用户 image20200407164550662.png image20200407164640254.png 设置密码 image20200407164723320.png image20200407164835369.png 把用户添加到组里面 image20200407164948977.png image20200407165031097.png 12345678910Guest：可以创建issue、发表评论，不能读写版本库Reporter：可以克隆代码，不能提交，QA、PM可以赋予这个权限Developer：可以克隆代码、开发、提交、push，RD可以赋予这个权限Maintainer：可以创建项目、添加tag、保护分支、添加项目成员、编辑项目，核心RD负责人可以赋予这个权限Owner：可以设置项目访问权限 - Visibility Level、删除项目、迁移项目、管理组成员，开发组leader可以赋予这个权限Gitlab中的组和项目有三种访问权限：Private、Internal、PublicPrivate：只有组成员才能看到Internal：只要登录的用户就能看到Public：所有人都能看到 创建仓库 管理区域-创建仓库 image20200407165129307.png image20200407170517512.png 也可以导入项目 image20200407170805432.png 创建仓库以后，网页下面有操作步骤的提醒 image20200407170918038.png 四、登陆用户测试是否能看到空的gitlabtest仓库，修改完密码后再次登录 image20200407171108761.png 五、添加ssh‐keys注 ：一个服务器的key只能添加到一个gitlab服务器上 ，一个用户可以添加多个key，切换到管理员用户 ssh‐keygen ‐t rsa image20200408093838255.png image20200407171928443.png 六、添加、推送到远程仓库默认master是不允许developer权限的成员执行推送操作的 12345[root@zutuanxue git_data]# git remote rm origin或者[root@zutuanxue git_data]# git remote rename origin old‐origin 也可以重命名[root@zutuanxue git_data]# git remote add origin git@192.168.2.100:gitlabtest/gitlabtest.git[root@zutuanxue git_data]# git push -u origin --all 七、克隆切换到另外一台主机 123[root@zutuanxue ~]# dnf install git -y[root@zutuanxue work]# ssh-keygen -t rsa[root@zutuanxue work]# cat /root/.ssh/id_rsa.pub 使用test用户登录gitlab并添加ssh秘钥 12345678910111213141516171819202122232425[root@zutuanxue work]# git clone git@192.168.2.100:gitlabtest/gitlabtest.git正克隆到 &#x27;gitlabtest&#x27;...The authenticity of host &#x27;192.168.2.100 (192.168.2.100)&#x27; can&#x27;t be established.ECDSA key fingerprint is SHA256:CDlvaoOre2O1oLbKC4umHcPZ/AfHk37sEZGZakepDd0.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &#x27;192.168.2.100&#x27; (ECDSA) to the list of known hosts.remote: Enumerating objects: 3, done.remote: Counting objects: 100% (3/3), done.remote: Compressing objects: 100% (2/2), done.remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0接收对象中: 100% (3/3), 完成.[root@zutuanxue ~]# cd gitlabtest/[root@zutuanxue gitlabtest]# lsa b c[root@zutuanxue gitlabtest]# git config --global user.name test[root@zutuanxue gitlabtest]# git config --global user.email &quot;test@aa.com&quot;[root@zutuanxue gitlabtest]# git branch usertest[root@zutuanxue gitlabtest]# git checkout usertest切换到分支 &#x27;usertest&#x27;[root@zutuanxue gitlabtest]# touch file4test[root@zutuanxue gitlabtest]# lsa b c file4test[root@zutuanxue gitlabtest]# git add .[root@zutuanxue gitlabtest]# git commit -m &quot;touch file4test&quot;[root@zutuanxue gitlabtest]# git push -u origin usertest 创建合并请求 image20200408111919102.png image20200408112004021.png 切换到管理员账号，处理请求 image20200408112235898.png image20200408112327012.png 切换到test用户或者直接使用管理员查看，内容已合并，之前的usertest分支已经被删除 image20200408112446861.png 设置保护主分支 image20200407181236004.png image20200407181310037.png image20200407182219612.png 默认情况下为了保证master分支的稳定是被保护的，只有维护者可以执行push的操作，所以，当一个开发者身份的用户在针对master分支进行操作的时候会出现被拒绝的提示 12345678[root@zutuanxue gitlabtest]# git push -u origin masterTo 192.168.2.100:gitlabtest/gitlabtest.git ! [rejected] master -&gt; master (fetch first)error: 无法推送一些引用到 &#x27;git@192.168.2.100:gitlabtest/gitlabtest.git&#x27;提示：更新被拒绝，因为远程仓库包含您本地尚不存在的提交。这通常是因为另外提示：一个仓库已向该引用进行了推送。再次推送前，您可能需要先整合远程变更提示：（如 &#x27;git pull ...&#x27;）。提示：详见 &#x27;git push --help&#x27; 中的 &#x27;Note about fast-forwards&#x27; 小节。 同样我们也可以利用上述功能去保护某些不想被修改的分支。 解决内容不一致 除了分支被保护会出现上述提示之外，有些时候在你返回master端测试推送 ，由于其他分支进行推送 ，和master端内容不一致 ，所以无法进行推送 ，这个时候可以使用git pull把代码拉取到本地 ，或者git fetch 把代码拉取到本地仓库后进行合并 （注意 ：git pull &#x3D; git fetch+git merge ） 1234567[root@zutuanxue git_data]# git fetch [root@zutuanxue git_data]# lsa b c README.md[root@zutuanxue git_data]# git merge origin/master[root@zutuanxue git_data]# lsa b c file4test README.md[root@zutuanxue git_data]# git push -u origin","categories":["Linux","CI和CD代码管理平台"]},{"title":"git常用命令","path":"/2023/09/27/CI和CD代码管理平台/git常用命令/","content":"git status&#x2F;git status -s查看状态 12345678910111213141516[root@zutuanxue git_data]# git status位于分支 master尚无提交无文件要提交（创建/拷贝文件并使用 &quot;git add&quot; 建立跟踪）[root@zutuanxue git_data]# touch a b c[root@zutuanxue git_data]# lsa b c[root@zutuanxue git_data]# git status 位于分支 master尚无提交未跟踪的文件: （使用 &quot;git add &lt;文件&gt;...&quot; 以包含要提交的内容）\ta\tb\tc提交为空，但是存在尚未跟踪的文件（使用 &quot;git add&quot; 建立跟踪） git add暂存内容 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@zutuanxue git_data]# git add a[root@zutuanxue git_data]# git status 位于分支 master尚无提交要提交的变更： （使用 &quot;git rm --cached &lt;文件&gt;...&quot; 以取消暂存）\t新文件： a未跟踪的文件: （使用 &quot;git add &lt;文件&gt;...&quot; 以包含要提交的内容）\tb\tc[root@zutuanxue git_data]# ll .git/总用量 16drwxr-xr-x 2 root root 6 4月 3 05:34 branches-rw-r--r-- 1 root root 92 4月 3 05:34 config-rw-r--r-- 1 root root 73 4月 3 05:34 description-rw-r--r-- 1 root root 23 4月 3 05:34 HEADdrwxr-xr-x 2 root root 301 4月 3 05:34 hooks-rw-r--r-- 1 root root 96 4月 5 06:05 index#你会发现index的时间产生了变化，这意味着，我们使用git add命令将文件提交到了暂存区域drwxr-xr-x 2 root root 21 4月 3 05:34 infodrwxr-xr-x 5 root root 40 4月 5 06:05 objectsdrwxr-xr-x 4 root root 31 4月 3 05:34 refs[root@zutuanxue git_data]# ll .git/objects/总用量 0drwxr-xr-x 2 root root 52 4月 5 06:05 e6drwxr-xr-x 2 root root 6 4月 3 05:34 infodrwxr-xr-x 2 root root 6 4月 3 05:34 pack[root@zutuanxue objects]# ls e69de29bb2d1d6434b8b29ae775ad8c2e48c5391[root@zutuanxue objects]# cat e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391 #在objects目录中可以看到已元数据形式存储的a文件，这个我们看不懂，我们可以将数据都添加 [root@zutuanxue git_data]# git add . #可以使用.也可以使用*[root@zutuanxue git_data]# git status位于分支 master尚无提交要提交的变更： （使用 &quot;git rm --cached &lt;文件&gt;...&quot; 以取消暂存）\t新文件： a\t新文件： b\t新文件： c git rm将文件从暂存区撤回到工作区（变成未跟踪的）、然后再删除文件；也可以直接从暂存区删除 1234567891011121314151617181920212223242526272829303132333435[root@zutuanxue git_data]# git rm --cached crm &#x27;c&#x27;[root@zutuanxue git_data]# git status 位于分支 master尚无提交要提交的变更： （使用 &quot;git rm --cached &lt;文件&gt;...&quot; 以取消暂存）\t新文件： a\t新文件： b未跟踪的文件: （使用 &quot;git add &lt;文件&gt;...&quot; 以包含要提交的内容）\tc[root@zutuanxue git_data]# rm -fr c[root@zutuanxue git_data]# git status 位于分支 master尚无提交要提交的变更： （使用 &quot;git rm --cached &lt;文件&gt;...&quot; 以取消暂存）\t新文件： a\t新文件： b[root@zutuanxue git_data]# git rm -f brm &#x27;b&#x27;[root@zutuanxue git_data]# git status 位于分支 master尚无提交要提交的变更： （使用 &quot;git rm --cached &lt;文件&gt;...&quot; 以取消暂存）\t新文件： a[root@zutuanxue git_data]# git commit -m &quot; new a&quot;\t#提交到本地仓库[master（根提交） 6ac34be] a 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 a[root@zutuanxue git_data]# git status位于分支 master无文件要提交，干净的工作区 git mv将暂存区里的数据改名或移动 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556571.使用mv命令配合git[root@zutuanxue git_data]# mv a a.txt[root@zutuanxue git_data]# git status位于分支 master尚未暂存以备提交的变更： （使用 &quot;git add/rm &lt;文件&gt;...&quot; 更新要提交的内容） （使用 &quot;git checkout -- &lt;文件&gt;...&quot; 丢弃工作区的改动）\t删除： a未跟踪的文件: （使用 &quot;git add &lt;文件&gt;...&quot; 以包含要提交的内容）\ta.txt修改尚未加入提交（使用 &quot;git add&quot; 和/或 &quot;git commit -a&quot;）[root@zutuanxue git_data]# git rm --cached a\t###从暂存区删除arm &#x27;a&#x27;[root@zutuanxue git_data]# git status 位于分支 master要提交的变更： （使用 &quot;git reset HEAD &lt;文件&gt;...&quot; 以取消暂存）\t删除： a未跟踪的文件: （使用 &quot;git add &lt;文件&gt;...&quot; 以包含要提交的内容）\ta.txt[root@zutuanxue git_data]# git add a.txt[root@zutuanxue git_data]# git status位于分支 master要提交的变更： （使用 &quot;git reset HEAD &lt;文件&gt;...&quot; 以取消暂存）\t重命名： a -&gt; a.txt\t########识别到a和a.txt是重命名的文件[root@zutuanxue git_data]# git commit -m &quot;rename a to a.txt&quot;#提交到本地仓库[master 47a267c] a.txt 1 file changed, 0 insertions(+), 0 deletions(-) rename a =&gt; a.txt (100%)2.使用git mv直接重命名[root@zutuanxue git_data]# git mv a.txt a\t#将工作区域和暂存区域的文件同时重命名[root@zutuanxue git_data]# git status位于分支 master要提交的变更： （使用 &quot;git reset HEAD &lt;文件&gt;...&quot; 以取消暂存）\t重命名： a.txt -&gt; a[root@zutuanxue git_data]# git commit -m &quot;rename a.txt to a&quot;[master a714e37] a 1 file changed, 0 insertions(+), 0 deletions(-) rename a.txt =&gt; a (100%) git diffgit status 只能查看区域状态的不同 ，不能查看文件内容的变化。 git diff 查看内容的不同 123456789101112131415161718192021222324252627282930[root@zutuanxue git_data]# git diff #没有变化时不显示内容[root@zutuanxue git_data]# vim ahelloabc[root@zutuanxue git_data]# git add a[root@zutuanxue git_data]# vim ahellotesttest1[root@zutuanxue git_data]# git diff a\t#调整完成文件后，对比本地工作目录和暂存区文件的差异diff --git a/a b/a#git格式的diff命令，进行比较的是a版本的a文件和b版本的a文件index e69de29..ce01362 100644#两个版本的哈希值，100644表示是对象是普通文件，权限是644--- a/a #---表示变动前，也就是a版本的a文件+++ b/a #+++表示变动后，也就是b版本的a文件@@ -1,2 +1,3 @@\t## 以@符号开始和结束“-1，2”表示前一个文件从第一行开始的连续两行；“+1，3”表示后一个文件的从第一行开始连续的3行（-表示前一个文件，+表示后一个文件）hello -abc #-表示去掉的内容+test+test1 #+表示新增的内容[root@zutuanxue git_data]# git diff --cached a\t#对比暂存区和本地仓库的差异diff --git a/a b/aindex e69de29..0e3af97 100644--- a/a+++ b/a@@ -0,0 +1,2 @@+hello+abc git commit -m将暂存区内容提交到本地仓库-m后面是描述信息 12345[root@zutuanxue git_data]# git commit -m &quot;version2 a&quot;[master 8f01c62] version2 a 1 file changed, 2 insertions(+)[root@zutuanxue git_data]# git diff --cached agit commit # 相当于虚拟机的镜像、任何操作都被做了一次快照 ，可恢复到任意一个位置 git commit -am快速提交到本地仓库 1234567891011121314151617181920212223242526272829303132333435363738[root@zutuanxue git_data]# cat ahaha[root@zutuanxue git_data]# git diff[root@zutuanxue git_data]# echo hello &gt;&gt; a[root@zutuanxue git_data]# git diffdiff --git a/a b/aindex 5ad28e2..5c06d49 100644--- a/a+++ b/a@@ -1 +1,2 @@ haha+hello[root@zutuanxue git_data]# git status 位于分支 master尚未暂存以备提交的变更： （使用 &quot;git add &lt;文件&gt;...&quot; 更新要提交的内容） （使用 &quot;git checkout -- &lt;文件&gt;...&quot; 丢弃工作区的改动）\t修改： a修改尚未加入提交（使用 &quot;git add&quot; 和/或 &quot;git commit -a&quot;）[root@zutuanxue git_data]# git add a[root@zutuanxue git_data]# git commit -m &quot;add hello&quot;[master 2add75e] add hello 1 file changed, 1 insertion(+)[root@zutuanxue git_data]# git diff######在a文件中添加hello并提交到仓库[root@zutuanxue git_data]# echo haha &gt;&gt; a[root@zutuanxue git_data]# git commit -am &quot;add haha&quot;#也可以使用-am直接提交到仓库，相当于先git add再git commit -m，但必须是跟踪状态的文件，参数a必须在m前面，否则会报错，无法提交。[master f3d6391] add haha 1 file changed, 1 insertion(+)[root@zutuanxue git_data]# git diff[root@zutuanxue git_data]# git status 位于分支 master无文件要提交，干净的工作区[root@zutuanxue git_data]# git log --oneline f3d6391 (HEAD -&gt; master) add haha2add75e add hello git checkout –检出，重写工作区数据 12345678910111213141516171819202122232425[root@zutuanxue git_data]# echo haha &gt;&gt; a[root@zutuanxue git_data]# cat ahellotesttest1123haha[root@zutuanxue git_data]# git status 位于分支 master尚未暂存以备提交的变更： （使用 &quot;git add &lt;文件&gt;...&quot; 更新要提交的内容） （使用 &quot;git checkout -- &lt;文件&gt;...&quot; 丢弃工作区的改动）\t修改： a修改尚未加入提交（使用 &quot;git add&quot; 和/或 &quot;git commit -a&quot;）[root@zutuanxue git_data]# git checkout -- a[root@zutuanxue git_data]# git status 位于分支 master无文件要提交，干净的工作区[root@zutuanxue git_data]# cat ahellotesttest1123 git reset HEAD本地仓库覆盖暂存区域 12345678910111213141516171819[root@zutuanxue git_data]# echo &quot;&quot; &gt; a\t#将a的内容清空[root@zutuanxue git_data]# git add a\t#提交到暂存区[root@zutuanxue git_data]# git commit -m &quot;test head&quot;\t#提交到仓库[master dd7925f] test head 1 file changed, 1 insertion(+), 1 deletion(-)[root@zutuanxue git_data]# echo haha &gt; a\t#添加内容到a[root@zutuanxue git_data]# git add a\t#提交到暂存区[root@zutuanxue git_data]# git diff a\t#确认没有差异[root@zutuanxue git_data]# git reset HEAD a\t#用本地仓库的数据将暂存区数据覆盖重置后取消暂存的变更：M\ta[root@zutuanxue git_data]# git diff a\t#比较工作区和暂存区的数据差异diff --git a/a b/aindex 8b13789..5ad28e2 100644--- a/a+++ b/a@@ -1 +1 @@-+haha git reset –hard 哈希头名Git服务程序中有一个叫做HEAD的版本指针，当用户申请还原数据时，其实就是将HEAD指针指向到某个特定的提交版本，但是因为Git是分布式版本控制系统，为了避免历史记录冲突，故使用了SHA‐1计算出十六进制的哈希字串来区分每个提交版本，另外默认的HEAD版本指针会指向到最近的一次提交版本记录，，注意恢复版本后代表的是在这个版本之前的内容全在（包括工作目录和暂存），本版本之后的都没了 12345678910111213141516171819202122232425262728293031323334[root@zutuanxue git_data]# git log --oneline f3d6391 (HEAD -&gt; master) add haha2add75e add helloff77333 aaadd7925f test heade2e2131 head test644d678 test head326e57a v2 a8f01c62 version2 aa714e37 a47a267c a.txt6ac34be a[root@zutuanxue git_data]# git reset --hard e2e2HEAD 现在位于 e2e2131 head test[root@zutuanxue git_data]# git log --oneline 2add75e (HEAD -&gt; master) add helloff77333 aaadd7925f test heade2e2131 head test644d678 test head326e57a v2 a8f01c62 version2 aa714e37 a47a267c a.txt6ac34be a[root@zutuanxue git_data]# cat atest#git reset --mixed：此为默认方式，不带任何参数的git reset，即是这种方式，移动head指针，改变暂存区内容，但不会改变工作区#git reset --soft：回退到某个版本，仅移动当前Head指针，不会改变工作区和暂存区的内容 #git reset --hard：彻底回退到某个版本，head指针、工作区和暂存区内容全部改变--soft用处不是很多；当执行git commit之后想撤回，但还不想覆盖工作区内容时，使用--mixed；当想完全回滚时，使用--hard来覆盖工作区。 git reflog123456789101112131415161718192021222324252627282930313233[root@zutuanxue git_data]# cat a #查看文件内容，发现恢复错了，本来是想恢复到“add haha”这个位置的test[root@zutuanxue git_data]# git log --oneline #使用log查看，发现没有“add haha”的内容了e2e2131 (HEAD -&gt; master) head test644d678 test head326e57a v2 a8f01c62 version2 aa714e37 a47a267c a.txt6ac34be a#原因很简单，因为我们当前的工作版本是历史的一个提交点，这个历史提交点还没有发生过add bbb更新记录，所以当然就看不到了 ，要是想”还原到未来”的历史更新点 ，可以用git reflog命令来查看所有的历史记录[root@zutuanxue git_data]# git reflog # 使用git reflog 可查看总历史内容（注意这里面也是所有的commit之后，也就是放到本地仓后的记录）再结合git reset --hard 哈希头部恢复版本快照 ，所有的数据根本就不可能丢失，随便删除，随便恢复（前提是已提交仓库的的内容）e2e2131 (HEAD -&gt; master) HEAD@&#123;0&#125;: reset: moving to e2e22add75e HEAD@&#123;1&#125;: reset: moving to 2add75ef3d6391 HEAD@&#123;2&#125;: commit: add haha2add75e HEAD@&#123;3&#125;: commit: add helloff77333 HEAD@&#123;4&#125;: commit: aaadd7925f HEAD@&#123;5&#125;: commit: test heade2e2131 (HEAD -&gt; master) HEAD@&#123;6&#125;: commit: head test644d678 HEAD@&#123;7&#125;: commit: test head326e57a HEAD@&#123;8&#125;: commit: v2 a8f01c62 HEAD@&#123;9&#125;: commit: version2 aa714e37 HEAD@&#123;10&#125;: commit: a47a267c HEAD@&#123;11&#125;: commit: a.txt6ac34be HEAD@&#123;12&#125;: commit (initial): a[root@zutuanxue git_data]# git reset --hard f3d6\t#使用reset恢复到“add haha”的版本HEAD 现在位于 f3d6391 add haha[root@zutuanxue git_data]# cat ahahahellohaha","categories":["Linux","CI和CD代码管理平台"]},{"title":"代码版本控制系统","path":"/2023/09/27/CI和CD代码管理平台/代码版本控制系统/","content":"版本控制介绍vcs version control system 版本控制是指对软件开发过程中各种程序代码、配置文件及说明文档等文件变更的管理，是软件配置管理的核心思想之一。版本控制最主要的功能就是记录一个或若干个文件内容变化 ，以便将来查阅特定版本内容，并且记录文件的所有历史变化，随时可恢复到任何一个历史状态。除了记录版本变更外，版本控制的另一个重要功能是并行开发。软件开发往往是多人协同作业，版本控制可以有效地解决版本的同步以及不同开发者之间的开发通信问题，提高协同开发的效率。并行开发中最常见的不同版本软件的错误(Bug)修正问题也可以通过版本控制中分支与合并的方法有效地解决。这就类似于我们玩游戏的存档，或者写论文一样，刚写完的论文是版本1，提交上去不合格，修改之后叫版本2，再修改叫版本3，以此类推，版本控制的工具有很多，从SVN、VSS、CVS、Clearcase到现在使用的比较多的git（注意这个git是本地的库，网络的库是github）等 版本控制系统变迁本地版本控制系统（CVCS） 许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。 这么做唯一 的好处就是简单，但是特别容易犯错。 有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的 文件。为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文 件的历次更新差异。也就是在硬盘上保存补丁集(补丁是指文件修订前后的变化);通过应用所有的补丁，可以重新计算出各个版本的文件内容。 image20200405145626878.png 集中式的版本控制系统 只有一个中央数据仓库 ，如果中央数据仓库挂了或者不可访问 ，所有的使用者无法使用SVN ，无法进行提交或备份文件。本地版本控制 系统也存在类似问题，只要整个项目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。 image20200405145221067.png 分布式的版本控制（DVCS） 在这类系统中，像 Git、Mercurial、Bazaar 以及 Darcs 等，客户端并不只提取最新版本的文件快照， 而是把代码仓库完整地镜像 下来，包括完整的历史记录。 这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。 因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。许多这类系统都可以指定和若干不同的远端代码仓库进行交互。籍此，你就可以在同一个项目中，分 别和不同工作小组的人相互协作。 你可以根据需要设定不同的协作流程，比如层次模型式的工作流，而这在以 前的集中式系统中是无法实现的。 image20200405150812041.png","categories":["Linux","CI和CD代码管理平台"]},{"title":"git日志","path":"/2023/09/27/CI和CD代码管理平台/git日志/","content":"git log查看历史的git commit快照操作 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@zutuanxue git_data]# git logcommit 326e57a3f87de546c8c17774f174192e280e36fc (HEAD -&gt; master)#哈希字符串的描述信息 HEAD-&gt;master表示当前工作目录所对应的commit，会随着新的commit变化（在个别版本中使用git log不会显示HEAD字样内容，需要使用git log --decorate）Author: aaa &lt;hello@localhost&gt;#作者Date: Mon Apr 6 01:00:27 2020 -0400#时间 v2 a\t#git commit -m添加的描述信息commit 8f01c62906ee7c06489aae7afb42adaa3da90fdcAuthor: aaa &lt;hello@localhost&gt;Date: Mon Apr 6 00:43:55 2020 -0400 version2 acommit a714e37d98c3ab77cfa27f0d0a1ca773c6e4ce57Author: aaa &lt;hello@localhost&gt;Date: Sun Apr 5 06:26:53 2020 -0400 acommit 47a267cc489a93f8fab100d7f945a15209f61240Author: aaa &lt;hello@localhost&gt;Date: Sun Apr 5 06:25:51 2020 -0400 a.txtcommit 6ac34be689eda430ffefc12114fde40759d536b0Author: aaa &lt;hello@localhost&gt;Date: Sun Apr 5 06:21:02 2020 -0400 a[root@zutuanxue git_data]# git log --oneline\t#简单的形式展示内容，只显示哈希标识符的前几位326e57a (HEAD -&gt; master) v2 a8f01c62 version2 aa714e37 a47a267c a.txt6ac34be a############################[root@zutuanxue git_data]# echo 123 &gt;&gt; a[root@zutuanxue git_data]# git add a[root@zutuanxue git_data]# git commit -m &quot;test head&quot;[master 644d678] test head 1 file changed, 1 insertion(+)[root@zutuanxue git_data]# git log --oneline --decorate644d678 (HEAD -&gt; master) test head\t#产生变化326e57a v2 a8f01c62 version2 aa714e37 a47a267c a.txt6ac34be a git log -p12345678910111213141516[root@zutuanxue git_data]# git log -p\t#显示具体变化的内容，调用了git diffcommit 644d6785e33714f8f21a3767e39e2013540e1ee2 (HEAD -&gt; master)Author: aaa &lt;hello@localhost&gt;Date: Mon Apr 6 01:12:02 2020 -0400 test headdiff --git a/a b/aindex b989558..864e0ba 100644--- a/a+++ b/a@@ -1,3 +1,4 @@ hello test test1+123 git log -n123456789101112131415161718[root@zutuanxue git_data]# git log -1\t#只显示最近几条内容commit 644d6785e33714f8f21a3767e39e2013540e1ee2 (HEAD -&gt; master)Author: aaa &lt;hello@localhost&gt;Date: Mon Apr 6 01:12:02 2020 -0400 test head[root@zutuanxue git_data]# git log -2commit 644d6785e33714f8f21a3767e39e2013540e1ee2 (HEAD -&gt; master)Author: aaa &lt;hello@localhost&gt;Date: Mon Apr 6 01:12:02 2020 -0400 test headcommit 326e57a3f87de546c8c17774f174192e280e36fcAuthor: aaa &lt;hello@localhost&gt;Date: Mon Apr 6 01:00:27 2020 -0400 v2 a","categories":["Linux","CI和CD代码管理平台"]},{"title":"代码合并分支","path":"/2023/09/27/CI和CD代码管理平台/代码合并分支/","content":"合并分支 ，A分支上合并另一分支B，则B的所有内容都合并到了A上，如果分支和主干相差太多，合并就会容易报错，所以通常的操作就是分支合并后就删除分支然后再重新创建分支（完全拷贝主支信息）后再进行后续的合并，依次循环 123456789101112131415161718192021222324252627282930[root@zutuanxue git_data]# git branch master* test[root@zutuanxue git_data]# git checkout master切换到分支 &#x27;master&#x27;[root@zutuanxue git_data]# git branch * master test[root@zutuanxue git_data]# git merge test #提示输入描述信息Merge made by the &#x27;recursive&#x27; strategy. test | 0 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 test[root@zutuanxue git_data]# git log --oneline e96f03c (HEAD -&gt; master) Merge branch &#x27;test&#x27;a6302d6 touch master003e619 (test) touch testf3d6391 add haha2add75e add helloff77333 aaadd7925f test heade2e2131 head test644d678 test head326e57a v2 a8f01c62 version2 aa714e37 a47a267c a.txt6ac34be a[root@zutuanxue git_data]# lsa master test 冲突合并 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@zutuanxue git_data]# echo master &gt;&gt; a[root@zutuanxue git_data]# git commit -am &quot;add master to a&quot;[master 801ff9a] add master to a 1 file changed, 1 insertion(+)[root@zutuanxue git_data]# git checkout test 切换到分支 &#x27;test&#x27;[root@zutuanxue git_data]# git branch master* test[root@zutuanxue git_data]# cat ahahahellohaha[root@zutuanxue git_data]# echo test &gt;&gt; a[root@zutuanxue git_data]# git commit -am &quot;add test to a&quot;[test 1cab1b9] add test to a 1 file changed, 1 insertion(+)[root@zutuanxue git_data]# git checkout master\t切换到分支 &#x27;master&#x27;[root@zutuanxue git_data]# git merge -m &quot;master&amp;test&quot; test#提示冲突自动合并 a冲突（内容）：合并冲突于 a自动合并失败，修正冲突然后提交修正的结果。[root@zutuanxue git_data]# cat ahahahellohaha&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADmaster=======test&gt;&gt;&gt;&gt;&gt;&gt;&gt; test[root@zutuanxue git_data]# vim a\t#手动更改冲突内容hahahellohahamastertest[root@zutuanxue git_data]# git commit -am &quot;merge test to master&quot; #再次提交[master d8aeb13] merge test to master[root@zutuanxue git_data]# cat ahahahellohahamastertest[root@zutuanxue git_data]# git log --oneline d8aeb13 (HEAD -&gt; master) merge test to master1cab1b9 (test) add test to a801ff9a add master to ae96f03c Merge branch &#x27;test&#x27;a6302d6 touch master003e619 touch testf3d6391 add haha2add75e add helloff77333 aaa 如果分支和主干相差太多，合并就会容易报错，所以通常的操作就是分支合并后就删除分支然后再重新创建分支（完全拷贝主支信息）后再进行后续的合并，依次循环 删除分支git branch -d1234[root@zutuanxue git_data]# git branch -d test已删除分支 test（曾为 1cab1b9）。[root@zutuanxue git_data]# git branch * master git tag 标签标签也是指向了一次commit提交，是一个里程碑式的标签，回滚打标签直接加标签号，不需要加唯一字符串，不用记唯一字符串，与指针的变动（reset）原理相似，也能通用git reset –hard命令 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@zutuanxue git_data]# git log --oneline d8aeb13 (HEAD -&gt; master) merge test to master1cab1b9 add test to a801ff9a add master to ae96f03c Merge branch &#x27;test&#x27;a6302d6 touch master003e619 touch testf3d6391 add haha2add75e add hello[root@zutuanxue git_data]# git tag -a V1.0 f3d6 -m &quot;add haha to V1.0&quot;#为“add haha”加上一个V1.0的标签 -a指定标签 f3d6为对应的哈希值，-m定义描述信息[root@zutuanxue git_data]# git tag -a V2.0 a630 -m &quot;touch master to V2.0&quot;#为“touch master”定义一个V2.0的标签[root@zutuanxue git_data]# git tag\t#查看已有的标签V1.0V2.0[root@zutuanxue git_data]# git show V1.0\t#查看指定标签的具体内容tag V1.0Tagger: aaa &lt;hello@localhost&gt;Date: Mon Apr 6 04:35:18 2020 -0400add haha to V1.0commit f3d6391659db69a5c9fec610b94dd42f827b39e9 (tag: V1.0)Author: aaa &lt;hello@localhost&gt;Date: Mon Apr 6 02:56:34 2020 -0400 add hahadiff --git a/a b/aindex 5c06d49..ec4f51e 100644--- a/a+++ b/a@@ -1,2 +1,3 @@ haha hello+haha[root@zutuanxue git_data]# git reset --hard V1.0\t#数据回滚到V1.0标签的位置HEAD 现在位于 f3d6391 add haha[root@zutuanxue git_data]# lsa[root@zutuanxue git_data]# cat ahahahellohaha[root@zutuanxue git_data]# git tag -d V2.0\t#删除标签已删除标签 &#x27;V2.0&#x27;（曾为 df79ae8）","categories":["Linux","CI和CD代码管理平台"]},{"title":"将代码传到github公库","path":"/2023/09/27/CI和CD代码管理平台/将代码传到github公库/","content":"github使用Github顾名思义是一个Git版本库的托管服务，是目前全球最大的软件仓库，拥有上百万的开发者用户，也是软件开发和寻找资源的最佳途径 ，Github不仅可以托管各种Git版本仓库，还拥有了更美观的Web界面，您的代码文件可以被任何人克隆 ，使得开发者为开源项贡献代码变得更加容易，当然也可以付费购买私有库，这样高性价比的私有库真的是帮助到了很多团队和企业 1、注册用户 2、配置ssh‐key 3、创建项目 4、克隆项目到本地 5、推送新代码到github 注册地址：https://github.com/ 远程仓库假设1：假设你准备开发一个新功能，但是需要两周才能完成。第一周写了50%，但是在第二周你的电脑粉碎了，并且还没有将上周工作代码存储到其他物理介质上，这样存在丢失的巨大风险 假设2：假设你是一个非常努力的程序员，除了在公司写代码外你还经常把代码用U盘拷贝回家继续工作，如果在通勤过程中U盘不小心丢了，回家之后你就不能工作了 配置Github 创建SSH Key 123456789101112131415161718192021222324[root@zutuanxue ~]# ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:UiiQi1grvAo9YFXFkuSHObA8XI2Jkpk07bUf1hSLXSw songs-wmx@163.comThe key&#x27;s randomart image is:+---[RSA 2048]----+|.o*o++B. .o. || =*==*o+oEo. ||oo+Bo=+o+o. ||=oo..oo+ . ||.+. + S ||..o o ||o . ||. || |+----[SHA256]-----+[root@zutuanxue ~]# cd .ssh/[root@zutuanxue .ssh]# lsid_rsa id_rsa.pub known_hosts .ssh&#x2F;id_rsa：私钥 .ssh&#x2F;id_res.pub：公钥 1[root@zutuanxue .ssh]# cat id_rsa.pub 添加公有秘钥到github image20200407105944844.png image20200407110032231.png image20200407110138300.png 12345[root@zutuanxue .ssh]# ssh git@github.com #测试秘钥是否有效Warning: Permanently added the RSA host key for IP address &#x27;52.74.223.119&#x27; to the list of known hosts.PTY allocation request failed on channel 0Hi gongjunhe! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.Connection to github.com closed. 创建远程仓库返回github首页 image20200407110632002.png image20200407110822461.png 关联本地仓库和远程仓库 在本地仓库中执行命令：git remote add origin 远程仓库地址 1[root@zutuanxue git_data]# git remote add origin git@github.com:gongjunhe/gittest.git image20200407111123617.png 1234567891011121314151617181920212223242526272829303132[root@zutuanxue git_data]# git push -u origin master\t#将本地仓库的内容推送到远程仓库To github.com:gongjunhe/gittest.git ! [rejected] master -&gt; master (non-fast-forward)error: 无法推送一些引用到 &#x27;git@github.com:gongjunhe/gittest.git&#x27;提示：更新被拒绝，因为您当前分支的最新提交落后于其对应的远程分支。提示：再次推送前，先与远程变更合并（如 &#x27;git pull ...&#x27;）。详见提示：&#x27;git push --help&#x27; 中的 &#x27;Note about fast-forwards&#x27; 小节。[root@zutuanxue git_data]# git fetch origin\t#获取远程更新[root@zutuanxue git_data]# git merge origin/master\t#将更新的内容合并到本地fatal: 拒绝合并无关的历史[root@zutuanxue git_data]# git merge origin/master --allow-unrelated-histories Merge made by the &#x27;recursive&#x27; strategy. README.md | 2 ++ 1 file changed, 2 insertions(+) create mode 100644 README.md [root@zutuanxue git_data]# touch c[root@zutuanxue git_data]# git add .[root@zutuanxue git_data]# git commit -m &quot;touch c&quot;[master 2ec770e] touch c 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 c[root@zutuanxue git_data]# git push -u origin master枚举对象: 3, 完成.对象计数中: 100% (3/3), 完成.Delta compression using up to 4 threads.压缩对象中: 100% (2/2), 完成.写入对象中: 100% (2/2), 274 bytes | 274.00 KiB/s, 完成.Total 2 (delta 0), reused 0 (delta 0)To github.com:gongjunhe/gittest.git e5d1eba..2ec770e master -&gt; master分支 &#x27;master&#x27; 设置为跟踪来自 &#x27;origin&#x27; 的远程分支 &#x27;master&#x27;。 image20200407113836692.png 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@zutuanxue git_data]# git log --oneline 2ec770e (HEAD -&gt; master, origin/master) touch ce5d1eba Merge remote-tracking branch &#x27;origin/master&#x27;3964bca touch dc2a2158 Initial commitf3d6391 (tag: V1.0) add haha2add75e add hello[root@zutuanxue git_data]# git reset --hard f3d6HEAD 现在位于 f3d6391 add haha[root@zutuanxue git_data]# lsa[root@zutuanxue git_data]# git log --oneline f3d6391 (HEAD -&gt; master, tag: V1.0) add haha2add75e add helloff77333 aaadd7925f test heade2e2131 head test644d678 test head326e57a v2 a8f01c62 version2 aa714e37 a47a267c a.txt6ac34be a[root@zutuanxue git_data]# git pull origin更新 f3d6391..2ec770eFast-forward README.md | 2 ++ c | 0 d | 0 3 files changed, 2 insertions(+) create mode 100644 README.md create mode 100644 c create mode 100644 d[root@zutuanxue git_data]# lsa c d README.md删除本地仓库与远程仓库的关联在本地仓库中执行命令：git remote rm origin推送本地仓库内容到远程仓库命令：git push origin 分支注意：关联后第一次推到远程库前需要先拉取内容，否则报错拉取远程仓库内容到本地仓库命令：git pull origin 分支存在本地库与远程库不一致情况：git pull origin 分支 --allow-unrelated-histories克隆远程仓库到本地电脑形成本地仓库格式：git clone 远程库地址示例：[root@zutuanxue git_data]# git clone git@github.com:gongjunhe/gittest.git .gitignore文件作用：忽略特殊文件。当工程中有些文件已经确定基本不会改变，所以不用每次推送时都推送，git在推送时会忽略.gitignore文件中列举的内容，可以提升推送效率注意：文件名必须叫做.gitignore，.gitignore和.git文件夹是同一目录；一定要push之前创建.gitignore文件，push之后创建.gitignore不用被git使用，因为git已经开始了版本控制。 1234567891011文件内容说明# 开头的行为注释，不生效支持正则表达（简化的）可以以(/)开头防止递归最后有斜杠(/)的代表要忽略的是目录加感叹号(!)表示取反 支持的正则表达规范 12345678910111213141516171819202122*\t零个或多个字符[]\t匹配括号中的任意字符?\t匹配一字符 [n-m]\t匹配一个范围内的字符，[abc] 匹配 任何一个列在方括号中的字符 (这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c)[^n-m]\t不要匹配一个范围内的字符**\t表示匹配任意中间目录，比如 a/**/z 可以 匹配 a/z 、 a/b/z 或 a/b/c/z 等。例如a/：忽略任何目录下名为a的目录/a.txt：只忽略当前目录下的a.txt，不忽略其它目录下的a.txt *.exe：忽略所有以.exe结尾的文件 !/a/a.jpg：不忽略a目录下的a.jpg文件 a/*.txt：忽略a目录下的以.txt结尾的文件,但不忽略其子目录下包含的以.txt结尾的文件 *.[ao]:\t忽略.a或.o结尾的文件","categories":["Linux","CI和CD代码管理平台"]},{"title":"本地git安装与初始化","path":"/2023/09/27/CI和CD代码管理平台/本地git安装与初始化/","content":"系统环境准备系统：CentOS8 123456789101112[root@zutuanxue ~]# sestatus -vSELinux status: disabled[root@zutuanxue ~]# systemctl status firewalld● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1)[root@zutuanxue ~]# dnf repolist上次元数据过期检查：6:26:44 前，执行于 2020年04月02日 星期四 23时17分37秒。仓库标识 仓库名称 状态app app 4,681os os 1,655 Git安装部署123456789101112131415161718192021222324252627282930[root@zutuanxue ~]# dnf install gitGit 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置:[root@zutuanxue ~]# git config--system\t系统配置文件\t配置内容会存放在/etc/gitconfig中，包含系统上每一个用户及他们的仓库的通用配置，需要管理员权限--global\t全局配置文件\t配置内容会存放在~/.gitconfig或者~/.config/git/gitconfig中--local 本地的配置文件 配置文件存放在git工作目录的.git/config中注：配置文件的优先级local&gt;global&gt;system，可以使用git config -h去获取相关帮助，也可以使用git config --list --show-origin查看所有的配置及所在的文件。[root@zutuanxue ~]# git config --global user.name &quot;hello&quot;#定义git用户[root@zutuanxue ~]# git config --global user.email &quot;hello@localhost#定义git使用的邮箱[root@zutuanxue ~]# git config --global color.ui true#定义语法高亮[root@zutuanxue ~]# git config --listuser.name=hellouser.email=hello@localhostcolor.ui=true#查看定义的信息[root@zutuanxue ~]# pwd/root[root@zutuanxue ~]# cat .gitconfig [user]\tname = hello\temail = hello@localhost[color]\tui = true git初始化初始化工作目录、主要用来初始化一个空的git本地仓库。执行完上面的命令，当前目录下会自动生成.git隐藏文件夹， 123456789101112131415161718192021222324252627282930313233#建立工作目录mkdir git_datacd git_data/#初始化git init#查看工作区状态git status[root@zutuanxue git_data]# pwd/root/git_data[root@zutuanxue git_data]# git status 位于分支 master尚无提交无文件要提交（创建/拷贝文件并使用 &quot;git add&quot; 建立跟踪）隐藏文件介绍：[root@zutuanxue git_data]# pwd/root/git_data[root@zutuanxue git_data]# ls -a. .. .git[root@zutuanxue git_data]# cd .git/[root@zutuanxue .git]# lsbranches config description HEAD hooks info objects refsbranches # 分支目录 config # 保存配置信息 description # 仅供git web程序使用 HEAD # 记录当前的分支指向 hooks # 包含脚本文件 info # 包含一个全局排除文件(exclude文件)，可以将不想被git处理的文件定义到exclude文件中 objects # 存放所有数据内容 ，有info和pack两个子文件夹（实际也就是本地仓库的目录）refs # 这个目录一般包括三个子文件夹，heads、remotes和tags，heads中的文件标识了项目中的各个分支指向的当前哪一个提交记录index # 保存暂存区信息 ，在执行git init的时候 ，这个文件还没有（也就是暂存区的内容）","categories":["Linux","CI和CD代码管理平台"]},{"title":"Grafana报警","path":"/2023/09/27/容器监控-Prometheus/Grafana报警/","content":"接下来设置grafana的报警通道 image20200225174606552.png 点击左侧铃铛图表—notification channels—Add channel image20200225175559736.png Name 部分：填一个名字 Type 部分：选择 webhook 方式 Send on all alerts：勾选后表示默认所有的报警都会通过这个通道发 Include image：勾选后表示在报警的时候同时截图发送，因为目前的报警通知不支持图片，所以这里不用勾选 Disable Resolve Message：勾选后表示当状态从报警中恢复到正常时，不再发送信息，即不告知恢复正常，这里不用勾选 Send reminders：勾选后表示除了状态刚变成报警中时会发报警消息，过后每隔一段时间，如果依然处于报警中的状态，那么还会发一次重复报警 Send reminder every：表示每隔多长时间发送重复报警，这里填默认30分钟 Url：正式服的报警服务器 Http Method：选择 POST 设置完成后点击send test可以去注册账号时使用的邮箱查看报警邮件 image20200225175125898.png 设置好通道并完成验证后，为图表设置报警 onealter7.png 选择图表 点击图表名称的下拉菜单—edit 进入编辑菜单 onealter8.png 选择铃铛图表—create alert 设置图表报警 onealter9.png 这里报警阈值设置的是取CPU Load平均值 因为是实验，所以预警值是0.5方便测试报警 onealter10.png 设置完成后，发现图表上出现了预警线，点击保存吧 接下来在node2上搞大CPU的负载吧 image20200225220905872.png image20200225222218919.png 报警了，完美。","categories":["Linux","容器监控-Prometheus"]},{"title":"Prometheus监控介绍","path":"/2023/09/27/容器监控-Prometheus/Prometheus监控介绍/","content":"Prometheus(由go语言开发)是一套开源的监控&amp;报警&amp;时间序列（按照时间排序）数据库的组合。适合监控docker 容器。因为kubernetes(俗称k8s)的流行带动了prometheus的发展。它可以监控主机，服务，容器 https://prometheus.io/docs/introduction/overview/ 时间序列数据(TimeSeries Data) : 按照时间顺序记录系统、设备状态变化的数据被称为时序数据。这种时序数据，会应用到很多场景, 如: 最常见的就是我们系统中的日志 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据、车流量 传统证券行业实时交易数据 实时运维监控数据，网卡流量图，服务的当前状态，资源的使用情况，比如说，你所监控的内容出现了直线飙升、断崖式下跌、断线，一般都意味着出现了问题，不管是什么时候发生的，都要赶紧查一下出了什么问题 时间序列数据库的主要优点:时间序列数据库主要用于指处理带时间标签（按照时间的顺序变化，即时间序列化）的数据，带时间标签的数据也称为时间序列数据。 性能好 关系型数据库对于大规模数据的处理性能糟糕，这一点可以从I&#x2F;O上有明显的体现。使用NOSQL可以比较好的处理大规模数据，但是依然比不上时间序列数据库。 存储成本低 由于采用的是metrics:key&#x3D;value（标签:关键字&#x3D;值）的数据存储方式，又使用了高效的压缩算法，平均消耗的存储成本在3.5个字节左右 ，所以比较节省存储空间 ，并且能有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列数据，每隔30秒采集一次，保留60天，大概占用200多G的空间（来自官方文件数据) Prometheus的主要特征 多维度数据模型，可以通过多个维度对数据建模，也可以通过多个维度对数据进行查询 灵活的查询语言，由于采用的是新兴的go语言进行开发，在灵活性和速度上都有明显的优势，有兴趣的同学可以去了解一下这门语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉取时间序列数据 也可以通过中间网关支持push模型 这种推，拉监控其实就是我们之前说的主动和被动监控，默认情况下是以pull(拉)的方式，也就是监控主机去找被监控主机将数据要过来，如果要实现push(推)的方式需要中间网关的支持，这只是与zabbix的叫法不同而已 通过服务发现或者静态配置来发现目标服务对象 支持多种多样的图表和界面展示，可以使用第三方的工具来展示内容，如grafana 监控原理 Prometheus Server负责定时在目标上抓取metrics(指标)数据， 每个抓取目标[主机、服务]都需要暴露一个HTTP服务接口用于Prometheus定时抓取。也就是说prometheus会将获取到的监控数据打包成一个可访问的web页面，通过访问指定的url来确定主机的状态 Pull方式的优势是能够自动进行上游监控和水平监控，配置更少，更容易扩展，更灵活，更容易实现高可用。简单来说就是Pull方式可以降低耦合。由于在推送系统中很容易出现因为向监控系统推送数据失败而导致被监控系统瘫痪的问题。因为如果同一时间有很多被监控主机都把数据推送给监控主机的话，就很可能导致监控主机处理不过来，所以通过Pull方式，被采集端无需感知监控系统的存在，完全独立于监控系统之外，这样数据的采集完全由监控系统控制。","categories":["Linux","容器监控-Prometheus"]},{"title":"prometheus+Grafana数据展示","path":"/2023/09/27/容器监控-Prometheus/prometheus+Grafana数据展示/","content":"通过前面课程的学习我们知道了如何部署和设置prometheus，但是这个监控软件的展示界面实在是有些难看，所以我们换一个展示方式Grafana，是一个开源的度量分析和可视化工具（没有监控功能），可以通过将采集的数据分析，查询，然后进行可视化的展示,并能实现报警。 一、部署grafana1.1、grafana安装软件包获得 官方网站: grafana:https://grafana.com/ 软件包安装 1[root@manage01 ~]# dnf -y localinstall grafana-6.6.1-1.x86_64... 服务启动 123456789#服务启动[root@manage01 ~]# systemctl enable grafana-serverCreated symlink from /etc/systemd/system/multi-user.target.wants/grafana-server.service to /usr/lib/systemd/system/grafana-server.service.[root@manage01 ~]# systemctl start grafana-server#验证启动[root@manage01 ~]# lsof -i :3000COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEgrafana-s 17154 grafana 8u IPv6 53939 0t0 TCP *:hbci (LISTEN) grafana启动成功后，可以通过页面访问到grafana页面 在浏览器中输入http://IP或者域名:3000 grafana1.png 要求输入账号密码： admin&#x2F;admin（默认） 当看到这个页面说明grafana已经安装成功并且工作了。 输入账号密码登录时，由于是第一次登录，为了安全要求必须更改密码后才能登录 grafana2.png 输入两次新密码后，点击save即可登录 1.2、grafana页面设置-添加prometheus数据源登录成功后，会发现页面为你提供了一个使用引导线，按着引导我们需要都设置一下，首先第一步就是告诉grafana，他需要展示谁的数据。也就是说数据源是谁 image20200225145354437.png 从图标上可以看出，我们需要设置数据源—展示仪表盘—添加用户这些操作，我们先来完成添加数据源吧。 点击Add data source 增加数据源 image20200225145454014.png 看到主角了把，Prometheus出现了。赶快点击进入下一步吧。 image20200225153536052.png auth部分的设置，主要是与HTTPS配合使用的，如果使用的是https的话就需要证书啊，认证啊这些，需要对此部分内容进行一些配置 按照页面要求填入对应信息即可，一般错误都是因为输入错误造成的。点击Save &amp; Test后保存成功 grafana6.png 我们可以通过左侧导航栏中的齿轮图标下拉菜单中的Data Source看到我们刚才添加的数据源 二、绘制图形2.1 仪表盘管理grafana7.png 添加完数据源后，可以继续添加仪表盘了，这样我们就能以图表的方式看到数据了，继续点击New Dshboard grafana8.png 图上显示你可以增加一个图形到仪表盘，也可以选择一个样式图标 这里任选一个都可以，这个版本不知道作者怎么想的，其实功能都能实现 我选择第一个 Add query grafana9.png 进入页面后，左侧有四个标识，分别是 数据源 image20200225154121203.png 图表 image20200225154146665.png 设置 image20200225154213541.png 告警 image20200225154254663.png 我们按照图标步骤先来设置数据源吧 如上图，在A项中根据需求，匹配你的监控项，如果有多项，可以通过右上角的add query增加，设置完成后就可以设置图表样式了，点击图表 grafana10.png 图表主要说的就是图表的样式，主要的我给大家展示一下 第一个Draw Modes 说的是图表中图的展示方式，有条状 线 点三种，看你喜好了 第二个Mode Options 说的是图表的填充阴影透明度 图上线的粗细 最后一个 是否开启图表堆叠和显示百分比 设置完成后再看看设置图标 该页面主要是设置图表名称和注释的 grafana11_1.png 设置好后我们图表设置就暂时这样，后续告警再细说告警设置。 点击保存后图表就保存好了。 grafana11.png 保存图表时会要求你输入仪表盘名称。这里输入Node2 grafana12.png 确认无误后，点击保存 grafana13.png 仪表盘做好了，同时也看到我们的图形了。 接下来应该设置用户了，这个用户添加，采用的是邀请机制，也就是需要我们生成邀请链接，然后发给对应的用户，然后对方访问相应的链接注册，这样，这个用户才能添加成功 点击Add users按钮 grafana14.png 按照要求添加一个用户 grafana15.png 点击邀请用户 image20200225161454447.png 输入用户名称、用户角色点击邀请 image20200225161653564.png 点击邀请后，需要将邀请链接发给用户或者自己在浏览器中打开确认邀请 我们切换到另一台主机在浏览器中打开 image20200225162223119.png 输入email地址和用户密码第几注册即可成功 image20200225162409462.png 回到使用admin账号登录grafana的主机，刷新后就可以看到新注册的用户，也可以对用户进行删除，修改权限的操作 2.2、grafana设置–添加监控cpu负载的图形点击左边侧栏：➕—Choose Visualization(这次练习这个) 选择graph图表样式 按照要求输入数据项: node_load1 CPU一分钟平均负载 node_load5 CPU五分钟平均负载 node_load15 CPU十五分钟平均负载 注意：如果同时监控了多个机器，图表会显示所有机器的，如果只想显示某个机器的可以使用监控匹配。 输入方法如下： 监控项{instance&#x3D;“被监控机IP:port”} 如下图 image20200225163828382.png 这样就可以显示一台机器了。 2.3、grafana设置—使用模板图表展示MySQL监控mysql监控模板下载https://github.com/percona/grafana-dashboards 模板设置 123456789101112131415161718#在grafana配置文件中添加插件信息[root@manage01 ~]# vim /etc/grafana/grafana.ini [root@manage01 grafana]# tail -3 /etc/grafana/grafana.ini [dashboards.json]enabled = truepath = /var/lib/grafana/dashboards#下载插件[root@manage01 ~]# unzip grafana-dashboards-master.zip #拷贝插件到指定位置[root@manage01 ~]# cd grafana-dashboards-master/[root@manage01 grafana-dashboards-master]# cp -r dashboards /var/lib/grafana/[root@manage01 dashboards]# vim /var/lib/grafana/dashboards/MySQL_Overview.json#搜索pmm-singlestat-panel替换为singlestat#重启生效[root@manage01 grafana]# systemctl restart grafana-server.service web界面导入模板 grafana20.png 选择左侧菜单—➕—Import 选择对应的json文件，然后导入即可 grafana21.png 点击导入后就可以看到图片了 image20200225171755015.png","categories":["Linux","容器监控-Prometheus"]},{"title":"使用prometheus监控一个业务机","path":"/2023/09/27/容器监控-Prometheus/使用prometheus监控一个业务机/","content":"案例要求：通过prometheus监控业务机器192.168.98.202(node2) 一、案例实现a、安装监控客户端12345678910111213141516171819[root@node2 ~]# tar xf node_exporter-0.18.1.linux-amd64.tar.gz -C /usr/local/[root@node2 ~]# cd /usr/local/node_exporter-0.18.1.linux-amd64/[root@node2 node_exporter-0.18.1.linux-amd64]# lsLICENSE node_exporter NOTICE#后台启动[root@node2 node_exporter-0.18.1.linux-amd64]# nohup /usr/local/node_exporter-0.18.1.linux-amd64/node_exporter &amp;[1] 7281[root@node2 node_exporter-0.18.1.linux-amd64]# nohup: 忽略输入并把输出追加到&quot;nohup.out&quot;#业务机器监控插件服务端口[root@node2 node_exporter-0.18.1.linux-amd64]# lsof -i :9100COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEnode_expo 7281 root 3u IPv6 42486 0t0 TCP *:jetdirect (LISTEN)#验证 http://被监控机名称:9100/metricshttp://192.168.98.202:9100/metrics现在我们这台机器上的数据被打包成了一个可以访问的页面，所以我们可以使用浏览器去访问这个页面，看下能否获取到相关的数据，如果能够获取的话就表示没有问题了。 b、在prometheus添加监控信息123456789101112131415161718#被监控主机设置完成之后，需要在prometeus主配置文件中添加被监控机信息[root@node1 prometheus-2.11.1.linux-amd64]# tail -4 prometheus.yml - job_name: &#x27;node2&#x27;\t#定义名称 static_configs:#定义具体配置 - targets: [&#x27;192.168.98.202:9100&#x27;]#定义目标 ####注意缩进 两个空格 #重启服务 [root@node1 prometheus-2.11.1.linux-amd64]# pkill prometheus[root@node1 prometheus-2.11.1.linux-amd64]# ./prometheus --config.file=prometheus.yml &amp;注意：prometheus启动报错**lock DB directory: resource temporarily unavailable&quot;** 原因:prometheus没有正常关闭，锁文件存在rm $prometheus_dir/data/lock 二、测试验证设置完毕看看prometheus页面吧 Prometheus_6.png 查看Status-Targets页面后可以看到被监控机node2(192.168.98.202)已经在监控列表中了，同时可以通过浏览器看看其监控数据。 Prometheus_node2_metrics5.png 在浏览器中输入http://192.168.98.202:9100/metrics 既可以看到数据了","categories":["Linux","容器监控-Prometheus"]},{"title":"使用prometheus监控一个业务","path":"/2023/09/27/容器监控-Prometheus/使用prometheus监控一个业务/","content":"案例需求 通过prometheus监控MariaDB业务 案例分析要监控mysql需要两个条件，一个是系统中有mysql，另一个是要有监控插件，现在监控插件我已经下载好了，所以我们要先安装mysql，然后进行相应的授权，让插件可以获取到所需要的信息，然后再设置相关插件，修改prometheus配置文件 案例实现a、部署mysql业务1234567891011[root@node2 node_exporter-0.18.1.linux-amd64]# dnf -y install mariadb-server mariadb[root@node2 mysqld_exporter-0.12.0.linux-amd64]# systemctl enable mariadbCreated symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service.[root@node2 mysqld_exporter-0.12.0.linux-amd64]# systemctl start mariadb#创建监控用户MariaDB [(none)]&gt; grant select,replication client,process on *.* to &#x27;hello&#x27;@&#x27;localhost&#x27; identified by &#x27;123456&#x27;;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) b、部署监控插件12345678910111213[root@node2 ~]# tar xf mysqld_exporter-0.12.1.linux-amd64.tar.gz -C /usr/local[root@node2 ~]# vim /usr/local/mysqld_exporter-0.12.1.linux-amd64/.my.cnf[root@node2 ~]# cat /usr/local/mysqld_exporter-0.12.1.linux-amd64/.my.cnf[client]user=hellopassword=123456#启动[root@node2 ~]# nohup /usr/local/mysqld_exporter-0.12.1.linux-amd64/mysqld_exporter --config.my-cnf=/usr/local/mysqld_exporter-0.12.1.linux-amd64/.my.cnf &amp;[root@node2 ~]# lsof -i :9104COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEmysqld_ex 7698 root 3u IPv6 46415 0t0 TCP *:peerwire (LISTEN) c、在prometheus主配置文件中添加监控123456789101112#[root@node1 prometheus-2.11.1.linux-amd64]# tail -10 prometheus.yml static_configs: - targets: [&#x27;localhost:9090&#x27;] - job_name: &#x27;node2&#x27; static_configs: - targets: [&#x27;192.168.98.202:9100&#x27;] - job_name: &#x27;mariadb&#x27; static_configs: - targets: [&#x27;192.168.98.202:9104&#x27;] d、重启prometheus服务12[root@node1 prometheus-2.11.1.linux-amd64]# pkill prometheus[root@node1 prometheus-2.11.1.linux-amd64]# ./prometheus --config.file=prometheus.yml &amp; e、通过监控页面查看服务Prometheus_node2_mysql9.png 通过Graph页面看看相关图表吧 Prometheus_node2_mysql8.png 出图了，可以勾选stacked将图形显示为堆叠状。","categories":["Linux","容器监控-Prometheus"]},{"title":"部署prometheus监控平台","path":"/2023/09/27/容器监控-Prometheus/部署prometheus监控平台/","content":"部署prometheus监控平台 安装部署prometheus服务监控端 监控一个远端机器 监控一个服务—mysql 一、软件获得官方网站：https://prometheus.io/download/ 12345prometheus 主程序包：wget https://github.com/prometheus/prometheus/releases/download/v2.11.1/prometheus-2.16.0.linux-amd64.tar.gz远端主机监控插件(类似于zabbix-agent): wget https://github.com/prometheus/node_exporter/releases/download/v0.18.1/node_exporter-1.0.0-rc.0linux-amd64.tar.gzmysql业务监控插件: wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.12.0/mysqld_exporter-0.12.1.linux-amd64.tar.gz 二、实验拓扑图prometheus实验图.png 三、软件安装与启动12345[root@node1 ~]# tar xf prometheus-2.11.1.linux-amd64.tar.gz -C /usr/local/[root@node1 ~]# cd /usr/local/prometheus-2.11.1.linux-amd64/[root@node1 prometheus-2.11.1.linux-amd64]# ./prometheus --config.file=prometheus.yml &amp; 四、启动测试Prometheus_1.png 看到这个页面说明prometheus启动成功了，默认监控了自己，我们来看一下本机的监控状态 Prometheus_2.png 点击 status—targets即可看到监控的机器或者资源 Prometheus_3.png 看到本机了，同时也可以根据提示在浏览器中输入http://IP或者域名:9090/metrics查看监控数据。 123显示监控数据http://192.168.98.201:9090/metrics Prometheus_node1_metrics4.png 如果能看到这些信息就说明监控拿到了数据，拿到数据就可以正常显示了。通过这个URL我们可以知道prometheus把监控的数据都统一存放在一起,然后生成一个web页面,用户可以通过web页面查看相关的数据,这些数据遵循了时序数据库的格式,也就是key&#x3D;value的形式.这些数据就是我们的监控指标,只不过现在我们还没有办法分析,借助图形展示才会更方便阅读 prometheus显示同样也提供了图表，可以通过图表很直观的看到监控项的状态，只不过自带的图形实在是不怎么好看。 通过点击Graph可以显示到下列图表，在搜索栏中输入关键字可以匹配出你想看的监控项 image20200225140312916.png 这里输入的是process_cpu_seconds_total，CPU使用状态表就出现了，注意要点一下图表左上角的Graph按钮，默认是在console按钮页面。 至于报警，这里我们就不介绍了，因为我们不用prometheus自带的报警功能","categories":["Linux","容器监控-Prometheus"]},{"title":"Zabbixweb监测","path":"/2023/09/27/企业级监控系统-Zabbix/Zabbixweb监测/","content":"业务中总会让我们去监控一些URL，比如支付接口中的微信支付，支付宝支付，那么这些URL是怎么监控的呢？可以使用zabbix提供的web监测功能。 web监控一般在生产环境中一般不会配置到模板，一般都是某个业务机由于业务需要去监控本机或者下游某个机器的URL的，所以我这里配置也是针对某个机器来配置的。本实验中我是给node1来配置 实验步骤 给node1安装一个web站点，然后用web监测来监控该web 监控平台配置web监测 a、为node1部署一个站点12345678910#安装服务[root@node1 ~]# dnf -y install httpd#配置页面[root@node1 ~]# echo haha &gt; /var/www/html/index.html#启动服务[root@node1 ~]# systemctl start httpd[root@node1 ~]# systemctl enable httpdCreated symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. b、监控平台配置web监测配置—主机—选择被监控机的web监测 web_check1.png 点击web监测进入本机的web监测管理页面，这里继续选择创建 web场景 web_check2.png 点击 创建web场景 web_check3.png 按要求填写内容后选择步骤 web_check4.png 点击添加后、web方案步骤就设置好了 web_check5.png 继续选择添加，WEB监测就做好了 测试一下，监测—web监测—node1_web，如下图 web_check6.png","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"Zabbix主动监控和被动监控","path":"/2023/09/27/企业级监控系统-Zabbix/Zabbix主动监控和被动监控/","content":"zabbix在监控的时候有两种模式，一种是主动模式，另外一种是被动模式 一、被动模式所谓的被动模式，是以zabbix-agent做为参考对象，也就是表示是server或proxy去找agent拿数据，agent被动的等待指令的下达，让我干什么活，我就去干什么活，这也是zabbix server的默认模式，为什么这么说？我们可以随便找一台主机的查看它的监控项中在名称下面有一个类型，在这里面我们看到的是“zabbix客户端”这个值 image20200215184213711.png 这个值在已经设置好的监控项当中是不能更改的，但是如果我们新建监控项的时候你就会发现，类型里面还有一个叫“zabbix客户端（主动式）”的选项。所以说zabbix默认的都是被动模式 配置方法如下: 1234agent端配置被动模式的参数如下[root@agent1 ~]# vim /etc/zabbix/zabbix_agentd.confServer=10.1.1.13 --IP为zabbix_proxy的ip(如果没有proxy，则直接为zabbix_server的ip)[root@agent1 ~]# systemctl restart zabbix-agent 二、主动模式也就是agent主动把数据传给server或proxy agent主动模式的优点是: 当agent太多的情况下，server或proxy去找这么多agent搜集数据，压力负载过大。用主动模式就可以缓解server或proxy的压力。 但用主动模式的问题是: 监控项当中的类型，也要转为主动式才行，而且很多zabbix自带模板里的监控项不支持转为主动式. 1234agent端配置主动模式的参数如下[root@agent1 ~]# vim /etc/zabbix/zabbix_agentd.confServeractive=10.1.1.13 --IP为zabbix_proxy的ip(如果没有proxy，则直接为zabbix_server的ip)[root@agent1 ~]# systemctl restart zabbix-agent","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"Zabbix用户管理","path":"/2023/09/27/企业级监控系统-Zabbix/Zabbix用户管理/","content":"看过了对本机的监控之后，我们来看一下zabbix的用户，Zabbix有多个默认的用户群组，其中最常用的是Zabbix administrators超级管理员组，其它的几乎没什么用。 安装完zabbix后，已经自带了两个用户 Admin Guests 超级管理员默认账号： Admin，密码：zabbix，这是一个超级管理员。 Guests用户: 使用guest账号，密码为空，只能看到zabbix后台，没有具体内容。我们可以启用来宾账户，使用来宾账户登录到zabbix页面看一下。 用户群组： 群组的增删改查，和权限管理 用户管理： 用户增删改查、用户报警媒介管理、用户权限查看。 要添加一个用户，有三类属性要填写。 属性 描述 用户信息 账号密码、所属组等基本信息 示警媒介 报警相关信息，例如邮箱地址、接受报警时段 许可权 权限，当前用户对哪些主机有权限 zabbix 用户和权限类似windows，用户的有什么权限是组说了算 案例： 创建一个群组和用户 群组创建选择 管理–&gt;用户群组–&gt;创建用户群组 image20200206152939063.png image20200206153014812.png image20200206153034828.png image20200206153102222.png 用户创建 管理–&gt;用户–&gt;创建用户 image20200206153449530.png image20200206153539824.png image20200206153750908.png 最后再点击添加 验证用户是否为只读权限 image20200206154053192.png 由于新建的用户只有只读的权限，所以根本没有“配置”、“管理”字样的选项","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"Zabbix模板管理","path":"/2023/09/27/企业级监控系统-Zabbix/Zabbix模板管理/","content":"模板(template): 对于我们来说是非常重要的，因为它保存了监控项，应用集（给监控项分的组），触发器，图形，聚合图形，自动发现规则，web监测等的一组实体。最主要的是给懒人们提供了方便 我们使用模板可以方便应用到主机，更改模板也会将更改应用到所有链接的主机。避免了每一台主机都需要手动去添加，手动去更改的麻烦 参考: https://www.zabbix.com/documentation/3.4/zh/manual/config/templates 在工作中，我们也可以根据自己公司的实际情况去创建模板，然后将目标应用到公司的服务器上去 一、创建一个模板配置—模板 模板1.png 点击创建模板进入模板菜单 模板2.png 模板创建成功后，需要设置模板中的相关属性 模板3.png 由于我们之前修改过系统自带的模板，我们现在把他还原，也就是把之前我们添加的那个查看用户数量的相关信息都删除，然后再将监控用户数量这个设置添加到自己的模板中 首先找到之前添加的位置 image20200215142907258.png 选择“监控项”把之前我们手动添加的内容并删除 image20200215143108427.png 注意：如果是先删除“监控项”中的记录，那么“触发器”和“图形”中的也会跟着删除，如果是先删除“触发器”和“图形”中的记录，一定要记得回到“监控项”中将记录删除，删除完成之后，找到我们自己的模板选择监控项 image20200215153151362.png 然后我们创建一个监控项 image20200215153833443.png 监控项添加好了我们接着添加图形 点击图形–创建图形 image20200215154057905.png 接下来是触发器–创建触发器 image20200215154323984.png 设置完成之后点击“插入”和“添加” 现在这个模板我就定义完成了，那这个模板怎么使用呢？ 直接点击配置–主机，选择node2 image20200215155458753.png 然后选择模板，取消并清理，选择我们自己创建的模板，点击更新 image20200215155614926.png 然后你就可以看到了 image20200215155638220.png 切换到监测–图形就可以查看到图形内容了 123456789101112131415161718注意：设置完成之后建议重新启动zabbix-proxy和zabbix-agent服务，如果是新的主机，新的主机上要存在相关的脚本和配置文件，相关操作还记得吧mkdir /etc/zabbix/libexeccat/etc/zabbix/libexec/check_user_number.sh#!/bin/bash#Description: 登陆用户监控脚本count=`who |wc -l`echo $countchmod 755 /etc/zabbix/libexec/check_user_number.sh/etc/zabbix/libexec/check_user_number.shvim /etc/zabbix/zabbix_agentd.d/check_user.confUserParameter=check.user,/etc/zabbix/libexec/check_user_number.sh systemctl restart zabbix-agent zabbix-proxy 二、导出一个模板导入导出模式是一个非常好的功能，在一台监控主机上的设置如果想用再其它监控主机而不想从头建立模板的时候，就需要用到这个功能 导入导出可以帮你轻松实现，导出的是xml格式文件. 配置－－主机－－选取要导出的主机（前面打勾）－－下面选择导出 image20200215175546553.png 各位要注意，导出的只是模板，如果想拿到其它主机上使用的话，模板里面所涉及到的key，插件也需要一起保存，所谓的插件就是存放在&#x2F;etc&#x2F;zabbix&#x2F;libexec目录下的内容，而key就是存放在&#x2F;etc&#x2F;zabbix&#x2F;zabbix_agent.d&#x2F;*.conf文件 三、导入一个模板你可以在网上下载好zabbix的监控模板，下载的时候记得把相关的key文件和插件文件一同下载,下载完成之后将对应的key文件和插件拷贝到对应目录 在被监控主机上添加key和插件 1234567[root@node2 ~]# cd znginx-master/[root@node2 znginx-master]# lsReadme.txt userparameter_znginx.conf.sample zbx_export_templates.xml znginx[root@node2 znginx-master]# cp znginx /etc/zabbix/libexec/[root@node2 znginx-master]# cp userparameter_znginx.conf.sample /etc/zabbix/zabbix_agentd.d/[root@node2 znginx-master]# cd /etc/zabbix/zabbix_agentd.d/[root@node2 zabbix_agentd.d]# mv userparameter_znginx.conf.sample userparameter_znginx.conf 配置—模板—导入 image20200215182702772.png 点击导入文件部分的按钮，选择对应的xml文件，点击导入 image20200215182818104.png 返回模板中看下是否有新导入的模板 image20200215182935259.png 然后你就可以正常使用了 注意：在导入过程中记得选择xml文件，而下载模板文件的时候注意版本跨度不要太大，否则模板会无法正常使用。","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"Zabbix分布式监控系统","path":"/2023/09/27/企业级监控系统-Zabbix/Zabbix分布式监控系统/","content":"生产环境中，我们为了实现地域容灾，我们会把服务器放在不同的地域，如果一台zabbix server去监控的话，延迟会高，因为中国的网络由很多运营商在经营，包括联通，移动，电信，教育等等，有玩游戏的同学应该清楚，家里是联通的网络，你去会去电信的服务器么？不会，因为延迟太高。为什么延迟高？因为运营商之间的出口带宽是有限制的，为什么有限制？因为费用不一样，你在便宜的运营商这里办宽带，在贵的运营商这里玩，这种事，换做是谁都不会高兴的。有的同学说我用游戏加速器怎么延迟就低了？使用游戏加速器相当于在大家都从一扇门进出的时候，你发现了一扇窗，而这扇窗就你自己在用，但是当其他人也发现了这扇窗之后呢？所以即便是使用了游戏加速器，在上网高峰时，延迟还是高，只不过没有那么拥挤而已。说完了为什么延迟会高，我们再看一下另外一个问题，这种把服务器放在不同的地域也会造成zabbix server压力也会很大，所以为了避免这种情况，我们的处理方法就是将权利下发，在不同的地域都找一个机器来充当代理，本地的监控工作由代理(proxy)来完成，代理完成收集工作后交给zabbix server，zabbix server在将收到的数据统一整理展示到web。 其实这个例子很简单就是你开了很多分公司，你一个人去管理这些分公司的员工的话，你是管不全面的，所以我们的方法是在每个分公司弄一个负责人，负责人管当地的员工，你管负责人。有问题他们集中向你汇报就好了。这样你就能很顺利的掌控全局了。 架构图 image20200219101305467.png 所以在这个分布式监控的架构中的流程是 1、zabbix server发布指令给代理 2、zabbix-proxy将指令发给被监控主机 3、被监控机将数据汇报给zabbix-proxy 4、zabbix-proxy再交给zabbix-server 5、zabbix-server将数据展示 这样解决了延迟问题，只要保证一条线路畅通就可以了，至于保证一条线路畅通的手段就看你的公司了，有钱可以接专线，没钱可以使用VPN，实在不行可以直接走广域网 实验拓扑图zabbix_proxy.png 在这个架构中我们至少需要三台机器，他们的角色为 zabbix-server： 192.168.98.200 zabbix-proxy： 192.168.98.205 被监控主机： 192.168.98.xxx 实验步骤部署server监控平台 (略) 部署proxy代理平台 被监控机安装zabbix-agent（略） 一、部署zabbix-proxy代理平台1.1、安装zabbix-proxy平台1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#设置yum源[root@proxy ~]# cat &gt;&gt; /etc/yum.repos.d/zabbix.repo &lt;&lt;EOF[zabbix]name=Zabbix Official Repository - $basearchbaseurl=http://repo.zabbix.com/zabbix/4.4/rhel/8/$basearch/#baseurl=https://mirrors.aliyun.com/zabbix/zabbix/4.4/rhel/8/$basearch/enabled=1gpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX-A14FE591[zabbix-non-supported]name=Zabbix Official Repository non-supported - $basearchbaseurl=http://repo.zabbix.com/non-supported/rhel/8/$basearch/enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIXgpgcheck=0#安装软件包[root@proxy ~]# dnf -y install mariadb-server mariadb zabbix-proxy-mysql zabbix-agent############################################################注意：如果无法连接公网的源，可以用浏览器将软件包下载到本地，然后自己创建本地源step1[root@proxy ~]# dnf install createrepo -ystep2[root@proxy ~]# createrepo zabbix/（此路径为存放软件包的路径）step3[root@proxy ~]# vim /etc/yum.repos.d/server.repo [server-app]name=server-appenable=1gpgcheck=0baseurl=file:///mnt/AppStream[server-os]name=server-osenable=1gpgcheck=0baseurl=file:///mnt/BaseOS[zabbix]name=zabbixenabled=1gpgcheck=0baseurl=file:///root/zabbixstep4[root@proxy ~]# dnf -y install mariadb-server mariadb zabbix-proxy-mysql zabbix-agent#############################################################mariadb设置#启动服务[root@proxy ~]# systemctl enable mariadbCreated symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service.[root@proxy ~]# systemctl start mariadb[root@proxy ~]# mysqladmin -u root password &#x27;123456&#x27;#创建数据库 zabbix_proxy及管理用户[root@proxy ~]# mysql -u root -pMariaDB [(none)]&gt; create database zabbix_proxy character set utf8 collate utf8_bin;Query OK, 1 row affected (0.00 sec)MariaDB [(none)]&gt; grant all privileges on zabbix_proxy.* to zabbix@localhost identified by &#x27;123456&#x27;;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; exitBye#导入数据[root@proxy ~]# zcat /usr/share/doc/zabbix-proxy-mysql/schema.sql.gz |mysql -u zabbix -p123456 zabbix_proxy 1.2、修改proxy配置文件1234[root@proxy ~]# egrep &quot;^(Server|Hostname|DBPass)&quot; /etc/zabbix/zabbix_proxy.conf Server=192.168.98.200 #将数据汇报给谁Hostname=zabbix_proxy #自己的名字DBPassword=123456 #数据库密码 1.3、关于proxy的监控问题由于proxy既是监控也是被监控机，所以本机的agent的服务器地址可以设置本机或者server地址，这里建议设置server地址。因为这样zabbix server能够直接监控到本机的状态 1234[root@proxy ~]# egrep &quot;^(Server|Hostname)&quot; /etc/zabbix/zabbix_agentd.conf Server=192.168.98.200ServerActive=192.168.98.200Hostname=proxy 1.4、启动服务1234[root@proxy ~]# systemctl enable zabbix-proxy zabbix-agentCreated symlink from /etc/systemd/system/multi-user.target.wants/zabbix-proxy.service to /usr/lib/systemd/system/zabbix-proxy.service.Created symlink from /etc/systemd/system/multi-user.target.wants/zabbix-agent.service to /usr/lib/systemd/system/zabbix-agent.service.[root@proxy ~]# systemctl start zabbix-proxy zabbix-agent 查看一下日志显示的内容，以及确认下端口是否打开 12345678910111213141516171819202122232425[root@proxy ~]# tail -f /var/log/zabbix/zabbix_proxy.log34539:20200215:133633.989 proxy #13 started [history syncer #2] 34547:20200215:133633.990 proxy #21 started [poller #4] 34548:20200215:133633.996 proxy #22 started [poller #5] 34546:20200215:133633.998 proxy #20 started [poller #3] 34551:20200215:133634.000 proxy #25 started [preprocessing manager #1] 34550:20200215:133634.003 proxy #24 started [icmp pinger #1] 34549:20200215:133634.003 proxy #23 started [unreachable poller #1] 34552:20200215:133635.011 proxy #26 started [preprocessing worker #1] 34554:20200215:133635.014 proxy #28 started [preprocessing worker #3] 34553:20200215:133635.019 proxy #27 started [preprocessing worker #2] 34534:20200215:133641.038 cannot send proxy data to server at &quot;192.168.98.200&quot;: proxy &quot;zabbix_proxy&quot; not found 34534:20200215:133642.041 cannot send proxy data to server at &quot;192.168.98.200&quot;: proxy &quot;zabbix_proxy&quot; not found 34534:20200215:133643.044 cannot send proxy data to server at &quot;192.168.98.200&quot;: proxy &quot;zabbix_proxy&quot; not found 34534:20200215:133644.046 cannot send proxy data to server at &quot;192.168.98.200&quot;: proxy &quot;zabbix_proxy&quot; not found 34534:20200215:133645.049 cannot send proxy data to server at &quot;192.168.98.200&quot;: proxy &quot;zabbix_proxy&quot; not found[root@proxy ~]# netstat -ntlp Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 33953/zabbix_agentd tcp 0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 33960/zabbix_proxy tcp6 0 0 :::10050 :::* LISTEN 33953/zabbix_agentd tcp6 0 0 :::10051 :::* LISTEN 33960/zabbix_proxy tcp6 0 0 :::3306 :::* LISTEN 33219/mysqld 通过查看日志，我们发现日志当中好像有报错，这个我们一会再说，通过查看端口可以发现zabbix_proxy与zabbix_server使用的端口是一样的，所以这两个角色不能配置在一台主机上 1.5、监控平台设置刚才我们在查看日志的时候发现日志中好像有错误提示，这个提示产生的原因就是服务端不认这个代理，代理给服务端发数据，服务端不要，所以我们要告诉服务端，它的代理是谁 管理—agent代理程序 zabbixproxy1.png 选择 创建代理 进入代理设置模式 zabbixproxy2.png 设置代理名称:一定要和proxy配置文件中的Hostname一致 设置代理模式：主动 1）proxy主动模式 zabbix_proxy主动发数据给zabbix_server(proxy的默认模式) 12# vim /etc/zabbix/zabbix_proxy.confProxyMode=0 --此参数为0表示proxy主动模式 2）proxy被动模式 zabbix_server找zabbix_proxy为收集数据 12# vim /etc/zabbix/zabbix_proxy.confProxyMode=1 --此参数为1表示proxy主动模式 警告 123为了避免服务端不识别代理或者其它主机的情况，建议在zabbix_server最好给代理名字及其它主机做个解析[root@zabbix ~]# vim /etc/hosts192.168.98.205 proxy zabbix_proxy 二、设置被监控机1234567891011[root@node4 ~]# egrep &quot;^(Server|Hostname)&quot; /etc/zabbix/zabbix_agentd.conf Server=192.168.98.205ServerActive=192.168.98.205Hostname=node4[root@node4 ~]# systemctl restart zabbix-agent[root@node2 ~]# netstat -ntlp Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 7836/zabbix_agentd tcp6 0 0 :::10050 :::* LISTEN 7836/zabbix_agentd 三、验证由于之前配置过自动注册，所以应该在主机列表中能看到就算成功了。 配置—主机 image20200215140100181.png 看到了，node2后面有一个zabbix_proxy 说明该主机走的是代理模式。 如果查看监测–图形时很久不出图，建议分别重启zabbix_proxy和客户端的zabbix-proxy以及zabbix-agent服务","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"Zabbix监控介绍","path":"/2023/09/27/企业级监控系统-Zabbix/Zabbix监控介绍/","content":"在前面的课程中我们已经知道zabbix是一个分布式的监控软件，是一个高度集成的网络监控解决方案,简单来说就是一个监控平台，并且可以提供企业级的开源(免费)分布式监控解决方案,由一个国外的团队持续维护更新,软件可以自由下载使用,运作团队靠提供收费的技术支持赢利。它支持分布式监控，使用简单方便，比nagios更加容易上手，又拥有cacti那样支持数据持久化保存。Zabbix 通过 C&#x2F;S 模式采集数据,通过 B&#x2F;S 模式在 web 端展示和配置。 官方下载地址：https://www.zabbix.com image20200215233224237.png LTS&#x3D;Long Term Support 长期支持 zabbix将为客户提供5年的支持服务。前三年完全支持与后两年有限制支持。前三年包括一般、关键、安全性问题解决，后两年包括关键、安全性问题解决。超出时间不提供技术支持服务。然而标准版，只提供6+1月支持。zabbix LTS与zabbix标准发行版本的生命周期区别，普通版本6个月开发发行，支持6个月无限制支持，外加一个月有限制支持。然后LTS版本1.5年开发发行，3年无限制支持，2年有限制支持。 监控原理 123zabbix-server平台根据监控项发指令给zabbix-agentzabbix-agent执行key对应的脚本，并把值返回给zabbix-serverzabbix-server接收数据并绘图 1、user—&gt;web—&gt;zabbix-server[监控平台] 用户通过web界面对zabbix监控平台进行操作 2、zabbix-server[监控平台]—&gt;监控插件[被监控机]执行 zabbix监控平台会执行任务，也就是调用对应的插件在被监控主机上执行(告诉被监控机去执行xx插件) 3、监控插件[被监控机]执行–&gt;zabbix-server 被监控机执行完成后将结果反馈给zabbix-server 4、zabbix-server—&gt;zabbix-web—&gt;user zabbix-server通过web界面展现，最终用户查看到相应信息 监控主机和被监控主机是如何通信的？ zabbix-server—zabbix-agent 在被监控主机上安装一个zabbix-agent软件包，所有的动作都由agent去执行，并将结果反馈给server snmp协议 简单网络管理协议 缺点是无法自定义监控","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"Zabbix监控图像展示","path":"/2023/09/27/企业级监控系统-Zabbix/Zabbix监控图像展示/","content":"一、聚合图形设置方法通过聚合图形可以将你感兴趣的几个图形放在一个页面，方便查看 将多个图形聚合到一个页面聚合图形1.png 点击 创建聚合图形 聚合图形2.png 这里设置的是聚合图形页面的名字 页面的格式 几行几列 聚合图形3.png 编辑聚合图形页面，放置需要放置的图形 自定义监控监控项4.png 聚合图形创建成功了 二、幻灯片轮询播放聚合图形我们还可以通过幻灯片的方式，让过个聚合图形轮动展示 幻灯片创建方法 监测—聚合图形 ppt1.png 右上角选择 幻灯片演示，点击创建幻灯片播放 ppt2.png 给幻灯片起个名称 定义幻灯片内的聚合页面切换时间 添加聚合页面 配置完成后选择添加 测试一下，看看是否能播放吧 监测—聚合图形—【右上角】幻灯片演示—PPT1 ppt3.png","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"Zabbix监控报警-onealter插件安装","path":"/2023/09/27/企业级监控系统-Zabbix/Zabbix监控报警-onealter插件安装/","content":"监控报警机制是我们四要素中的一个重要要素，当机器或者监控资源达到阈值，就应该受到管理员关注。但是那么多的机器靠管理员去用眼睛看肯定是不行的，那么怎么能做到管理员只看有问题的机器呢，大家可能都能想到筛选机制吧！对的，我们把有问题的筛选出来就可以了，怎么筛选呢？那就让监控平台根据触发器筛选出来，并通过邮件、微信、钉钉等方式推送给管理员就可以了，做到有的放矢。 关于监控报警有很多种方式，常见的有两种 1）通过本机邮件客户端生成邮件， 通过传输代理发给邮件服务器， 通过邮件投递代理发给管理员。 2）三方报警插件：如 onealter 由于自己配置报警比较复杂，而且邮件容易被拒或当做垃圾邮件。有些专业的报警平台就可以帮你简单实现。 如:onealeart参考:https://www.aiops.com/ onealter报警设置1、 onealter设置访问官网 可以访问http://www.onealert.com/；也可以访问https://www.aiops.com/，注册账户 如果访问的是http://www.onealert.com/，点击免费试用之后注册 image20200213164140494.png 如果访问的是https://www.aiops.com/，直接注册 image20200213193407234.png 注册一个账号并登陆 image20200213164226522.png 登陆后选择CA image20200213164348628.png 点击集成–选择zabbix image20200213164622598.png 可以看到onealter很强大，支持多种监控类型，课程中用的是zabbix，所有我们选项zabbix，然后点击配置。 image20200213164941337.png 应用名称：为这个应用起一个名字 自动关闭时间：如果没有手动关闭告警，多久内自动关闭 点击保存应获取应用Key,为该应用生成一个key image20200213165138456.png key生成成功了，接下来就要在监控平台按照上述的命令执行安装告警插件了。 12345678910111213141516171819202122232425262728#zabbix 监控平台 插件目录[root@zabbix ~]# mkdir -p /usr/local/zabbix-server/share/zabbix/alertscripts[root@zabbix ~]# cd /usr/local/zabbix-server/share/zabbix/alertscripts#下载监控插件[root@zabbix alertscripts]# wget https://download.aiops.com/ca_agent/zabbix/ca_zabbix_release-2.1.0.tar.gz#安装监控插件[root@zabbix alertscripts]# tar -xzf ca_zabbix_release-2.1.0.tar.gz[root@zabbix alertscripts]# cd cloudalert/bin [root@zabbix bin]# bash install.sh 188728c3-c12b-fd2f-f3fd-bf8eb761e919 ./log.sh:行6: /etc/zabbix/libexec/cloudalert/bin/cloudalert.conf: 没有那个文件或目录start to create config file...##输入交互信息Zabbix管理地址: http://192.168.98.200/zabbixZabbix管理员账号: AdminZabbix管理员密码: ...create action success!安装成功.","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"Zabbix监控报警","path":"/2023/09/27/企业级监控系统-Zabbix/Zabbix监控报警/","content":"一、onealter 报警插件设置告警插件安装成功了，接下来我们要设置告警通知了 告警通知有多种，比如：邮件、微信、钉钉、APP、电话、短信等 这里主要给大家介绍：邮件、微信、APP image20200213184629351.png 点击配置—通知策略进入通知页面 在这里可以设置邮件报警，同时右侧也给出了APP下载地址，下载后直接安装登陆即可。 这里我们先把告警状态、告警级别、通知方式、通知人都设置一下。 image20200213194108292.png 好了，我点点添加，全部都设置成功了 添加多个人step 1 为团队添加成员 image20200213201420457.png image20200213200952058.png image20200213194416754.png step 2 登录被邀请的用户邮箱选择接受邀请 image20200213195116050.png 可以选择新用户，也可以选择已有账户，完成注册&#x2F;登录的操作后使用被邀请的用户进入到配置中的团队管理界面，看下能否看到两个用户 image20200213201542249.png 如果不可以看到的话就切换到添加成员的界面，刷新一下就可以看到成员已经添加进来了，并且在团队管理中也可以看到响应的用户 image20200213200626704.png image20200213201741467.png step 3 在配置，通知策略中可以新建通知了 image20200213202254560.png step 4 选择保存之后，就可以看到两个用户都有显示了 image20200213202350511.png 以上就是单人通知和多人通知的设置方式。 接下来我们在设置一下微信报警 点击右上角的人头像—个人中心 image20200213202703413.png 点击绑定微信，使用微信扫描即可绑定。 好了到此我们的告警插件就设置好了，接下来要设置zabbix-server平台。 二、zabbix监控平台调用报警插件案例: 监控平台调用onealter插件，实现报警 点击管理—报警媒介类型 可以看到我们安装好的onealter，我们点击后边的测试，看看是否能正常工作 onealter8.png 12如果测试失败，一般是找不到文件，做个链接[root@manage01 bin]# ln -s /usr/local/zabbix-server/share/zabbix/alertscripts/cloudalert /usr/lib/zabbix/alertscripts/ 再次测试 image20200215220103776.png 输入收件人地址后，点击测试 image20200215220148496.png 如上图，测试成功了。 回到zabbix告警平台点击右上角 人头像—报警媒介—添加收件人 image20200214161626166.png 设置告警收件人，可以设置多个人。 image20200214155900052.png ok，我们zabbix监控平台设置好了。 测试报警之前设置过一个自定义监控，我们监控了登陆用户数量，我们通过同时登陆node1超过三个用户，验证报警。 onealter12.png 可以看到，node1的当前用户量已经超过了预警值 看看邮箱吧，是否收到报警 image20200214155944190.png 当你把多余的用户退出以后还会收到邮件 image20200214161309486.png ok，完美了，如果你下载了APP和微信，看看他们是否也收到了，答案是肯定的。","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"监控自动化-自动添加业务机器","path":"/2023/09/27/企业级监控系统-Zabbix/监控自动化-自动添加业务机器/","content":"现在有这样一个需求，公司采购了100台主机，并且需要监控这100台主机，这个工作量有点大。如果真是一台一台的去弄的话，最近这一两天就什么都别做了，而且效率还低。我们可以把这100台连好网络，在部署系统的过程中让这些主机自动配置并启动好zabbix-agent服务。然后让zabbix server自动添加这100台主机，这样的话不仅提升效率，还能节省下大量时间，这个自动添加有两种方式： 自动发现 自动注册 一、自动发现自动发现是由服务端主动发起，Zabbix Server开启发现进程，定时扫描（非常消耗资源）本网络中符合条件的主机。发现了相应的主机后，通过“动作”来添加监控主机、链接模板。这样我们就可以看到了 教学案例：通过自动发现自动添加业务机器 设置被监控机配置文件 配置自动发现发现主机 配置动作添加主机 1.1、设置被监控机配置文件1234567891011[root@node2 ~]# rpm -Uvh https://repo.zabbix.com/zabbix/4.4/rhel/8/x86_64/zabbix-release-4.4-1.el8.noarch.rpm[root@node2 ~]# dnf -y install zabbix-agent[root@node2 ~]# egrep &quot;^(Server|Hostname)&quot; /etc/zabbix/zabbix_agentd.conf Server=192.168.98.200 #被动模式zabbix服务器的IP ServerActive=192.168.98.200\t#主动模式zabbix服务器的IPHostname=node2[root@node2 ~]# systemctl start zabbix-agent.service [root@node2 ~]# systemctl enable zabbix-agent.service 1.2、配置自动发现-发现机器配置—自动发现—创建发现规则 自动发现1.png 该页面是自动发现管理页面，可以看到系统提供了一个demo，我们不用他提供的，因为网段不对，所以我打算在创建一个 image20200214210142325.png 关于IP范围，我不建议大家写整个网段。因为zabbix-server针对会对全网段做扫描的，那样对zabbix-server压力是很大的。所以大家尽可能写的范围小一点。 更新间隔：代表扫描的频率，这里千万不要设置过小，频繁扫描会造成服务器压力巨大。 键值：定义的是zabbix需要获取到的被监控主机的什么信息，可以按照如下步骤操作，找到zabbix的键值。 image20200214184321212.png 点击完监控项之后，选择右上角的创建监控项，在新的页面中“键值”的位置点击选择，就能看到系统中的键值及作用了。 主机名称和可见的名称这两部分建议选择IP地址，相信大家装系统的时候很少有特意设置主机名的吧？如果选择DNS或者是主机名的话，一会测试结果的时候看到的都是localhost，你根本不知道谁是谁 如上图设置完成后，我们可以验证一下。看看是否真的发现了我们的主机：监测—自动发现 image20200214184647398.png 发现主机了，第一步完成了。 主机是发现了，但是并没有添加到监控队列中，原因是我们还没有设置要求监控平台将符合的机器加入监控队列。如果需要设置，就要通过配置—动作 来完成。 1.3、配置自动发现动作，实现机器自动添加到监控队列为了让发现的机器自动添加到监控队列，需要在zabbix-server监控平台设置动作来完成添加。 具体方法如下： 配置—动作在动作管理页面，该页面中为自动发现提供了一个动作模板，点击这个模板，选择克隆 image20200214202229503.png 然后取个名字，选择已启用，在这个模板中的A,B,C三个条件是与的关系，也就是说满足这三个条件 客户端系统是linux，状态是UP的状态，并可装的是zabbix客户端，你也可以再添加，这三条已经够了 image20200214202648838.png 如果这三个条件都匹配的话，就执行操作，执行什么操作呢？我们点击动作胖点的“操作”按钮，点击“新的”加入两步操作“添加主机”和“启用主机”，加上原来的一共是四步 image20200214203844140.png 所以说自动发现呢分为这么几个步骤，先自动发现主机，然后根据动作去匹配，如果匹配我给出的条件就会执行操作中所定义的工作，从添加主机一直到启用主机 以上是使用原有的模板克隆，现在我们自己新建一个 选择右上角 事件源: 自动发现 然后点击创建动作， 进入自动发现 动作创建页面 自动发现动作4.png image20200214204339859.png 这里要做条件匹配，只有匹配添加的机器才会被执行对应的操作 我这里条件是根据IP地址来匹配的，也就是被监控机的IP地址必须是192.168.98.199-220之间，除此之外还可以和demo动作中的一样，也可以做匹配。 选择操作来定义如何将符合条件的机器加入到监控队列 image20200214204622681.png 注意操作选项，我添加了四个动作： 添加主机 添加到主机群组 链接到模板 启用主机 顺序不能错的，大家想想是不是我们手动添加也是这个顺序啊？ 完成后选择添加，自动发现动作就完成了， 注意关于自动发现主机添加问题可能时间会比较长，实验中需要等一会，过一会儿你就会点击检测–图形就可以查看到自动添加的主机了。同时你也会发现多了一个叫“Discovered hosts”的主机群组，如果不喜欢可以选择管理–一般–其他，然后去调整设置 image20200214211213424.png 二、自动注册自动发现是主动去扫描对应的网段的IP段，带来的问题是比较浪费监控平台资源且不能实时添加，而且遇到不在同一网段的主机显得比较无力，为了解决这个问题，我们换一种方式：自动注册 自动注册是被监控机主动找监控平台，监控平台发现其满足自动注册的条件后就直接根据操作添加到监控队列了。 自动注册不需要配置自动发现，监控平台被动等待被监控机向其发起连接；只需要配置动作即可 自动注册步骤 客户端配置文件设置 设置动作 2.1、客户端配置文件1234[root@node2 ~]# egrep &quot;^(Server|Hostname)&quot; /etc/zabbix/zabbix_agentd.conf Server=192.168.98.200 ServerActive=192.168.98.200Hostname=node2 2.2、设置动作配置—动作 自动注册1.png 事件源: 自动注册 点击创建动作，进入动作菜单 自动注册2.png 这里的条件是根据计算机名来匹配的 自动注册3.png 操作中没有启用主机，默认自动注册就会启用主机，所以操作中没有该选项。 自动发现7.png 配置完成后，点击配置—主机。可以看到主机已经添加成功了。","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"服务器监控介绍","path":"/2023/09/27/企业级监控系统-Zabbix/服务器监控介绍/","content":"一、监控思考监控只能让维护人员查看到主机的状态么? 答: 实时收集数据，通过报警及时发现问题，及时处理，所获取的数据也可以为系统优化提供依据。 监控四要素 如果我想让你监控一个人 你最想知道的是什么? 1、监控谁 监控什么 2、什么时候监控 你现在就去 全天跟着 还是看十分钟就回来? 也就是说是一次性的还是循环的? 3、有问题如何汇报? 管理员还是其他用户 4、监控方法 明着跟着 还是暗地跟着 监控一个设备也是这样的 监控对象 [主机状态 服务 资源 页面，url] 用什么监控 [zabbix-server zabbix-agent] 什么时间监控 [7x24 5x8] 报警给谁 [管理员] 二、主流的开源监控平台分析 mrtg (Multi Router Traffic Grapher)通过snmp协议得到设备的流量信息，并以包含PNG格式的图形的HTML页面方式显示给用户。 cacti (仙人掌) 用php语言实现的一个软件，它的主要功能是用snmp服务获取数据，然后用rrdtool储存和更新数据。现在主要在IDC机房使用，主要用在监控网卡以及交换机路由器的端口，由于出图慢，默认5分钟更新一次（最快可以调成一分钟），而现在很多领域都要求实时的，这个时间就显得有些长，又很难自定义监控，所以很少用它监控除了交换机路由器以外的设备 image20200215230745016.png 官网地址: https://www.cacti.net/ ntop 官网地址: https://www.ntop.org/ nagios 能够跨平台,插件多(监控的东西多),可以自定义–灵活，报警功能强大。或者说nagios就是一个平台，这个平台依靠插件来工作，想要什么样的插件可以用任意语言 自己写，但是由于机器数量越来越多，并且还要求地域性容灾，所以服务器都存放在不同的机房里面，这个时候nagios的不能分布式监控的缺陷就显现出来了。如果想监控这些服务器，就需要在每一个机房都部署一台nagios，然后分别去登录这些服务器查看。 image20200215230831917.png 官网地址: https://www.nagios.org/ centreon 底层使用的就是nagios。是一个nagios整合版软件。界面比nagios要好看很多。 image20200215231227341.png 官网地址: https://www.centreon.com/ ganglia 设计用于测量数以千计的节点,资源消耗非常小。 官网地址: http://ganglia.info/ open-falcon 小米发布的运维监控软件，高效率，高可用。时间较短，用户基数小。 官网地址: http://open-falcon.org/ zabbix 跨平台，支持分布式，可以集中管理，可以画图，能够持久化保存数据，多条件告警，多种API接口，扩展性非常强。使用基数特别大，阿里云使用的就是zabbix。 官网地址: https://www.zabbix.com/ prometheus 是一个基于时间序列的数值数据的容器监控解决方案。 官网地址: https://prometheus.io/ 综合分析：zabbix比较适合公司的监控需求，主要特点如下： 1、丰富的模板 2、可以自定义监控项 3、完善的告警机制** 4、适合分布式监控 5、集中管理系统 6、开源、免费系统","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"监控案例监控一台业务服务器","path":"/2023/09/27/企业级监控系统-Zabbix/监控案例监控一台业务服务器/","content":"案例： 通过监控平台监控一台远端的业务机器 监控远端机器.png 监控方法:zabbix-agent 监控步骤： 1、在被监控机安装zabbix-agent客户端服务 2、修改配置文件指定监控平台 3、启动服务 4、zabbix server监控平台添加 a、部署zabbix-agent监控服务12345678910111213141516171819#设置源[root@node1 ~]# cat /etc/yum.repos.d/zabbix.repo[zabbix]name=Zabbix Official Repository - $basearch#baseurl=http://repo.zabbix.com/zabbix/4.4/rhel/8/$basearch/baseurl=https://mirrors.aliyun.com/zabbix/zabbix/4.4/rhel/8/$basearch/enabled=1gpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX-A14FE591[zabbix-non-supported]name=Zabbix Official Repository non-supported - $basearchbaseurl=http://repo.zabbix.com/non-supported/rhel/8/$basearch/enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIXgpgcheck=0#安装zabbix-agent服务[root@node1 ~]# dnf -y install zabbix-agent b、修改配置文件12[root@node1 ~]# vim /etc/zabbix/zabbix_agentd.conf Server=192.168.98.200 #指定监控平台IP地址 c、启动服务123456#启动服务[root@node1 ~]# systemctl enable zabbix-agentCreated symlink from /etc/systemd/system/multi-user.target.wants/zabbix-agent.service to /usr/lib/systemd/system/zabbix-agent.service.[root@node1 ~]# systemctl start zabbix-agent d、在监控平台添加被监控机器配置——主机——创建主机 zabbix_agent1.png 进入创建主机菜单 zabbix_agent2.png 主机名称：可以随便写，但是要有意义，建议按照城市名称+机房名称+主机IP这样比较好识别 群组：可以理解为业务组 IP地址：填入被监控机的IP地址 模板：链接一个监控模板，里面已经设置好了监控项和图形、报警等 zabbix_agent3.png 选择一个适合的模板，这里我们监控的node1是个linux机器，所以我选择的是Template OS Linux模板，注意一定别忘了点击模板下的添加小按钮，将其链接过来 最后点击下方添加，主机就添加成功了 zabbix_agent4.png 稍等一会，等被监控机的可用性ZBX[因为我们是基于zabbix-agent监控的]变成绿色，我们的任务就完成了 zabbix_agent5.png 看到标记处变成绿色也就放心了。 我们可以通过监控——图形来看看是不是有图形了 zabbix_agent6.png","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"给监控项设定阈值","path":"/2023/09/27/企业级监控系统-Zabbix/给监控项设定阈值/","content":"给监控项设置触发器定义好了图形，我们的监控就完成了，但是怎么判断当前的监控值是否健康呢？那么我们就应该设置一个阈值了，也就是我们常说的警戒线，达到这个警戒线就应该报警通知管理员了。 接下来我来带大家看看如何定义一个阈值来判定监控项的健康情况，我们来学习触发器 选择 配置—模板— Template OS Linux 选择触发器 触发器1.png 点击 触发器后进入触发器管理界面，此页面可以管理所有触发器，我们需要创建一个触发器 触发器2.png 点击 添加触发器，进入触发器设置菜单 触发器3.png OK！触发器设置成功了，我们验证看一下吧 我们通过多个终端同时登陆node1，登陆数量超过3个，我们来看看在监测—仪表盘是否会报警呢 触发器4.png 报警啦，说明我们的触发器设置正确，同时我们看看node1的用户监控[Current_login_user]的那个图形吧 触发器5.png","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"自定义一个监控项","path":"/2023/09/27/企业级监控系统-Zabbix/自定义一个监控项/","content":"在zabbix当中默认给我们提供了很多监控项，但是，有些监控项我们用不到，而有些监控项又没有，那这个时候怎么办呢？ 定义一个监控脚本 定义一个键值对 创建一个监控项 设置一个图形 教学案例： 自定义一个当前登陆用户数量监控脚本 a、自定一个用户数量收集脚本12345678910111213141516#创建一个插件目录，用于以后存放插件[root@zutuanxue ~]# mkdir /etc/zabbix/libexec#编写一个统计用户登陆数量的脚本[root@zutuanxue ~]# cat/etc/zabbix/libexec/check_user_number.sh#!/bin/bash#Description: 登陆用户监控脚本count=`who |wc -l`echo $count#给脚本执行权限[root@zutuanxue ~]# chmod 755 /etc/zabbix/libexec/check_user_number.sh#测试脚本执行[root@zutuanxue ~]# /etc/zabbix/libexec/check_user_number.sh1 b、定义一个键值12345678[root@zutuanxue ~]# vim /etc/zabbix/zabbix_agentd.d/check_user_number.confUserParameter=check.user.number,/etc/zabbix/libexec/check_user_number.sh 插件配置文件的格式 指令=kye,value 按照格式写就可以了#重启生效[root@manage01 zabbix]# systemctl restart zabbix-agent 注意:如果是监控其它主机，请将libexec目录以及zabbix_agentd.d目录下的配置文件都拷贝到远程主机的&#x2F;etc&#x2F;zabbix目录下，并重启zabbix-agent服务 c、新建一个监控项，调用键值12注意：如果是希望所有主机都应用该监控项，那么就在对应的模板中创建监控项、图形 如果只是个别机器，那么就针对主机来设置监控项、图形 给 Template OS Linux 模板添加一个监控项 依次点击 配置——模板 找到Template OS Linux选项，如图 自定义监控监控项1.png 1234567891011应用集： 监控项分组监控项： 监控什么触发器： 监控阈值图形： 监控图形自动发现： 自动添加监控业务WEB监测： 监控WEB站点 点击 监控项，可以看到模板中的所有监控项，该页面可以对模板中的监控项进行管理。 自定义监控监控项2.png 点击 创建监控项 后会弹出一个创建监控项菜单，依次填入对应的信息，就可以创建一个自定义的监控项了。 自定义监控监控项3.png 单击 添加后，监控项就添加成功了。 创建好了监控项不是最终的目的，最终的目的是通过监控项绘制图形，我们可以通过图表能看到信息，接下来我们来为这个监控项创建一个图表吧。 点击当前界面的图形，就可以进入模板的图表管理界面了，如图 自定义监控监控项4.png 图表管理界面可以对图形就行管理，我们这里选择 创建图形。 自定义监控图形5.png 点击创建图形后，就会出现一个创建图形菜单 自定义监控图形62579308.png 根据提示就把图形名称和对应的监控项填入即可。 图形创建成功了，接下来测试一下吧。 我们去找一个应用该模板的机器来看看是否有图形，图形是否有数据。 自定义监控图形7.png","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"部署zabbix监控平台","path":"/2023/09/27/企业级监控系统-Zabbix/部署zabbix监控平台/","content":"通过前面的课程我们知道了zabbix的官网给我们提供了一个安装的指导流程，那我们按照这个流程来部署一下zabbix 部署zabbix监控平台 站点设置 界面介绍与用户管理 一、部署zabbix监控平台a. 安装zabbix下载源 12[root@zutuanxue ~]# rpm -Uvh https://repo.zabbix.com/zabbix/4.4/rhel/8/x86_64/zabbix-release-4.4-1.el8.noarch.rpm[root@zutuanxue ~]# dnf clean all b. 安装Zabbix server，Web前端，agent 12345678910111213141516171819[root@zutuanxue ~]# dnf -y install zabbix-server-mysql zabbix-web-mysql zabbix-apache-conf zabbix-agent##注意：如果国外的官方源下载失败或者速度慢，直接切换阿里的源即可[root@zutuanxue ~]# cat /etc/yum.repos.d/zabbix.repo [zabbix]name=Zabbix Official Repository - $basearchbaseurl=https://mirrors.aliyun.com/zabbix/zabbix/4.4/rhel/8/$basearch/enabled=1gpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX-A14FE591[zabbix-non-supported]name=Zabbix Official Repository non-supported - $basearch baseurl=http://repo.zabbix.com/non-supported/rhel/8/$basearch/enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIXgpgcheck=1## c. 创建初始数据库 123456789101112131415161718192021222324[root@zutuanxue ~]# systemctl restart mariadb.service [root@zutuanxue ~]# mysqladmin -u root password &#x27;123456&#x27;[root@zutuanxue ~]# mysql -u root -pEnter password: Welcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 9Server version: 10.3.11-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type &#x27;help;&#x27; or &#x27;\\h&#x27; for help. Type &#x27;\\c&#x27; to clear the current input statement.MariaDB [(none)]&gt; create database zabbix character set utf8 collate utf8_bin;Query OK, 1 row affected (0.001 sec)MariaDB [(none)]&gt; grant all privileges on zabbix.* to zabbix@localhost identified by &#x27;123456&#x27;;Query OK, 0 rows affected (0.000 sec)MariaDB [(none)]&gt; quitBye导入初始架构和数据[root@zutuanxue ~]# zcat /usr/share/doc/zabbix-server-mysql/create.sql.gz | mysql -uzabbix -p zabbixEnter password: d. 为Zabbix server配置数据库编辑配置文件 &#x2F;etc&#x2F;zabbix&#x2F;zabbix_server.conf 12[root@zutuanxue ~]# vim /etc/zabbix/zabbix_server.conf DBPassword=123456 e. 为Zabbix前端配置PHP编辑配置文件 &#x2F;etc&#x2F;php-fpm.d&#x2F;zabbix.conf 12[root@zutuanxue ~]# vim /etc/php-fpm.d/zabbix.conf php_value[date.timezone] = Asia/Shanghai f. 启动Zabbix server和agent进程启动Zabbix server和agent进程，并为它们设置开机自启： 1234567[root@zutuanxue ~]# systemctl restart zabbix-server zabbix-agent httpd php-fpm[root@zutuanxue ~]# systemctl enable zabbix-server zabbix-agent httpd php-fpm[root@zutuanxue ~]# netstat -ntlp\t#zabbix_server的端口是10051Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 2106/zabbix_server tcp6 0 0 :::10051 :::* LISTEN 2106/zabbix_server g. 配置Zabbix前端连接到新安装的Zabbix前端： http://server_ip_or_name/zabbix 二、站点设置image20200206131850564.png 图：zabbix-web-setup-01 image20200206132044127.png 图：zabbix-web-setup-02 zabbix_web3.png 图：zabbix-web-setup-03 zabbix_web4.png 图：zabbix-web-setup-04 zabbix_web5.png 图：zabbix-web-setup-05 zabbix_web6.png 图：zabbix-web-setup-06 image20200206132343605.png 图：zabbix-web-setup-07 image20200206132450564.png 图：zabbix-web-setup-08 image20200206132720327.png image20200206132751747.png image20200206132813412.png 三、zabbix web界面介绍我们现在已经登录了zabbix的页面，并且设置成了中文，那我们一起来看一下这个设置成中文后的界面 监测—仪表盘 在仪表板当中我们可以查看到很多信息，如果感觉信息不够丰富的话，在右上角可以选择编辑仪表盘，添加新的内容。 可以挨着点一下后面的选项，都是没有内容的，这个我们后面都会说到 监测—图形 在这里可以查看各种类型的图表，比如 image20200206133841844.png 通过右上方的时间选项你可以获取到不同时间范围的信息，这就是可持续化的体现，因为这些数据都存放到数据库里面了，但是不管选择哪个时间范围的，你都会发现有乱码，为什么会有乱码？因为没有相关的字库，所以我们要解决乱码的问题 关于zabbix web设置成中文后图形上的汉字显示乱码问题-解决方案。 12345678复制本地电脑C:\\Windows\\Fonts\\simkai.ttf（楷体）上传到zabbix服务器[root@zutuanxue ~]# cp SIMKAI.TTF /usr/share/fonts/dejavu/[root@zutuanxue ~]# chmod 644 /usr/share/fonts/dejavu/SIMKAI.TTF [root@zutuanxue ~]# cd /etc/alternatives/[root@zutuanxue alternatives]# rm -fr zabbix-web-font[root@zutuanxue alternatives]# ln -s /usr/share/fonts/dejavu/SIMKAI.TTF /etc/alternatives/zabbix-web-font刷新页面 四、监控本机zabbix默认就是对本机进行监控的，但是一定要开启zabbix-agent服务，在对应的界面，我们可以看到，zabbix的监控有四种： ZBX SNMP JMX IPMI image20200216003900217.png 绿色表示正常 红色则表示有问题 如果出现红色了，首先要检查系统中是否安装了zabbix-agent软件包，然后再确认服务是否开启，第三个要检查状态是否已启用。各位可以尝试停止zabbix-agent服务，并且点击一下状态下的已启用按钮改为停用，看一下彻底不好用是什么样的。 1systemctl stop zabbix-agent image20200216004245599.png","categories":["Linux","企业级监控系统-Zabbix"]},{"title":"GPT磁盘管理","path":"/2023/09/27/Linux系统管理宝典/Linux-GPT磁盘管理/","content":"GPT分区工具：gdisk gdisk gdisk分区 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145GPT 128个主分区[root@zutuanxue ~]# gdisk -l /dev/sdc[root@zutuanxue ~]# gdisk -l /dev/sdc 查看sdc信息GPT fdisk (gdisk) version 1.0.3Partition table scan: MBR: MBR only BSD: not present APM: not present GPT: not present ###GPT分区无法使用***************************************************************Found invalid GPT and valid MBR; converting MBR to GPT formatin memory. ***************************************************************Disk /dev/sdc: 41943040 sectors, 20.0 GiBModel: VMware Virtual SSector size (logical/physical): 512/512 bytesDisk identifier (GUID): B228357D-34EC-4E47-BB81-A7312F3BCF8DPartition table holds up to 128 entriesMain partition table begins at sector 2 and ends at sector 33First usable sector is 34, last usable sector is 41943006Partitions will be aligned on 2048-sector boundariesTotal free space is 37748669 sectors (18.0 GiB)Number Start (sector) End (sector) Size Code Name 1 2048 2099199 1024.0 MiB 8300 Linux filesystem 2 2099200 4196351 1024.0 MiB 8300 Linux filesystem将MBR转换成GPT分区[root@zutuanxue ~]# gdisk /dev/sdcGPT fdisk (gdisk) version 1.0.3Partition table scan: MBR: MBR only BSD: not present APM: not present GPT: not present***************************************************************Found invalid GPT and valid MBR; converting MBR to GPT formatin memory. THIS OPERATION IS POTENTIALLY DESTRUCTIVE! Exit bytyping &#x27;q&#x27; if you don&#x27;t want to convert your MBR partitionsto GPT format!***************************************************************Command (? for help): oThis option deletes all partitions and creates a new protective MBR.Proceed? (Y/N): yCommand (? for help): wFinal checks complete. About to write GPT data. THIS WILL OVERWRITE EXISTINGPARTITIONS!!Do you want to proceed? (Y/N): yOK; writing new GUID partition table (GPT) to /dev/sdc.The operation has completed successfully.[root@zutuanxue ~]# gdisk -l /dev/sdcGPT fdisk (gdisk) version 1.0.3Partition table scan: MBR: protective BSD: not present APM: not present GPT: present ###GPT可用了Found valid GPT with protective MBR; using GPT.Disk /dev/sdc: 41943040 sectors, 20.0 GiBModel: VMware Virtual SSector size (logical/physical): 512/512 bytesDisk identifier (GUID): 7CA4232A-4A9E-467D-AADD-BB84DB2126E3Partition table holds up to 128 entriesMain partition table begins at sector 2 and ends at sector 33First usable sector is 34, last usable sector is 41943006Partitions will be aligned on 2048-sector boundariesTotal free space is 41942973 sectors (20.0 GiB)Number Start (sector) End (sector) Size Code Name#再次分区[root@zutuanxue ~]# gdisk /dev/sdcGPT fdisk (gdisk) version 1.0.3Partition table scan: MBR: protective BSD: not present APM: not present GPT: presentFound valid GPT with protective MBR; using GPT.Command (? for help): nPartition number (1-128, default 1): 1First sector (34-41943006, default = 2048) or &#123;+-&#125;size&#123;KMGTP&#125;: Last sector (2048-41943006, default = 41943006) or &#123;+-&#125;size&#123;KMGTP&#125;: +2GCurrent type is &#x27;Linux filesystem&#x27;Hex code or GUID (L to show codes, Enter = 8300): Changed type of partition to &#x27;Linux filesystem&#x27;Command (? for help): pDisk /dev/sdc: 41943040 sectors, 20.0 GiBModel: VMware Virtual SSector size (logical/physical): 512/512 bytesDisk identifier (GUID): 7CA4232A-4A9E-467D-AADD-BB84DB2126E3Partition table holds up to 128 entriesMain partition table begins at sector 2 and ends at sector 33First usable sector is 34, last usable sector is 41943006Partitions will be aligned on 2048-sector boundariesTotal free space is 37748669 sectors (18.0 GiB)Number Start (sector) End (sector) Size Code Name 1 2048 4196351 2.0 GiB 8300 Linux filesystemCommand (? for help): wFinal checks complete. About to write GPT data. THIS WILL OVERWRITE EXISTINGPARTITIONS!!Do you want to proceed? (Y/N): yOK; writing new GUID partition table (GPT) to /dev/sdc.The operation has completed successfully.[root@zutuanxue ~]# partprobe /dev/sdc2.创建文件系统（格式化）CentOS8默认使用xfs[root@zutuanxue ~]# mkfs.xfs -f /dev/sdc13.挂载[root@zutuanxue ~]# mkdir /disk1[root@zutuanxue ~]# mount -t xfs -o ro /dev/sdc1 /disk1 //手动挂载[root@zutuanxue ~]# umount /disk1 ##卸载","categories":["Linux","Linux系统管理宝典"]},{"title":"LVM逻辑卷介绍","path":"/2023/09/27/Linux系统管理宝典/Linux-LVM逻辑卷介绍/","content":"在分区的时候，每个分区应该分多大是令人头疼的，而且随着长时间的运行，分区不管你分多大，都会被数据给占满。当遇到某个分区不够用时管理员可能甚至要备份整个系统、清除硬盘、重新对硬盘分区，然后恢复数据到新分区。 虽然现在有很多动态调整磁盘的工具可以使用，但是它并不能完全解决问题，因为某个分区可能会再次被耗尽；另外一个方面这需要重新引导系统才能实现，对于很多关键的服务器，停机是不可接受的，而且对于添加新硬盘，希望一个能跨越多个硬盘驱动器的文件系统时，分区调整程序就不能解决问题。 因此完美的解决方法应该是在零停机前提下可以自如对文件系统的大小进行调整，可以方便实现文件系统跨越不同磁盘和分区。那么我们可以通过逻辑盘卷管理（LVM，Logical Volume Manager）的方式来非常完美的实现这一功能。 解决思路：将所有可用存储汇集成池，当池中某个分区空间不够时就会从池中继续划分空间给分区，池中空间不够就可以通过加硬盘的方式来解决。 一、逻辑卷介绍逻辑卷（LVM）：它是Linux环境下对磁盘分区进行管理的一种机制，它是建立在物理存储设备之上的一个抽象层，优点在于灵活管理。特点：1、动态在线扩容2、离线裁剪3、数据条带化4、数据镜像 二、名词解释：lvm.png 物理卷 物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备(如RAID)，是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与LVM相关的管理参数 卷组 LVM卷组类似于非LVM系统中的物理硬盘，其由物理卷组成。可以在卷组上创建一个或多个“LVM分区”（逻辑卷），LVM卷组由一个或多个物理卷组成。 逻辑卷 LVM的逻辑卷类似于非LVM系统中的硬盘分区，在逻辑卷之上可以建立文件系统(比如&#x2F;home或者&#x2F;usr等)。 PE 每一个物理卷被划分为称为PE(Physical Extents)的基本单元，具有唯一编号的PE是可以被LVM寻址的最小单元。PE的大小是可配置的，默认为4MB。 LE 逻辑卷也被划分为被称为LE(Logical Extents) 的可被寻址的基本单位。在同一个卷组中，LE的大小和PE是相同的，并且一一对应。 三、逻辑卷使用流程真实的物理设备—-&gt;物理卷（pv）—-&gt;卷组（vg）—-&gt;逻辑卷（lv）——&gt;逻辑卷格式化—-&gt;挂载使用","categories":["Linux","Linux系统管理宝典"]},{"title":"CentOS8启动流程","path":"/2023/09/27/Linux系统管理宝典/Linux-CentOS8启动流程/","content":"一、BIOS与UEFIBIOS Basic Input Output System的缩写，翻译过来就是“基本输入输出系统”，是一种业界标准的固件接口，第一次出现在1975年，是计算机启动时加载的第一个程序，主要功能是检测和设置计算机硬件，引导系统启动。 UEFIUnified Extensible Firmware interface的缩写，翻译过来为统一可扩展固件接口，是BIOS的替代方案，前身是Intel在1998年开始开发的Inter Bot Initiative，后来被命名为可扩展固件接口（Extensible Firmware Interface EFI），2005年交由统一可扩展固件接口论坛，并更名为UEFI UEFI的优势 1、支持硬盘容量更大：相比于传统BIOS+MBR只能支持2048G的硬盘分区和4个主分区相比，UEFI+GPT不会受到硬盘容量大小、分区数量的限制，不过在Windows系统上由于系统的限制，支持最多128个GPT磁盘分区，最大分区18EB，并且GPT格式是没有主分区和逻辑分区这个概念的 2、容错特性：UEFI是模块化构建，比BIOS容错和纠错特性强。 3、鼠标操作：UEFI内置图形驱动，可以提供原生分辨率的图形环境，用户进入后可以使用鼠标调整。 4、扩展性强：UEFI包含一个可编程的开放接口，厂商利用这个接口可以对功能进行扩展，如：备份和诊断 5、支持联网：在不进入操作系统的前提下就可以通过网络进行远程故障诊断 二、CentOS8启动流程现代计算机是软件与硬件的复杂组合，从接通电源开始，到可以登录到系统中，需要大量的软件和硬件的配合，我们一起来了解一下CentOS8的x86_64系统在启动过程中所涉及的任务，虚拟机的流程也是大致相同的，但是某些与硬件相关的步骤是由虚拟机的相关程序在软件中处理的。 1、接通电源 系统固件（UEFI或BIOS初始化）运行开机自检，并初始化部分硬件 2、系统固件搜索可启动设备 启动设备可能是UEFI启动固件中配置的，也可能是按照BIOS中配置的顺序搜索所有磁盘上的主启动记录（MBR） 3、读取启动加载器（boot loader） 系统固件会从MBR中读取启动加载器，然后将控制权交给启动加载器，在CentOS8中启动加载器为GRUB2 4、grub.cfg GRUB2将从&#x2F;boot&#x2F;grub2&#x2F;grub.cfg文件中加载配置并显示一个菜单，在这个菜单中可以选择要启动的内核，我们可以使用grub2-mkconfig命令配合&#x2F;etc&#x2F;grub.d&#x2F;目录和&#x2F;etc&#x2F;default&#x2F;grub文件生成grub.cfg文件。 12345[root@zutuanxue ~]# cd /boot/grub2/[root@zutuanxue grub2]# lsdevice.map fonts grub.cfg grubenv i386-pc[root@zutuanxue grub2]# pwd/boot/grub2 5、initramfs 在选择内核或到达超时时间后，启动加载器会从磁盘加载内核(vmlinuz)和initramfs，并将它们放入内存中，initramfs中包含启动时所有必要硬件的内核模块（驱动）和初始化脚本等，使用lsinitrd和dracut命令配合&#x2F;etc&#x2F;dracut.conf.d&#x2F;目录可以查看和配置initramfs文件 123[root@zutuanxue grub2]# lsinitrd | moreImage: /boot/initramfs-4.18.0-80.el8.x86_64.img: 27M##可以在回显中看到系统的主要目录，包括/etc /usr /dev /lib /lib64等 6、启动加载器放权 启动加载器将控制权交给内核 7、内核初始化 内核会在initramfs中寻找硬件的相关驱动并初始化相关硬件，然后启动&#x2F;usr&#x2F;sbin&#x2F;init（PID&#x3D;1），在CentOS8中&#x2F;sbin&#x2F;init是systemd的链接 1234[root@zutuanxue grub2]# ll /sbin/init lrwxrwxrwx. 1 root root 22 5月 23 2019 /sbin/init -&gt; ../lib/systemd/systemd[root@zutuanxue grub2]# find / -name systemd/usr/lib/systemd/systemd 8、启动initrd.target并挂载 systemd会执行initrd.target包含的所有单元，并将根文件系统挂载到&#x2F;sysroot&#x2F;目录,在initrd.target启动时的依赖单元，会按照&#x2F;etc&#x2F;fstab设置对硬盘进行挂载 9、切换根文件系统 内核将根文件系统从initramfs切换为&#x2F;sysroot（硬盘上的根文件系统），systemd会找到磁盘上安装的systemd并自动重新执行 10、启动相应目标 硬盘上安装的systemd会查找从内核命令行传递的目标或是系统中配置的默认目标并启动对应单元后就可以进入到对应的登录界面。默认目标是&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;default.target， 注意：字符界面： 如果默认目标为multi-user.target（字符界面），systemd会先执行sysinit.target初始化系统之后执行basic.target与getty.target准备基本系统环境和终端，再启动multi-user.target下的相关应用，同时执行&#x2F;etc&#x2F;rc.d&#x2F;rc.local(需要执行权限)与与登录服务（systemd-logind.service），开启登录界面 1234567891011121314151617[root@zutuanxue ~]# systemctl list-dependencies multi-user.target | grep targetmulti-user.target● ├─basic.target● │ ├─paths.target● │ ├─slices.target● │ ├─sockets.target● │ ├─sysinit.target● │ │ ├─cryptsetup.target● │ │ ├─local-fs.target● │ │ └─swap.target● │ └─timers.target● ├─getty.target● ├─nfs-client.target● │ └─remote-fs-pre.target● └─remote-fs.target● └─nfs-client.target● └─remote-fs-pre.target 图形界面： 在multi-user.target的基础上执行graphical.target启动所需要的服务，开启图形界面 123456789101112131415161718[root@zutuanxue ~]# systemctl list-dependencies graphical.target | grep targetgraphical.target● └─multi-user.target● ├─basic.target● │ ├─paths.target● │ ├─slices.target● │ ├─sockets.target● │ ├─sysinit.target● │ │ ├─cryptsetup.target● │ │ ├─local-fs.target● │ │ └─swap.target● │ └─timers.target● ├─getty.target● ├─nfs-client.target● │ └─remote-fs-pre.target● └─remote-fs.target● └─nfs-client.target● └─remote-fs-pre.target 三、运行级别切换与相关配置文件运行级别切换 通过前面的课程我们了解到CentOS8在启动过程中需要判断对应的运行级别，在不同的运行级别中会启动不同的单元，那么运行级别如何切换呢？ 在CentOS8中运行级别的设置涉及到下面几个命令 1234systemctl isolate\t.../init [0-6]\t切换运行级别systemctl\tget-default 查看当前的默认运行级别systemctl set-default ... 设置默认的运行级别runlevel 查看之前的运行级别和当前的运行级别 运行级别对照 123456789[root@localhost system]# cd /usr/lib/systemd/system[root@localhost system]# ll runlevel*.targetrunlevel0.target -&gt; poweroff.targetrunlevel1.target -&gt; rescue.targetrunlevel2.target -&gt; multi-user.targetrunlevel3.target -&gt; multi-user.targetrunlevel4.target -&gt; multi-user.targetrunlevel5.target -&gt; graphical.targetrunlevel6.target -&gt; reboot.target 所以当我们使用init [0-6]切换运行级别的时候系统执行的是systemctl isolate runlevel[0-6].target 123456789101112[root@zutuanxue ~]# runlevel #查看运行级别N 5[root@zutuanxue ~]# init 3\t#切换到字符界面[root@zutuanxue ~]# runlevel #查看运行级别5 3[root@zutuanxue ~]# systemctl isolate graphical.target #切换到图形界面[root@zutuanxue ~]# runlevel 3 5#########emergency.target[root@zutuanxue ~]# systemctl isolate emergency.target image20191224152253190.png 注意：此为紧急模式，用于紧急处理系统的错误，无法使用rescue.target时，可以尝试使用此模式。 四、Boot Loader与GRUB2前面的课程我们了解的CentOS8的启动流程，在这个流程中有一个叫启动加载器，也就是boot loader的工具，如果没有这个boot loader就无法加载内核。在CentOS8中使用的是启动加载器是Grub2，在了解Grub2之前，我们先聊一下boot loader 4.1、Boot Loader的两个阶段我们知道在BIOS或者UEFI加载完成之后，会到MBR中读取boot loader，这个boot loader可以让用户选择加载的内核并且移交系统的控制权限等，而加载内核只能通过boot loader，但是boot loader在MBR中，这个MBR是硬盘的第一个扇区，一个扇区的大小是512字节，boot loader的大小只有446字节，即便是GPT磁盘也没有足够的空间存储boot loader所包含的内容，所以为了避免空间的限制，导致无法引导系统正常启动的问题，Linux将boot loader的工作过程分为了两步。 stage1 执行boot loader的主程序主程序必须安装在MBR或者是启动扇区，由于空间限制，MBR或启动扇区仅存放最小化的boot loader，并不会存放相关的配置文件 stage2 通过主程序加载配置文件通过boot loader的主程序加载所有相关的配置文件，这些配置文件中包括定义文件系统类型的和CentOS8中的grub.cfg文件，而这些文件通常都存放在&#x2F;boot当中 12345678910111213[root@zutuanxue ~]# ll -F /boot/grub2/总用量 32-rw-r--r--. 1 root root 64 12月 13 21:50 device.mapdrwxr-xr-x. 2 root root 4096 12月 13 21:50 fonts/-rw-r--r--. 1 root root 5032 12月 13 21:50 grub.cfg-rw-r--r--. 1 root root 1024 12月 13 21:50 grubenvdrwxr-xr-x. 2 root root 12288 12月 13 21:50 i386-pc/device.map 设备对应文件，用来帮助系统判断磁盘与设备文件的对应关系fonts 开机过程中用到的字体文件grub.cfg grub2的主配置文件grubenv grub环境区块文件大小为1K，用来记录GRUB环境变量i386-PC 针对x86架构的电脑所需要的相关模块，包括电源管理支持，文件系统支持等模块 在这些文件中最重要的就是grub.cfg文件，以及文件系统支持的相关模块 4.2、GRUB2GRUB与LILO目前为止，linux下的启动加载器有两种，一种是LILO另外一种就是GRUB，由于GRUB的功能更强大，支持的文件系统较多，所以越来越多的操作系统使用GRUB做为boot loader，CentOS从7开始使用了功能更为强大的GRUB2 GRUB2的优点 支持更多的文件系统 开机时可以手动调整启动参数 动态更新配置文件，修改完配置文件后不需要重新安装 GRUB2与硬盘 由于grub2的主要任务是从硬盘当中加载内核，所以grub2必须要识别硬盘，但是grub2识别硬盘的方式与linux系统识别的方式还是有些区别的。在Linux系统中，硬盘一般会被识别为类似sda1这种形式，而在grub2中硬盘会统一被识别为hd的设备，排序方式全部是用数字进行排序，而不是用字母加数字的混合形式。这么做的目的是为了定义grub2的查找内核时的顺序。如： 1234hd0,1 搜索第一块硬盘的第一个分区hd0,msdos1\t搜索第一块MBR硬盘的第一个分区hd0,gpt1\t搜索第一块GPT磁盘的第一个分区简单来说，两个数字，第一个数字表示硬盘序号，第二个数字表示分区序号 grub2配置文件 了解了grub2中的硬盘识别方式，我们就可以了解一下grub2的配置文件了，这个文件建议各位不要随意更改 12345678## DO NOT EDIT THIS FILE## It is automatically generated by grub2-mkconfig using templates# from /etc/grub.d and settings from /etc/default/grub#此部分内容提示我们不要编辑这个文件，此文件是有grub2-mkconfig命令自动建立的，相关模板与设置存放在/etc/grub.d/目录以及/etc/default/grub中，也就是说grub.cfg文件的内容会调用/etc/grub.d目录下的内容，如果需要修改的话需要调整/etc/default/grub文件 基本上grub2不希望用户去修改grub.cfg这个文件，如果需要调整的话需要通过修改其它文件并配合grub2-mkconfig命令来生成新的grub.cfg文件，但是各位还是要了解一下这个文件的大致格式 &#x2F;etc&#x2F;default&#x2F;grub与&#x2F;etc&#x2F;grub.d&#x2F;在前面的课程中我们知道了grub2的配置文件是grub.cfg，但是此文件内容比较复杂，且官方不建议我们手动修改，如果需要修改的话需要通过&#x2F;etc&#x2F;default&#x2F;grub文件以及&#x2F;etc&#x2F;grub.d&#x2F;目录内的内容来实现，那我们一起来看一下 &#x2F;etc&#x2F;default&#x2F;grub 123456789101112[root@zutuanxue ~]# vim /etc/default/grubGRUB_TIMEOUT=5\t定义在启动菜单默认的等待时间，单位是秒GRUB_DISTRIBUTOR=&quot;$(sed &#x27;s, release .*$,,g&#x27; /etc/system-release)&quot; 定义获取操作系统名称的方式GRUB_DEFAULT=saved\t定义开机时默认启动的项目，可以是数字，也可以是标题名称，(这个标题就是开机时看到的那个标题），还可以是saved（表示默认启动上次启动成功的操作系统）\tGRUB_DISABLE_SUBMENU=true\t是否隐藏子菜单GRUB_TERMINAL_OUTPUT=&quot;console&quot;\t定义启动时的界面使用哪种终端输出，值包含console，serial，gfxterm，vga_text等GRUB_CMDLINE_LINUX=&quot;resume=/dev/mapper/cl-swap rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rhgb quiet&quot;\t定义额外的启动参数GRUB_DISABLE_RECOVERY=&quot;true&quot;\t是否启用修复模式GRUB_ENABLE_BLSCFG=true\t是否启用bootloader规范修改完成之后需要使用grub2-mkconfig -o /boot/grub2/grub.cfg,重新生成配置文件 &#x2F;etc&#x2F;grub.d&#x2F; 00_header 设置默认参数 00_tuned 额外调整的值 01_menu_auto_hide 与菜单隐藏相关的设置 01_users 与用户相关的设置 10_linux 与内核相关的设置 20_ppc_terminfo 与终端相关的设置 20_linux_xen 与虚拟化相关的设置 30_os-prober 与操作系统检测相关 30_uefi-firmware 与UEFI启动设置相关，需要硬件支持 40_custom&amp;41_custom 自定义设置 注：这些文件会按照数字的顺序由小到大加载","categories":["Linux","Linux系统管理宝典"]},{"title":"VIM文本编辑器","path":"/2023/09/27/Linux系统管理宝典/Linux-VIM文本编辑器/","content":"一、vim使用介绍vim介绍 在linux系统中，大部分配置文件都是ASCII的纯文本形式存放的，所以我们在修改系统设置的时候使用简单的文本编辑软件就可以实现了，如果你使用过windows当中的word的话，那么你可能会感觉linux字符界面的文本编辑工具并不是太好用，毕竟没有图形窗口，看着不会太舒服。但是既然要学习linux，掌握并熟练使用文本编辑工具是必不可少的技能，在linux当中的文本编辑工具有很多，如emacs pico nano joe vi&#x2F;vim 等等 既然有这么多文本编辑工具，为什么要学习vi&#x2F;vim呢？ 为什么要使用vim？ 虽然在linux下的文本编辑器众多，这些工具都有各自的优点，但是有几点是其它编辑工具所不能比拟的 所有的类Unix系统都内建vi，其它的编辑工具则不一定，而vim相当于是vi的升级版 很多软件的编辑界面都会调用vi，如后面提到的crontab、edquota等 vim具有程序编辑能力，可以主动以字体颜色标识语法的正确性，方便代码编写 程序简单，编辑速度非常快 综上所述这是一个老式的文字处理工具，但是功能很齐全，不仅是文本处理工具，还是一个程序编辑工具，就连官方网站也说vim是一个程序开发工具而不是文字处理软件，因为它包含了很多额外的功能，如：多文件编辑，区块复制等，这些功能让我们在进行配置文件修改的时候会更方便。 介绍就到这里，我们来看一下基本使用 二、基本使用由于vi&#x2F;vim是一个全屏幕的文本编辑器，它工作在三种模式下：分别是命令模式、输入模式和末行模式。可以分别从命令模式切换到输入模式和末行模式，也可以从末行模式或输入模式切换到命令模式，但是输入模式与末行模式之间不能互相切换。 1571203454643.png 第一种：命令模式，当我使用“vim myfile”命令打开myfile这个文件时就处于命令模式,屏幕左下角为文件名（myfile），1L 表示本文件有1 行，26C 表示此文件有26 个字符。1,25表示光标当前位置，在此模式下用户可以输入命令来进行文件存盘、移动光标、删除字符、撤消命令和重复命令等操作，还可以设置编辑环境。 1234this is the command mode.~ ~ 表示没有内容 &quot;myfile&quot; 1L, 26C 1,25 全部 第二种：编辑模式，又叫输入模式。在输入模式下，屏幕的左下方会出现INSERT (插入)字样。在输入状态下，用户可以输入文本的内容。 123456this is the command mode.~ ~ ~ ~ -- 插入 -- 1,25 全部 第三种：末行模式。只要在命令模式下输入命令“：”即可进入末行模式。在末行模式下，可以进行保存文件、退出vi、进行查找和替换等操作。 123456this is the command mode.~ ~ ~ ~ :q! 三种模式介绍完了，我们看下vim的使用，这里面我们还是按照三种模式来对vim的使用进行说明 命令模式可以使用的按键说明 光标控制按键 h 或 向左箭头键(←) 光标向左移动一个字符 j 或 向下箭头键(↓) 光标向下移动一个字符 k 或 向上箭头键(↑) 光标向上移动一个字符 l 或 向右箭头键(→) 光标向右移动一个字符 15j&#x2F;15↓ 向下移动15行 [Ctrl] + [f] 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用) [Ctrl] + [b] 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用) [Ctrl] + [d] 屏幕『向下』移动半页 [Ctrl] + [u] 屏幕『向上』移动半页 n 那个 n 表示『数字』，例如 3 。按下数字后再按空格键，光标会向右移动3 个字符。 0 或功能键[Home] 这是数字『 0 』：移动到这一行的最前面字符处 (常用) $ 或功能键[End] 移动到这一行的最后面字符处(常用) H 光标移动到这个屏幕的最上方那一行的第一个字符 M 光标移动到这个屏幕的中央那一行的第一个字符 L 光标移动到这个屏幕的最下方那一行的第一个字符 G 移动到这个文件的最后一行(常用) nG n 为数字。移动到这个文件的第 n 行。可配合 :set nu gg 移动到这个档案的第一行，相当于 1G (常用) n n 为数字。光标向下移动 n 行(常用) 搜索与替换 &#x2F;abc 向光标之下查找一个名称为 abc 的字符串。 (常用) ?abc 向光标之上查找一个字符串名称为 abc 的字符串。 n 这个 n 是英文按键。代表『重复前一个查找的动作』。 N 这个 N 是英文按键。与 n 刚好相反 :n1,n2s&#x2F;abc1&#x2F;abc2&#x2F;g n1 与 n2 为数字。在第 n1 与 n2 行之间查找 abc1 替换为 abc2 :1,$s&#x2F;abc1&#x2F;abc2&#x2F;g 从第一行到最后一行查找 abc1 字符串，并将该字符串替换为 abc2 (常用) :1,$s&#x2F;abc1&#x2F;abc2&#x2F;gc 从第一行到最后一行查找 abc1 字符串，并将该字符串替换为 abc2 ,且在替换前显示提示字符给用户确认 删除与复制粘贴 x, X x 相当于 [del] ， X 相当于 [backspace] (常用) nx n 为数字，连续向后删除 n 个字符。 dd 删除光标所在的那一整行(常用) ndd n 为数字。删除光标所在的向下 n 行(常用) d1G 删除光标所在行到第一行的所有数据 dG 删除光标所在行到最后一行的所有数据 d$ 删除光标所在处，到该行的最后一个字符 d0 那个是数字的 0 ，删除光标所在处，到该行的最前面一个字符 yy 复制光标所在的那一行(常用) nyy n 为数字。(常用) y1G 复制光标所在行到第一行的所有数据 yG 复制光标所在行到最后一行的所有数据 y0 复制光标所在的那个字符到该行行首的所有数据 y$ 复制光标所在的那个字符到该行行尾的所有数据 p, P p 为将已复制的数据在光标下一行贴上，P 则为贴在光标上一行 (常用) J 将光标所在行与下一行的数据结合成同一行 c 重复删除多个数据，例如向下删除 4 行，[ 4cj ]，配合上下左右的按键使用 u 撤销操作。(常用) [Ctrl]+r 重做上一个动作。(常用) 从命令模式进入输入模式 i, I i&#x3D;从当前光标所在处插入， I &#x3D;在当前所在行的第一个非空处开始插入。 (常用) a, A a &#x3D;从当前光标所在的下一个字符处开始插入， A &#x3D;从光标所在行的最后一个字符处开始插入。(常用) o, O o &#x3D;在当前光标所在的下一行处插入新的一行； O &#x3D;在当前光标所在处的上一行插入新的一行。(常用) r, R r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止；(常用) [Esc] 退出输入模式，回到命令模式中(常用) 从命令模式进入到末行模式 :w 保存(常用) :w! 若文件属性为『只读』时，强制保存，是否能保存与权限有关 :q 不保存退出(常用) :q! 强制退出不保存。 :wq 保存退出， :wq! 则为强制保存退出 (常用) ZZ 这是大写的 Z ！若档案没有更动，则不储存离开，若档案已经被更动过，则储存后离开！ :w [filename] 将编辑的数据储存成另一个档案（类似另存新档） :r [filename] 在编辑的数据中，从指定的文件读取数据并加到光标所在行后面 :n1,n2 w [filename] 将 n1 到 n2 的内容保存为 filename 这个档案。 :! command 在系统中执行指定的命令 如 :! ls &#x2F;home vim 环境的变更 :set nu 显示行号 :set nonu 取消行号 三、额外功能区块选择 v 字符选择，选中光标经过的地方 V 选中光标经过的行 [Ctrl]+v 区块选择 y 复制选中的部分 d 删除选中的部分 多文件编辑 :n 编辑下一个文件 :N 编辑上一个文件 :files 列出目前这个 vim 的开启的所有文件 多窗口编辑 :sp&#x2F;:vsp [filename] 开启一个新窗口，如果加 filename， 表示在新窗口编辑指定的文件，否则表示两个窗口为同一个文件(同步显示)。 [ctrl]+w+ j [ctrl]+w+↓ 按键的按法是：先按下 [ctrl] 不放， 再按下 w 后放开所有的按键，然后再按下 j (或向下箭头键)，则光标可移动到下方的窗口。 [ctrl]+w+ k [ctrl]+w+↑ 同上，不过光标移动到上面的窗口。 [ctrl]+w+ q 退出光标所在窗口，也可以 [ctrl]+w+j&#x2F;k 切换窗口后，按下 :q 即可离开， 也可以按下 [ctrl]+w+q 。 环境变量与记录 .viminfo:记录用户的行为，之前编辑过的文件光标在什么位置，在这个文件中进行过什么操作等，自动建立 .vimrc：定义vim的默认设置，如是否显示行号等，需要手动生成 :set nu &#x2F;:set nonu 就是设定与取消行号！ :set hlsearch &#x2F;:set nohlsearch 搜索时是否高亮显示。默认值是 hlsearch :set autoindent :set noautoindent 是否自动缩排？autoindent 就是自动缩排。 :set backup&#x2F;:set nobackup 是否自动备份，一般是 nobackup 的， 如果设定 backup 的话，那么当你更动任何一个档案时，则源文件会被另存成一个档名为 filename~ 的档案。 :set ruler&#x2F;:set noruler 是否显示右下角的一些状态栏说明 :set showmode&#x2F;:set noshowmode 是否显示左下角的状态栏。 :set backspace&#x3D;(012) 一般来说， 如果我们按下 i 进入编辑模式后，可以利用backspace来删除任意字符的。 但是，某些版本则不许如此。这时就可以使用这个设置2 可以删除任意；0 或 1 仅可删除刚刚输入内容 :set all 显示目前所有的环境变量设定值。 :set 显示与系统默认值不同的设置， 用户修改过的 :syntax on :syntax off 是否显示颜色 :set bg&#x3D;dark :set bg&#x3D;light 可用以显示不同的颜色色调，预设是『 light 』。如果你常常发现批注的字体深蓝色实在很不容易看， 那么这里可以设定为 dark 喔！试看看，会有不同的样式呢！ 密码设置与取消 加密 1vim filename---&gt;:X---&gt;输入密码---&gt;保存（否则不加密） 取消密码 1234vim filename---&gt;输入正确密码---&gt;:X---&gt;空密码---&gt;保存vim filename---&gt;:set key= ---&gt;保存注意：不要对系统文件进行加密的操作 vim插件 123456781、虚拟机网卡设置为NAT2、释放IP并重新获取IPdhclient -r ensxxdhclient ensxx3、安装EPELyum源dnf install epel-release -y4、安装vim插件dnf install vim-airline -y vimdiff&amp;vimtutor vimdiff：编辑两个或者更多个文件并显示不同 vimtutor:一条神奇的命令 四、使用中的注意事项由于个别版本的linux默认只安装vi，所以你需要额外安装vim的软件包，如何安装软件包我们会在后续的课程中讲解，另外vim在字符界面下不能输入中文，而在图形界面下能否输入中文则取决于系统中是否安装了中文输入法 字符差异 由于linux和windows的系统差异，它们针对于文件的中的一些特殊符号表示方式也是不同的，比如说用来表示换行的符号等，如 123456[root@zutuanxue ~]# cat -A hello-linux.txt hello$$[root@zutuanxue ~]# cat -A hello-windows.txt hello^M$^M$ 如果这种文件是从windows拷贝到linux的一本小说的话，基本没什么问题，但是如果是一个我们需要执行指定工作的shell脚本就会出现问题，因为linux不认识这种符号的含义，就会导致shell脚本无法执行。所以此时我们就要对这种文件进行处理 1234[root@zutuanxue ~]# unix2dos [-kn] file [newfile]选项与参数：-k ：保留文件原本的 mtime 时间格式-n ：保留旧文件，将转换后的内容输出到新文件，如： dos2unix -n old new","categories":["Linux","Linux系统管理宝典"]},{"title":"linuxacl权限","path":"/2023/09/27/Linux系统管理宝典/Linux-acl权限/","content":"linux的权限非常重要，我们之前所说的几种权限中，但是并不能只针对一个用户或者一个组进行单独设置，而ACL权限可以帮助我们实现这个功能，比如说有一个文件的所有者和所有者组都是a，这个文件的权限是660，我可以让b这个用户可以对文件进行读写的操作，而b这个用户并不属于a组的成员。那我们来看下如何使用 ACL权限的设置和查看如果要使用acl权限，首先要确定你的文件系统支持acl权限,如果再Default mount options字段出现acl字样就意味着你的文件系统支持acl，不过在CentOS8中默认是都支持的。 1234567891011121314[root@zutuanxue test]# tune2fs -l /dev/sda1tune2fs 1.44.3 (10-July-2018)Filesystem volume name: &lt;none&gt;Last mounted on: /bootFilesystem UUID: be03eaec-6474-42ea-8f79-06e7198f5155Filesystem magic number: 0xEF53Filesystem revision #: 1 (dynamic)Filesystem features: has_journal ext_attr resize_inode dir_index filetype needs_recovery extent 64bit flex_bg sparse_super large_file huge_file dir_nlink extra_isize metadata_csumFilesystem flags: signed_directory_hash Default mount options: user_xattr aclFilesystem state: clean... 配置acl权限我们需要使用两个命令一个是setfacl用来设置acl权限，另一个是getfacl用来查看acl权限 setfacl命令：设置文件或文件夹的ACL权限 1234命令选项：-m ：设置acl-x ：删除指定的acl-b ：删除所有的acl getfacl命令：用来查看文件的acl权限 现在我们来看下如何设置 12345678[root@zutuanxue test]# lsfile file1[root@zutuanxue test]# ll file1-rw-r--r-- 1 root root 0 10月 18 02:48 file1[root@zutuanxue test]# setfacl -m u:oracle:rw file1\t为指定的用户配置一个rw的权限[root@zutuanxue test]# setfacl -m u::rwx file1 如果没有指定用户则默认是为该文件的所有者设置[root@zutuanxue test]# ll file1-rwxrw-r--+ 1 root root 0 10月 18 02:48 file1\t所有者权限变成的rwx而且后面多了一个+号 你会发现使用ll（等同于ls -l）命令查看时会发现多了一个+号，这只是提醒我们此文件被设置了acl权限，但是具体是什么样的，我们还需要使用getfacl来查看 123456789[root@zutuanxue test]# getfacl file1# file: file1 文件名# owner: root 所有者# group: root 所有者组user::rwx user：后面是空的，代表的是所有者的权限user:oracle:rw- 我们之前给额外用户设置的权限group::r-- 所有者组的权限mask::rw- 默认的有效权限other::r-- 其他人的权限 以上是我们针对一个额外的用户设置的权限，同理可以设置针对组和其他人的acl权限 为不同用户或组设置不同权限 123456789101112[root@zutuanxue test]# setfacl -m g:oracle:rw file1[root@zutuanxue test]# setfacl -m o:rw file1[root@zutuanxue test]# getfacl file1# file: file1# owner: root# group: rootuser::rwxuser:oracle:rw-group::r--group:oracle:rw-mask::rw-other::rw- 删除指定的acl 1234567891011121314151617181920212223242526272829[root@zutuanxue test]# setfacl -x u:oracle file1 删除用户acl[root@zutuanxue test]# getfacl file1# file: file1# owner: root# group: rootuser::rwxgroup::r--group:oracle:rw-mask::rw-other::rw-[root@zutuanxue test]# setfacl -x g:oracle file1 删除组acl[root@zutuanxue test]# getfacl file1# file: file1# owner: root# group: rootuser::rwxgroup::r--mask::r--other::rw-[root@zutuanxue test]# chmod o=r file1 删除其他人直接使用chmod就可以[root@zutuanxue test]# ll file1-rw-r--r-- 1 root root 0 10月 18 04:21 file1[root@zutuanxue test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-group::r--other::r-- 删除所有acl 1234567891011121314151617181920[root@zutuanxue test]# setfacl -m u:oracle:rw,g:oracle:rw,o:rwx file1[root@zutuanxue test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-user:oracle:rw-group::r--group:oracle:rw-mask::rw-other::rwx[root@zutuanxue test]# setfacl -b file1[root@zutuanxue test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-group::r--other::rwx","categories":["Linux","Linux系统管理宝典"]},{"title":"linuxnmcli命令详解","path":"/2023/09/27/Linux系统管理宝典/Linux-nmcli命令详解/","content":"nmcli connection及常用选项123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@zutuanxue ~]# nmcli connection add 添加delete 删除edit 编辑help 帮助load 加载monitor 监控show 查看clone 克隆down 停用modify 修改reload 重载up 启用 [root@zutuanxue ~]# nmcli connection modify ens37 ipv4.addresses 192.168.18.100/24 ipv4.gateway 192.168.18.1 ipv4.method manual autoconnect yes[root@zutuanxue ~]# nmcli connection down ens37成功停用连接 &quot;ens37&quot;（D-Bus 活动路径：...[root@zutuanxue ~]# nmcli connection up ens37连接已成功激活（D-Bus 活动路径：...[root@zutuanxue ~]# nmcli ens37: 已连接 to ens37 &quot;Intel 82545EM&quot; ethernet (e1000), 00:0C:29:11:47:A1, 硬件, mtu 1500 ip4 默认 inet4 192.168.18.100/24 route4 192.168.18.0/24 route4 0.0.0.0/0 inet6 fe80::4283:ec57:8781:deff/64 route6 fe80::/64 route6 ff00::/8[root@zutuanxue ~]# nmcli connection clone ens37 ens-test1ens37 (077945cb-1d12-4c06-bba3-562426336b67) 已克隆为 ens-test1 (ab1cc22a-21b5-4059-9b3e-b9d14b1084fe)。[root@zutuanxue ~]# nmcli connection NAME UUID TYPE DEVICE ens33 b5ecf... ethernet ens33 ens37 07794... ethernet ens37 ens-test1 ab1cc... ethernet -- ！！！！ 此命令在使用时，可以加设备名称，UUID，配置文件如[root@zutuanxue ~]# nmcli connection down ens37[root@zutuanxue ~]# nmcli connection up ens37[root@zutuanxue ~]# nmcli connection down 077945cb-1d12-4c06-bba3-562426336b67 [root@zutuanxue ~]# nmcli connection up 077945cb-1d12-4c06-bba3-562426336b67 [root@zutuanxue ~]# nmcli connection down /etc/sysconfig/network-scripts/ifcfg-ens37 [root@zutuanxue ~]# nmcli connection up /etc/sysconfig/network-scripts/ifcfg-ens37 这三种方式都可以，其中最后一种是网卡配置文件存放的位置，都会以ifcfg-开头，后面加上设备名 nmcli device及常用选项1234567891011121314151617181920212223242526272829[root@zutuanxue ~]# nmcli device connect 连接disconnect 断开lldp 显示通过lldp协议学习到的相邻设备信息monitor 监控设备set 设置设备status 显示设备状态delete 删除设备 只能删除软件设备help 帮助modify 修改reapply 更新show 查看详细信息wifi 无线网络管理例：[root@zutuanxue ~]# nmcli device modify ens37 +ipv4.addresses 192.168.20.100/24成功重新应用连接到设备 &quot;ens37&quot;。[root@zutuanxue ~]# nmcli ens37: 已连接 to ens37 &quot;Intel 82545EM&quot; ethernet (e1000), 00:0C:29:11:47:A1, 硬件, mtu 1500 ip4 默认 inet4 192.168.20.100/24 inet4 192.168.17.131/24 route4 0.0.0.0/0 route4 192.168.17.0/24 route4 192.168.20.0/24 inet6 fe80::f91c:608a:8381:2cb4/64 route6 fe80::/64 nmcli的其他常用设置123456789101112131415161718192021222324252627282930313233343536373839[root@zutuanxue ~]# nmcli -t 简洁输出\t与-p冲突-p 人性化输出 与-t冲突-c 颜色开关 auto/on/off-f 过滤字段\tall查看所有字段 connection 连接 device 设备general 全局monitor 监控networking 网络radio 无线广播 例：[root@zutuanxue ~]# nmcli -t connection ens33:b5ecf570-543c-4da7-b082-bdc073b56acb:802-3-ethernet:ens33ens37:5b91e453-1130-48ce-a2a1-f6f728e072ed:802-3-ethernet:ens37ens37:077945cb-1d12-4c06-bba3-562426336b67:802-3-ethernet:[root@zutuanxue ~]# nmcli -p connection ======================== 网络管理器连接配置集========================NAME UUID TYPE DEVICE ----------------------------------------------------ens33 b5ec... ethernet ens33 ens37 5b91... ethernet ens37 ens37 0779... ethernet -- [root@zutuanxue ~]# nmcli -f STATE connection STATE 已激活 已激活 -- [root@zutuanxue ~]# nmcli general hostname localhost.localdomain[root@zutuanxue ~]# nmcli general hostname hello[root@zutuanxue ~]# nmcli general hostname hello nmcli的返回值123456789100: 成功-指示操作已成功1: 位置或指定的错误2: 无效的用户输入，错误的nmcli调用3: 超时了（请参阅 --wait 选项）4: 连接激活失败5: 连接停用失败6: 断开设备失败7: 连接删除失败8: 网络管理器没有运行10: 连接、设备或接入点不存在","categories":["Linux","Linux系统管理宝典"]},{"title":"linuxshadow文件","path":"/2023/09/27/Linux系统管理宝典/Linux-shadow文件/","content":"说到用户管理，就不得不提到shadow这个文件，shadow有三个功能： 隐藏密码 扩充密码的功能 提供账号管理工具 隐藏密码： 因为&#x2F;etc&#x2F;passwd和&#x2F;etc&#x2F;group文件的权限必须是0644，这意味着所有的用户都能读取到内容，所以为了安全起见，我们通过shaodw把用户和组的密码分别隐藏在&#x2F;etc&#x2F;shadow,&#x2F;etc&#x2F;gshadow文件中，且这两个文件只有管理员，也就是root能调用 提供账号管理工具 ：我们之前所介绍的用户和组管理的相关命令，都是shadow所提供的工具 扩充密码功能： 这个扩充密码功能就是除了密码之外的额外功能，如，密码的有效期限，设置群组管理员（组长）等，这些都是记录在&#x2F;etc&#x2F;shadow,&#x2F;etc&#x2F;gshadow文件中 &#x2F;etc&#x2F;shadow: 存储用户密码及密码额外功能的文件 123文件内容：root:$6$T52Xvk7zu84.tDXp$nfXcm6LTfUx.ZviEo7Eq1bPjDO...::0:99999:7:::bin:*:18027:0:99999:7::: &#x2F;etc&#x2F;shadow文件的格式与&#x2F;etc&#x2F;passwd类似，也是每一行代表一个账号的数据，使用：进行分隔. 内容详解 12345678910111213141516171819USERNAME:PASSWORD:LAST_CHANGED:MIN_DAYS:MAX_DAYS:WARNNING:EXPIRES:INVALID:RESERVED1、USERNAME：用户账号名称。2、PASSWORD：加密后的密码。3、LAST_CHANGED：密码最后一次修改的日期。4、MIN_DAYS：密码修改的最小间隔天数。5、MAX_DAYS：密码修改的最大天数。6、WARNNING：密码过期前警告的天数。7、EXPIRES：密码过期的日期8、INVALID:\t账号失效日期9、RESERVED：保留位，未定义功能 这里面我们所提到的日期都是从1970年1月1日起经过的天数，所以我们看到的不是日期的格式，而是一组数字，我们接下来看下另一个文件 &#x2F;etc&#x2F;gshadow: 存储组密码及密码额外功能的文件 1234文件内容：root:::bin:::daemon::: 内容详解 123456789GROUPNAME:PASSWORD:ADMINISTRATORS:MEMBERS GROUPNAME:\t组名PASSWORD：\t组密码ADMINISTRATORS： 组长MEMBERS：\t组成员 除此之外用户管理还有一个简单的方法，那就是以root用户身份登录图形界面 1571302990425.png 1571303014802.png cockpit 12# systemctl start cockpithttp://localhost:9090 image20200331143440902.png image20200331143459395.png 管理密码的有效期限 Shadow除了会把密码数据隐藏到其他文件、提供许多账号管理工具外，还允许你为账号或密码设置有效期限，以提高Linux 的安全性。目前的 Shadow 可以设置下列两种期限： 密码过期 一旦超过密码过期日期，用户成功的登录Linux 时，会强迫用户设置一个新的密码。设置完毕后，才会开启用户的 Shell 程序。设置密码过期的目的，在于提高 Linux 的安全性。 账号过期 若超过账号过期日期，Linux 会禁止用户登录系统，即使输入正确的密码，也无法登录。当账号过期时，Linux 会提示用户联系管理员修改账号过期日期。 1Your account has expired; please contact your system administrator 我们可以使用chage命令来查看或调整这些相关的期限 chage命令 123456789101112131415161718[root@zutuanxue ~]# chage -l hello最近一次密码修改时间 ：从不密码过期时间 ：从不密码失效时间 ：从不帐户过期时间 ：从不两次改变密码之间相距的最小天数 ：0两次改变密码之间相距的最大天数 ：99999在密码过期之前警告的天数\t：7chage -m\t设置密码修改的最小天数 -M\t设置密码修改的最大天数 -d\t设置密码最后修改日期 -I\t设置密码过期后，锁定账号的天数 -E\t设置账号过期日期，0=立即过期，-1=永不过期 -W\t设置密码过期前的警告天数 -l\t查看指定用户的相关信息 -h\t帮助 image20200331164400723.png","categories":["Linux","Linux系统管理宝典"]},{"title":"shell数据处理","path":"/2023/09/27/Linux系统管理宝典/Linux-shell数据处理/","content":"一、linux中的常用符号 * 代表任意字符串 ？ 代表任意字符 &#x2F; 代表根目录或作为路径间隔符使用 \\ 转义字符。 &lt;ENTER&gt; 续行符。可以使用续行符将一个命令行分写在多行上 $ 变量值置换，如：$PATH表示环境变量PATH的值 ’ 在’…’中间的字符都会被当做普通字符处理 ‘’ 在’’…’’中间的字符会被当做文字处理并允许变量值置换 &#96; 命令替换，置换`…&#96;中命令的执行结果 &lt; 输入重定向字符 &gt; 输出重定向字符 | 管道字符 &amp; 后台执行字符。在一个命令之后加上字符“&amp;”，该命令就会以后台方式执行 ; 按照顺序执行的多个命令 () 在子Shell中执行命令 {} 在当前Shell中执行命令 ! 执行命令历史记录中的命令 ~ 代表登录用户的宿主目录（自家目录） 二、历史记录linux系统在shell中保留了用户键入的每一个命令的历史记录，并且提供了很多种方法让用户通过历史记录找到曾经使用过的命令，并且调用这个历史记录的命令。 12345678[root@zutuanxue ~]# history 1 ifconfig 2 nmcli connection modify ens33 ipv4.addresses 192.168.2.220/24 ipv4.gateway 192.168.2.1 ipv4.method manual autoconnect yes 3 route -n 4 nmcli connection down ens33 . . . 语法 替换 ！！ 前一个命令 ！n 命令号n ！-n 倒数第n个命令 ！cmd 最后用来启动cmd的命令 与历史记录相关的文件和变量 123456789[root@zutuanxue ~]# echo $HISTFILE/root/.bash_history#用户的历史记录保存的位置[root@zutuanxue ~]# echo $HISTFILESIZE1000#启动时，从历史记录中读取的记录条数[root@zutuanxue ~]# echo $HISTSIZE1000#退出时，被写入历史记录的最大条数 历史记录技巧 12esc+./alt+.\t调用上一条命令的最后一部分内容ctrl+r\t在历史记录中搜索给出关键字的命令 三、标准输入、标准输出、标准错误在linux系统中，大多数时候我们从键盘读取输入，在终端显示输出，而我们在键盘中输入的内容，多数都是执行命令，这些命令属于终端程序，除了终端程序还有图形程序和屏幕程序（如vim），不管是哪一种程序都会涉及到输入，输出，错误，多数情况下，我们在键盘输入信息，在显示器查看信息（正确的信息和错误的信息），这些输入的信息我们称之为标准输入（可以用0表示），输出的信息我们称之为标准输出（可以用1表示），而错误的信息（可以用2表示），我们称之为标准错误。在日常使用中我们除了可以使用键盘输入信息，从显示器读取信息之外，还可以指定程序从键盘以外的地方读取需要输入的内容，也可以让程序将信息输出到显示器以外的地方。 重定向输入和输出 12345678910111213141516171819202122232425262728#重定向输出[root@zutuanxue ~]# mkdir a[root@zutuanxue ~]# cd a[root@zutuanxue a]# mkdir aa ab ac[root@zutuanxue a]# cd aa[root@zutuanxue aa]# touch bb bc bd[root@zutuanxue ~]# ls a/ &gt; test\t[root@zutuanxue ~]# cat testaaabac[root@zutuanxue ~]# ls a/aa/ &gt;&gt; test[root@zutuanxue ~]# cat testaaabacbbbcbd&gt;覆盖&gt;&gt;追加#重定向输入[root@zutuanxue ~]# wc -l test6 hello[root@zutuanxue ~]# wc -l &lt; test 6注意：第一个例子，会输出文件名；第二个不会，因为它仅仅知道从标准输入读取内容。 我们知道标准输入可以用0来表示，标准输出可以用1来表示，标准错误可以用2来表示，而有些时候这些输出的信息中即包含了正确的信息，也包含了错误的信息，如： 1234567891011121314151617181920212223242526272829[root@zutuanxue ~]# ls /etc/rc.d/init.d rc0.d rc1.d rc2.d rc3.d rc4.d rc5.d rc6.d rc.local[root@zutuanxue ~]# head -1 /etc/rc.d/*==&gt; /etc/rc.d/init.d &lt;==head: 读取&#x27;/etc/rc.d/init.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc0.d &lt;==head: 读取&#x27;/etc/rc.d/rc0.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc1.d &lt;==head: 读取&#x27;/etc/rc.d/rc1.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc2.d &lt;==head: 读取&#x27;/etc/rc.d/rc2.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc3.d &lt;==head: 读取&#x27;/etc/rc.d/rc3.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc4.d &lt;==head: 读取&#x27;/etc/rc.d/rc4.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc5.d &lt;==head: 读取&#x27;/etc/rc.d/rc5.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc6.d &lt;==head: 读取&#x27;/etc/rc.d/rc6.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc.local &lt;==#!/bin/bash 我们通过ls命令查看&#x2F;etc&#x2F;rc.d这个目录的时候，我们发现，这个目录中即有目录，也有文件，而当我们使用“head -1”命令去查看文件的第一行内容的时候， 很显然目录是无法查看第一行的，这时就会有报错，当我想把这些信息都写入到一个指定的文件中而不想看到这些内容我该如何去做？ 1234567891011121314151617181920[root@zutuanxue ~]# head -1 /etc/rc.d/* &gt; testhead: 读取&#x27;/etc/rc.d/init.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc0.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc1.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc2.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc3.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc4.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc5.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc6.d&#x27; 时出错: 是一个目录[root@zutuanxue ~]# cat test==&gt; /etc/rc.d/init.d &lt;====&gt; /etc/rc.d/rc0.d &lt;====&gt; /etc/rc.d/rc1.d &lt;====&gt; /etc/rc.d/rc2.d &lt;====&gt; /etc/rc.d/rc3.d &lt;====&gt; /etc/rc.d/rc4.d &lt;====&gt; /etc/rc.d/rc5.d &lt;====&gt; /etc/rc.d/rc6.d &lt;====&gt; /etc/rc.d/rc.local &lt;==#!/bin/bash 我们可以利用之前的&gt;将输出的信息重定向到一个指定的文件，但是仍然会收到错误提示，这是为什么呢？因为在linux当中正确的输出和错误的输出实际上是两种数据流，默认情况下这两种数据流都会在显示器上打印出来，而我们使用的&gt;相当于1&gt;,也就是将正确的信息写入到了test文件中，错误的信息依旧会看到。利用前面的提到0，1，2这三个数字，我们可以这样做 123456789101112131415161718192021[root@zutuanxue ~]# head -1 /etc/rc.d/* &gt; test 2&gt; test.err[root@zutuanxue ~]# cat test==&gt; /etc/rc.d/init.d &lt;====&gt; /etc/rc.d/rc0.d &lt;====&gt; /etc/rc.d/rc1.d &lt;====&gt; /etc/rc.d/rc2.d &lt;====&gt; /etc/rc.d/rc3.d &lt;====&gt; /etc/rc.d/rc4.d &lt;====&gt; /etc/rc.d/rc5.d &lt;====&gt; /etc/rc.d/rc6.d &lt;====&gt; /etc/rc.d/rc.local &lt;==#!/bin/bash[root@zutuanxue ~]# cat test.err head: 读取&#x27;/etc/rc.d/init.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc0.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc1.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc2.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc3.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc4.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc5.d&#x27; 时出错: 是一个目录head: 读取&#x27;/etc/rc.d/rc6.d&#x27; 时出错: 是一个目录 但是这依然是两个文件，能不能将这些信息都写入到一个文件中呢？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@zutuanxue ~]# head -1 /etc/rc.d/* &gt; test.both 2&gt;&amp;1[root@zutuanxue ~]# cat test.both ==&gt; /etc/rc.d/init.d &lt;==head: 读取&#x27;/etc/rc.d/init.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc0.d &lt;==head: 读取&#x27;/etc/rc.d/rc0.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc1.d &lt;==head: 读取&#x27;/etc/rc.d/rc1.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc2.d &lt;==head: 读取&#x27;/etc/rc.d/rc2.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc3.d &lt;==head: 读取&#x27;/etc/rc.d/rc3.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc4.d &lt;==head: 读取&#x27;/etc/rc.d/rc4.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc5.d &lt;==head: 读取&#x27;/etc/rc.d/rc5.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc6.d &lt;==head: 读取&#x27;/etc/rc.d/rc6.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc.local &lt;==#!/bin/bash或者[root@zutuanxue ~]# head -1 /etc/rc.d/* &gt;&amp; test.both1[root@zutuanxue ~]# cat test.both1 ==&gt; /etc/rc.d/init.d &lt;==head: 读取&#x27;/etc/rc.d/init.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc0.d &lt;==head: 读取&#x27;/etc/rc.d/rc0.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc1.d &lt;==head: 读取&#x27;/etc/rc.d/rc1.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc2.d &lt;==head: 读取&#x27;/etc/rc.d/rc2.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc3.d &lt;==head: 读取&#x27;/etc/rc.d/rc3.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc4.d &lt;==head: 读取&#x27;/etc/rc.d/rc4.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc5.d &lt;==head: 读取&#x27;/etc/rc.d/rc5.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc6.d &lt;==head: 读取&#x27;/etc/rc.d/rc6.d&#x27; 时出错: 是一个目录==&gt; /etc/rc.d/rc.local &lt;==#!/bin/bash这两种使用方式都是告诉shell将错误信息写入到正确信息所写入的文件中。如果这些错误信息是我们早就知道的，并且还不想看到的呢？[root@zutuanxue ~]# head -1 /etc/rc.d/* 2&gt; /dev/null ==&gt; /etc/rc.d/init.d &lt;====&gt; /etc/rc.d/rc0.d &lt;====&gt; /etc/rc.d/rc1.d &lt;====&gt; /etc/rc.d/rc2.d &lt;====&gt; /etc/rc.d/rc3.d &lt;====&gt; /etc/rc.d/rc4.d &lt;====&gt; /etc/rc.d/rc5.d &lt;====&gt; /etc/rc.d/rc6.d &lt;====&gt; /etc/rc.d/rc.local &lt;==#!/bin/bash/dev/null:表示的是一个黑洞，通常用于丢弃不需要的数据输出 综上所述针对于输入输出重定向与合并的用法有 语法 作用 cmd &lt; file 从file重定向标准输入 cmd &gt; file 把标准输出重定向到file中，如果file存在的话，覆盖（损坏）它 cmd&gt;&gt;file 把标准输出重定向到file中，如果file存在，附加给它 cmd 2&gt;file 把标准错误重定向到file，如果file 存在，覆盖（损坏）它 cmd 2&gt;&gt; file 把标准错误重定向到file中，如果file 存在，附加给他 cmd&gt;file 2&gt;&amp;1 合并标准输出和标准错误，并且重定向到file中（可移植的语法） cmd &gt;&amp; file 合并标准输出和标准错误，并且重定向到file中（方便的语法） 四、管道在前面，我们已经看到，进程的输出可以被重定向到终端显示器以外的地方，或者可以让进程从终端键盘以外的地方读取输入。一种最常用，最有力的重定向形式是把这二者结合起来，在这种形式下，一个命令的输出（标准输出）被直接“用管道输送”到另一个命令的输入（标准输入）中，从而构成了 Linux（和Unix）所谓的管道（pipe）。当两个命令用管道连接起来时，第一个进程的标准输出流被直接连接到第二个进程的标准输入序列。为了用bash创建管道，用一个垂直的小节线 | 把这两个命令连接起来。 image20200323144226709.png 12345[root@zutuanxue ~]# pwd/root[root@zutuanxue ~]# ls | grep anaanaconda-ks.cfg注意：从管道读数据是一次性操作，数据一旦被读，它就从管道中被抛弃，释放空间以便写更多的数据。它只能处理经由前面一个指令传出的正确输出信息，对错误信息信息没有直接处理能力。然后，传递给下一个命令，作为标准的输入。 五、数据处理常用工具5.1、find文件查找命令. 代表当前目录 ~ 代表用户家目录 find命令选项 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166-name\t按照文件名查找文件。[root@zutuanxue ~]# find ~ -name &quot;test.*&quot;/root/test.err/root/test.both/root/test.both1-perm\t按照文件权限来查找文件。[root@zutuanxue ~]# chmod 777 hello[root@zutuanxue ~]# find . -perm 777./hello-user\t按照文件属主来查找文件。-group\t按照文件所属的组来查找文件。-uid\t查找指定uid-gid\t查找指定gid[root@zutuanxue ~]# chown hello.hello test[root@zutuanxue ~]# find . -user hello./test[root@zutuanxue ~]# find . -group hello./test[root@zutuanxue ~]# chown root.hello hello[root@zutuanxue ~]# find . -user root -group hello./hello[root@zutuanxue ~]# find . -uid 1000./test[root@zutuanxue ~]# find . -gid 1000./test-mtime -n +n\t按照文件的更改时间来查找文件， -n表示n天以内，+n表示n天以前。还有-atime和-ctime 选项-amin/-cmin/-mmin n 查找系统中最后N分钟 #如果-mtime +2 表示当前时间-2day以前的mtime的文件。即文件的mtime小于 sysdate -2#如果-mtime -2 表示当前时间-2day以后的mtime的文件。即文件的mtime大于 sysdate -2#如果-mtime 2 表示文件mtime在sysdate -2 与 sysdate-1 之间的文件。#！！！！！实际上再记不住，记住一般删除旧数据，一定是选择+。[root@zutuanxue ~]# find /etc -mtime -2 /etc/etc/cups/etc/cups/subscriptions.conf/etc/resolv.conf-nogroup\t查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。-nouser\t查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。[root@zutuanxue ~]# chown 1400.1400 hello[root@zutuanxue ~]# ll hello-rwxrwxrwx 1 1400 1400 8 3月 22 23:25 hello[root@zutuanxue ~]# find . -nogroup./hello[root@zutuanxue ~]# find . -nouser./hello-newer file1 查找更改时间比文件file1新的文件。[root@zutuanxue ~]# find /etc -newer initial-setup-ks.cfg /etc/etc/dnf/modules.d/etc/dnf/modules.d/httpd.module/etc/logrotate.d还有anewer和cnewer-type\t查找某一类型的文件，诸如：b - 块设备文件。d - 目录。c - 字符设备文件。p - 管道文件。l - 符号链接文件。f - 普通文件。[root@zutuanxue ~]# find /etc -newer initial-setup-ks.cfg -type f/etc/dnf/modules.d/httpd.module/etc/logrotate.d/glusterfs/etc/pki/nssdb/cert9.db/etc/pki/nssdb/key4.db/etc/yum.repos.d/server.repo-size n[bcwkMG] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。 b\t512字节一块 c\t字节 w\t字（2字节） k\tk字节（1024） M\tM字节（1024x1024字节） G\tG字节（1024x1024x1024字节）[root@zutuanxue ~]# find . -size +1M./.cache/tracker/meta.db./.cache/tracker/meta.db-wal./.cache/mozilla/firefox/mduza4q4.default/startupCache/startupCache.8.little./.cache/mozilla/firefox/mduza4q4.default/startupCache/scriptCache-child-current.bin./.cache/mozilla/firefox/mduza4q4.default/startupCache/scriptCache-current.bin./.mozilla/firefox/mduza4q4.default/places.sqlite./.mozilla/firefox/mduza4q4.default/favicons.sqlite# 在使用的时候注意一下单位，如find . -size 4k使用4k时会显示所有大与3k小于等于4k的文件，如果使用的是4096c则是查找大小为4k的文件[root@zutuanxue ~]# find . -size 4k../.cache/mozilla/firefox/mduza4q4.default/startupCache/urlCache-current.bin./.cache/mozilla/firefox/mduza4q4.default/startupCache/urlCache.bin./.cache/mozilla/firefox/mduza4q4.default/safebrowsing./.config/pulse./.mozilla/firefox/mduza4q4.default./.mozilla/firefox/mduza4q4.default/datareporting/archived/2020-02./.mozilla/firefox/mduza4q4.default/saved-telemetry-pings[root@zutuanxue ~]# find . -size 4096c../.cache/mozilla/firefox/mduza4q4.default/safebrowsing./.config/pulse./.mozilla/firefox/mduza4q4.default./.mozilla/firefox/mduza4q4.default/datareporting/archived/2020-02./.mozilla/firefox/mduza4q4.default/saved-telemetry-pings[root@zutuanxue ~]# find . -size 4k |wc -l8[root@zutuanxue ~]# find . -size 4096c |wc -l6[root@zutuanxue ~]# ll -h .cache/mozilla/firefox/mduza4q4.default/startupCache/urlCache-current.bin -rw-r--r-- 1 root root 3.1K 2月 24 02:34 .cache/mozilla/firefox/mduza4q4.default/startupCache/urlCache-current.bin-follow：如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。[root@zutuanxue ~]# ln -s /etc/ linketc[root@zutuanxue ~]# find . -name passwd[root@zutuanxue ~]# find . -name passwd -follow./linketc/pam.d/passwd./linketc/passwd-exec command &#123;&#125; \\; —–将查到的文件执行command操作,&#123;&#125; 和 \\;之间有空格-ok 和-exec相同，只不过在操作前要询用户[root@zutuanxue ~]# find /etc -name passwd -exec grep &quot;hello&quot; &#123;&#125; \\;hello:x:1000:1000:hello:/home/hello:/bin/bash[root@zutuanxue ~]# find /etc -name passwd -ok grep &quot;hello&quot; &#123;&#125; \\;&lt; grep ... /etc/pam.d/passwd &gt; ? y&lt; grep ... /etc/passwd &gt; ? yhello:x:1000:1000:hello:/home/hello:/bin/bash-empty\t查找空文件或目录[root@zutuanxue ~]# find /etc -empty/etc/crypttab/etc/dnf/aliases.d/etc/dnf/modules.defaults.d-inum\t查找i节点编号为指定数值的文件-samefile\t查找相同的文件[root@zutuanxue ~]# ln hello hello1[root@zutuanxue ~]# ln hello hello2[root@zutuanxue ~]# ll -i hello34510098 -rwxrwxrwx 3 1400 1400 8 3月 22 23:25 hello[root@zutuanxue ~]# find . -inum 34510098./hello./hello1./hello2[root@zutuanxue ~]# find . -samefile hello./hello./hello1./hello2 5.2、grep&amp;egrep 数据检索命令一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来，最常用。egrep是grep的扩展，支持更多的正则表达式元字符,等同于grep -E。 useradd HELLO useradd helo useradd helllo grep 与 正则表达式符号 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869^ 行的开始 如：&#x27;^grep&#x27;匹配所有以grep开头的行。[root@zutuanxue ~]# grep &#x27;^he&#x27; /etc/passwd$\t行的结束 如：&#x27;grep$&#x27;匹配所有以grep结尾的行。[root@zutuanxue ~]# grep &#x27;sh$&#x27; /etc/passwd.\t匹配一个非换行符(&#x27; &#x27;)的字符如：&#x27;gr.p&#x27;匹配gr后接一个任意字符，然后是p。[root@zutuanxue ~]# grep &#x27;t.e&#x27; /etc/passwd* 匹配零个或多个先前字符 如：&#x27; *grep&#x27; (注意*前有空格)匹配所有零个或多个空格后紧跟grep的行，需要用egrep 或者grep带上 -E 选项。 .*一起用代表任意字符。[root@zutuanxue ~]# grep -E &#x27;el*lo&#x27; /etc/passwd[]\t匹配一个指定范围内的字符，如&#x27;[Gg]rep&#x27;匹配Grep和grep。[root@zutuanxue ~]# grep &#x27;[Hh]el&#x27; /etc/passwd[^] 匹配一个不在指定范围内的字符，如：&#x27;[^A-FH-Z]rep&#x27;匹配不包含A-F和H-Z的一个字母开头，紧跟rep的行。[root@zutuanxue ~]# grep &#x27;[^A-Z]ello&#x27; /etc/passwd[root@zutuanxue ~]# grep &#x27;[^a-z]ello&#x27; /etc/passwd\\?\t匹配零个或一个先前的字符。如：&#x27;gre\\?p&#x27;匹配gr后跟一个或零个e字符，然后是p的行。[root@zutuanxue ~]# grep &#x27;hell\\?o&#x27; /etc/passwdhello:x:1000:1000:hello:/home/hello:/bin/bashhelo:x:1002:1002::/home/helo:/bin/bashx\\&#123;m\\&#125; 重复字符x，m次，如：&#x27;o\\&#123;5\\&#125;&#x27;匹配包含5个o的行。[root@zutuanxue ~]# grep &#x27;l\\&#123;2\\&#125;&#x27; /etc/passwdx\\&#123;m,\\&#125; 重复字符x,至少m次，如：&#x27;o\\&#123;5,\\&#125;&#x27;匹配至少有5个o的行。[root@zutuanxue ~]# grep &#x27;l\\&#123;2,\\&#125;&#x27; /etc/passwdx\\&#123;m,n\\&#125; 重复字符x，至少m次，不多于n次，如：&#x27;o\\&#123;5,10\\&#125;&#x27;匹配5--10个o的行。[root@zutuanxue ~]# grep &#x27;l\\&#123;1,3\\&#125;&#x27; /etc/passwd\\b 单词锁定符，如: &#x27;\\bgrep\\b&#x27;只匹配grep。[root@zutuanxue ~]# grep &#x27;hell&#x27; /etc/passwdhello:x:1000:1000:hello:/home/hello:/bin/bashhelllo:x:1003:1003::/home/helllo:/bin/bash[root@zutuanxue ~]# grep &#x27;\\bhell\\b&#x27; /etc/passwdegrep和 grep -E的扩展集+\t匹配一个或多个先前的字符。如：&#x27;[a-z]+able&#x27;，匹配一个或多个小写字母后跟able的串.[root@zutuanxue ~]# grep -E &#x27;[a-z]+llo&#x27; /etc/passwdhello:x:1000:1000:hello:/home/hello:/bin/bashhelllo:x:1003:1003::/home/helllo:/bin/bash[root@zutuanxue ~]# grep -E &#x27;[a-z]+lo&#x27; /etc/passwd?\t作用同\\?,如：&#x27;gre?p&#x27;匹配gr后跟一个或零个e字符，然后是p的行。[root@zutuanxue ~]# grep -E &#x27;hel?lo&#x27; /etc/passwdhello:x:1000:1000:hello:/home/hello:/bin/bashhelo:x:1002:1002::/home/helo:/bin/bash[root@zutuanxue ~]# grep &#x27;hel?lo&#x27; /etc/passwd[root@zutuanxue ~]# grep &#x27;hel\\?lo&#x27; /etc/passwdhello:x:1000:1000:hello:/home/hello:/bin/bashhelo:x:1002:1002::/home/helo:/bin/basha|b|c 匹配a或b或c。如：grep|sed匹配grep或sed[root@zutuanxue ~]# grep -E &#x27;llo|lllo&#x27; /etc/passwdhello:x:1000:1000:hello:/home/hello:/bin/bashhelllo:x:1003:1003::/home/helllo:/bin/bash*\t0次或多次?\t0次或1次+\t1次或多次-E 支持扩展正则，相当于egrep-i 不区分大小写-v 取反，显示不匹配的--color=auto\t高亮显示 5.3、sort 对文件内容进行排序常用命令选项 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970-b 忽略每行前面开始出的空格字符。[root@zutuanxue ~]# sort passwdapache:x:48:48:Apache:/usr/share/httpd:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologin hello:x:1000:1000:hello:/home/hello:/bin/bash HELLO:x:1001:1001::/home/HELLO:/bin/bash helo:x:1002:1002::/home/helo:/bin/bashlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinnobody:x:65534:65534:Kernel Overflow User:/:/sbin/nologinroot:x:0:0:root:/root:/bin/bash[root@zutuanxue ~]# sort -b passwdapache:x:48:48:Apache:/usr/share/httpd:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologin hello:x:1000:1000:hello:/home/hello:/bin/bash HELLO:x:1001:1001::/home/HELLO:/bin/bash helo:x:1002:1002::/home/helo:/bin/bashlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinnobody:x:65534:65534:Kernel Overflow User:/:/sbin/nologinroot:x:0:0:root:/root:/bin/bash-c 检查文件是否已经按照顺序排序。[root@zutuanxue ~]# sort -c passwd sort：passwd:2：无序： bin:x:1:1:bin:/bin:/sbin/nologin-t\t用指定的符号做为分隔符-k\t指定区间-n 依照数值的大小排序。-r 以相反的顺序来排序。[root@zutuanxue ~]# sort -t &#x27;:&#x27; -k 3 -r -n passwd nobody:x:65534:65534:Kernel Overflow User:/:/sbin/nologin helo:x:1002:1002::/home/helo:/bin/bash HELLO:x:1001:1001::/home/HELLO:/bin/bash hello:x:1000:1000:hello:/home/hello:/bin/bashdbus:x:81:81:System message bus:/:/sbin/nologin apache:x:48:48:Apache:/usr/share/httpd:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologinroot:x:0:0:root:/root:/bin/bash或者[root@zutuanxue ~]# sort -t &#x27;:&#x27; -k 3rn passwd nobody:x:65534:65534:Kernel Overflow User:/:/sbin/nologin helo:x:1002:1002::/home/helo:/bin/bash HELLO:x:1001:1001::/home/HELLO:/bin/bash hello:x:1000:1000:hello:/home/hello:/bin/bashdbus:x:81:81:System message bus:/:/sbin/nologin apache:x:48:48:Apache:/usr/share/httpd:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologinroot:x:0:0:root:/root:/bin/bash-o&lt;输出文件&gt; 将排序后的结果存入指定的文件。[root@zutuanxue ~]# sort -t &#x27;:&#x27; -k 3 -r -n passwd -o /root/passwd-sort[root@zutuanxue ~]# cat /root/passwd-sort nobody:x:65534:65534:Kernel Overflow User:/:/sbin/nologin helo:x:1002:1002::/home/helo:/bin/bash HELLO:x:1001:1001::/home/HELLO:/bin/bash hello:x:1000:1000:hello:/home/hello:/bin/bashdbus:x:81:81:System message bus:/:/sbin/nologin apache:x:48:48:Apache:/usr/share/httpd:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologinroot:x:0:0:root:/root:/bin/bash 5.4、uniq 数据去重一般配合sort使用 案例文档 12345678910[root@zutuanxue ~]# cat testuniq192.168.98.2192.168.98.8192.168.98.3192.168.98.3192.168.98.9192.168.98.8192.168.98.8192.168.98.0192.168.98.3 常用命令选项 12345678910111213141516171819202122232425262728293031323334353637-c\t在每列旁边显示该行重复出现的次数。[root@zutuanxue ~]# uniq -c testuniq 1 192.168.98.2 1 192.168.98.8 2 192.168.98.3 1 192.168.98.9 2 192.168.98.8 1 192.168.98.0 1 192.168.98.3[root@zutuanxue ~]# uniq -c testuniq | sort 1 192.168.98.0 1 192.168.98.2 1 192.168.98.3 1 192.168.98.8 1 192.168.98.9 2 192.168.98.3 2 192.168.98.8-d\t仅显示重复出现的行列。[root@zutuanxue ~]# uniq -d testuniq 192.168.98.3192.168.98.8-u\t仅显示出一次的行列。[root@zutuanxue ~]# uniq -u testuniq 192.168.98.2192.168.98.8192.168.98.9192.168.98.0192.168.98.3[root@zutuanxue ~]# uniq -u testuniq | sort192.168.98.0192.168.98.2192.168.98.3192.168.98.8192.168.98.9 5.5、tree 以树状结构列出目录内容1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980-a 显示所有文件和目录,默认不显示隐藏文件[root@zutuanxue ~]# tree -a-C 在文件和目录清单加上色彩，便于区分各种类型。[root@zutuanxue ~]# tree -C-d 只显示目录。[root@zutuanxue ~]# tree -d-D 列出文件或目录的更改时间。[root@zutuanxue ~]# tree -D.├── [Feb 4 15:07] 公共├── [Feb 4 15:07] 模板-f 在每个文件或目录之前，显示完整的路径名称。[root@zutuanxue ~]# tree -f.├── ./公共├── ./模板-F 加上文件类型标记，在执行文件，目录，Socket，管道名称名称，各自加上&quot;*&quot;,&quot;/&quot;,&quot;@&quot;,&quot;|&quot;号。[root@zutuanxue ~]# tree -F.├── 公共/├── 模板/-g -u 列出文件或目录的所属群组、主名称，没有对应的名称时，则显示群组、主的识别码。[root@zutuanxue ~]# tree -g.├── [root ] 公共├── [root ] 模板-i 不以阶梯状列出文件或目录名称。[root@zutuanxue ~]# tree -i.公共模板视频-n 不在文件和目录清单加上色彩。[root@zutuanxue ~]# tree -n.├── 公共├── 模板-p 列出权限标示。[root@zutuanxue ~]# tree -p.├── [drwxr-xr-x] 公共├── [drwxr-xr-x] 模板-s 列出文件或目录大小。[root@zutuanxue ~]# tree -s.├── [ 6] 公共├── [ 6] 模板-t 用文件和目录的更改时间排序。[root@zutuanxue ~]# tree -t.├── anaconda-ks.cfg├── initial-setup-ks.cfg├── 公共-u 列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码。[root@zutuanxue ~]# tree -u.├── [root ] 公共├── [root ] 模板-L 显示目录层数，数值为正整数[root@zutuanxue ~]# tree -a -L 2.├── .cache│ ├── dconf│ ├── event-sound-cache.tdb.d5b6fe70a77f4945aa0999abdd33e686.x86_64-redhat-linux-gnu│ ├── evolution│ ├── gnome-shell│ ├── gnome-software 5.6、xargs命令xargs 是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。用于一些不支持管道输入的命令如ls 案例文件 12345678910111213[root@zutuanxue ~]# cat xargtest a a ab b bc c cd d defghijkl 常用命令选项 123456789101112131415161718192021222324252627282930-n num 后面加列数[root@zutuanxue ~]# cat xargtest | xargs -n 2a aa bb bc cc dd de fg hi jk l[root@zutuanxue ~]# cat xargtest | xargsa a a b b b c c c d d d e f g h i j k l-I\t指定替换的字符串，并在后续的命令中用指定的字符串表示接收到的输入内容，并执行，可以用任意字符代替（不推荐有特殊含义的字符，如*等，如果使用请记得转意），一般为[]或&#123;&#125;[root@zutuanxue ~]# mkdir testx[root@zutuanxue ~]# find /var/ -name &quot;*.log&quot; | xargs -I a cp a ./testx[root@zutuanxue ~]# ls testx | wc -l39-i\t类似-I，相当于固定就是使用&#123;&#125;来表示接收到的输入内容[root@zutuanxue ~]# find /var/ -name &quot;*.log&quot; | xargs -i cp &#123;&#125; ./testx[root@zutuanxue ~]# ls testx | wc -l39-d 指定分隔符[root@zutuanxue ~]# echo &quot;a9b9c9d9&quot; | xargs -d 9a b c d","categories":["Linux","Linux系统管理宝典"]},{"title":"linux分区挂载","path":"/2023/09/27/Linux系统管理宝典/Linux-分区挂载/","content":"磁盘在linux中经过分区、格式化后是无法直接使用的，因为该分区在系统中是以一个设备文件的形式存在的。我们如果希望使用这个磁盘分区还得经过最后一步，就是将这个分区设备挂载到系统中的某个文件夹下。这样你往这个挂载文件夹里存东西其实即使往分区里存东西了。接下来我们来看看linux下挂载磁盘分区的方式 手动挂载 开机自动挂载 触发挂载 一、手动挂载mount挂载命令 12345678910111213141516171819mount - mount a filesystem命令语法mount device dir命令选项-a 挂载所有文件系统，参考文件 /etc/fstab-l 显示当前挂载-t 文件系统类型-o 指定挂载权限##用法说明mount [options] 需要挂载的设备 挂载点特点：系统重启后需要重新挂载；手动卸载后需要手动挂载-o:挂载选项\tro,sync,rw,remount-t:文件系统类型mount -t nfs=mount.nfsmount -t cifs=mount.cifs 挂载分区演示 1234567891011#案列1：以只读的方式重新挂载/u02分区[root@zutuanxue ~]# mount -o remount,ro /u02 //可以是挂载点也可以是设备remount:重新挂载一个正在挂载的设备# mount -o remount,ro /dev/sdb1 # mount -o remount,ro /u01注意：后面可以根挂载点也可以跟设备本身#案例2: 如果希望将本机的某个文件夹挂到另一个文件夹mount -o bind /etc /opt/data3 设备表示方法： 设备文件 设备UUID 设备的卷标 12345678910111213141516171819202122232425262728293031#设备文件：/dev/sdb/dev/sdb1#通过UUID表示设备[root@zutuanxue ~]# blkid /dev/sdb1 //查看设备的UUID和文件系统类型/dev/sdb1: UUID=&quot;96b67b7b...&quot; TYPE=&quot;xfs&quot; PARTUUID=&quot;80e196f2-01&quot;[root@zutuanxue ~]# blkid /dev/sdb2/dev/sdb2: UUID=&quot;6821-049E&quot; TYPE=&quot;vfat&quot; PARTUUID=&quot;80e196f2-02&quot;#通过卷标表示设备#不同类型分区卷标管理与查看ext*设置&amp;查看卷标[root@zutuanxue ~]# e2label /dev/sdb1 DISK1 ext*设置卷标[root@zutuanxue ~]# e2label /dev/sdb1 ext*查看卷标xfs设置&amp;查看卷标[root@zutuanxue ~]# xfs_admin -L DISK1 /dev/sdb1\txfs设置卷标[root@zutuanxue ~]# xfs_admin -l /dev/sdb1 xfs查看卷标label = &quot;DISK1&quot;vfat设置&amp;查看卷标[root@zutuanxue ~]# dosfslabel /dev/sdb2 hello[root@zutuanxue ~]# dosfslabel /dev/sdb2也可以使用blkid查看卷标[root@zutuanxue ~]# blkid /dev/sdb1/dev/sdb1: LABEL=&quot;DISK1&quot; UUID=&quot;96..&quot; TYPE=&quot;xfs&quot; PARTUUID=&quot;80..-01&quot;[root@zutuanxue ~]# blkid /dev/sdb2/dev/sdb2: LABEL=&quot;disk2&quot; UUID=&quot;6...&quot; TYPE=&quot;vfat&quot; PARTUUID=&quot;8e.2-02&quot; umount设备卸载命令命令详解 12345umount - 卸载文件系统umount 设备挂载点|设备源-l 懒惰卸载 命令用法演示 123卸载设备：umount[root@zutuanxue ~]# umount /u01[root@zutuanxue ~]# umount /dev/sdb2 二、开机自动挂载：自动挂载 &#x2F;etc&#x2F;fstab文件特点：系统开机或重启会自动挂载；手动卸载后，使用mount -a自动挂载 12345678910111213141516171819202122232425262728293031文件内容格式：要挂载的资源路径\t挂载点\t文件系统类型\t挂载选项\tdump备份支持 文件系统检测UUID=289370eb-9459-42a8-8cee-7006507f1477 / ext4 defaults 1 1#字段说明1段：挂载的设备（磁盘设备的文件名或设备的卷标或者是设备的UUID）2段：挂载点（建议用一个空目录），建议不要将多个设备挂载到同一个挂载点上3段：文件系统类型（ext3、ext4、vfat、ntfs（安装软件包）、swap等等）4段：挂载选项dev/nodev 被挂载的设备上的设备文件，是否被识别为设备文件async/sync 异步/同步 同步利于数据保存 异步利于提高性能auto/noauto 自动/非自动：rw/ro 读写/只读：exec/noexec 被挂载设备中的可执行文件是否可执行remount 重新挂在一个已经挂载的文件系统，常用于修改挂载参数user/nouser 允许/不允许其他普通用户挂载：suid/nosuid 具有/不具有suid权限：该文件系统是否允许SUID的存在。usrquota 这个是在启动文件系统的时候，让其支持磁盘配额，这个是针对用户的。grpquota 支持用户组的磁盘配额。....defaults 同时具有rw, dev, exec, async,nouser等参数。更多挂载选项可以通过 man mount -o 命令选项可以找到详细信息5段：是否支持dump备份。//dump是一个用来备份的命令，0代表不要做dump备份，1代表要每天进行dump的动作，2也代表其他不定日期的dump备份。通常这个数值不是0就是1。数字越小优先级越高。6段：是否用 fsck 检验扇区。//开机的过程中，系统默认会用fsck检验文件系统是否完整。0是不要检验，1表示最先检验(一般只有根目录会设定为1)，2也是要检验，只是1是最先，2是其次才进行检验。# fsck -f /dev/sdb2 强制检验/dev/sdb2上文件系统说明：要挂载的资源路径可以是文件系统的UUID，设备路径，文件系统的标签 ，光盘镜像文件（iso），亦或是来自网络的共享资源等 三、自动挂载 Automount：特点：挂载是由访问产生；卸载是由超时产生；依赖于后台的autofs服务 思路： 所有的监控都是由一个程序完成 autofs 服务启动后才会监控挂载的设备 修改配置文件来指定需要监控的设备 案例演示需求：让系统自动挂载&#x2F;dev&#x2F;sdb2设备，如果2分钟没有被用自动卸载 12345678910111213141516171819202122232425262728293031步骤：1）安装autofs软件[root@zutuanxue ~]# rpm -q autofspackage autofs is not installed[root@zutuanxue ~]# dnf install autofs[root@zutuanxue ~]# rpm -q autofsautofs-5.1.4-29.el8.x86_642）修改配置文件（指定需要监控的设备和挂载的目录）vim /etc/auto.master //定义一级挂载点/u01和子配置文件/u01 /etc/auto.test\t-t 120 或者 --timeout 120 单位秒 （设置超时时间去卸载）vim /etc/auto.test //子配置文件自己创建，定义二级挂载点和需要挂载的设备test -fstype=ext4,ro :/dev/sdb23）重启服务[root@zutuanxue ~]# systemctl restart autofs4）测试验证[root@zutuanxue ~]# ls /u01/test[root@zutuanxue ~]# df -h后续补充：如果想要将/dev/sdb2挂载到/u01下，怎么做？vim /etc/auto.master/- /etc/auto.testvim /etc/auto.test/u01\t-fstype=ext4 :/dev/sdb2","categories":["Linux","Linux系统管理宝典"]},{"title":"创建高可用逻辑卷","path":"/2023/09/27/Linux系统管理宝典/Linux-创建高可用逻辑卷/","content":"一、逻辑卷条带化：把保存到逻辑卷的数据分成n等分，分别写到不同的物理卷，可以提高数据的读写效率；如果任何一个涉及到的物理卷出现故障，数据都会无法恢复。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546创建物理卷[root@manage01 ~]# pvcreate /dev/sdb[12]查看物理卷[root@manage01 ~]# pvs/dev/sdb1 lvm2 a-- 2.01g 2.01g/dev/sdb2 lvm2 a-- 2.01g 2.01g创建卷组：[root@manage01 ~]# vgcreate vg01 /dev/sdb[12][root@manage01 ~]# pvs /dev/sdb[12] PV VG Fmt Attr PSize PFree /dev/sdb1 vg01 lvm2 a-- 2.00g 2.00g /dev/sdb2 vg01 lvm2 a-- 2.00g 2.00g创建实现条带化的逻辑卷：[root@zutuanxue ~]# lvcreate -n lv1 -L 1G vg01 -i 2 /dev/sdb&#123;1,2&#125;-i 参数：给出条带化的数量[root@zutuanxue ~]# lvs /dev/vg01/lv01格式化挂载使用：[root@zutuanxue ~]# mkfs.ext4 /dev/vg1/lv1[root@zutuanxue ~]# mount /dev/vg1/lv1 /lv1测试：[root@zutuanxue ~]# dnf install sysstat -y[root@zutuanxue ~]# iostat -m -d /dev/sdb[12] 2 -d 查看磁盘-m 以什么速度显示，每秒M 2 每隔2s显示一次 如果后面还有数字则代表总共显示多少次 [root@zutuanxue ~]# dd if=/dev/zero of=/lv1/test bs=1M count=1000 模拟写数据[root@zutuanxue ~]# iostat -m -d /dev/sdb[12] 1...Device tps MB_read/s MB_wrtn/s MB_read MB_wrtnsdb1 4015.00 0.01 364.38 0 364sdb2 4005.00 0.00 364.33 0 364 二、逻辑卷实现镜像镜像是一种文件存储形式，是冗余的一种类型，一个磁盘上的数据在另一个磁盘上存在一个完全相同的副本即为镜像。对某个逻辑卷的数据做镜像，起到数据备份的作用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374当前环境：[root@zutuanxue ~]# lsblk├─sdb3 8:19 0 2G 0 part ├─sdb4 8:20 0 2G 0 part 创建物理卷：[root@zutuanxue ~]# pvcreate /dev/sdb[34][root@zutuanxue ~]# pvs PV VG Fmt Attr PSize PFree /dev/sdb3 lvm2 --- 2.00g 2.00g /dev/sdb4 lvm2 --- 2.00g 2.00g 将物理卷加入到vg1卷组：[root@zutuanxue ~]# vgextend vg1 /dev/sdb[34] Volume group &quot;vg1&quot; successfully extended[root@zutuanxue ~]# vgs VG #PV #LV #SN Attr VSize VFree vg1 4 1 0 wz--n- 7.98g 6.98g创建实现镜像的逻辑卷：[root@zutuanxue ~]# lvcreate -n lv2 -L 1G vg1 -m 1 /dev/sdb[34] Logical volume &quot;lv2&quot; created.-m参数：给出镜像的个数；1表示1个镜像[root@zutuanxue ~]# lvs -a -o +devices[root@zutuanxue ~]# lvs -a -o +devices LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert Devices root cl -wi-ao---- &lt;17.00g /dev/sda2(512) swap cl -wi-ao---- 2.00g /dev/sda2(0) lv1 vg1 -wi-ao---- 1.00g /dev/sdb1(0),/dev/sdb2(0) lv2 vg1 rwi-a-r--- 1.00g 100.00 lv2_rimage_0(0),lv2_rimage_1(0) [lv2_rimage_0] vg1 iwi-aor--- 1.00g /dev/sdb3(1) [lv2_rimage_1] vg1 iwi-aor--- 1.00g /dev/sdb4(1) [lv2_rmeta_0] vg1 ewi-aor--- 4.00m /dev/sdb3(0) [lv2_rmeta_1] vg1 ewi-aor--- 4.00m /dev/sdb4(0) 说明： Cpy%Sync 18.77该值是100%说明复制ok 格式化逻辑卷：[root@zutuanxue ~]# mkfs.ext4 /dev/vg1/lv2挂载使用[root@zutuanxue ~]# mount /dev/vg1/lv2 /lv2/[root@zutuanxue ~]# touch /lv2/file&#123;1..10&#125;[root@zutuanxue ~]# mkdir /lv2/dir&#123;1..10&#125; 测试验证：思路：损坏一个磁盘，测试数据是否在第二个物理卷中1. 使用dd命令破坏一个物理卷[root@zutuanxue ~]# dd if=/dev/zero of=/dev/sdb3 bs=1M count=1002. 再次查看物理卷发现有一个unknown Device pvs命令 [unknown] vg1 lvm2 a-m &lt;2.00g 1016.00m3. 将损坏的盘从卷组中移除[root@zutuanxue ~]# vgreduce vg1 --removemissing --force4. 再次查看挂载点/lv2数据依然存在自己也可以再次测试：1. 再拿刚刚人为损坏的盘做成物理卷再次加入到vg1卷组中[root@zutuanxue /]# pvcreate /dev/sdb3 [root@zutuanxue /]# vgextend vg1 /dev/sdb32. 修复[root@zutuanxue /]# lvconvert --repair /dev/vg1/lv2 /dev/sdb[34] 三、逻辑卷快照快照的作用：保存做快照那一刻数据的状态，方便用户实现数据回滚，避免重要数据被覆盖。 快照的大小：快照需要占用卷组空间，快照的大小决定了允许有多少数据发生改变，如果制作快照时分配的容量与对应的逻辑卷相同，那么就允许逻辑卷中所有的数据发生改变。 COW：copy on write 当系统检测到做快照的逻辑卷当中的数据发生了改变，会在改变前将逻辑卷中的PE的数据复制到快照中的PE，然后再写入新的数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344451. 创建快照 (EXT4)[root@zutuanxue /]# lvcreate -L 200M -s -n lv1-snap /dev/vg1/lv1\t给lv1逻辑卷创建快照[root@zutuanxue /]# mount -o ro /dev/vg1/lv1-snap /lv1-snap/\t挂载快照[root@zutuanxue /]# lvscan ACTIVE Original &#x27;/dev/vg1/lv1&#x27; [2.00 GiB] inherit ACTIVE Snapshot &#x27;/dev/vg1/lv1-snap&#x27; [200.00 MiB] inherit[root@zutuanxue /] dmsetup ls --treevg1-lv2--snap (252:5) ├─vg1-lv1--snap-cow (253:4) 保存原卷改变前的数据 │ └─ (8:17) └─vg1-lv1-real (253:3) 真实的逻辑卷（原卷） ├─ (8:17) └─ (8:18)vg1-lv1 (253:2) └─vg1-lv1-real (253:3) ├─ (8:17) └─ (8:18) 2. 修改原卷的数据[root@zutuanxue /]# dd if=/dev/zero of=/lv1/test bs=1M count=303. 观察Snapshot[root@zutuanxue /]# lvs /dev/vg1/lv1-snap LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1-snap vg1 swi-aos--- 200.00m lv1 0.02 [root@zutuanxue /]# lvs /dev/vg1/lv1-snap LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1-snap vg1 swi-aos--- 200.00m lv1 15.10 XFS：[root@node1 ~]# mount -o nouuid,ro /dev/vg1/lv1-snap /lv1-snap挂载快照，尽量使用ro的方式，将不会破坏快照卷中的数据快照实现自动扩容：/etc/lvm/lvm.conf snapshot_autoextend_threshold = 80snapshot_autoextend_percent = 20//当快照使用到80%时，自动扩容20%；当snapshot_autoextend_threshold = 100表示关闭自动扩容修改完成后建议重启","categories":["Linux","Linux系统管理宝典"]},{"title":"创建一个软raid阵列","path":"/2023/09/27/Linux系统管理宝典/Linux-创建一个软raid阵列/","content":"环境准备添加一个20G的虚拟硬盘，分成10个2G的分区 一、创建raid0123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475系统中如果没有mdadm命令请安装相关工具：[root@zutuanxue ~]# which mdadm/usr/sbin/mdadm[root@zutuanxue ~]# rpm -qf /usr/sbin/mdadm mdadm-4.1-4.el8.x86_64[root@zutuanxue ~]# dnf install -y mdadm创建raid0：[root@zutuanxue ~]# mdadm --create /dev/md0 --raid-devices=2 /dev/sdb1 /dev/sdb2 --level=0mdadm: Defaulting to version 1.2 metadatamdadm: array /dev/md0 started.或者[root@zutuanxue ~]# mdadm -C /dev/md0 -l 0 -n 2 /dev/sdb1 /dev/sdb2-C:创建软raid-l：指定raid级别-n：指定raid中设备个数查看RAID信息：/proc/mdstat文件记录了所有raid信息[root@zutuanxue ~]# cat /proc/mdstat Personalities : [raid0] md0 : active raid0 sdb2[1] sdb1[0]#md0为raid0，两个成员sdb2（第二个成员），sdb1（第一个成员） 41905152 blocks super 1.2 512k chunks#一共有多少个块（每块1K）\t数据段的大小是512K#chunk决定了阵列中每个成员盘写入的数据量，大于这个值才会到下一个盘读写unused devices: &lt;none&gt;查看指定的RAID信息：[root@zutuanxue ~]# mdadm -D/--detail /dev/md0[root@zutuanxue ~]# mdadm --detail /dev/md0/dev/md0:\t#名称 Version : 1.2\t#工具版本 Creation Time : Wed Dec 11 03:05:31 2019\t#建立时间 Raid Level : raid0\t#类型 Array Size : 41905152 (39.96 GiB 42.91 GB)#容量 Raid Devices : 2\t#组成RAID的硬盘数量 Total Devices : 2#成员总数，包含备用磁盘 Persistence : Superblock is persistent Update Time : Wed Dec 11 03:05:31 2019 State : clean #raid的状态 Active Devices : 2\t#活跃的设备数量 Working Devices : 2\t#工作的设备数量 Failed Devices : 0\t#故障的数量 Spare Devices : 0\t#备用设备数量 Chunk Size : 512K Consistency Policy : none Name : localhost.localdomain:0 (local to host localhost.localdomain) UUID : 06b2d3b2:3ace3ddf:b5b65dd7:eb40b040 Events : 0Number Major Minor RaidDevice State 0 8 17 0 active sync /dev/sdb1 1 8 33 1 active sync /dev/sdb2格式化挂载使用：[root@zutuanxue ~]# mkfs.ext4 /dev/md0[root@zutuanxue ~]# mkdir /md0[root@zutuanxue ~]# mount /dev/md0 /md0/查看空间使用情况：[root@zutuanxue ~]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/md0 3.9G 16M 3.7G 1% /md0#可用空间100%测试：[root@zutuanxue ~]# iostat -m -d /dev/sdb1 /dev/sdb2 2[root@zutuanxue ~]# dd if=/dev/zero of=/md0/file bs=1M count=1024 二、创建RAID1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869创建raid1：[root@zutuanxue ~]# mdadm -C /dev/md1 -l 1 -n 2 /dev/sdb3 /dev/sdb4 查看状态信息：root@zutuanxue ~]# watch -n1 &quot;cat /proc/mdstat&quot; watch命令监控该文件变化情况,1秒钟显示一次或者直接查看[root@zutuanxue ~]# cat /proc/mdstat Personalities : [raid0] [raid1] md1 : active raid1 sdb4[1] sdb3[0] 20953024 blocks super 1.2 [2/2] [UU] #两个UU说明状态ok，一个盘故障则显示_U [==============&gt;......] resync = 73.5% (15404032/20953024) finish=0.4min speed=205582K/secunused devices: &lt;none&gt; #以上信息说明两块盘在进行同步，100%说明同步完成查看raid1详细信息[root@zutuanxue ~]# mdadm -D /dev/md1 格式化挂载使用：[root@zutuanxue ~]# mkfs.ext4 /dev/md1[root@zutuanxue ~]# mount /dev/md1 /md1查看空间使用情况：[root@zutuanxue ~]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/md1 2.0G 6.0M 1.9G 1% /md1#可用空间50%测试验证热插拔：1. 模拟一块盘故障（将磁盘标记为失效）[root@zutuanxue ~]# mdadm /dev/md1 -f /dev/sdb3mdadm: set /dev/sdb1 faulty in /dev/md1#-f or --fail 表示失效2. 查看raid1状态[root@zutuanxue ~]# cat /proc/mdstat Personalities : [raid0] [raid1] md1 : active raid1 sdb4[1] sdb3[0](F)\tF表示失效失败 20953024 blocks super 1.2 [2/1] [_U] #_表示有一块盘失效unused devices: &lt;none&gt;[root@zutuanxue ~]# mdadm -D /dev/md1。。。Number Major Minor RaidDevice State- 0 0 0 removed1 8 33 1 active sync /dev/sdb40 8 17 - faulty /dev/sdb3 #失效盘等待移除 3. 移除故障或者失效硬盘（热拔）[root@zutuanxue ~]# mdadm /dev/md1 -r /dev/sdb3mdadm: hot removed /dev/sdb3 from /dev/md1#-r or --remove 表示移除[root@zutuanxue ~]# mdadm -D /dev/md1。。。 Number Major Minor RaidDevice State - 0 0 0 removed 1 8 33 1 active sync /dev/sdb44. 加入新的磁盘到raid1中（热插）[root@zutuanxue ~]# mdadm /dev/md1 -a /dev/sdb5mdadm: added /dev/sdd5#-a or --add 表示增加[root@zutuanxue ~]# cat /proc/mdstat 三、创建RAID512345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970创建raid5:[root@zutuanxue ~]# mdadm -C /dev/md5 -l 5 -n 3 -x 1 /dev/sdb&#123;6,7,8,9&#125;#-x, --spare-devices= 表示指定热备盘[root@zutuanxue ~]# cat /proc/mdstat Personalities : [raid0] [raid1] [raid6] [raid5] [raid4] md5 : active raid5 sdb8[4] sdb9[3](S) sdb7[1] sdb6[0]\t#S备用盘 4188160 blocks super 1.2 level 5, 512k chunk, algorithm 2 [3/3] [UUU] unused devices: &lt;none&gt;说明：热备盘表示当其中一块盘故障后，热备盘会立马顶上去，而不需要人为手动干预。[root@zutuanxue ~]# mdadm -D /dev/md5 查看详细信息。。。 Number Major Minor RaidDevice State 0 8 22 0 active sync /dev/sdb6 1 8 23 1 active sync /dev/sdb7 4 8 24 2 active sync /dev/sdb8 3 8 25 - spare /dev/sdb9格式化挂载使用：[root@zutuanxue ~]# mkfs.ext4 /dev/md5[root@zutuanxue ~]# mkdir /md5[root@zutuanxue ~]# mount /dev/md5 /md5/查看空间使用情况：[root@zutuanxue ~]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/md5 3.9G 16M 3.7G 1% /md5#可用空间 （磁盘数量-1）x 单一磁盘容量测试热备磁盘作用：1. 标记一块活动盘失效[root@zutuanxue /]# mdadm /dev/md5 -f /dev/sdb6mdadm: set /dev/sdb6 faulty in /dev/md5立即查看状态：[root@zutuanxue /]# cat /proc/mdstat Personalities : [raid0] [raid1] [raid6] [raid5] [raid4] md5 : active raid5 sdb8[4] sdb9[3] sdb7[1] sdb6[0](F)说明：sdb6(F)失效后，原来的sdb9(S)热备盘立马顶上去同步数据 4188160 blocks super 1.2 level 5, 512k chunk, algorithm 2 [3/2] [_UU] [==&gt;..................] recovery = 13.0% .. unused devices: &lt;none&gt;[root@zutuanxue /]# mdadm -D /dev/md5... Number Major Minor RaidDevice State 3 8 25 0 active sync /dev/sdb9 1 8 23 1 active sync /dev/sdb7 4 8 24 2 active sync /dev/sdb8 0 8 22 - faulty /dev/sdb6 2. 移除失效的盘[root@zutuanxue /]# mdadm /dev/md5 -r /dev/sdb6 mdadm: hot removed /dev/sdb6 from /dev/md53. 为了日后考虑，再次添加一个热备盘到raid5中[root@zutuanxue /]# mdadm /dev/md5 -a /dev/sdb6mdadm: added /dev/sdb6 四、 保存RAID信息问：为什么要保存raid信息？答：如果不做信息的保存，在CentOS6中，重启系统后raid不能自动被识别到，7,8系统中不会出现这种状况。 1234561. 创建配置文件[root@zutuanxue ~]# mdadm -D --scan &gt;&gt; /etc/mdadm.conf [root@zutuanxue ~]# cat /etc/mdadm.conf ARRAY /dev/md/1 metadata=1.2 name=localhost.localdomain:1 UUID=170d690d:4f7ccd02:646c3ce0:8f6012beARRAY /dev/md/0 metadata=1.2 name=localhost.localdomain:0 UUID=a845702e:9251cae9:25d1bc8b:9a337df2ARRAY /dev/md/5 metadata=1.2 spares=1 name=localhost.localdomain:5 UUID=d49e6cca:5312271b:7e8e83d5:adac4ed5 raid停止与启动123456789101112131415161718192021222324252627282930313233以RAID5为例说明：停止raid:1. 卸载raid[root@zutuanxue ~]# umount /md5 2. 使用命令停止raid[root@zutuanxue ~]# mdadm --stop /dev/md5mdadm: stopped /dev/md5启动raid：1. 配置文件(/etc/mdadm.conf)存在如下启动[root@zutuanxue ~]# mdadm -A /dev/md5mdadm: /dev/md5 has been started with 3 drives and 1 spare.#-A：Assemble a pre-existing array 表示装载一个已存在的raid2. 配置文件(/etc/mdadm.conf)不存在如下启动[root@zutuanxue ~]# mdadm -A /dev/md5 /dev/sdb[6789]mdadm: /dev/md5 has been started with 3 drives and 1 spare.3. 如果设备名不知道，可以去查看每个设备的raid信息，使用uuid把raid设备重新组合[root@zutuanxue ~]# mdadm -E /dev/sdb6 | grep UUID Array UUID : d49e6cca:5312271b:7e8e83d5:adac4ed5 Device UUID : b933b8d5:04a6e003:90e9b230:d13cacf5 说明：同一个raid里每个磁盘查看的UUID都是这个值。。。[root@zutuanxue ~]# mdadm -E /dev/sdb7 | grep UUID Array UUID : d49e6cca:5312271b:7e8e83d5:adac4ed5 Device UUID : b8ca85bd:7809faa4:48882a21:98ef9349通过以上方法找到后进行重新组合，如下：[root@zutuanxue ~]# mdadm -A --uuid=d49e6cca:5312271b:7e8e83d5:adac4ed5 /dev/md5mdadm: /dev/md5 has been started with 3 drives and 1 spare. raid的删除12345678910111213141516171819201. 卸载设备[root@zutuanxue ~]# umount /md5/2. 移除所有磁盘[root@zutuanxue ~]# mdadm /dev/md5 -f /dev/sdb[6789]mdadm: set /dev/sdb6 faulty in /dev/md5mdadm: set /dev/sdb7 faulty in /dev/md5mdadm: set /dev/sdb8 faulty in /dev/md5mdadm: set /dev/sdb9 faulty in /dev/md5[root@zutuanxue ~]# mdadm /dev/md5 -r /dev/sdb[6789]mdadm: hot removed /dev/sdb6 from /dev/md5mdadm: hot removed /dev/sdb7 from /dev/md5mdadm: hot removed /dev/sdb8 from /dev/md5mdadm: hot removed /dev/sdb9 from /dev/md53. 停止raid[root@zutuanxue ~]# mdadm --stop /dev/md5mdadm: stopped /dev/md54. 擦出超级块（superblock）清除相关信息[root@zutuanxue ~]# mdadm --zero-superblock /dev/sdb[6789]","categories":["Linux","Linux系统管理宝典"]},{"title":"linux启动常见问题","path":"/2023/09/27/Linux系统管理宝典/Linux-启动常见问题/","content":"一、忘记root密码日常生活中，我们会接触到很多账号和密码，而这些账号和密码我们不能都很好的记忆，对于linux也是一样的，如果root密码忘记了怎么办？岂不是都无法登陆使用Linux了？现在我就教各位，在不知道root密码的前提下，如何给root设置一个新的密码 step 1 重启你的linux系统，在下图这个界面中按“E” image20200112153327155.png step 2 将光标移动到开头为linux这行的行位，删除rhgb quiet并添加rd.break image20200112153507293.png step 3 按键盘上的ctrl+x组合键继续启动linux，等待出现提示符后执行mount命令 image20200112153640666.png step 4 执行chroot命令将根目录切换为&#x2F;sysroot(因为硬盘上的数据都存放在&#x2F;sysroot目录中) image20200112153755987.png step 5 看到提示符发生变化后执行passwd命令修改root密码 image20200112153933632.png 注：由于字符编码问题可能会出现不能正常显示的情况，如： 启动流程.assets/image-20200112154028844.png image-20200112154028844没有关系，不影响密码的设置 step 6 修改完密码之后，建立autorelabel文件 image20200112154548103.png step 7 输入两次exit退出，系统会继续启动 image20200112154627704.png 启动完成之后就可以用我们刚才设置的账号及密码进行登录了 二、GRUB2加密前面我们知道了，如果不知道root密码的话，也是可以以root身份登录系统，那这样岂不是很危险？所以GRUB2又提供了一种保护机制，这种保护机制就是为grub2设置密码，如果用户不知道这个密码，是无法编辑启动时所看到的那个菜单的，这样也就组织了root密码被修改的问题，那么如何为grub2加密呢？ setp 1 以root用户的身份登录系统并打开终端，在终端中输入grub2-setpassword命令，系统就会提示我们设置一个密码，这个密码就是grub2的密码 image20200112155155252.png step 2 重启系统，验证是否加密成功 image20200112155226916.png step 3 在启动菜单界面按”E”编辑内容时，系统会提示输入用户名和密码，这个用户名是root，密码就是我们前面设置的grub2密码 image20200112155403705.png 注意：密码在输入的时候是不会显示任何信息的 step 4 如果密码输入错误就会返回启动菜单界面 image20200112155529537.png 三、删除&#x2F;修改GRUB2密码前面我们学会了如何为grub2设置密码，这样能有效的避免root用户密码被修改，但是如果我忘记了grub2的密码怎么办呢？ 如果忘记了grub2密码，你可以让系统正常启动，然后用root用户登录系统，登录完成后使用grub2-setpassword命令重新设置一个grub2密码，或者删除&#x2F;boot&#x2F;grub2&#x2F;user.cfg文件将密码删除。 但是如果连root密码也不知道呢？这个时候，我们就需要用到修复模式了 step 1 插入系统光盘，选择从光盘启动 image20200112160255030.png step 2 选择故障排除（troubleshooting） image20200112160449625.png step 3 选择修复系统 image20200112160639592.png step 4 启动完成后，系统提示我们，修复模式会查找硬盘上是否安装有Linux系统，并将其挂载到&#x2F;mnt&#x2F;sysimage目录下，我们希望它如何操作，选择1是以读写的形式挂载，选择2是以只读的形式挂载，选择3是直接获取一个shell，选择4是重启，这里面我们选择1 image20200112161205845.png step 5 稍微等一下之后系统会提示我们已经挂载到&#x2F;mnt&#x2F;sysimage目录下了，按“enter”会得到一个shell image20200112161319135.png step 6 执行chroot &#x2F;mnt&#x2F;sysimage将工作目录切换到硬盘中 image20200112161421279.png step 7 接下来就像没有忘记root密码一样，可以重新设置grub2密码，或者删除user.cfg文件了，然后输入两次exit重启 image20200112161615836.png image20200112161628253.png","categories":["Linux","Linux系统管理宝典"]},{"title":"Linux命令行介绍","path":"/2023/09/27/Linux系统管理宝典/Linux-命令行介绍/","content":"Linux命令行介绍 阅读 (246299) 分享 一、命令行的介绍命令行界面（英语：command-line interface，缩写：CLI）是在图形用户界面得到普及之前使用最为广泛的用户界面，它通常不支持鼠标，用户通过键盘输入指令，计算机接收到指令后，予以执行。也有人称之为字符用户界面CUI。通常认为，命令行界面（CLI）没有图形用户界面GUI那么方便用户操作。因为，命令行界面的软件通常需要用户记忆操作的命令，但是，由于其本身的特点，命令行界面要较图形用户界面节约计算机系统的资源。在熟记命令的前提下，使用命令行界面往往要较使用图形用户界面的操作速度要快。所以，图形用户界面的操作系统中，都保留着可选的命令行界面。另外Linux 系统的优势基因还是快速、批量、自动化、智能化管理系统及处理业务。和Windows系统使用鼠标点击的可视化管理大不相同 ，Linux通过键盘输入指令就可以完成管理系统的相关操作。说完命令行，我们来看下命令提示符 二、命令提示符的介绍当我们打开终端时，不论是在图形界面还是在字符界面，我们看到的格式都是类似于[root@localhost ~]#这种格式的一串字符，这串字符就是命令提示符 1570783019496.png 提示符组成详解： 123456789root：当前用户的名称@：分隔符localhost：当前主机的主机名~：用户当前所在的目录名称 “~”表示为用户家目录（发音tilde[ˈtɪldə]）#： 用户身份提示符，#表示超级用户，也就是管理员；$表示普通用户 (发音pound[paʊnd]) 三、命令的语法格式命令+选项+操作对象这三部分是组成了一个标准的linux命令，其中命令部分需要输入命令的名称；选项部分定义命令的执行特性，可以有长短两种选项，长选项用“ –” （发音dash[dæʃ]）引导，后面跟完整的单词，如 –help；短选项用 ‘- ’引导，后面跟单个的字符， 如 -a 。多个短选项可以组合使用，例如：-h -l -a &#x3D;&#x3D; -hla，但是长选项不能组合使用，如 –help后面就不能再跟另外一个单词了。 1570784712025.png 但是大家需要注意，命令与选项，选项与选项，选项与操作对象，操作对象与操作对象他们之间是必须用空格分隔！至于操作对象就是图片中的&#x2F;boot，操作对象是可以有多个的 1570784853770.png 语法格式我们就介绍完了，咱们接着往下看 四、如何高效的输入命令想提高命令的输入效率除了要提升命令的熟练度之外，还要掌握我们上节课所学的快捷键，这样能让你在输入命令是更得心应手。那如何提升命令熟练度呢？ 就要会查看命令的说明，只有看懂了才能记住，记住了才能熟练 使用tab键查询或补全 4.1、如何快速获取命令的帮助说明在linux中获取命令的帮助说明的途径很多，这里面给大家简单介绍几个 a、help命令可以帮助我们获取到内建命令的使用帮助 1570785422297.png b、–help参数 1570785480088.png c、man手册 1570785620561.png 以上这是三种获取帮助的方式，另外还有info、whatis等也可以获取帮助，各位还可以通过一些在线查询工具获取到相关命令的帮助！ 4.2、Tab键模糊查询命令a、命令模糊查找：如果你命令记不住了，大概能记得个开头，你可以使用： 命令开头字符+两次tab键找到所有以该命令开头字符的命令，然后就能找到了！ 命令模糊查找.gif b、命令补全： 当你打命令的时候，一般情况下你打出命令的前3-5个字符按一下tab就可以完成命令补全，补全的前提是你打的这些字符可以直接匹配到这个命令。","categories":["Linux","Linux系统管理宝典"]},{"title":"Linux基本优化","path":"/2023/09/27/Linux系统管理宝典/Linux-基本优化/","content":"一、selinux和防火墙优化1、SElinuxselinux 安全增强型 Linux（Security-Enhanced Linux）简称 SELinux，它是一个 Linux 内核模块，也是 Linux 的一个安全子系统。SELinux 主要由美国国家安全局开发。它的主要 作用就是最大限度地减小系统中服务进程可访问的资源（最小权限原则）。也由于它的这个原则，导致我们很多操作无法正确的执行，所以对于初学者而言在会用selinux之前我们要把这个子系统关闭 SELinux 的工作模式 SELinux 有三种工作模式，分别是： 12345- enforcing：强制模式。违反 SELinux 规则的行为将被阻止并记录到日志中。- permissive：宽容模式。违反 SELinux 规则的行为只会记录到日志中。一般为调试用。- disabled：关闭 SELinux。 SElinux工作模式设置方法 临时设置 enforcing 和 permissive 模式可以通过 setenforce 1|0 命令快速切换,重启系统后失效。 永久生效 SELinux 工作模式可以在 &#x2F;etc&#x2F;selinux&#x2F;config 中设定。 1如果想从 disabled 切换到 enforcing 或者 permissive 的话，需要重启系统。反过来也一样。 需要注意的是，如果系统已经在关闭 SELinux 的状态下运行了一段时间，在打开 SELinux 之后的第一次重启速度可能会比较慢。因为系统必须为磁盘中的文件创建安全上下文，我们现在来看一下如何关闭selinux，首先用root的身份登录系统，打开一个终端输入gedit &#x2F;etc&#x2F;selinux&#x2F;config命令，回车之后会打开一个文件，将所标记出来部分的enforcing改为disabled，保存之后重启linux系统 123456789101112131415[root@zutuanxue ~]# gedit /etc/selinux/config##/etc/selinux/config 内容# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=enforcing #这里定义selinux是否为开启状态# SELINUXTYPE= can take one of these three values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection.SELINUXTYPE=targeted #这里定义的是selinux保护级别 重启登录之后可以使用sestatus -v命令去查看是否成功，如果看到的状态不是disabled则需要重新操作 12[root@zutuanxue ~]# sestatus -vSELinux status: disabled 2、防火墙防火墙技术是通过有机结合各类用于安全管理与筛选的软件和硬件设备，帮助计算机网络于其内、外网之间构建一道相对隔绝的保护屏障，以保护用户资料与信息安全性的一种技术。 在CentOS8中使用firewalld作为防火墙，基于iptables的防火墙被默认不启动，但仍然可以继续使用。CentOS8中有几种防火墙共存：firewalld、iptables、ebtables等，默认使用firewalld作为防火墙，通过firewall-cmd工具来管理netfilter,不过底层调用的命令仍然是iptables，虽然防火墙是安全软件，但是它的一些默认设置会对初学者造成困扰，所以我们要先关闭firewalld。通过systemctl stop firewalld.service停止防火墙，systemctl disable firewalld.service禁止防火墙服务开机启动，接下来我们看一下如何设置中文 1571044294838.png 二、中文设置优化我们在安装系统选择的是中文，但是我们系统当中并没有中文输入法，所以如果要想输入中文的话需要添加中文输入法，以root用户身份登录系统之后我们使用gedit &#x2F;etc&#x2F;yum.repos.d&#x2F;server.repo,输入如下内容保存退出，确保虚拟机的光驱中加载的是CentOS8的光盘镜像，并且已连接 1571048414719.png 1571047694890.png 设置完成之后执行mkdir命令建立目录，然后挂载光盘 1571047821170.png 光盘挂载完成之后执行输入法安装命令，如果只要拼音则安装的是： ibus-libpinyin.x86_64 12345# 安装所有支持的输入法[root@zutuanxue ~]# dnf install ibus* -y# 或者 精准安装拼音输入法[root@zutuanxue ~]# dnf install ibus-libpinyin.x86_64 -y 等待软件包安装完成之后重启系统然后重新登录 12345如果不想重启系统可以使用[root@zutuanxue ~]# ibus restart 命令重启ibus-daemon进程来实现 1571048752409.png 安装完成之后点击右上角的按钮然后点击设置 1571048826875.png 在新打开的窗口中找到语言，选择添加，选择汉语，然后选择一个适合自己的中文输入法点击添加之后就可以使用中文输入法了 1571048904227.png 1571049215146.png 1571049244944.png 输入法设置完成之后，我们来看下时间相关的设置 三、网络时间服务器优化如果系统的时间不准，自己手动设置起来比较麻烦，我们可以看下怎么来优化一下 同样还是找到设置，在里面找到详细信息，展开之后可以看到日期和时间的设置，两个自动设置的选项打开，如果你的虚拟机可以联网的话，过一会就会看到时间正常了 1571049564017.png 1571049605979.png 1571049727212.png 四、自启动服务优化自启动服务优化的方式类似我们之前提到的停止firewalld，但是首先我们要确认一下有哪些服务是开机启动的，然后利用之前用过的systemctl stop servername和systemctl disabled servername这两条命令停止相应的服务，比如说蓝牙服务和防火墙服务，但是各位需要注意的是，这里面所涉及的服务在你不了解的前提下不要乱停止，否则可能会导致系统功能失灵，甚至是崩溃 1571050099841.png","categories":["Linux","Linux系统管理宝典"]},{"title":"linux基本权限","path":"/2023/09/27/Linux系统管理宝典/Linux-基本权限/","content":"Linux系统是一个典型的多用户操作系统，不同的用户处于不同的地位，为了保护系统的安全性，linux系统对于不同用户访问同一个文件或目录做了不同的访问控制。而这种控制就是通过权限实现的，本节课我们介绍linux权限的使用 一、基本权限的介绍Linux中每个文件或目录都有3个基本权限位，控制三种访问级别用户的读、写、执行，所以linux的基本权限位一共有9个。基本权限位和另外3个可以影响可执行程序运行的3个特殊权限位一起构成了文件访问模式。三个属性规定了对应三种级别的用户能够如何使用这个文件，这三个基本权限位对于文件和目录的含义有所差别的，我们一起来看一下 字符 权限 对文件的含义 对目录的含义 r 读 意味着我们可以查看阅读 可以列出目录中的文件列表 w 写 意味着，对文件可以修改或删除 可以在该目录中创建、删除文件 x 执行 如果是文件就可以运行，比如二进制文件或脚本。 可以使用cd命令进入该目录 那三种访问级别都有哪些呢？每个文件都有三组不同的读、写和执行权限，分别适用于三种访问级别，其中每组中的三个栏位分别使用读取权限（r）、写入权限（w）、执行权限（x）或没有相应的权限（-）来表示，共9位来表示。 1571370358704.png 第一组：适用于文件的属主，图中属主的权限是rwx。 第二组：适用于文件的属组，图中属组的权限是r-x。 第三组：使用于其它用户权限位，图中其它用户权限位是r-x。 当有人试图访问一个文件的时候，linux系统会按顺序执行如下步骤： （1）使用者拥有这个文件吗？如果是，启用用户权限。 （2）用户是组所有者成员吗？如果是，启用组权限 （3）如果以上两个都不是，启用其它人权限 上面我们提到的是第一种表示方法，在linux中还有另外一种表示方法，八进制表示法，我们来看下字母和八进制表示方法的对应关系 字符表示法 八进制表示法 含义 r 4 读 w 2 写 x 1 执行 所以上面给出的权限rwxr-xr-x换成数字的表示方式就是755，那权限如何设置呢？ 二、基本权限的设置和查看通过前面的学习我们知道，用户分为所有者，所有者组，其他人这三类，而每一类有包含三种基本权限，他们的对应关系是 权限位 含义 属主权限位 用于限制文件或目录的创建者 属组权限位 用于限制文件或目录所属组的成员 其它用户的权限 用于限制既不是属主又不是所属组的能访问该文件或目录的其他人员 当我们使用命令来查看文件或目录时，会看如下内容 123456789101112[root@zutuanxue ~]# ls -l总用量 13804drwxr-xr-x. 2 root root 6 10月 11 06:36 公共drwxr-xr-x. 2 root root 6 10月 11 06:36 模板drwxr-xr-x. 2 root root 6 10月 11 06:36 视频drwxr-xr-x. 2 root root 6 10月 11 06:36 图片drwxr-xr-x. 2 root root 6 10月 11 06:36 文档drwxr-xr-x. 2 root root 6 10月 11 06:36 下载drwxr-xr-x. 2 root root 6 10月 11 06:36 音乐drwxr-xr-x. 2 root root 6 10月 11 06:36 桌面-rw-------. 1 root root 1214 10月 11 06:12 anaconda-ks.cfg-rw-r--r--. 1 root root 1369 10月 11 06:17 initial-setup-ks.cfg 每一行显示一个文件或目录的信息，这些信息包括文件的类型（1位）、文件的权限(9位)、文件的连接数、文件的属主（第3列）、文件的所属组（第4列），大小以及相关时间和文件名。其中Linux 文件的权限标志位九个，分为3 组，分别代表文件拥有者的权限，文件所属用户组的权限和其它用户的权限，现在我们知道文件有三种权限（（r）读取、（w）写入和（x）执行）和三种访问级别（（u）用户、（g）主要组和（o）其它人）决定文件可以被如何使用。那如何修改？ chmod命令:修改文件权限 1571375694210.png 缩写 含义 u User(用户) g Group (组) o Other(其它) a All(所有) + Add(加) - Remove(减去) &#x3D; Set (设置) r Read (可读) w Write (可写) x Execute (执行) 命令 作用 结果权限 chmod o-r a.file 取消其他人的可读权限 rw-rw— chmod g-w a.file 取消组的写入权限 rw-r–r– chmod ug+w a.file 赋予用户和组写入权限 rwxrwxr– chmod o+w a.file 赋予其他人写入权限 rw-rw-rw- chmod go-rwx a.file 取消组和其他人的阅读、写入和执行权限 rw——- chmod a-w a.file 取消所有人的写入权限 r– r– r– chmod uo-r a.file 取消用户和其它人的阅读权限 -w-rw–w- chmod go&#x3D;rw a.file 将组和其他人的权限设置为阅读和写入 rw-rw-rw- 使用数字的表示方式类似chmod 755 a,执行完成后a这个文件的权限对应就是 -rwxr-xr-x,这是文件权限的两种修改方式，如果你想修改文件的所有者和所有者组需要使用的命令就是chown,chgrp chown命令:改变文件或文件夹的所有者 1234567[root@zutuanxue test]# ll总用量 0-rw-r--r-- 1 root root 0 10月 18 01:26 file1[root@zutuanxue test]# chown oracle file1[root@zutuanxue test]# ll总用量 0-rw-r--r-- 1 oracle root 0 10月 18 01:26 file1 chgrp命令: 改变文件或文件夹属组 1234[root@zutuanxue test]# chgrp oracle file1[root@zutuanxue test]# ll总用量 0-rw-r--r-- 1 oracle oracle 0 10月 18 01:26 file1 这里，我们涉及到了三条与权限修改相关的命令 操作 可以执行的用户 chmod Root用户和文件的所有者 chgrp Root用户和文件的所有者（必须是组成员） chown 只有root用户 以上是三种基本权限 -R 三、文件或目录的默认权限每一个新产生的文件都会有一个默认的权限，这个权限是通过系统中的umask来控制的 文件的最大权限是666 目录的权限是777 使用umask查看","categories":["Linux","Linux系统管理宝典"]},{"title":"linux密码管理","path":"/2023/09/27/Linux系统管理宝典/Linux-密码管理/","content":"账号犹如一张通行证，有了账号你才能顺利的使用Linux。不过 Linux 怎么确认使用某账号的人，是这个账号的真正拥有者呢？此时Linux 会根据用户的密码，来确认用户的身份。Linux 的用户账号与群组账号都可设置密码。用户账号的密码用来验证用户的身份；而群组账号的密码则是用来确认用户是否为该群组的成员，以及确认是否为该群组的管理者。 在 Linux 中，使用 useradd 新建一个用户账号时，useradd 会锁定用户的密码，如此一来，用户暂时不能使用 。你必须要修改其密码后，新建的用户才能用他的账号登录。要修改用户账号的密码需要使用passwd命令 passwd命令 123456789101112命令介绍\t修改用户密码命令语法\tpasswd [选项] 用户命令选项-d 删除用户密码，亦即把文件中的密码字段清空。-l 这个参数用来锁定账号，账号一经锁定，用户再怎样输入密码，都会被判断为错误。这个参数只能由 root 使用，普通用户无法用来锁定自己的账号。-u 解锁用户 除了可以修改用户账号的密码外，你也可以为每一个群组设置一个密码，这个密码称为群组密码（Group Password）。Linux 的用户，可以通过 newgrp 暂时修改其主要群组的身份。执行 newgrp 时，会以指定的群组身份，开启一个登录 Shell，这样就可以获得暂时修改主要群组之功效。此时，如果该群组没有指定密码，那么 Linux 只允许群组的成员可以使用 newgrp修改主要群组的身份；如果群组设置了密码，群组成员仍可以不用密码就可切换主要群组身份，但非群组的成员，则必须要提供正确的密码才行。 gpasswd命令 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253命令介绍\t修改组密码,对群组管理命令选项-r 用来删除群组的密码。-R 锁定 GROUP 的群组密码。-A 设置组管理员-a 添加组成员到组-d 从组中 删除组成员命令用法指派群组管理员，如果有多个管理员用“，”分隔，如果想删除群组管理员，保持位置为空组管理员用法案例创建组admin[root@zutuanxue ~]# groupadd admin创建用户 ztxa ztxb ztxc[root@zutuanxue ~]# useradd ztxa[root@zutuanxue ~]# useradd ztxb[root@zutuanxue ~]# useradd ztxc设置ztxa为admin组的组管理员[root@zutuanxue ~]# gpasswd -A ztxa admin切换到ztxa 将ztxb ztxc加入 admin组[root@zutuanxue ~]# su - ztxa -c &quot;gpasswd -a ztxb admin&quot;正在将用户“ztxb”加入到“admin”组中[root@zutuanxue ~]# su - ztxa -c &quot;gpasswd -a ztxc admin&quot;正在将用户“ztxc”加入到“admin”组中切换到ztxa 从admin组中删除ztxc[root@zutuanxue ~]# su - ztxa -c &quot;gpasswd -d ztxc admin&quot;正在将用户“ztxc”从“admin”组中删除","categories":["Linux","Linux系统管理宝典"]},{"title":"Linux基本命令与常用符号","path":"/2023/09/27/Linux系统管理宝典/Linux-基本命令与常用符号/","content":"一、常用命令介绍在linux系统中存在很多命令，这些命令可以帮助我们完成不同的工作，在这里面我们先介绍一些常用的基础命令，这些命令可以帮助我们完成对应的基本操作，随着以后的学习，我们还会接触到更多可以帮助我们完成不同工作的linux命令，我们来一起看一下这些基础命令都有哪些 1、关机、重启命令 关机命令 init 0 #管理员可以使用 halt shutdown -h poweroff 重启命令 shutdown -r reboot shutdown -r 强烈推荐：关机或重启命令及步骤 12345678910111213141516171） sync：将缓冲区的数据同步到磁盘中(关机，重启前都需要执行，避免数据丢失)，在Linux系统中，当数据需要存入磁盘时，通常会先放到缓冲区内，等到适当的时刻再写入磁盘，如此可提高系统的执行效率2） shutdown： 以一种安全的方式关闭或重启系统。所有登陆用户都可以看到关机信息提示，并且禁止登陆\t-k\t并非真正关机，只向所有人显示警告信息。 如：shutdown -k +5\t-r\t重启。默认延迟一分钟 如：shutdown -r +3 &quot;shutdown in 3 minutes&quot;\t-h\t关机。默认延迟一分钟 如：shutdown -h 12：00/shutdown -h now\t-f\t重启时跳过磁盘检测。\t-F\t重启时强制磁盘检测。\t-c\t取消shutdown推荐理由：1、将内存中的数据刷入硬盘，避免因为重启或关机数据没有及时保存而丢失2、避免多用户使用突然某个用户强行关机，影响其他用户，使用shutdown关机和重启可以通知其他用户，给予缓冲时间 2、系统信息 uname 123456789-s 输出内核名称-n 输出网络节点上的主机名-r 输出内核发行号-v 输出内核版本-m 输出主机的硬件架构名称-p 输出处理器类型或&quot;unknown&quot;-i\t输出硬件平台或&quot;unknown&quot;-o\t输出操作系统名称-a 以如下次序输出所有信息。其中若-p和-i的结果不可知则省略 hostname 查看主机名 1# hostnamectl set-hostname hello date 查看和设置时间 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768时间方面：%n : 下一行%t : 跳格 tab%H : 小时(00..23)%I : 小时(01..12)%k : 小时(0..23)%l : 小时(1..12)%M : 分钟(00..59)%p : 显示本地 AM 或 PM%r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M)%s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数%S : 秒(00..60)%T : 直接显示时间 (24 小时制)%X : 相当于 %H:%M:%S%Z : 显示时区日期方面：%a : 星期几 (Sun..Sat)%A : 星期几 (Sunday..Saturday)%b : 月份 (Jan..Dec)%B : 月份 (January..December)%c : 直接显示日期与时间%d : 日 (01..31)%D : 直接显示日期 (mm/dd/yy)%h : 同 %b%j : 一年中的第几天 (001..366)%m : 月份 (01..12)%U : 一年中的第几周 (00..53) (以 Sunday 为一周的第一天的情形)%w : 一周中的第几天 (0..6)%W : 一年中的第几周 (00..53) (以 Monday 为一周的第一天的情形)%x : 直接显示日期 (yyyy-mm-dd)%y : 年份的最后两位数字 (00.99)%Y : 完整年份 (0000..9999)[root@zutuanxue ~]# date &#x27;+%I%M%S&#x27;025929[root@zutuanxue ~]# date &#x27;+%r&#x27;上午 02时59分49秒[root@zutuanxue ~]# date &#x27;+%s&#x27;1584428402[root@zutuanxue ~]# date &#x27;+%Z&#x27;EDT[root@zutuanxue ~]# date &#x27;+%a&#x27;二[root@zutuanxue ~]# date &#x27;+%A&#x27;星期二[root@zutuanxue ~]# date &#x27;+%b&#x27;3月[root@zutuanxue ~]# date &#x27;+%B&#x27;三月[root@zutuanxue ~]# date &#x27;+%c&#x27;2020年03月17日 星期二 03时01分36秒[root@zutuanxue ~]# date &#x27;+%T%n%D&#x27;03:03:3503/17/20[root@zutuanxue ~]# date &#x27;+%T%t%D&#x27;03:03:58\t03/17/20[root@zutuanxue ~]# date -s 2021-10-252021年 10月 25日 星期一 00:00:00 EDT[root@zutuanxue ~]# date -s 18:002021年 10月 25日 星期一 18:00:00 EDT[root@zutuanxue ~]# date -s 18:30:212021年 10月 25日 星期一 18:30:21 EDT[root@zutuanxue ~]# date -s &quot;2021-04-28 15:30:20&quot;2021年 04月 28日 星期三 15:30:20 EDT 3、文件和目录 cd 目录 进入目录 pwd： 查看当前的工作路径 1234567891011121314-P 显示实际位置-L 显示所在位置[root@zutuanxue ~]# cd /etc #进入到/etc这个目录[root@zutuanxue ~]# cd /[root@zutuanxue /]# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var[root@zutuanxue /]# cd bin/[root@zutuanxue bin]# pwd/bin[root@zutuanxue bin]# pwd -P/usr/bin[root@zutuanxue bin]# pwd -L/bin ls： 查看当前目录下有哪些文件 12345678910111213141516171819202122232425262728293031-a 列出目录下的所有文件，包括以 . 开头的隐含文件。-A 显示除 “.”和“..”外的所有文件。-B 不输出以 “~”结尾的备份文件。-c 与lt一起使用，显示并按照修改时间（ctime）排序，与l一起使用，显示修改时间，按名称排序。-d 将目录象文件一样显示，而不是显示其下的文件。-f 对输出的文件不排序，使用此选项后aU选项生效，lst选项失效-F 在每个文件名后附上一个字符以说明该文件的类型，“*”表示可执行的普通文件；“/”表示目录；“@”表示符号链接；“|”表示FIFOs；“=”表示套接字(sockets)。-g 类似l但是不显示所有者-h 与l一起，以易于阅读的格式输出文件大小(例如 1K 234M 2G)-i 输出文件的i节点的索引信息。-k 以k字节的形式表示文件的大小。--si类似k但是以1000为进制而非1024-l 列出文件的详细信息。-L 遇到链接文件是，显示原文件的信息，而非链接信息-m 横向输出文件名，并以“，”作分格符。-n 类似l,但是用数字的 UID,GID 代替名称。-o 显示文件的除组信息外的详细信息。-p 目录后面加上/标识-q 用?代替不可输出的字符。-r 对目录反向排序。-s 在每个文件名后输出该文件的大小。-t 以修改时间排序。-u 与lt一起使用，以访问时间(atime)排序；与l一起使用显示访问时间，按照名称排序-x 按列输出，横向排序。-Q 把输出的文件名用双引号括起来。-R 列出所有子目录下的文件。-S 以文件大小排序。-X 以文件的扩展名(最后一个 . 后的字符)排序。-1 一行只输出一个文件。--color=no 不显示彩色文件名--help 在标准输出上显示帮助信息。--version 在标准输出上输出版本信息并退出。 mkdir 建立目录 1234-m\t设置权限模式(类似chmod)-p\t需要时创建目标目录的上层目录，但即使这些目录已存在也不当作错误处理-v\t每次创建新目录都显示信息-Z\t将每个创建的目录的SELinux 安全环境设置为CTX rmdir 删除空文件夹 1-p 递归删除空目录，从最后一个目录倒删 touch 建立文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566-a\t只更改访问时间-c\t不创建任何文件-m\t只更改修改时间-r\t使用指定文件的时间属性替代当前时间-t\t使用[[CC]YY]MMDDhhmm[.ss] 格式的时间替代当前时间[root@zutuanxue ~]# stat hello 文件：hello 大小：0 块：0 IO 块：4096 普通空文件设备：fd00h/64768d\tInode：34502264 硬链接：1权限：(0644/-rw-r--r--) Uid：( 0/ root) Gid：( 0/ root)最近访问：2020-03-17 16:51:35.502961371 -0400最近更改：2020-03-17 16:51:35.502961371 -0400最近改动：2020-03-17 16:51:35.502961371 -0400创建时间：-[root@zutuanxue ~]# touch -a -t 202002010101.30 hello[root@zutuanxue ~]# stat hello 文件：hello 大小：0 块：0 IO 块：4096 普通空文件设备：fd00h/64768d\tInode：34502264 硬链接：1权限：(0644/-rw-r--r--) Uid：( 0/ root) Gid：( 0/ root)最近访问：2020-02-01 01:01:30.000000000 -0500最近更改：2020-03-17 16:51:35.502961371 -0400最近改动：2020-03-17 16:51:53.143475189 -0400创建时间：-[root@zutuanxue ~]# touch -m -t 202002050101.30 hello[root@zutuanxue ~]# stat hello 文件：hello 大小：0 块：0 IO 块：4096 普通空文件设备：fd00h/64768d\tInode：34502264 硬链接：1权限：(0644/-rw-r--r--) Uid：( 0/ root) Gid：( 0/ root)最近访问：2020-02-01 01:01:30.000000000 -0500最近更改：2020-02-05 01:01:30.000000000 -0500最近改动：2020-03-17 16:52:07.837453512 -0400创建时间：-#将hello-linux.txt的属性改成与anaconda-ks.cfg一样[root@zutuanxue ~]# stat hello-linux.txt 文件：hello-linux.txt 大小：12 块：8 IO 块：4096 普通文件设备：fd00h/64768d\tInode：34513350 硬链接：1权限：(0644/-rw-r--r--) Uid：( 0/ root) Gid：( 0/ root)最近访问：2020-03-17 22:50:51.319377144 -0400最近更改：2020-03-17 22:50:45.909483733 -0400最近改动：2020-03-17 22:50:45.912483674 -0400创建时间：-[root@zutuanxue ~]# stat anaconda-ks.cfg 文件：anaconda-ks.cfg 大小：1378 块：8 IO 块：4096 普通文件设备：fd00h/64768d\tInode：34973658 硬链接：1权限：(0600/-rw-------) Uid：( 0/ root) Gid：( 0/ root)最近访问：2020-03-16 23:08:34.121427663 -0400最近更改：2020-02-04 15:01:33.273959663 -0500最近改动：2020-03-18 16:33:48.873881970 -0400创建时间：-[root@zutuanxue ~]# touch -r anaconda-ks.cfg hello-linux.txt [root@zutuanxue ~]# stat hello-linux.txt 文件：hello-linux.txt 大小：12 块：8 IO 块：4096 普通文件设备：fd00h/64768d\tInode：34513350 硬链接：1权限：(0644/-rw-r--r--) Uid：( 0/ root) Gid：( 0/ root)最近访问：2020-03-16 23:08:34.121427663 -0400最近更改：2020-02-04 15:01:33.273959663 -0500最近改动：2020-03-18 18:22:48.694597233 -0400创建时间：- cat 查看文件内容 123456789-A\t等价于-vET-b\t对非空输出行编号-e 等价于-vE-E\t在每行结束处显示$-n\t对输出的所有行编号-s\t不输出多行空行-t\t与-vT等价-T\t将跳格字符（tab）显示为 ^I-v\t使用^和M rm 删除文件或目录 12345-f\t强制删除。忽略不存在的文件，不提示确认-i\t在删除前需要确认-I\t超过三个文件或者递归删除前要求确认。比-i提示内容更少-d\t删除空目录-r\t递归删除目录及其内容 这些命令都是初学者可能会经常用到的，大家可以在自己的虚拟机上练习一下 cp 拷贝 12345-i\t覆盖前询问(使前面的 -n 选项失效)-n\t不要覆盖已存在的文件(使前面的 -i 选项失效)-R, -r, --recursive 递归复制目录及其子目录内的所有内容-s\t只创建符号链接而不复制文件-f\t强制，将目标文件无法打开则将其移除并重试 mv 移动&#x2F;改名 1234-f\t覆盖前不询问-i\t覆盖前询问-n\t不覆盖已存在文件#如果您指定了-i、-f、-n 中的多个，仅最后一个生效。 二、常用符号12345678*\t任意字符串?\t任意字符/\t路径间隔符~\t当前用户的家目录\t管理员家目录为/root，其它用户的家目录在/home/用户名","categories":["Linux","Linux系统管理宝典"]},{"title":"linux文件压缩与解压","path":"/2023/09/27/Linux系统管理宝典/Linux-文件压缩与解压/","content":"压缩工具的介绍说到文件管理，就不得不说到tar，因为tar可以压缩和解压缩linux文件，所以要先了解一下压缩和解压缩。 由于以前的计算机磁盘容量比较小，业内人士绞尽脑汁，终于开发出了一个能帮助用户节省磁盘的工具，就是压缩工具，我们知道计算机在存储数据的时候都是使用bytes来计算的，但是实际上1byte&#x3D;8bits，在日常使用中并不是所有的数据都能把这个1byte用完，有的可能用了三个bits，有的可能用了四个bits，而他们的实际占用空间是2bytes&#x3D;16bits，剩余的空间就浪费了，压缩工具就是通过算法，将占用三个bits的数据和占用四个bits的数据放在一个byte里，这样我们就能节省出来1byte，这种空间的节省，当你在压缩一个包含了很多文本文件的目录时是非常明显的。其实就像没有人知道早高峰的公交车里有多少人一样，一个人理论上占用的公交车内的空间，跟实际占用的空间，往往有很大差别，因为挤挤总能上去的。 压缩工具诞生的初衷和原理我们说完了，那现在它就没用了么？依然有用，只不过现在我们使用压缩工具的目的，更多的是便于存储和传输，在linux系统中压缩工具有很多，不同的工具压缩后的后缀名和大小都有差异，从远古时代说起，linux都出现了以下这些格式的压缩文件 *.Z 使用compress压缩的文件 *.zip 使用zip压缩的文件 *.gz 使用gzip压缩 *.bz2 使用bzip2压缩 *.xz 使用xz压缩 *.tar 使用tar工具打包，没有压缩 *.tar.gz 使用tar工具打包，经过gzip压缩 *.tar.bz2 使用tar工具打包，经过bzip2压缩 *.tar.xz 使用tar工具打包，经过xz压缩 其中，compress已经过时了，因为太老，个别版本的linux已经不支持了，linux下的压缩工具还是以gzip和bzip2以及后加入的xz作为主力，但是由于这些工具，最早不能压缩目录，只能针对单一文件进行压缩，所以在日常使用中，他们都是配合着tar这个打包工具，由tar把目录中的很多文件打包成一个文件，再经由对应的工具进行压缩，所以我们会看上面的那些tar.*的压缩包。好了我们先来学习下这些压缩工具如何使用 12345压缩文件的好处有如下几点：- 文件更小，便于网络传输，效率高；- 避免杂乱，可以减少文件个数，多个文件一起压缩；- 有些文件不能直接传输，比如安装程序，压缩后就可以传输了 压缩工具的使用 gzip 12345678910111213141516171819202122232425262728293031323334[root@zutuanxue ~]# gzip -hUsage: gzip [OPTION]... [FILE]... -c\t保留源文件 -d\t解压缩 -h\t显示帮助 -t\t检查压缩文件的数据一致性，用来确定压缩文件是否有错误 -v\t显示压缩包的相关信息，包括压缩比等 -V\t显示版本号 -1\t压缩最快，压缩比低 -9\t压缩最慢，压缩比高例子：[root@zutuanxue test]# pwd/root/test[root@zutuanxue test]# cp /etc/services ./[root@zutuanxue test]# gzip -v services services: 79.4% -- replaced with services.gz[root@zutuanxue test]# ll /etc/services services.gz -rw-r--r--. 1 root root 692241 Sep 10 2018 /etc/services-rw-r--r-- 1 root root 142549 Oct 20 23:32 services.gz[root@zutuanxue test]# zcat services.gz 由于service文件本来就是一个文本文档，所以还可以使用zmore，zless去查看内容[root@zutuanxue test]# lsservices.gz[root@zutuanxue test]# gzip -d services.gz [root@zutuanxue test]# lsservices我们可以看到，gzip这个工具压缩文件和源文件默认只保留一个，所以还可以[root@zutuanxue test]# gzip -1 -c services &gt; test.gz[root@zutuanxue test]# lsservices test.gz[root@zutuanxue test]# zgrep -n ssh test.gz 44:ssh 22/tcp # The Secure Shell (SSH) Protocol45:ssh 22/udp # The Secure Shell (SSH) Protocol你也可以使用zgrep找出指定的关键字在压缩文件的那几行 bzip2 123456789101112131415[root@zutuanxue test]# bzip2 -h -h 帮助 -d 解压 -z 压缩 默认值 -k 保留源文件 -v 查看版本信息 -1 ..-9 同gzip相同 bzip2的使用与gzip相同，两种工具的区别就是压缩算法不同，bzip2的压缩比更好一些，bzip的包查看的时候使用的是bzcat,bzmore,bzless,bzgrep同gzip用法相同[root@zutuanxue test]# gzip -c services &gt; services.gz[root@zutuanxue test]# bzip2 -k services[root@zutuanxue test]# ll总用量 948-rw-r--r-- 1 root root 692241 10月 21 01:31 services-rw-r--r-- 1 root root 129788 10月 21 01:31 services.bz2-rw-r--r-- 1 root root 142549 10月 21 01:32 services.gz xz 虽然bzip2的压缩效果相对比gzip已经提升很多，但是技术是永无止境的，于是出现了xz，它的用法跟gzip和bzip2一样 123456789101112131415161718192021222324252627282930313233343536[root@zutuanxue test]# xz -h -d 解压缩 -t 检查压缩文件的完整性 -l 查看压缩文件的相关信息 -k 保留源文件 -c 将信息输出到显示器上 -0 ... -9 指定压缩级别 -h 显示帮助[root@zutuanxue test]# xz -k services[root@zutuanxue test]# ll总用量 1052-rw-r--r-- 1 root root 692241 10月 21 01:31 services-rw-r--r-- 1 root root 129788 10月 21 01:31 services.bz2-rw-r--r-- 1 root root 142549 10月 21 01:32 services.gz-rw-r--r-- 1 root root 105872 10月 21 01:31 services.xz可以看到，在使用默认压缩比压缩的情况下，xz压缩完的文件体积更小[root@zutuanxue test]# xz -l services.xz 查看相关信息Strms Blocks Compressed Uncompressed Ratio Check Filename 1 1 103.4 KiB 676.0 KiB 0.153 CRC64 services.xz[root@zutuanxue test]# xzcat services.xz 查看文件内容[root@zutuanxue test]# xz -d services.xz 解压缩虽然xz的压缩算法更好，但是相对来说时间也比较长[root@zutuanxue test]# time gzip -c services &gt; services.gzreal\t0m0.023suser\t0m0.020ssys\t0m0.003s[root@zutuanxue test]# time bzip2 -k servicesreal\t0m0.047suser\t0m0.043ssys\t0m0.003s[root@zutuanxue test]# time xz -k servicesreal\t0m0.264suser\t0m0.258ssys\t0m0.003s我们可以使用time这个命令去对比一下时间gzip，bzip2，xz的时间分别是0.023,0.047,0.264，可以看到xz所使用的时间是比较长的，而这个时间会跟文件体积成正比，所以这三种压缩方式大家在使用的时候也要把时间成本考虑在内，除非你很富有。 tar 前面我们提到了，大多数压缩工具只能针对单一文件进行操作，如果你要压缩目录的话就会很麻烦，这时候我们可以使用tar这个打包工具，将目录内的多个文件打包成一个文件，再进行压缩。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@zutuanxue test]# tar --help用法: tar [选项...] [FILE]... -C 解压到指定目录 -c 建立tar包 -t 查看tar包内的文件 -x 解压tar包 -p 不修改文件属性 -f 指定文件名称 -j 使用bzip2算法 -J 使用xz算法 -z 使用gzip算法 -P 允许压缩路径中包含有&quot;/&quot; -v 显示详细信息 -?, --help 查看帮助 --exclude\t压缩过程中排除指定的文件例：压缩[root@zutuanxue test]# tar -czf etc.tar.gz etc[root@zutuanxue test]# lsetc etc.tar.gz解压缩[root@zutuanxue test]# lsetc.tar.gz[root@zutuanxue test]# tar -xf etc.tar.gz [root@zutuanxue test]# lsetc etc.tar.gz查看压缩包内容[root@zutuanxue test]# tar -tf etc.tar.gzetc/etc/libreport/etc/libreport/workflows.d/etc/libreport/workflows.d/report_uploader.confetc/libreport/workflows.d/anaconda_event.conf...查询压缩包里面的文件信息[root@zutuanxue test]# tar -tvf etc.tar.gz |moredrwxr-xr-x root/root 0 2019-10-21 04:35 etc/drwxr-xr-x root/root 0 2019-10-21 04:35 etc/libreport/drwxr-xr-x root/root 0 2019-10-21 04:35 etc/libreport/workflows.d/...解压压缩包指定的文件[root@zutuanxue test]# tar -tvf etc.tar.gz | grep shadow---------- root/root 792 2019-10-21 04:35 etc/gshadow---------- root/root 1506 2019-10-21 04:35 etc/shadow---------- root/root 781 2019-10-21 04:35 etc/gshadow----------- root/root 1374 2019-10-21 04:35 etc/shadow--rw-r--r-- root/root 214 2019-10-21 04:35 etc/pam.d/sssd-shadowutils[root@zutuanxue test]# tar -xf etc.tar.gz etc/shadow[root@zutuanxue test]# lsetc etc.tar.gz[root@zutuanxue test]# ls etcshadow","categories":["Linux","Linux系统管理宝典"]},{"title":"linux日志服务器部署","path":"/2023/09/27/Linux系统管理宝典/Linux-日志服务器部署/","content":"集中式日志服务器介绍如果你负责管理数台的 Linux，你得登录每一台Linux 后，才能阅读其中的信息！ 这样是不是很麻烦？？ 那有没有什么更好的方案呢？ Linux 的系统日志服务，允许你把信息传递到某一台 Linux 的系统日志服务中；那你就可以把一台 Linux 作为日志服务器 （Log Server），而其他的 Linux 则当作日志客户端。此时，在作为日志服务器中就可以保存所有日志客户端产生的信息，因此，你就可以在日志服务器中阅读信息，而不用登录到其他的主机了。 搭建流程环境准备：server：192.168.1.55 client：192.168.1.18 关闭SELinux和防火墙12345678关闭SELinux[root@zutuanxue ~]# vim /etc/sysconfig/selinuxSELINUX=disabled[root@zutuanxue ~]# reboot关闭防火墙[root@zutuanxue ~]# systemctl stop firewalld[root@zutuanxue ~]# systemctl disable firewalld 流程setp 1 修改server端rsyslog服务配置文件 12345678server[root@zutuanxue ~]# vim /etc/rsyslog.conf开放通过UDP协议514端口接收日志信息功能 19 module(load=&quot;imudp&quot;) 20 input(type=&quot;imudp&quot; port=&quot;514&quot;)开放通过TCP协议514端口接收日志信息功能 24 module(load=&quot;imtcp&quot;) 25 input(type=&quot;imtcp&quot; port=&quot;514&quot;) step 2 重启server端rsyslog服务 12[root@zutuanxue ~]# systemctl restart rsyslog #重启日志服务[root@zutuanxue ~]# systemctl status rsyslog #确认服务启动状态 step 3 修改client端rsyslog服务配置文件 123456789client[root@zutuanxue ~]# vim /etc/rsyslog.conf 67 *.* @192.168.1.55 #告知客户端将所有日志信息使用UDP协议传送到日志服务器，日志服务器的ip地址为192.168.1.55 68 #*.* @@192.168.1.55 #也可以使用@@告诉客户端将所有日志信息使用TCP协议传送到日志服务器 step 4 重启client端rsyslog服务 12[root@zutuanxue ~]# systemctl restart rsyslog #重启日志服务[root@zutuanxue ~]# systemctl status rsyslog #查看服务状态 step 5 测试 123456789101112server端使用tail命令查看日志信息[root@zutuanxue ~]# tail -f /var/log/messages client使用logger工具产生测试日志[root@zutuanxue ~]# logger &quot;this is a test from 192.168.1.18&quot;如果在server端能查看到logger工具产生的内容就证明集中式日志服务器搭建成功Dec 6 21:18:21 localhost root[2519]: this is a test from 192.168.1.18注：其它的client端的设置都是相同的，这样我们就可以将很多台linux主机的日志信息都收集到一台主机上，方便查阅和后期的日志备份工作。","categories":["Linux","Linux系统管理宝典"]},{"title":"Linux服务介绍","path":"/2023/09/27/Linux系统管理宝典/Linux-服务介绍/","content":"什么是服务？在linux系统中，有一些特殊程序，启动后就会持续在后台执行，等待用户或者其他软件调用使用，这种程序我们称为服务。 linux系统中服务的管理工具 systemV systemd 一、systemV与initsystemV，systemV当中有一个叫init的程序，这个程序可以让系统中的service命令去调用&#x2F;etc&#x2F;init.d&#x2F;目录下的服务脚本，我们可以通过service命令去控制服务的启动与关闭,或者找到服务相应的执行文件，然后执行，比如&#x2F;usr&#x2F;sbin&#x2F;httpd,这样才能启动一个服务，如果想要停止一个服务则需要使用kill命令去停止该服务管理方式从RHEL7之前的系统中默认 init的特点 启动&#x2F;停止&#x2F;查看 &#x2F;etc&#x2F;init.d&#x2F;servername start&#x2F;stop&#x2F;restart&#x2F;status ​ 或 ​service servername start&#x2F;stop&#x2F;restart&#x2F;status 开机启动管理与查看 chkconfig –level 0-6 servername on&#x2F;off 指定一个服务在哪个运行级别启动 chkconfig –list servername 查看一个服务在哪些运行级别启动 分类按照功能分类 系统服务：这些服务的服务对象是linux系统本身，或者linux系统的用户 网络服务：网络服务的服务对象是网络中的其他客户端 按照启动方法分类 独立系统服务：这类服务一经启动，除非系统关闭或者管理者手动结束，否则会一直在后台执行，不管是否用到。由于这类服务一直在后台执行，所以响应速度快，同时也会占用系统资源 临时服务：跟独立的服务不同，临时服务是用到的时候启动，使用完毕后服务会停止，所以临时服务响应速度慢，但是节省系统资源 手动解决服务的依赖关系 服务之间是有依赖关系的，比如说，联网的服务如果想正常运行的话，就必须启动网络服务。而这些服务就需要用户手动去处理 运行级别分类 init会根据用户指定的运行级别，来启动不同的服务，在linux系统中包含了0-6，一共7个运行级别 0 关机 1 单用户 2 无网络的多用户 3 字符模式 4 保留 5 图形模式 6 重启 二、systemd与unit从CentOS7开始SystemV，也就是init服务，被效率更高的systemd所替代，而这个systemd对应的管理命令就是systemctl，并且systemctl命令也兼容了service（service命令做为systemd的入口，是systemctl命令的封装）。 systemd的优势 并行处理所有服务，缩短开机时间 响应速度快，通过systemctl命令就可以完成所有操作 自动解决服务的依赖关系，类似yum 方便记忆，按照类型对服务进行分类 兼容init 相关文件&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F; 服务的启动脚本，包含所有安装完成的服务设置文件 &#x2F;run&#x2F;systemd&#x2F;system&#x2F; 系统运行过程中的服务脚本优先级高于上一个文件 &#x2F;etc&#x2F;systemd&#x2F;system&#x2F; 管理员手动建立的服务启动脚本，优先级最高 &#x2F;etc&#x2F;sysconfig&#x2F;* 系统功能的默认设置 服务分类123456789101112[root@zutuanxue ~]# systemctl -t helpservice 服务单元，用于控制服务socket 套接字单元，用于进程间通信target 目标单元，用于控制一组其它单元device 设备单元，用于控制动态的设备mount 挂载单元，用于管理文件系统挂载点automount 自动挂载单元，用于管理文件系统自动挂载点swap 交换分区单元，用于管理swap设备或swap文件timer 定时器单元，用于管理基于时间触发的动作path 路径单元，用于监视文件系统路径，以用于基于路径的启动slice 范围单元，用于管理与控制一组特定进程的资源占用scope 范围单元，与service类似，系统自动创建","categories":["Linux","Linux系统管理宝典"]},{"title":"linux日志管理","path":"/2023/09/27/Linux系统管理宝典/Linux-日志管理/","content":"一、日志服务的介绍日志介绍程序执行的时候，可以通过标准输出（stdout, Standard Output）与标准错误输出 （stderr, Standard Error Output）来输送信息，用户就可以了解该程序执行时发生了什么状况；可是对于在后台执行的服务器程序，或者Linux 内核本身来说，就没有办法这样做了。服务与内核启动后，会切断与终端机（Terminal） 或控制台（Console）的联机，如此一来，即使有信息通过标准输出、标准错误输出传送出去，用户也未必能从屏幕上看到信息。 更何况，用户根本不可能全天候在计算机前面，盯着屏幕上显示的信息啊！为了让 管理者可以随时监控服务所产生的信息，Linux 提供了一个日志服务，该服务可以收集（Collect）任何服务传递过来的信息，储存成为记录文件（Log File） 、或直接传送给某些用户，甚至也可以传送到其他计算机的系统日志服务。 日志的作用系统方面的问题 linux系统长时间运行，可能会出现一些软件，硬件方面的问题，这些问题都会记录到日志文件中，我们可以通过查看相应的日志文件，找出问题所在 网络服务的问题 网络服务在运行过程中产生的信息都会记录到日志文件中，一旦服务出现问题，无法正常运行，我们可以通过查看相应的日志文件就知道服务出现了什么问题 历史事件查询 由于日志服务每天都会将系统运行的信息保存到日志文件当中，所以我们也可以通过日志信息去追溯之前的系统运行状况 二、相关软件包和文件软件包12345[root@zutuanxue ~]# rpm -qa | grep rsyslogrsyslog-gssapi-8.37.0-9.el8.x86_64rsyslog-relp-8.37.0-9.el8.x86_64rsyslog-8.37.0-9.el8.x86_64rsyslog-gnutls-8.37.0-9.el8.x86_64 相关文件1234567891011配置文件：/etc/rsyslog.conf辅助配置文件：/etc/rsyslog.d/*.conf日志文件存放位置：\t/var/log/执行文件：/usr/sbin/rsyslogd模块路径：/usr/lib64/rsyslog/服务单元：/usr/lib/systemd/system/rsyslog.service 三、配置文件说明&#x2F;etc&#x2F;rsyslog.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[root@zutuanxue yum.repos.d]# grep &#x27;####&#x27; /etc/rsyslog.conf #### MODULES ####定义模块#### GLOBAL DIRECTIVES ####定义全局环境#### RULES ####\t定义规则模块定义module(load=&quot;imuxsock&quot; # 提供对本地系统日志的支持 SysSock.Use=&quot;off&quot;) # 关闭通过本地日志接口的信息接收功能，日志信息接收通过下面的imjournal模块module(load=&quot;imjournal&quot; # 提供对systemd日志的访问 StateFile=&quot;imjournal.state&quot;) # 定义状态文件，rsyslog用于记录文件上传进度，避免日志内容混乱全局环境设置# 定义工作目录global(workDirectory=&quot;/var/lib/rsyslog&quot;)# 使用默认的时间戳格式module(load=&quot;builtin:omfile&quot; Template=&quot;RSYSLOG_TraditionalFileFormat&quot;)# 定义辅助配置文件位置include(file=&quot;/etc/rsyslog.d/*.conf&quot; mode=&quot;optional&quot;)规则设置信息来源.安全级别 处理方式信息来源 kern：内核相关的日志 user：用户相关的日志 mail：邮件相关的日志 daemon：系统服务相关的日志 lpr： 打印相关的日志 cron：计划任务相关的日志 authpriv:认证相关的日志 news：新闻相关的日志 uucp：文件copy相关的日志 local0-local7：自定义相关的日志信息\t*： 所有安全级别 debug: 调试\tinfo: 消息\tnotice: 注意 warn,warning: 警告\terr,error: 错误\tcrit: 严重级别\talert: 需要立即修改该的信息\temerg,panic: 内核崩溃，系统接近崩溃\t*：所有日志级别 none:没有任何级别，也就是不记录日志信息表达形式mail.err err+crit+alert+emergmail.=err errmail.!err 除了err处理方式/PATH/FILENAME：将信息储存至 /PATH/FILENAME文件中。注意，如果要系统日志服务把信息储存到文件，该文件必须以斜线（/） 开头的绝对路径命名之。USERNAME：将信息送给已登录的用户。@HOSTNAME：代表使用udp协议将信息转送到远端的日志服务器。@@hostname：代表使用tcp协议将信息传送到远端的日志服务器*：将信息传送给所有已登录的用户。 常见的日志文件及作用&#x2F;var&#x2F;log&#x2F;boot.log 系统启动时的日志。 &#x2F;var&#x2F;log&#x2F;dnf.* dnf软件包管理器相关日志 &#x2F;var&#x2F;log&#x2F;firewalld 防火墙日志 &#x2F;var&#x2F;log&#x2F;lastlog 所有用户最后一次登录信息,需要使用lastlog命令查看 &#x2F;var&#x2F;log&#x2F;maillog 电子邮件系统相关日志 &#x2F;var&#x2F;log&#x2F;messages 整体的系统日志，具体记录范围取决于服务的配置文件 &#x2F;var&#x2F;log&#x2F;wtmp 记录当前登录和过去登录的用户信息，使用last命令查看 日志文件的安全设置123[root@zutuanxue ~]# chattr +a /var/log/messages [root@zutuanxue ~]# lsattr /var/log/messages -----a------------ /var/log/messages 日志的格式1234567891011121314151617[root@zutuanxue ~]# tail /var/log/messages Dec 6 03:29:09 localhost systemd[1]: Started PackageKit Daemon.Dec 6 03:43:44 localhost systemd[1]: Starting dnf makecache...Dec 6 03:43:44 localhost dnf[7594]: 元数据缓存近期已刷新。Dec 6 03:43:44 localhost systemd[1]: Started dnf makecache.DATE TIME HOSTNAME APP（NAME）[PID]: MESSAGES每一个字段的意义如下说明：DATE：信息发生的日期。TIME：信息发生的时间。HOSTNAME：信息发生的主机。APP：产生信息的软件。NAME：软件的名称，或是软件组件（Component）的名称。可以省略。PID：进程标识符 （Process ID）。可以省略。MESSAGES：信息的内容。 四、日志切割日志切割介绍 随着系统时间使用的增长，日志文件的体积会越来越大，过大的日志文件对于查看或者备份来讲都是极为不便的。所以linux系统提供了一个日志切割工具，这个工具就是logrotate，用户可以用过这个工具对日志文件进行切割，系统也利用这个工具配合计划任务服务，定期的对系统日志进行切割。 相关文件 12/etc/logrotate.conf\t主配置文件，定义日志切割规则/etc/logrotate.d/\t辅助配置文件，可以让用户针对不类型的信息，定义不同的切割规则 主配置文件说明 123456[root@zutuanxue ~]# vim /etc/logrotate.conf weekly\t#定义切割周期为每周一次rotate 4 #默认保留四个文件create #切割完成后，建立一个新的文件继续存储日志信息dateext\t#定义切割后的文件名中要包含日期信息include /etc/logrotate.d #辅助配置文件的存放位置 辅助配置文件说明 12345678910111213141516171819格式日志文件的名称(绝对路径)\t&#123;\t额外的设置&#125;[root@zutuanxue ~]# vim /etc/logrotate.d/syslog /var/log/cron/var/log/maillog/var/log/messages/var/log/secure/var/log/spooler&#123; missingok #如果文件丢失，转到下一个文件，不报告错误信息 sharedscripts #定义执行的脚本，需要与endscript结合使用 postrotate\t#定义执行完logrotate操作之后，执行的操作 /usr/bin/systemctl kill -s HUP rsyslog.service &gt;/dev/null 2&gt;&amp;1 || true #重启日志服务 endscript\t#定义执行的脚本，需要sharedscripts结合使用。&#125; logrotate 1234567891011[root@zutuanxue ~]# logrotate -vf /etc/logrotate.conf #参数说明 v 显示详细信息f 强制切割[root@zutuanxue ~]# logrotate -vf /etc/logrotate.conf[root@zutuanxue log]# cd /var/log/[root@zutuanxue log]# lssecure-20191206 boot.log-20191206 maillog-20191206btmp-20191206 messages-20191206 spooler-20191206wtmp-20191206 cron-20191206 系统如何使用logrotate 1234567891011linux系统通过计划任务去定期的执行切割动作[root@zutuanxue ~]# cat /etc/cron.daily/logrotate#!/bin/sh/usr/sbin/logrotate /etc/logrotate.confEXITVALUE=$?if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate &quot;ALERT exited abnormally with [$EXITVALUE]&quot;fiexit $EXITVALUE此文件定义了如果切割的操作执行成功的话，会调用logger命令记录一条标签为logrotate的日志信息到日志文件里 五、systemd-journald.service很早之前，日志信息是需要等到开机完成并启动日志服务之后才会开始记录的，这种方式会导致开机过程中的信息无法记录，为了避免这种情况，内核用一个叫klogd的服务来记录开机过程中产生的日志信息，然后等到日志服务启动完再将这些信息交给日志服务。 现在linux系统采用systemd来管理系统服务，而systemd又是第一个启动的服务，所以现在我们通过一个systemd自带的，名字叫systemd-journald的服务来协助记录日志信息。那是不是就意味着我们可以不使用rsyslog这个服务了呢？不能，因为systemd-journald服务使用内存来记录相关日志信息，断电之后内容消失，所以我们不能停止rsyslog服务，而且rsyslog服务有一个很重要的功能，可以对日志内容进行分类。 journalctl命令 12345678910111213141516171819systemd-journald提供了一个叫journalctl的工具用来查询它所记录的信息[root@zutuanxue ~]# journalctl -n 显示最后的几行内容，默认为10行 -r 倒序输出，最新的日志先输出 -S/--since\t开始的时间 -U/--until\t结束的时间 -p 指定日志等级0-7，（0=emerg，1=alert，2=crit，3=err，4=warninig，5=notice，6=info，7=debug）如：4代表的就是0-4-f 持续输出，类似于tail的-f\t使用ctrl+c结束--disk-usage\t磁盘空间占用-u 指定单元，如 -u crond.service--vacuum-size\t释放日志文件占用的空间，如\t--vacuum-size 1G_PID=0 查看指定PID的信息_UID=0 查看指定UID的信息 [root@zutuanxue ~]# journalctl --since &quot;YYYY-MM-DD 00:00:00&quot; --until &quot;YYYY-MM-DD 00:00:00&quot;[root@zutuanxue ~]# journalctl --since today[root@zutuanxue ~]# journalctl --since yesterday --until today[root@zutuanxue ~]# journalctl -u crond.service[root@zutuanxue ~]# journalctl _SYSTEM_UNIT=crond.service 六、日志分析工具虽然我们有相关的工具来查看日志信息，但是如果信息量过大的话查看起来也是比较费时的，所以linux系统给我们提供了一个日志分析工具，这个工具叫logwatch，它会每天分析日志信息，并将信息通过邮件的形式发送给root用户 安装logwatch及相关软件包 123456789101112[root@zutuanxue ~]# dnf install logwatch -y[root@zutuanxue ~]# dnf install sendmail -y[root@zutuanxue ~]# systemctl start sendmail[root@zutuanxue ~]# ll /etc/cron.daily/0logwatch -rwxr-xr-x 1 root root 434 5月 11 2019 /etc/cron.daily/0logwatch[root@zutuanxue ~]# /etc/cron.daily/0logwatch [root@zutuanxue ~]# mailHeirloom Mail version 12.5 7/5/10. Type ? for help.&quot;/var/spool/mail/root&quot;: 2 messages 1 new1 logwatch@zutuanxue.l Sat Dec 7 01:50 57/2011 &quot;Logwatch for localhos&quot;&gt;N 2 logwatch@zutuanxue.l Sat Dec 7 01:52 56/2000 &quot;Logwatch for localhos&quot;输入数字查看对应的邮件，输入q退出","categories":["Linux","Linux系统管理宝典"]},{"title":"linux服务管理","path":"/2023/09/27/Linux系统管理宝典/Linux-服务管理/","content":"systemctl命令管理服务我们一起来看一下在服务管理方面systemctl这个工具如何使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101[root@zutuanxue ~]# systemctl start servernamestart 启动服务stop 停止服务restart 重启服务(没启动的服务会启动)try-restart 只重启正在运行的服务(没有运行则不启动)reload 重载配置文件(修改完服务的配置文件后使用)status 检查服务状态is-active 检查服务是否已经启动enable 设置服务开机时启动disable 设置服务开机时不启动is-enabled 查看服务是否开机自动启动mask 屏蔽一个服务unmask 取消屏蔽[root@zutuanxue ~]# systemctl status httpd● httpd.service - The Apache HTTP Server 服务名称 Loaded: loaded\t加载到内存中；error加载失败；bad-setting无法理解单元配置文件中的设置；masked被屏蔽 (/usr/lib/systemd/system/httpd.service; disabled; vendor preset: disabled) 服务开机时是否启动 enabled为启动；disabled为不启动 Active: active (running) since Mon 2019-11-18 15:56:46 CST; 1h 11min ago 服务当前的状态，active(running)为运行；active(exited)运行一次就退出了；active(waiting)运行中，但是再等待其它程序结束才能继续；inactive(dead)为没有运行；activating为启动中，deactivating停止中；failed启动失败 Docs: man:httpd.service(8)\t服务的帮助文档 Main PID: 57779 (httpd)\t服务的主进程号 Status: &quot;Running, listening on: port 80&quot; 额外的状态信息 Tasks: 213 (limit: 24882) 任务数量，含进程+线程 Memory: 22.4M 当前占用的内存 CGroup: /system.slice/httpd.service ├─57779 /usr/sbin/httpd -DFOREGROUND ├─57780 /usr/sbin/httpd -DFOREGROUND ├─57781 /usr/sbin/httpd -DFOREGROUND ├─57782 /usr/sbin/httpd -DFOREGROUND └─57783 /usr/sbin/httpd -DFOREGROUND Control Groups额外信息11月 18 15:56:46 localhost.localdomain systemd[1]: Starting The Apache HTTP Server...11月 18 15:56:46 localhost.localdomain httpd[57779]: AH00558: httpd: Could not reliably determ&gt;11月 18 15:56:46 localhost.localdomain httpd[57779]: Server configured, listening on: port 8011月 18 15:56:46 localhost.localdomain systemd[1]: Started The Apache HTTP Server.例：[root@zutuanxue ~]# systemctl is-active atd\tinactive[root@zutuanxue ~]# systemctl start atd[root@zutuanxue ~]# systemctl status atd● atd.service - Job spooling tools Loaded: loaded (/usr/lib/systemd/system/atd.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2019-11-18 18:36:26 CST; 7s ago Main PID: 60620 (atd) Tasks: 1 (limit: 24882) Memory: 504.0K CGroup: /system.slice/atd.service └─60620 /usr/sbin/atd -f11月 18 18:36:26 localhost.localdomain systemd[1]: Started Job spooling tools.[root@zutuanxue ~]# systemctl stop atd[root@zutuanxue ~]# systemctl status atd● atd.service - Job spooling tools Loaded: loaded (/usr/lib/systemd/system/atd.service; enabled; vendor preset: enabled) Active: inactive (dead) since Mon 2019-11-18 18:36:43 CST; 6s ago Process: 60620 ExecStart=/usr/sbin/atd -f $OPTS (code=exited, status=0/SUCCESS) Main PID: 60620 (code=exited, status=0/SUCCESS)11月 18 18:36:26 localhost.localdomain systemd[1]: Started Job spooling tools.11月 18 18:36:43 localhost.localdomain systemd[1]: Stopping Job spooling tools...11月 18 18:36:43 localhost.localdomain systemd[1]: Stopped Job spooling tools.[root@zutuanxue ~]# systemctl is-enabled atdenabled[root@zutuanxue ~]# systemctl disable atdRemoved /etc/systemd/system/multi-user.target.wants/atd.service.[root@zutuanxue ~]# systemctl is-enabled atddisabled[root@zutuanxue ~]# systemctl enable atdCreated symlink /etc/systemd/system/multi-user.target.wants/atd.service → /usr/lib/systemd/system/atd.service.[root@zutuanxue ~]# systemctl is-enabled atdenabled[root@zutuanxue ~]# systemctl stop atd[root@zutuanxue ~]# systemctl mask atdCreated symlink /etc/systemd/system/atd.service → /dev/null.[root@zutuanxue ~]# systemctl status atd● atd.service Loaded: masked (Reason: Unit atd.service is masked.) Active: inactive (dead)11月 05 18:12:41 localhost.localdomain systemd[1]: Started Job spooling tools.11月 18 18:34:15 localhost.localdomain systemd[1]: Stopping Job spooling tools...11月 18 18:34:15 localhost.localdomain systemd[1]: Stopped Job spooling tools.11月 18 18:36:26 localhost.localdomain systemd[1]: Started Job spooling tools.11月 18 18:36:43 localhost.localdomain systemd[1]: Stopping Job spooling tools...11月 18 18:36:43 localhost.localdomain systemd[1]: Stopped Job spooling tools.[root@zutuanxue ~]# systemctl unmask atdRemoved /etc/systemd/system/atd.service.[root@zutuanxue ~]# systemctl status atd● atd.service - Job spooling tools Loaded: loaded (/usr/lib/systemd/system/atd.service; enabled; vendor preset: enabled) Active: inactive (dead)11月 05 18:12:41 localhost.localdomain systemd[1]: Started Job spooling tools.11月 18 18:34:15 localhost.localdomain systemd[1]: Stopping Job spooling tools...11月 18 18:34:15 localhost.localdomain systemd[1]: Stopped Job spooling tools.11月 18 18:36:26 localhost.localdomain systemd[1]: Started Job spooling tools.11月 18 18:36:43 localhost.localdomain systemd[1]: Stopping Job spooling tools...11月 18 18:36:43 localhost.localdomain systemd[1]: Stopped Job spooling tools 查看服务123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116[root@zutuanxue ~]#systemctl command --type=xxx --alllist-units 查看所有加载到内存中的单元 list-unit-files\t查看系统中所有安装的单元文件（存放在/usr/lib/systemd/system）的启用状态--type=xxx 单元类型--all 列出系统中所有加载的，不管状态为何[root@zutuanxue ~]# systemctl UNIT\tLOAD ACTIVE SUB DESCRIPTION sys.. loaded active plugged /sys.....sys.. loaded active plugged /sys.....sys.. loaded active plugged /sys.....sys.. loaded active plugged /sys.....sys.. loaded active plugged /sys.....sys.. loaded active plugged /sys.....UNIT：\t单元名称LOAD：\t是否被加载ACTIVE：\t高优先级单元状态，与SUB结合就是使用status查看的状态SUB：\t低优先级单元状态 DESCRIPTION：简介[root@zutuanxue ~]# systemctl list-unit-files UNIT\tFILE STATE proc... static -.mount generatedboot.mount generateddev-hugepages.mount\tstatic dev-mqueue.mount static proc-fs-nfsd.mount\tstatic proc-... static sys-f... static sys-... static sys-ke.. static tmp.mount static var-lib.. static var-lib.. static cups.path.. enabled systemd.. static查看指定类型的服务[root@zutuanxue ~]# systemctl --type target --all UNIT LOAD ACTIVE SUB DESCRIPTION basic.target loaded active active Basic System bluetooth.target loaded active active Bluetooth cryptsetup.target loaded active active Local... ● dbus.target not-found inactive dead dbus.target [root@zutuanxue ~]# systemctl --type=target --all UNIT LOAD ACTIVE SUB DESCRIPTION basic.target loaded active active Basic System bluetooth.target loaded active active Bluetooth cryptsetup.target loaded active active Local...● dbus.target not-found inactive dead dbus.target[root@zutuanxue ~]# systemctl list-units --type=target --all UNIT LOAD ACTIVE SUB DESCRIPTION basic.target loaded active active Basic System bluetooth.target loaded active active Bluetooth cryptsetup.target loaded active active Local...● dbus.target not-found inactive dead dbus.target 使用systemctl切换运行级别[root@zutuanxue ~]# systemctl list-units --type target --all UNIT LOAD ACTIVE SUB DESCRIPTION basic.target loaded active active Basic System bluetooth.target loaded inactive dead Bluetooth cryptsetup.target loaded active active Local ..● dbus.target not-found inactive dead dbus.target emergency.target loaded inactive dead Emergency Mode getty-pre.target loaded inactive dead Login.. getty.target loaded active active Login Prompts graphical.target loaded inactive dead Graphica..Interface 常用的targetgraphical.target：图形模式multi-user.target：字符模式rescue.target：救援模式emergency.target：紧急模式，无法进入到救援模式时使用shutdown.target：关机[root@zutuanxue ~]# systemctl get-default\t查看默认运行级别graphical.target [root@zutuanxue ~]# systemctl set-default multi-user.target\t设置 Removed /etc/systemd/system/default.target.Created symlink /etc/systemd/system/default.target → /usr/lib/systemd/system/multi-user.target.[root@zutuanxue ~]# systemctl isolate multi-user.target 切换除了可以使用上述方法设置和查看之外 系统还给我们提供了几个简单的命令，方便操作[root@zutuanxue ~]# systemctl poweroff 关机[root@zutuanxue ~]# systemctl reboot 重启[root@zutuanxue ~]# systemctl suspend 挂起[root@zutuanxue ~]# systemctl hibernate 休眠[root@zutuanxue ~]# systemctl rescue 进入到救援模式[root@zutuanxue ~]# systemctl emergency 进入到紧急模式查看服务之间的依赖关系[root@zutuanxue ~]# systemctl list-dependencies multi-user.target查看multi-user.target依赖谁multi-user.target● ├─atd.service...● ├─basic.target● │ ├─-.mount● │ ├─microcode.service● │ ├─paths.target● │ ├─slices.target● │ │ ├─-.slice● │ │ └─system.slice● │ ├─sockets.target● │ │ ├─avahi-daemon.socket...[root@zutuanxue ~]# systemctl list-dependencies multi-user.target --reverse 查看谁依赖multi-user.targetmulti-user.target● └─graphical.target 服务与端口 我们知道在服务中分为系统服务和网络服务，系统服务是本机使用的，网络服务是给网络中的其它客户端使用的，那其它客户端是如何连接上的网络服务的呢？端口和协议，协议在我们之前的课程中了解过，那端口是什么呢？ 端口：设备与外界通讯的出口，分为虚拟端口和物理端口，物理端口又叫接口，比如电脑中可以插网线的RJ45接口等,而虚拟端口指的就是网络服务使用的通讯接口，是不可见的，这些每个虚拟端口都有一个编号，我们称之为端口号，系统当中有一个文件记录的服务和端口号以及协议的对应关系 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@zutuanxue ~]# cat /etc/services | more服务名称 端口号/协议 描述 ftp-data 20/tcpftp-data 20/udp# 21 is registered to ftp, but also used by fspftp 21/tcpftp 21/udp fsp fspdssh 22/tcp ssh 22/udp telnet 23/tcptelnet 23/udp我们还可以使用netstat工具去查看自己的系统打开了哪些端口[root@zutuanxue ~]# netstat -antulpa 查看所有服务以及对应的端口号n 将输出结果以数字的形式表示，而不是主机名，服务名等t 使用tcp协议u 使用udp协议l 只显示处于监听状态的p 显示程序的名称与进程号c 指定自动更新的间隔时间 秒r 查看路由表信息[root@zutuanxue ~]# netstat -antlup Proto：协议Recv-Q：接收队列，如果接收队列阻塞，可能是受到拒绝服务攻击 Send-Q：发送队列，如果发送队列不能很快清零，可能是有应用向外发送数据包过快，或者对方接收数据包不够快Recv-Q和Send-Q通常应该为0，如果不为0可能意味着有问题，数据包有堆积状态，可以接受短暂的非0状态Local Address：本地的地址和端口号Foreign Address：\t外部地址和状态State： 端口状态 CLOSED 端口未被使用中。 LISTEN 监听中，可以连接 SYN_SEND 处在TCP三次握手期间，已经发送SYN包后，等待对方的ACK包。 SYN_RECV 处在TCP三次握手期间，已经收到SYN包后，进入SYN_RECV状态。 ESTABLISHED\t完成TCP三次握手，进入ESTABLISHED状态。可以进行通信。 FIN_WAIT_1 在TCP四次挥手时，主动关闭端发送FIN包后，进入此状态。 FIN_WAIT_2 在TCP四次挥手时，主动关闭端收到ACK包后，进入此状态。 TIME_WAIT 在TCP四次挥手时，主动关闭端发送了ACK包之后，进入此状态， 等待一段时间，让被动关闭端收到ACK包。 CLOSING 在TCP四次挥手时，主动关闭端发送了FIN包后，没有收到对应的ACK 包，却收到对方的FIN包，此时，进入CLOSING状态。 CLOSE_WAIT 在TCP四次挥手期间，被动关闭端收到FIN包后，进入此状态。 LAST_ACK 在TCP四次挥手时，被动关闭端发送FIN包后，等待对方的ACK包。 UNKNOWN 未知状态PID/Program name： 进程号/程序名称通过netstat命令可以看到自己的linux系统打开了哪些服务及端口号，如果有些端口不想被占用可以关闭相应的网络服务[root@zutuanxue ~]# systemctl list-units --all | grep avahiavahi-daemon.service loaded active running Avahi mDNS/DNS-SD Stack avahi-daemon.socket loaded active running Avahi mDNS/DNS-SD Stack Activation Socket 可以看到这个服务的作用是为内网提供域名解析的[root@zutuanxue ~]# systemctl stop avahi-daemon.service Warning: Stopping avahi-daemon.service, but it can still be activated by: avahi-daemon.socket[root@zutuanxue ~]# systemctl stop avahi-daemon.socket [root@zutuanxue ~]# systemctl disable avahi-daemon.service avahi-daemon.socket Removed /etc/systemd/system/multi-user.target.wants/avahi-daemon.service.Removed /etc/systemd/system/sockets.target.wants/avahi-daemon.socket.Removed /etc/systemd/system/dbus-org.freedesktop.Avahi.service. 服务设置相关文件我们现在知道了服务的管理是通过systemctl，而它的设置文件存放在&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;目录下，但是官方不建议我们修改这个目录下的文件，如果需要修改的话，建议我们修改&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;目录内的相关文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@zutuanxue ~]# yum install dhcp-server[root@zutuanxue ~]# systemctl enable dhcpdCreated symlink /etc/systemd/system/multi-user.target.wants/dhcpd.service → /usr/lib/systemd/system/dhcpd.service.[root@zutuanxue ~]# cd /etc/systemd/system/[root@zutuanxue system]# ls在此目录中包含的文件有三种功能*.service 服务的设置文件*.wants 此单元可选的依赖，启动指定单元后，建议启动此目录内的单元*.requires 此单元必要的依赖，启动指定单元前，需要启动此目录内的单元服务的设置文件[root@zutuanxue system]# vim /etc/systemd/system/multi-user.target.wants/dhcpd.service [Unit] 对于此单元的简介Description=DHCPv4 Server DaemonDocumentation=man:dhcpd(8) man:dhcpd.conf(5)Wants=network-online.target\tAfter=network-online.targetAfter=time-sync.targetUnit部分会出现的常见内容\tDescription 简介\tDocumentation 如何进一步查询相关信息\tWants 与当前单元配合的单元，如果这些单元没有运行，此单元不会启动失败\tAfter 在哪些单元之后启动此单元\tBefor 在哪些单元之前启动此单元\tRequires 当前单元依赖的单元，如果这些单元没有运行，此单元启动失败\tConflicts 哪些单元与此单元冲突[Service]\t这是一个服务还可能是Socket、Timer、Mount等Type=notifyEnvironmentFile=-/etc/sysconfig/dhcpdExecStart=/usr/sbin/dhcpd -f -cf /etc/dhcp/dhcpd.conf -user dhcpd -group dhcpd --no-pid $DHCPDARGSStandardError=nullService部分会出现的内容\tType 启动时，相关进程的行为 simple 默认值 oneshot 一次性进程，systemd会等待当前服务结束，再继续执行 notify 启动完毕后通知systemd idle 所有其它任务执行完毕后，此服务才会运行\tEnviromentFile\t指定环境变量配置文件\tEnviroment\t指定环境变量\tExecStart\t执行什么命令启动当前服务\tExecStartPre\t启动当前服务之前执行什么命令\tExecStartPost\t启动当前服务之后执行什么命令\tExecStop\t执行什么命令停止当前服务\tExecStopPost\t停止当前服务后执行什么命令\tExecReload\t执行什么命令重新加载服务的配置文件\tRestart 服务正常退出、异常退出、被杀死、超时的时候是否重启。常用值 no 不重启 always 无条件重启 on-failure\t异常退出时重启\tRestartSec\t自动重启服务的间隔时间\tRemainAfterExit\t此服务的进程全部退出之后，是否依然将服务的状态视为active状态\tTimeoutSec\t定义服务启动或停止的超时时间\tKillMode\t服务停止时，杀死进程的方法\t[Install]\t将此单元放到哪一个目标（target）当中WantedBy=multi-user.target\t此服务所在的target，当执行systemctl enabled dhcpd时，dhcpd.service的链接会放在/etc/systemd/system/multi-user.target.wants/中Install字段出现的内容WantedBy=multi-user.target\t此服务所在的target，当执行systemctl enabled dhcpd时，dhcpd.service的链接会放 在/etc/systemd/system/multi-user.target.wants/中Also附加单元，当用户使用systemctl enable/disabled时，也自动启用或者停用附加单元Alias 定义别名 服务多实例1234567891011121314151617181920212223242526272829303132[root@zutuanxue yum.repos.d]# dnf install vsftpd -y 安装一个服务[root@zutuanxue yum.repos.d]# systemctl start vsftpd[root@zutuanxue yum.repos.d]# netstat -antulp | grep vsftpdtcp6 0 0 :::21 :::* LISTEN 6331/vsftpd [root@zutuanxue yum.repos.d]# cd /etc/systemd/system/[root@zutuanxue system]# cp /usr/lib/systemd/system/vsftpd.service ./vsftpd2.service[root@zutuanxue system]# cd /etc/vsftpd/[root@zutuanxue vsftpd]# cp vsftpd.conf vsftpd2.conf[root@zutuanxue vsftpd]# vim vsftpd2.conf listen_port=2100[root@zutuanxuet vsftpd]# vim /etc/systemd/system/vsftpd2.service [Unit]Description=the second Vsftpd ftp daemon 修改简介After=network.target[Service]Type=forkingExecStart=/usr/sbin/vsftpd /etc/vsftpd/vsftpd2.conf 修改配置文件[Install]WantedBy=multi-user.target[root@zutuanxue system]# systemctl list-unit-files | grep vsftpdvsftpd.service disabled vsftpd2.service disabled vsftpd@zutuanxue.service indirect vsftpd.target disabled [root@zutuanxue system]# systemctl start vsftpd[root@zutuanxue system]# systemctl start vsftpd2[root@zutuanxue system]# netstat -antulp | grep vsftpdtcp6 0 0 :::21 :::* LISTEN 7388/vsftpd tcp6 0 0 :::2100 :::* LISTEN 7392/vsftpd","categories":["Linux","Linux系统管理宝典"]},{"title":"深入理解linux文件","path":"/2023/09/27/Linux系统管理宝典/Linux-深入理解文件/","content":"一、linux的文件存储假如有一个用户在linux系统中编辑了一个文件，编辑完内容后，关闭编辑器时会问用户改如何命名这个文件，设置完名称之后会选择一个目录将该文件保存到指定目录下，在这个例子中包含了linux系统中与文件相关的三个组成部分 数据：就是文件的内容，保存在一个叫data（数据块）的结构中 元数据：保存一个文件的特征的系统数据，用来保存除了文件内容和文件名以外的与文件相关的信息， 诸如文件的创建者，日期，大小等等，保存在一个叫inode（i节点）的结构中。 文件名：用来保存文件名称，文件名保存在一个叫dentry（目录项）的结构中。 二、i节点介绍通过前面的课程我们知道，inode是用来保存文件的元数据的，除此之外还保存文件相关属性信息，如链接数等。我们通过类似stat hello.txt这条命令查看指定文件的inode信息。 三、链接文件介绍 Linux中如果用户想把同一个文件保存在两个地方，或用两个不同的文件名保存，除了复制之外还有另外一种选择，就是链接，在linux系统中链接分为硬链接，软链接，空链接，递归链接等 链接命令: ln 语法：ln 源文件路径 链接位置路径 常用命令选项: 123456789-s 创建软连接-f 强制执行-i 交互模式，文件存在则提示用户是否覆盖-n 把符号链接视为一般目录,显示为一般文件-v 显示详细的处理过程 硬链接：允许一个文件拥有多个有效路径名，这样用户就可以建立硬链接到重要的文件，以防止“误删”源数据，不过硬链接只能在同一文件系统中的文件之间进行连接 软链接 ： 也叫符号链接，类似于windows系统中的快捷方式，与硬链接不同，软链接就是一个普通文件，软链接可对文件或目录创建。 这是概念上的描述，我们用一句话来将这两种链接进行总结： a、硬链接不能链目录，不能跨文件系统，软链接可以； b、源文件删除后软链接失效，硬链接依然可用； 我们通过下面的例子可以看到硬链接和软链接的创建方式以及基本对比 软连接 1234567891011121314151617181920# 在root家目录下创建一个文件ztx[root@zutuanxue ~]# touch ztx# 为/root/ztx文件创建一个软连接文件在/tmp目录下[root@zutuanxue ~]# ln -s /root/ztx /tmp/# 验证快捷方式是否创建成功[root@zutuanxue ~]# ls -l /tmp/ztx lrwxrwxrwx 1 root root 9 11月 26 15:06 /tmp/ztx -&gt; /root/ztx# 查看源文件和链接文件的i节点信息[root@zutuanxue ~]# ls -i /root/ztx /tmp/ztx 674632 /root/ztx 929916 /tmp/ztx # 发现软连接的文件i节点不同# 删除源文件[root@zutuanxue ~]# rm -f /root/ztx # 验证链接文件是否可用[root@zutuanxue ~]# cat /tmp/ztx cat: /tmp/ztx: 没有那个文件或目录 #删除源文件发现链接文件失效 硬链接 12345678910111213141516# 创建一个源文件 名字为组团学[root@zutuanxue ~]# touch zutuanxue # 为/root/zutuanxue文件创建一个硬链接文件 到/tmp/zutuanxue[root@zutuanxue ~]# ln /root/zutuanxue /tmp/zutuanxue # 查看源文件和链接文件的i节点[root@zutuanxue ~]# ls -i /root/zutuanxue /tmp/zutuanxue 674632 /root/zutuanxue 674632 /tmp/zutuanxue # 硬链接的i节点和源文件的i节点一致# 删除源文件，看看硬链接文件是否可用[root@zutuanxue ~]# echo test &gt; /root/zutuanxue [root@zutuanxue ~]# rm /root/zutuanxue rm：是否删除普通文件 &quot;/root/zutuanxue&quot;？y[root@zutuanxue ~]# cat /tmp/zutuanxue test #删除硬链接源文件后，发现链接文件依然可以使用 除了上面我们说到的硬链接和软链接之外还有 空链接，所谓的空链接就是软链接指向的源文件不存在了，包括源文件被删除，改名。 递归链接：递归链接不如空链接常见，如果想看的话几乎需要专门寻找，如果用户创建两个软链接，linka与linkb关联，而linkb又与linka关联，这时候就会出现递归链接，比如 1571130770456.png 绝对软链接和相对软链接：主要指的是用户在创建软链接的时候使用的是绝对路径还是相对路径来指定链接目标，如果链接创建完成之后不会移动，那么这两种方法可以随意使用，但是如果链接文件需要被移动，那么建议还是使用绝对路径，比如 1571132049532.png 好了链接我们就说到这里，下面我们看一下时间戳 四、时间戳时间戳是指格林威治时间1970年01月01日00时00分00秒(北京时间1970年01月01日08时00分00秒)起至现在的总毫秒数。通俗的讲， 时间戳是一份能够表示一份数据在一个特定时间点已经存在的完整的可验证的数据。 它的提出主要是为用户提供一份电子证据， 以证明用户的某些数据的产生时间。 当我们使用stat命令查看文件的时候除了创建时间你会发现有三个跟时间戳相关的信息 1571133239914.png 1571133272500.png 缩写 命令 目的 Atime 访问时间 文件数据每次被阅读后的更新 Ctime 改变时间 文件的i-节点信息每次被改变后都更新 Mtime 修改时间 文件数据每次被改变后的更新 五、常用目录管理命令总结 目录： 命令 用法 功能 mkdir mkdir 目录名称 创建一个目录 rmdir rmdir 目录名称 删除一个空目录 cd cd 目录名称 进入一个目录 ls ls 目录名称 列出一个目录内容 文件： 命令 用法 功能 touch touch 文件名 新建一个文件 rm rm 文件名 删除一个文件 cat cat 文件名 打印一个文件内容 其他： 命令 用法 功能 cp mkdir file folder 将文件file拷贝到目录folder mv mv A B 移动A到B目录或者从命名 A为B ln ln -s A B 给A做一个快捷方式,放到B位置","categories":["Linux","Linux系统管理宝典"]},{"title":"构建可视化日志管理服务器","path":"/2023/09/27/Linux系统管理宝典/Linux-构建可视化日志管理服务器/","content":"我们可以通过集中式日志服务器将多台机器的日志收集在一个日志服务器，然后通过脚本或者其他方式去分析，但是真正做过运维的小伙伴明白，日子收集在硬盘上，硬盘的空间有限且大文件分析起来IO压力超级大，分析日志需要高超的技术，一般运维人员分析起来会很困难，更无法实时的去查看某个机器的日志。这样的话我们的日志收集就变成了真正意义上的收集了，收集起来如何利用就变成了一个难题，总结一下主要的问题就是以下几点： 日志文件巨大，硬盘IO压力大 无法实时分析 分析需要消耗很多计算机资源且困难 如何解决这个问题呢？ IO压力:我们可以将日志收集在数据库中，海量的日志通过分布式存储的底层支撑加上数据库对数据的高效管理，使得数据读写变得轻松，避免了原理日志服务器的IO压力。 无法实时分析：可以部署一个日志分析系统来辅助分析，苦难的分析工作瞬间变得简单。 分析需要消耗很多计算机资源：分布式处理分担处理压力 接下来我就给大家介绍一款高性能的日志收集、存储、分析架构，同时也是一个可以使用web页面查看日志的可视化架构： rsyslog+mariadb+loganalyzer环境准备：与前面课程提到的集中式日志服务器的架构一样，只是这个架构是在server上搭建的，也就是IP地址为192.168.1.55的这台主机上 server端的环境准备和设置setp 1 安装所需要的软件包 1[root@zutuanxue ~]# dnf install mariadb mariadb-server rsyslog-mysql -y step 2 启动mariadb服务 12[root@zutuanxue ~]# systemctl restart mariadb[root@zutuanxue ~]# systemctl status mariadb **step 3 设置mariadb ** 123456789101112131415161718##将mariadb的管理员密码设置为‘123456’[root@zutuanxue ~]# mysqladmin -u root password 123456##建立日志服务需要用到的数据库[root@zutuanxue ~]# cd /usr/share/doc/rsyslog/[root@zutuanxue rsyslog]# mysql -u root -p &lt; mysql-createDB.sql Enter password: ##进入到mariadb中验证一下是否有一个叫Syslog的数据库，如果有就代表前面的操作成功[root@zutuanxue rsyslog]# mysql -u root -pEnter password: MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| Syslog | step 4 为后面将要用到的用户进行授权，允许用户访问mairadb中的Syslog库 123456789101112131415#允许一个叫syslogroot的用户从127.0.0.1、192.168.1.55、192.168.1.18这三个ip地址访问我的数据库，密码为syslogpass，设置完成之后刷新一下并退出（如果你的架构中还有其它的主机，只要修改数据库语句中的IP地址即可）MariaDB [(none)]&gt; grant all on Syslog.* to &#x27;syslogroot&#x27;@&#x27;127.0.0.1&#x27;identified by &#x27;syslogpass&#x27;;Query OK, 0 rows affected (0.000 sec)MariaDB [(none)]&gt; grant all on Syslog.* to &#x27;syslogroot&#x27;@&#x27;192.168.1.55&#x27;identified by &#x27;syslogpass&#x27;;Query OK, 0 rows affected (0.000 sec)MariaDB [(none)]&gt; grant all on Syslog.* to &#x27;syslogroot&#x27;@&#x27;192.168.1.18&#x27;identified by &#x27;syslogpass&#x27;;Query OK, 0 rows affected (0.000 sec)MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.000 sec)MariaDB [(none)]&gt; quitBye setp 5 修改rsyslog服务的配置文件 1234567891011121314151617[root@zutuanxue ~]# vim /etc/rsyslog.conf 7 #### MODULES ####... 24 module(load=&quot;imtcp&quot;) # needs to be done just once 25 input(type=&quot;imtcp&quot; port=&quot;514&quot;) 26 module(load=&quot;ommysql&quot;)#加载一个叫ommysql的模块是日志服务可以连接mariadb . . 65 local7.* /var/log /boot.log 66 #告诉日志服务通过ommysql模块，将日志信息发送到192.168.1.55的Syslog库中，使用的用户名和密码就是我们在前一步设置的syslogroot,syslogpass 67 *.* :ommysql:192.168.1.55,Syslog,syslogroot,syslogpass ##重启日志服务 [root@zutuanxue ~]# systemctl restart rsyslog step 6 测试一下日志信息能否记录到数据库中 12345678910111213141516[root@zutuanxue ~]# logger &quot;hello test test test&quot;[root@zutuanxue ~]# mysql -u root -pEnter password: MariaDB [(none)]&gt; use Syslog;Database changedMariaDB [Syslog]&gt; select * from SystemEvents\\G*************************** 8. row *************************** ID: 8 CustomerID: NULL ReceivedAt: 2019-12-07 03:22:31DeviceReportedTime: 2019-12-07 03:22:31 Facility: 1 Priority: 5 FromHost: localhost Message: hello test test test###如果可以看到我们之前使用logger产生的日志信息及代表rsyslog可以将日志信息存入数据库中 step 7 设置client(192.168.1.18),此步骤是唯一一步需要对client的做出的设置 12345678910111213141516171819202122232425##安装软件包[root@zutuanxue ~]# dnf install rsyslog-mysql -y##修改服务的配置文件添加相应内容(与server端添加的内容一致)[root@zutuanxue ~]# vim /etc/rsyslog.confmodule(load=&quot;ommysql&quot;)*.* :ommysql:192.168.1.55,Syslog,syslogroot,syslogpass[root@zutuanxue ~]# systemctl restart rsyslog###测试一下client的日志信息能否在server端的数据库中查看###client[root@zutuanxue ~]# logger &quot;hello this is a test from client 18&quot;####server端使用与刚才相同的方法去查看内容MariaDB [Syslog]&gt; select * from SystemEvents\\G*************************** 28. row *************************** ID: 28 CustomerID: NULL ReceivedAt: 2019-12-07 03:30:28DeviceReportedTime: 2019-12-07 03:30:28 Facility: 1 Priority: 5 FromHost: localhost Message: hello this is a test from client 18 step 8 server端安装支持web页面查看日志的工具loganalyzer 1234567[root@zutuanxue ~]# dnf install httpd php php-mysqlnd php-gd -y[root@zutuanxue ~]# tar fx loganalyzer-4.1.8.tar.gz [root@zutuanxue ~]# cp -r loganalyzer-4.1.8/src/* /var/www/html/[root@zutuanxue ~]# cp loganalyzer-4.1.8/contrib/* /var/www/html/[root@zutuanxue ~]# cd /var/www/html/[root@zutuanxue html]# sh configure.sh [root@zutuanxue html]# systemctl restart httpd step 9 在mariadb中创建lyzeruser工具需要用到的库、用户并授权 12345678910111213[root@zutuanxue html]# mysql -u root -pEnter password: MariaDB [(none)]&gt; create database loganalyzer;Query OK, 1 row affected (0.000 sec)MariaDB [(none)]&gt; grant all on loganalyzer.* to lyzeruser@&#x27;192.168.1.55&#x27; identified by &#x27;lyzeruser&#x27;;Query OK, 0 rows affected (0.000 sec)MariaDB [(none)]&gt; flush privileges;Query OK, 0 rows affected (0.001 sec)MariaDB [(none)]&gt; quitBye step 10 打开浏览器，部署loganalyzer image20191207164609190.png image20191207164635046.png image20191207164704698.png image20191207164929730.png image20191207164950624.png image20191207165010297.png image20191207165056960.png image20191207165711728.png image20191207165220988.png image20191207165748067.png","categories":["Linux","Linux系统管理宝典"]},{"title":"linux用户管理","path":"/2023/09/27/Linux系统管理宝典/Linux-用户管理/","content":"一、用户和组的相关概念账号的概念和分类 账号：是一种用来记录单个用户或是多个用户的数据。Linux中每一个合法的用户都必须要拥有账号，才能使用 。它不仅可以用来验证用户身份，还决定了一个用户在系统中可以从事什么工作 在Linux 上的账号可以分成两类： 用户账号 用来储存单一用户的数据，你可以使用一个用户账号，来储存某一个用户的数据。 群组账号 用来储存多个用户的信息，每一个群组账号可以用来记录一组用户的数据。 我们可以把 Linux 的所有账号依照下面两种方法进行分类： 依照账号的位置。 依照账号的功能。 依照账号存储的位置 账号数据存放在不同的地方，其可使用的范围就会不太一样，账号的使用范围我们称为视野。依照账号储存的位置与视野不同，我们可以区分本机账号与网域账号两种： 本机账号: 账号密码储存于本机硬盘中，我们称为本机账号。本机账号使用范围只能在账号建立的 Linux 系统上，如果超出范围时，本机账号将无法使用。比如：你在自己电脑上登录用的账号和密码，正常是无法在其它的电脑上使用的。 本机账号的优点：是简单易用，你无须作额外的设置，就可以直接建立本机账号； 本机账号的缺点：则是无法具备延展性（Scalability）。比如：你在一个拥有很多主机的环境中，想拥有一个在每台主机都可以登录的账号时，你就需要在所有的主机上都建立相关的用户 网域账号： 你也可以把大量的计算机组织成为一个网域，然后在网域中的某一台 Linux 上建立账号数据，并且通过某些通信协议，将账号数据分享出来。当其他计算机需要取得账号数据时，再通过网络调用这些分享的账号即可。这种账号我们称为网域账号 （Domain Account）。 网域账号的优点：在于具备延展性。在大规模的环境中，使用网域账号往往能节省管理账号的时间； 但网域账号也有缺点，其最大的缺点就是要配置网域账号前，你必须先建立“域”的环境才行。 依照账号的功能 不管是本机账号或是网域账号，我们还可以把所有账号依照功能分成下面几类 1571285802298.png 用户账号部分： 包含了超级用户、普通用户；而普通用户中还可细分为系统用户、真实用户两种。 超级用户：在Linux 系统上拥有完整的控制能力，常被称为系统管理员，在 系统上拥有完整的控制能力，你可以利用超级用户读取或写入 上任何文件、安装或删除软硬件、启动或停止服务，甚至关机与停止系统的执行。 通常只有在管理系统时才会使用超级用户账号登录，所以超级用户常被称为系统管理员 （System Administrator）。由于超级用户的权限不受任何限制，你可以使用该账号来管理 系统；但是，也可能因为操作错误，或者打错命令而造成无法挽救的伤害。 在此，强烈建议你“除非有必要，否则请不要轻易以超级用户身份使用 Linux”！ 在 Linux 系统中，默认超级用户的用户为 root，其 UID（用户ID号）一定为 0。 普通用户账号：行为能力会受到限制，只能调用具备权限的文件，如果没有足够的权限，普通用户是完全无法调用的；所以，普通用户账号不太容易危害 Linux 系统。普通用户账号中，我们又可分为两大类： 系统账号 这种类型的账号仅提供给Linux 系统本身使用。在某些软件执行的时候，需要你提供一个普通用户类型的账号。为了满足这些软件而建立的账号，我们称为系统账号 （System Account）。 真实用户 系统用户账号是给软件或程序使用的，那么，什么账号是让我们登录Linux 时使用的呢？答案就是真实用户（Real User）。真实用户账号是为了让其他人登录系统使用的 群组账号部分： 包含了超级用户群组、系统群组以及用户自定义组三大类。 超级用户群组：Linux 有一个叫做 root 的群组，因为这个群组的名称与 root 这个超级用户的名称相同，所以，我们习惯把 root 群组叫做超级用户群组。超级用户群组的 GID 为 0。 系统群组： 与系统账号一样，系统群组是给 Linux 系统本身，或是某个软件所使用 用户自定义组：除了上述的群组外其余的所有群组，皆是由管理者自行定义，因此我们把这些群组称之为用户自定义组 另外，Linux 系统的“用户自定义组“类型中，还有一种名为用户私有群组 （UPG, User Private Group）的群组。什么是 用户私有群组呢？用户私有群组（UPG, User Private Group）是指 “与用户账号名称相同，且为用户的主要群组”的群组。当你建立新的用户账号时，Linux 会自动建立该用户的私有群组。如，当你建立 test 这个用户账号时，Linux 会自动建立了一个名为 test 的群组，并且让 test群组成为 test 用户账号的主要群组，test 群组即是 test 的私有群组。 了解完账号的基本概念后，我们一起来看下账号到底记录了哪些信息 二、用户账号管理 useradd命令 用户创建命令，创建一个linux用户。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960命令介绍 useradd - 创建一个新用户或更新默认新用户信息命令语法 useradd [选项] 登录 useradd -D useradd -D [选项]命令选项 -D 默认 ­ -u UID 用来指定账号的 UID，如果省略这个参数，useradd会自动以最后一个可用的 UID 作为新账号的 UID。 -o 告诉 useradd 允许重复的 UID。 -g gid 定义用户的主要群组。使用 -g 参数前，GROUP 必须已经存在。 -d HOME 指定用户的主目录。默认的主目录是建立在 /home/ 目录下，而且目录名称与用户名称相同。 -s SHELL 指定用户登录执行的程序。 -c COMMENT 指定用户的批注说明。如果批注文字包含空白，请记得使用双引号 （&quot;） 包起来。 -r 这个参数用来指出建立一个系统用户的账号。 -M 不创建家目录 -N 不创建同名组 #相关文件\t/etc/passwd 用户账户信息。 /etc/shadow 安全用户账户信息。 /etc/group 组账户信息。 /etc/gshadow 安全组账户信息。 /etc/default/useradd 账户创建的默认值。 /etc/skel/ 包含默认文件的目录。 /etc/subgid Per user subordinate group IDs. /etc/subuid Per user subordinate user IDs. /etc/login.defs Shadow 密码套件配置。 这些参数大多数可以同时使用，可以根据自己的需求指定，例如创建一个linux用户hello– uid为 1500– 附加组为 hello– 家目录为 &#x2F;home&#x2F;hello– 登陆shell为 &#x2F;bin&#x2F;bash– 描述为 “this is a test user” 1useradd -u 1500 -G hello -d /home/hello -s /bin/bash -c &quot;this is a test user&quot; hello 关于linux本机用户本机的用户账号数据储存于&#x2F;etc&#x2F;passwd文件中。与其他的配置文件一样，passwd 也是一个文本文件，因此，你可以直接使用文字处理程序，例如 cat 或 less 浏览其中的内容。 123root:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologin &#x2F;etc&#x2F;passwd 权限必须是0644，每一行代表一个用户的账号数据，每一行又使用冒号（:）分隔为几个部分 123456789USERNAME:PASSWORD:UID:GID:COMMENT:HOMEDIR:SHELL - USERNAME:用户识别名称，也是登录的名称- PASSWORD：密码位，用于存储用户的密码，为了安全起见，密码放在另一个文件中，这里统一用x- UID：用户识别号，0表示为管理员，非0为普通用户- GID：组识别号，用来识别用户组的身份，同样0为管理员组，非0为系统群组或者自定义组- COMMENT：描述信息- HOMEDIR：家目录位置- SHELL：shell类型 usermod命令 是用来修改用户相关信息的，和useradd使用的参数很多是相同的，用法也是一样的，除此之外usermod命令还有一些额外的参数 123456789101112命令介绍 usermod - 修改一个用户账户命令语法 usermod [选项] 登录命令选项-l NEWNAME 修改账号的用户名称，NEWNAME 即是新的账号名称。-L 锁定账号，一经锁定的账号将无法用来登录系统。-U 解除锁定。 userdel命令 删除linux用户 12345678910命令介绍 userdel - 删除用户账户和相关文件命令语法 userdel [选项] 登录命令选项-r 用户主目录中的文件将随用户主目录和用户邮箱一起删除。在其它文件系统中的文件必须手动搜索并删除。-f 强制 删除tom用户以及其家目录文件 1[root@zutuanxue ~]# userdel -r tom 三、用户查询命令 id命令：查询用户uid、gid信息 12345[root@zutuanxue ~]# id hellouid=1500(hello) gid=1500(hello) 组=1500(hello)[root@zutuanxue ~]# id -u hello1500 whoami命令：查询当前登录用户 12[root@zutuanxue ~]# whoamiroot w命令:查询linux系统中登陆的所有用户 1234[root@zutuanxue ~]# w 18:21:43 up 2:01, 1 user, load average: 0.00, 0.00, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 192.168.1.17 16:16 3.00s 0.08s 0.00s w","categories":["Linux","Linux系统管理宝典"]},{"title":"Linux特殊权限","path":"/2023/09/27/Linux系统管理宝典/Linux-特殊权限/","content":"linux基本权限只是规定了所有者、属组、其他人三种用户的权限，如果希望对文件或文件夹做一些特殊的权限设置呢？比如： 设置属组继承权限 为执行文件设置临时超管执行权限 公共文件夹中的文件谁建立谁删除 这些任务基本权限就解决不聊了，需要解决这个问题得靠特殊权限。 一、特殊权限的介绍之前我们提到了特殊权限有三个，这三个特殊权限是在可执行程序运行时影响操作权限的，它们分别是SUID,SGID,sticky-bit位 特殊权限 说明 SUID 当一个设置了SUID 位的可执行文件被执行时，该文件将以所有者的身份运行，也就是说无论谁来执行这个文件，他都有文件所有者的特权。任意存取该文件拥有者能使用的全部系统资源。如果所有者是 root 的话，那么执行人就有超级用户的特权了。 SGID 当一个设置了SGID 位的可执行文件运行时，该文件将具有所属组的特权，任意存取整个组所能使用的系统资源；若一个目录设置了SGID，则所有被复制到这个目录下的文件，其所属的组都会被重设为和这个目录一样，除非在复制文件时保留文件属性，才能保留原来所属的群组设置。 stickybit 对一个文件设置了sticky-bit之后，尽管其他用户有写权限，也必须由属主执行删除、移动等操作；对一个目录设置了sticky-bit之后，存放在该目录的文件仅准许其属主执行删除、移动等操作。 一个典型的例子就是passwd命令，这个命令允许用户修改自己的密码。我们可以看到本来是rwx的权限表示形式变成了rws，同样如果&#x2F;usr&#x2F;bin&#x2F;passwd这个文件同时被设置了三个特殊权限，那么权限的格式就会变成rwsrwsrwt,需要注意的是特殊权限设置的前置要求是可执行，也就是如果没有x权限位，是不要设置的，即便你使用root用户设置上了特殊权限，也不会生效。 12[root@zutuanxue test]# ll /usr/bin/passwd -rwsr-xr-x. 1 root root 34928 5月 11 11:14 /usr/bin/passwd 二、特殊权限的设置和查看特殊权限的设置也是使用chmod 123456789101112131415[root@zutuanxue test]# ll总用量 0-rwxr-xr-x 1 oracle oracle 0 10月 18 01:26 file1[root@zutuanxue test]# chmod u+s file1[root@zutuanxue test]# ll总用量 0-rwsr-xr-x 1 oracle oracle 0 10月 18 01:26 file1[root@zutuanxue test]# chmod g+s file1[root@zutuanxue test]# ll总用量 0-rwsr-sr-x 1 oracle oracle 0 10月 18 01:26 file1[root@zutuanxue test]# chmod o+t file1[root@zutuanxue test]# ll总用量 0-rwsr-sr-t 1 oracle oracle 0 10月 18 01:26 file1 或者使用数字 12345678[root@zutuanxue test]# chmod u-s,g-s,o-t file1[root@zutuanxue test]# ll总用量 0-rwxr-xr-x 1 oracle oracle 0 10月 18 01:26 file1[root@zutuanxue test]# chmod 7755 file1[root@zutuanxue test]# ll总用量 0-rwsr-sr-t 1 oracle oracle 0 10月 18 01:26 file1","categories":["Linux","Linux系统管理宝典"]},{"title":"Linux目录结构和文件属性管理","path":"/2023/09/27/Linux系统管理宝典/Linux-目录结构和文件属性管理/","content":"一、FHS介绍Filesystem Hierarchy Standard（文件系统层次化标准）的缩写，多数Linux版本采用这种文件组织形式，类似于Windows操作系统中c盘的文件目录，FHS采用树形结构组织文件。FHS定义了系统中每个区域的用途、所需要的最小构成的文件和目录，同时还给出了例外处理与矛盾处理。 FHS定义了两层规范，第一层是， &#x2F; 下面的各个目录应该要放什么文件数据，例如&#x2F;etc应该要放置设置文件，&#x2F;bin与&#x2F;sbin则应该要放置可执行文件等等。第二层则是针对&#x2F;usr及&#x2F;var这两个目录的子目录来定义。例如&#x2F;var&#x2F;log放置系统登录文件、&#x2F;usr&#x2F;share放置共享数据等等。 二、linux目录结构介绍整个Linux系统最重要的地方就是在于目录树架构，所谓的目录树架构就是以根目录为主， 然后向下呈现分支状的目录结构的一种档案架构。下图给出了linux的目录结构，那这些目录都有什么作用呢？ 1571118994639.png 三、linux目录的作用 根目录（&#x2F;） 最高一级目录，所有目录都是根目录衍生出来，只有root用户具有写权限，一般根目录下只存放目录，不要存放件 &#x2F;bin目录 – 用户二进制文件 包含二进制的可执行文件，你需要的常见的Linux命令都位于此目录下。 &#x2F;sbin目录 – 系统二进制文件 这个目录下的命令通常由系统管理员使用， 对系统进行维护。 &#x2F;etc– 配置文件 包含所有程序所需要的配置文件，也包含用于启动&#x2F;停止单个程序的起动和关闭shell脚本。 &#x2F;dev-设备文件 包含设备文件，包括终端设备、USB或连接到系统的任何设备，如网卡等。 &#x2F;proc-进程信息文件 这是一个虚拟的文件系统，包含有关正在运行的进程信息。 &#x2F;usr-用户程序 包含二进制文件、库文件、文档和二级程序的源代码。 1234/usr/bin中包含用户程序的二进制文件。如果你在/bin中找不到用户二进制文件，到/usr/bin目录看看。/usr/sbin中包含系统管理员的二进制文件。如果你在/sbin中找不到系统二进制文件，到/usr/sbin目录看看。/usr/lib中包含了/usr/bin和/usr/sbin用到的库。/usr/local中包含了从源安装的用户程序。 &#x2F;home -HOME目录 包含所有用户的个人档案，Linux是多用户的系统，所以用该目录保存各用户的信息。 &#x2F;boot -引导加载程序 包含引导加载程序相关的文件。 &#x2F;lib -系统库 包含支持位于&#x2F;lib和&#x2F;sbin下的二进制文件的库文件。 &#x2F;opt -可选的附加应用程序 给主机额外安装软件所摆放的目录，以前的 Linux 系统中，习惯放置在 &#x2F;usr&#x2F;local 目录下 &#x2F;mnt &#x2F;media -挂载目录 光盘默认挂载点，通常光盘挂载于 &#x2F;mnt&#x2F;cdrom 下，也不一定，可以选择任意位置进行挂载。 &#x2F;root 管理员家目录 在这里我们所介绍的目录是在linux系统中常见的目录，不同厂商的linux有所差异，有的版本中会出现有额外作用的目录，这个就需要具体问题具体对待了。 四、目录和设备节点我们已经知道目录是用来存放文件的，不同的目录存放的文件作用不同，那么我们来看下设备节点是什么？ 一个设备节点其实就是一个文件，Linux中称为设备文件。有一点必要说明的是，在Linux中，所有的设备访问都是通过文件的方式，一般的数据文件程序普通文件，设备节点称为设备文件，而这些设备节点，或者说是设备文件都统一存放在&#x2F;dev目录下，简单来说，设备节点是一种特殊的文件，只不过这个文件存放的不是一般的数据，而是和你计算机中的设备相关联的。 五、.和…在linux系统中，使用ls -a命令时，你会发现每一个目录下都包含两个目录，这两个目录就是.和…，其中”.“表示是的是当前目录，也就是你使用pwd所查看到的路径，而”…”表示的上一级目录，也就是父目录。 六、绝对路径和相对路径linux的路径书写方式有两种： 绝对路径：路径的写法一定是由根目录 &#x2F; 写起的，以根目录为起点； 相对路径：路径的写法不是由根目录 &#x2F; 写起的，不以根目录为起点。 例如，你知道你的朋友在四楼，而你在五楼，如果你的朋友询问你的位置，你就有两种回答方式： 绝对路径的方式就是你告诉对方你在XX小区的xx号楼的五楼， 相对路径的方式就是你告诉对方你在对方五楼。","categories":["Linux","Linux系统管理宝典"]},{"title":"linux磁盘使用实战案例","path":"/2023/09/27/Linux系统管理宝典/Linux-磁盘使用实战案例/","content":"案例需求： 添加一块硬盘，需要将其分区，最终需要使用2G空间。 案例思路 增加一块硬盘 使用fdisk命令进行分区 格式化指定分区 创建一个空的目录作为挂载点 挂载使用 创建新的挂载点 挂载使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103步骤：1. 增加硬盘增加完硬盘记得重启系统# lsblk\t查看硬盘是否添加成功...sdb 8:16 0 20G 0 disk [root@zutuanxue ~]# fdisk -l /dev/sdbDisk /dev/sdb：20 GiB，21474836480 字节，41943040 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节2. 使用fdisk命令分区[root@zutuanxue ~]# fdisk /dev/sdb欢迎使用 fdisk (util-linux 2.32.1)。更改将停留在内存中，直到您决定将更改写入磁盘。使用写入命令前请三思。设备不包含可识别的分区表。创建了一个磁盘标识符为 0x0c7799c3 的新 DOS 磁盘标签。命令(输入 m 获取帮助)：pDisk /dev/sdb：20 GiB，21474836480 字节，41943040 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x0c7799c3命令(输入 m 获取帮助)：n分区类型 p 主分区 (0个主分区，0个扩展分区，4空闲) e 扩展分区 (逻辑分区容器)选择 (默认 p)：p分区号 (1-4, 默认 1): 第一个扇区 (2048-41943039, 默认 2048): 上个扇区，+sectors 或 +size&#123;K,M,G,T,P&#125; (2048-41943039, 默认 41943039): +1G创建了一个新分区 1，类型为“Linux”，大小为 1 GiB。命令(输入 m 获取帮助)：pDisk /dev/sdb：20 GiB，21474836480 字节，41943040 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x80e196f2设备 启动 起点 末尾 扇区 大小 Id 类型/dev/sdb1 2048 2099199 2097152 1G 83 Linux命令(输入 m 获取帮助)：n分区类型 p 主分区 (1个主分区，0个扩展分区，3空闲) e 扩展分区 (逻辑分区容器)选择 (默认 p)：p分区号 (2-4, 默认 2): 2第一个扇区 (2099200-41943039, 默认 2099200): 上个扇区，+sectors 或 +size&#123;K,M,G,T,P&#125; (2099200-41943039, 默认 41943039): +1G创建了一个新分区 2，类型为“Linux”，大小为 1 GiB。命令(输入 m 获取帮助)：pDisk /dev/sdb：20 GiB，21474836480 字节，41943040 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x80e196f2设备 启动 起点 末尾 扇区 大小 Id 类型/dev/sdb1 2048 2099199 2097152 1G 83 Linux/dev/sdb2 2099200 4196351 2097152 1G 83 Linux命令(输入 m 获取帮助)：w分区表已调整。将调用 ioctl() 来重新读分区表。正在同步磁盘。3. 再次查看分区情况# lsblksdb 8:16 0 20G 0 disk ├─sdb1 8:17 0 1G 0 part └─sdb2 8:18 0 1G 0 part 4. 刷新分区表信息[root@zutuanxue ~]# partprobe /dev/sdb5. 格式化分区[root@zutuanxue ~]# mkfs.xfs /dev/sdb1[root@zutuanxue ~]# mkfs.vfat /dev/sdb26. 创建新的挂载点[root@zutuanxue ~]# mkdir /u01[root@zutuanxue ~]# mkdir /u027. 挂载使用[root@zutuanxue ~]# mount /dev/sdb1 /u01[root@zutuanxue ~]# mount /dev/sdb2 /u02","categories":["Linux","Linux系统管理宝典"]},{"title":"linux磁盘分区与格式化","path":"/2023/09/27/Linux系统管理宝典/Linux-磁盘分区与格式化/","content":"一、基本分区管理1.1、linux磁盘表示方法介绍硬盘命名方式 OS IDE(并口) SATA(串口) SCSI CentOS6 &#x2F;dev&#x2F;hda &#x2F;dev&#x2F;sda &#x2F;dev&#x2F;sda CentOS7 &#x2F;dev&#x2F;sda &#x2F;dev&#x2F;sda &#x2F;dev&#x2F;sda CentOS8 &#x2F;dev&#x2F;sda &#x2F;dev&#x2F;sda &#x2F;dev&#x2F;sda 磁盘设备的命名&#x2F;dev&#x2F;sda2 s&#x3D;硬件接口类型（sata&#x2F;scsi）,d&#x3D;disk（硬盘）,a&#x3D;第1块硬盘（b，第二块），2&#x3D;第几个分区&#x2F;dev&#x2F;hd h&#x3D;IDE硬盘 &#x2F;dev&#x2F;hdd3&#x2F;dev&#x2F;vd v&#x3D;虚拟硬盘 &#x2F;dev&#x2F;vdf7 HP服务器硬盘&#x2F;dev&#x2F;cciss&#x2F;c0d0&#x2F;dev&#x2F;cciss&#x2F;c0d0p1 c0第一个控制器, d0第一块磁盘, p1分区1&#x2F;dev&#x2F;cciss&#x2F;c0d0p2 c0第一个控制器, d0第一块磁盘, p2分区2 1.2、磁盘分区1）、磁盘划分思路 进入分区表 新建分区 更新分区表&lt;刷新分区表&gt; 格式化分区——&gt;文件系统 2）、磁盘分区fdisk命令 12345678910111213141516171819fdisk磁盘分区命令fidsk [命令选项] [参数]命令选项-l list 列出磁盘分区-u 与-l一起使用，显示分区的相关信息fdisk /dev/sda 为/dev/sda分区m ：显示菜单和帮助信息a ：活动分区标记/引导分区d ：删除分区l ：显示分区类型n ：新建分区p ：显示分区信息q ：退出不保存t ：设置分区号v ：进行分区检查w ：保存修改x ：扩展应用，高级功能 分区前了解设备信息 12345678910111213141516171819202122232425# lsblk 查看块设备# df -h 查看正在挂载的设备情况# blkid 打印某个已经格式化分区的UUID# fdisk -l 查看当前系统的所有设备分区情况# fdisk /dev/sdb[root@zutuanxue ~]# fdisk -l /dev/sdb硬盘容量　＝　柱面数　×　盘面数（磁头数）　×　扇区数　×　扇区大小（一般为512字节）Disk /dev/sdb: 20 GiB, 21474836480 bytes, 41943040 sectors\t磁盘空间统计，大小和扇区数量几何属性：255 个磁头, 63 个扇区/磁道, 2610 个柱面 ###此行内容只有在使用fdisk分区时，使用c命令加上与dos兼容的标记时才会出现，这里面所提到的磁头等数量与磁盘中的物理寻址和逻辑块寻址相关，而且它们都是逻辑地址，产生访问时，磁盘控制器会把这些确定的逻辑地址转换为实际的物理地址；对于我们来讲这几个数值可以帮助我们计算磁盘空间的大小以及一个磁柱的大小，比如说 ##一个磁柱的容量=255x63x512=8225280（约8M空间）单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x178c5f83 设备 启动 起点 末尾 扇区 大小 Id 类型/dev/sda1 * 2048 2099199 2097152 1G 83 Linux/dev/sda2 2099200 41943039 39843840 19G 8e Linux LVM命令(输入 m 获取帮助)： fdisk分区总结命令缺点：单个分区不能超过2T 超过的话需要用parted命令在linux 下大磁盘的分区不能再采用fdisk了，MBR分区表只支持2T磁盘，所以大于2T的磁盘必须使用GPT分区表。 3）、磁盘格式化格式化(format)是指对磁盘或磁盘中的分区（partition）进行初始化的一种操作，这种操作通常会导致现有的磁盘或分区中所有的文件被清除。格式化通常分为低级格式化和高级格式化。如果没有特别指明，对硬盘的格式化通常是指高级格式化，而对软盘的格式化则通常同时包括这两者。 1234567891011121314-L 标签名-V : 详细显示模式-t : 给定档案系统的型式，Linux 的预设值为 ext2-c : 在制做档案系统前，检查该partition 是否有坏轨-l bad_blocks_file : 将有坏轨的block资料加到 bad_blocks_file 里面-b : 给定 block 的大小关于block and inode dentry实验发现这句话不对block越大，inode越少，适合存储大文件的文件系统；block越小，inode越多，适合存储文件多而小的文件系统。磁盘分区格式化mkfs.ext4 /dev/sda3 注意： MBR分区表最多允许4个主分区，或者3个主分区+1个扩展分区 扩展分区不能直接存储数据 扩展分区的大小决定了所有逻辑分区的大小，逻辑分区的编号从5开始 删除扩展分区后下面的逻辑分区都被删除 分完区后需要手动刷新分区表，如果刷新不成功需要重启操作系统 创建分区的时候尽可能注意分区序号的连续性","categories":["Linux","Linux系统管理宝典"]},{"title":"Linux系统监控工具-glances","path":"/2023/09/27/Linux系统管理宝典/Linux-系统监控工具-glances/","content":"一、glances介绍glances是一个基于python语言开发，可以为linux或者UNIX性能提供监视和分析性能数据的功能。glances在用户的终端上显示重要的系统信息，并动态的进行更新，让管理员实时掌握系统资源的使用情况，而动态监控并不会消耗大量的系统资源，比如CPU资源，通常消耗小于2%，glances默认每两秒更新一次数据。同时glances还可以将相同的数据捕获到一个文件，便于以后对报告进行分析和图形绘制，支持的文件格式有.csv电子表格格式和和html格式。 glances可以分析系统的： CPU使用率 内存使用率 内核统计信息和运行队列信息 磁盘I&#x2F;O速度、传输和读&#x2F;写比率 磁盘适配器 网络I&#x2F;O速度、传输和读&#x2F;写比率 页面监控 进程监控-消耗资源最多的进程 计算机信息和系统资源 二、glances安装方式 源码安装 基于pip命令安装 基于epel公网yum源 由于源码安装需要解决大量的依赖包的问题，对于小白同学学习压力较大，所以本文将重点介绍基于yum的安装方法，让大家快速安装，并能及时体验到glances监控的强大和高效。 三、基于epel公网源安装glances由于glances运行需要python环境，所以我们需要首先安装好python环境，这里我给大家使用的是一个脚本安装python3.7.3，目前的最新版本。 3.1、python3.7.3安装脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#!/bin/bash# #Name: #Author: zutuanxue_com#Created Time: 2019/10/1 11:20#Release: #Description:python 3.7.3安装脚本#变量source_url=&quot;https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tgz&quot;source_pkg=&quot;Python-3.7.3.tgz&quot;source_doc=&quot;Python-3.7.3&quot;cpu_count=`egrep &quot;flags&quot; /proc/cpuinfo |wc -l`#程序check () &#123; [ &quot;$USER&quot; != &quot;root&quot; ]&amp;&amp;echo &quot;need be root so that&quot;&amp;&amp;exit 1 [ ! -x /usr/bin/wget ]&amp;&amp;echo &quot;not found command: wget&quot;&amp;&amp;exit 1 &#125;install_python () &#123;check#1、download python source packageif ! (wget $source_url &amp;&gt;/dev/null) ;then echo &quot;$source_pkg download fail&quot; exit 1fi#2、Decompression source packageif [ -f $source_pkg ];then tar xf $source_pkgelse echo &quot;not found package: $source_pkg&quot; exit 1fi#3、python install preif ! (yum -y install gcc-* openssl-* libffi-devel curses-devel lm_sensors sqlite-devel &amp;&gt;/dev/null);then echo &quot;yum install software package fail&quot; exit 1fi#4、configure python install envif [ -d $source_doc ];then #5、python configure cd $source_doc sed -i.bak &#x27;212s/#//&#x27; Modules/Setup.dist sed -i &#x27;213s/#//&#x27; Modules/Setup.dist sed -i &#x27;214s/#//&#x27; Modules/Setup.dist echo &quot;python configure...please waiting&quot; if ./configure --enable-optimizations --with-openssl=/usr/bin/openssl &amp;&gt;/dev/null ;then #6、python make echo &quot;python make...please waiting&quot; if make -j $cpu_count &amp;&gt;/dev/null ;then #7、python install echo &quot;python install...please waiting&quot; if make install &amp; &gt; /dev/null;then echo &quot;$source_doc install success&quot; else echo &quot;python make install fail&quot; exit 1 fi else echo &quot;python make fail&quot; exit 1 fi else echo &quot;python configure fail&quot; exit 1 fielse echo &quot;not found $source_doc&quot; exit 1fipost_install&#125; #Post-installation settingspost_install () &#123;#update pip toolpip3 install --upgrade pip&#125;#函数调用install_python &amp;&amp; rm -rf $source_doc 3.2、glances 安装1234567891011[root@manager01 ~]# pip install glancesCollecting glances Downloading https://files.pythonhosted.org/packages/32/34/72f9202ad5b7ada314507a50b9ab1fb604d2f468b138679e0a4fedeb91fa/Glances-3.1.0.tar.gz (6.7MB) |████████████████████████████████| 6.7MB 659kB/s Collecting psutil&gt;=5.3.0 (from glances) Downloading https://files.pythonhosted.org/packages/1c/ca/5b8c1fe032a458c2c4bcbe509d1401dca9dda35c7fc46b36bb81c2834740/psutil-5.6.3.tar.gz (435kB) |████████████████████████████████| 440kB 575kB/s Installing collected packages: psutil, glances Running setup.py install for psutil ... done Running setup.py install for glances ... doneSuccessfully installed glances-3.1.0 psutil-5.6.3 3.3、温度监控工具安装1[root@manager01 ~]# yum -y install lm_sensors 3.4、epel公网源安装12[root@manager01 ~]# yum install epel* -y[root@manager01 ~]# yum -y install glances 四、glances监控4.1、开启glances监控1[root@manager01 ~]# glances glances_1.png glances 工作界面的说明 :在上图 的上部是 CPU 、Load（负载）、Mem（内存使用）、 Swap（交换分区）的使用情况。在上图的中上部是网络接口、Processes（进程）的使用情况。通常包括如下字段： 1234567891011%CPU：该进程占用的 CPU 使用率%MEM：该进程占用的物理内存和总内存的百分比VIRT: 虚拟内存大小RES: 进程占用的物理内存值PID: 进程 ID 号USER: 进程所有者的用户名NI: 进程优先级S: 进程状态，其中 S 表示休眠，R 表示正在运行，Z 表示僵死状态。TIME+: 该进程启动后占用的总的 CPU 时间IO_R 和 IO_W: 进程的读写 I/O 速率Command: 进程名称 在上图的左侧是网络、磁盘IO、磁盘分区使用情况。 另外 glances 可以使用交互式的方式运行该工具，用户可以使用如下快捷键： 123456789101112h ： 显示帮助信息q ： 离开程序退出c ：按照 CPU 实时负载对系统进程进行排序m ：按照内存使用状况对系统进程排序i：按照 I/O 使用状况对系统进程排序p： 按照进程名称排序d ： 显示磁盘读写状况 w ： 删除日志文件l ：显示日志s： 显示传感器信息f ： 显示系统信息1 ：轮流显示每个 CPU 内核的使用情况（次选项仅仅使用在多核 CPU 系统） 4.2、glances 使用方法12345678910111213141516glances 是一个命令行工具包括如下命令选项：-b：显示网络连接速度 Byte/ 秒-B @IP|host ：绑定服务器端 IP 地址或者主机名称-c @IP|host：连接 glances 服务器端-C file：设置配置文件默认是 /etc/glances/glances.conf -d：关闭磁盘 I/O 模块-e：显示传感器温度-f file：设置输出文件（格式是 HTML 或者 CSV）-m：关闭挂载的磁盘模块-n：关闭网络模块-p PORT：设置运行端口默认是 61209 -P password：设置客户端 / 服务器密码-s：设置 glances 运行模式为服务器-t sec：设置屏幕刷新的时间间隔，单位为秒，默认值为 2 秒，数值许可范围：1~32767 -h : 显示帮助信息-v : 显示版本信息 五、glances C&#x2F;S模式glances还支持C&#x2F;S模式监控，被监控机运行服务端，监控端运行客户端既可以实现远程监控。 glances_cs.png 注意：C&#x2F;S模式都必须安装glances才可以实现 5.1、服务端启动服务端使用的端口默认是61209,如果使用服务端请注意开启防火墙。 glances_服务端.png 5.2、客户端访问1[root@zutuanxue ~]# glances -c 192.168.10.100 六、其他数据保存方式6.1、导出数据为CSV电子表格1[root@manager01 ~]# glances --export-csv /tmp/1.csv","categories":["Linux","Linux系统管理宝典"]},{"title":"linux磁盘基本管理","path":"/2023/09/27/Linux系统管理宝典/Linux-磁盘基本管理/","content":"一、磁盘介绍磁盘：计算机中的外部存储设备，负责存储计算机数据，并且断电后也能保持数据不丢失。 磁盘分类： 按照物理结构： 机械磁盘 固态磁盘 按照接口: IDE SCSI SATA SAS mSATA M.2 NVME PCIe 按照尺寸： 机械硬盘：1.8寸 2.5寸 3.5寸 固态硬盘：SATA: 2.5寸 M.2： 2242、2260、2280 二、熟悉磁盘的工作原理机械磁盘的读写数据依靠电机带动盘片转动来完成数据读写的。 机械磁盘剖析图机械硬盘结构.jpeg 1为了使磁盘内部清洁，磁盘是在真空特殊环境中制作的，不能随意拆卸，拆开后基本报废了 机械磁盘工作是依靠马达带动盘片转动，通过磁头来读取磁盘上的数据。 磁盘术语磁盘硬盘中一般会有多个盘片组成，每个盘片包含两个面，每个盘面都对应地有一个读&#x2F;写磁头。受到硬盘整体体积和生产成本的限制，盘片数量都受到限制，一般都在5片以内。盘片的编号自下向上从0开始，如最下边的盘片有0面和1面，再上一个盘片就编号为2面和3面。 磁头负责读取盘面数据的设备 磁道从盘片的最内侧向外有很多同心圆圈，我们称为磁道 扇区从圆心向外画直线，可以将磁道划分为若干个弧段，称之为扇区，一个扇区通常为512B disk2.png 磁柱硬盘通常由重叠的一组盘片构成，每个盘面都被划分为数目相等的磁道，并从外缘的“0”开始编号，具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面。磁盘的柱面数与一个盘面上的磁道数是相等的。由于每个盘面都有自己的磁头，因此，盘面数等于总的磁头数。 disk3.png 三、磁盘的性能指标影响磁盘性能的指标寻道时间（seek time）【和 转速 相关】：Tseek，是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I&#x2F;O操作越快，目前磁盘的平均寻道时间一般在3-15ms 旋转延迟：Trotation，是指盘片旋转将请求数据所在的扇区移动到读写磁头下方所需要的时间。旋转延迟取决于磁盘转速，通常用磁盘旋转一周所需时间的1&#x2F;2表示。比如：7200rpm的磁盘平均旋转延迟大约为60*1000&#x2F;7200&#x2F;2 &#x3D; 4.17ms，而转速为15000rpm的磁盘其平均旋转延迟为2ms。 数据传输时间：Ttransfer，是指完成传输所请求的数据所需要的时间 衡量磁盘性能的指标IOPS：IOPS（Input&#x2F;Output Per Second）即每秒的输入输出量（或读写次数），即指每秒内系统能处理的I&#x2F;O请求数量。随机读写频繁的应用，如小文件存储等，关注随机读写性能，IOPS是关键衡量指标。可以推算出磁盘的IOPS &#x3D; 1000ms &#x2F; (Tseek + Trotation + Transfer)，如果忽略数据传输时间，理论上可以计算出随机读写最大的IOPS。常见磁盘的随机读写最大IOPS为： 7200rpm的磁盘 IOPS &#x3D; 76 IOPS 10000rpm的磁盘IOPS &#x3D; 111 IOPS 15000rpm的磁盘IOPS &#x3D; 166 IOPS throughput ： 吞吐量指单位时间内可以成功传输的数据数量。 单位为（m&#x2F;s G&#x2F;s） 3.png 文件系统：是告知操作系统使用何种方法和数据结构在存储设备或分区上读写数据的；是分区数据管家，负责如何将数据写入磁盘或者从磁盘读出 NTFS EXT3 EXT4 XFS ISO9660 具体有多少 man mount -t 1adfs, affs, autofs, cifs, coda, coherent, cramfs,debugfs, devpts, efs, ext, ext2, ext3, ext4, hfs, hfsplus, hpfs,iso9660, jfs, minix, msdos, ncpfs, nfs, nfs4, ntfs, proc, qnx4,ramfs, reiserfs, romfs, squashfs, smbfs, sysv, tmpfs, ubifs,udf, ufs, umsdos, usbfs, vfat, xenix, xfs, xiafs. 文件系统可以根据应用场景去选择使用哪一款，如果不会选择，推荐ext4或者XFS page cache 其实就是内存上空闲的部分 用来缓存数据，比如buffer cache 作用：对IO读写做优化 测试缓存对读写的影响 12345678910111213141516171819202122232425262728293031323334353637写[root@zutuanxue ~]# echo 3 &gt; /proc/sys/vm/drop_caches[root@zutuanxue ~]# free -m total used free shared buff/cache availableMem: 1980 95 1807 9 77 1754Swap: 2047 0 2047[root@zutuanxue ~]# dd if=/dev/zero of=/tmp/big bs=1M count=1000记录了1000+0 的读入记录了1000+0 的写出1048576000字节(1.0 GB)已复制，10.2412 秒，102 MB/秒[root@zutuanxue ~]# free -m total used free shared buff/cache availableMem: 1980 95 779 9 1105 1698Swap: 2047 0 2047[root@zutuanxue ~]# dd if=/dev/zero of=/tmp/big1 bs=1M count=1000记录了1000+0 的读入记录了1000+0 的写出1048576000字节(1.0 GB)已复制，7.89978 秒，133 MB/秒读[root@zutuanxue ~]# echo 3 &gt; /proc/sys/vm/drop_caches [root@zutuanxue ~]# free -m total used free shared buff/cache availableMem: 1980 95 1805 9 79 1753Swap: 2047 0 2047[root@zutuanxue ~]# dd if=/tmp/big of=/dev/null 记录了2048000+0 的读入记录了2048000+0 的写出1048576000字节(1.0 GB)已复制，2.23965 秒，468 MB/秒[root@zutuanxue ~]# free -m total used free shared buff/cache availableMem: 1980 95 800 9 1084 1710Swap: 2047 0 2047[root@zutuanxue ~]# dd if=/tmp/big of=/dev/null 记录了2048000+0 的读入记录了2048000+0 的写出1048576000字节(1.0 GB)已复制，1.92811 秒，544 MB/秒 四、linux磁盘的使用方法4.1、磁盘初始化 一块新的磁盘使用必须初始化为MBR或者GPT分区。 MBR &lt;2TB fdisk 4个主分区或者3个主分区+1个扩展分区（N个逻辑分区） MBR(Master Boot Record)的缩写，由三部分组成，即： Bootloader（主引导程序）&#x3D; 446字节 引导操作系统的主程序 DPT分区表（Disk Partition Table）&#x3D; 64字节 分区表保存了硬盘的分区信息，操作系统通过读取分区表内的信息，就能够获得该硬盘的分区信息 每个分区需要占用16个字节大小，保存有文件系统标识、起止柱面号、磁头号、扇区号、起始扇区位置（4个字节）、分区总扇区数目（4个字节）等内容 分区表中保存的分区信息都是主分区与扩展分区的分区信息，扩展分区不能直接使用，需要在扩展分区内划分一个或多个逻辑分区后才能使用 逻辑分区的分区信息保存在扩展分区内而不是保存在MBR分区表内，这样，就可以突破MBR分区表只能保存4个分区的限制 硬盘有效标志（校验位）&#x3D;2个字节 GPT &gt;2TB gdisk(parted) 128个主分区 注意：从MBR转到GPT，或从GPT转换到MBR会导致数据全部丢失！ 4.2、分区 将磁盘合理分区，能使计算机或者使用者更快的存取数据 MBR 主分区+扩展分区&lt;&#x3D;4 GPT 主分区&lt;&#x3D;128 4.3、格式化 装载文件系统(相当于库管，负责数据的写入和读出)。 常见的文件系统:NTFS EXT EXT2 EXT3 EXT4 XFS vfat 4.4、挂载 linux中设备不能直接使用，需要挂载到文件夹才可以。 挂载方式： 手动挂载 开机挂载 自动挂载","categories":["Linux","Linux系统管理宝典"]},{"title":"linux磁盘管理-RAID介绍","path":"/2023/09/27/Linux系统管理宝典/Linux-磁盘管理-RAID介绍/","content":"一、RAID介绍RAID(Redundant Array of Independent Disk 独立冗余磁盘阵列)技术是加州大学伯克利分校1987年提出，最初是为了组合小的廉价磁盘来代替大的昂贵磁盘，同时希望磁盘失效时不会使对数据的访问受损失而开发出一定水平的数据保护技术。RAID就是一种由多块廉价磁盘构成的冗余阵列，在操作系统下是作为一个独立的大型存储设备出现。RAID可以充分发挥出多块硬盘的优势，可以提升硬盘速度，增大容量，提供容错功能，能够确保数据安全性，易于管理的优点，在任何一块硬盘出现问题的情况下都可以继续工作，不会 受到损坏硬盘的影响。 二、常见的RAID级别2.1、 RAID0raid0.png RAID0特点： 至少需要两块磁盘 数据条带化分布到磁盘，高的读写性能，100%高存储空间利用率 数据没有冗余策略，一块磁盘故障，数据将无法恢复 应用场景： 对性能要求高但对数据安全性和可靠性要求不高的场景，比如音频、视频等的存储。 2.2、 RAID1raid1.png RAID1特点： 至少需要2块磁盘 数据镜像备份写到磁盘上(工作盘和镜像盘)，可靠性高，磁盘利用率为50% 读性能可以，但写性能不佳 一块磁盘故障，不会影响数据的读写 应用场景： 对数据安全可靠要求较高的场景，比如邮件系统、交易系统等。 2.3、 RAID5raid5.png RAID5特点： 至少需要3块磁盘 数据条带化存储在磁盘，读写性能好，磁盘利用率为(n-1)&#x2F;n 以奇偶校验(分散)做数据冗余 一块磁盘故障，可根据其他数据块和对应的校验数据重构损坏数据（消耗性能） 是目前综合性能最佳的数据保护解决方案 兼顾了存储性能、数据安全和存储成本等各方面因素（性价比高） 适用于大部分的应用场景 2.4、 RAID6raid6.png RAID6特点： 至少需要4块磁盘 数据条带化存储在磁盘，读取性能好，容错能力强 采用双重校验方式保证数据的安全性 如果2块磁盘同时故障，可以通过两个校验数据来重建两个磁盘的数据 成本要比其他等级高，并且更复杂 一般用于对数据安全性要求非常高的场合 2.5、 RAID10raid10.png RAID10特点： RAID10是raid1+raid0的组合 至少需要4块磁盘 两块硬盘为一组先做raid1，再将做好raid1的两组做raid0 兼顾数据的冗余（raid1镜像）和读写性能（raid0数据条带化） 磁盘利用率为50%，成本较高 三、RAID总结 类型 读写性能 可靠性 磁盘利用率 成本 RAID0 最好 最低 100% 较低 RAID1 读快；写一般 高 50% 高 RAID5 读:近似RAID0 写:多了校验 RAID0&lt;RAID5&lt;RAID1 (n-1)&#x2F;n RAID0&lt;RAID5&lt;RAID1 RAID6 读：近似RAID0 写:多了双重校验 RAID6&gt;RAID5 RAID6&lt;RAID5 RAID6&gt;RAID1 RAID10 读：RAID10&#x3D;RAID0 写：RAID10&#x3D;RAID1 高 50% 最高 四、RAID分类软RAID软RAID运行于操作系统底层，将SCSI或者IDE控制器提交上来的物理磁盘，虚拟成虚拟磁盘，再提交给管理程序来进行管理。软RAID有以下特点： 节省成本，系统支持就可以使用相应功能 占用内存空间 占用CPU资源 如果程序或者操作系统故障就无法运行 硬RAID通过用硬件来实现RAID功能的就是硬RAID，独立的RAID卡，主板集成的RAID芯片都是硬RAID。RAID卡就是用来实现RAID功能的板卡。硬RAID的特点： 硬RAID有独立的运算单元，性能好 可能需要单独购买额外的硬件 不同RAID卡支持的功能不同，需要根据自己的需求选择","categories":["Linux","Linux系统管理宝典"]},{"title":"linux组管理","path":"/2023/09/27/Linux系统管理宝典/Linux-组管理/","content":"组账号管理本机的群组账号数据被储存在 &#x2F;etc&#x2F;group 文件中，权限也必须为0644，与 &#x2F;etc&#x2F;passwd 一样，这也是一个文本文件。 123root:x:0:bin:x:1:daemon:x:2: 这与&#x2F;etc&#x2F;passwd文件的格式类似 123456789GROUPNAME:PASSWORD:GID:MEMBERS - GROUPNAME:组名- PASSWORD:组密码，这里也和passwd文件一样是个x- GID：群组识别号- MEMBERS：组成员 一起来看下组管理的相关命令 groupadd 建立组 1234567891011121314151617181920212223242526命令介绍 groupadd - 创建一个新组命令语法 groupadd [选项] group命令选项-g GID 指定群组账号的标识符 -r 指定添加的群组成为系统群组-f 强制执行。 在一般的情况下，groupadd 不允许建立一个与使用过的 GID 相同的群组账号，而使用这个参数时，groupadd 将会建立相同 GID 的 群组账号。-o 此选项允许添加一个使用非唯一 GID 的组。#组相关文件 /etc/group 组账户信息。 /etc/gshadow 安全组账户信息。 /etc/login.defs Shadow 密码套件配置。 groupmod 修改群组信息 123456789命令介绍 groupmod - 修改组信息命令语法 groupmod [选项] GROUP命令选项-g GID 修改群组账号的标识符。GID 就是新的标识符。-n NEWNAME 用来修改群组的名称。NEWNAME 就是新的组名。 groupdel 删除群组账号 12345678命令介绍\tgroupdel - 删除一个组命令语法\tgroupdel [选项] GROUP命令选项-f 强制 您不能移除现有用户的主组。在移除此组之前，必须先移除此用户。","categories":["Linux","Linux系统管理宝典"]},{"title":"Linux终端的使用","path":"/2023/09/27/Linux系统管理宝典/Linux-终端的使用/","content":"一、终端的作用要了解终端，就要了解一下计算机方面的历史，早期的计算机都属于大中型计算机，是个庞然大物，占用很大的空间，属于公用产品。不像现在的电脑，可以人手一部，直接操作。那如何对这些计算机进行控制与操作呢。那就搞个终端设备来操作。因此一台计算机上有很多种不同的终端设备也和正常。也就是说终端就是为主机提供了人机接口，每个人都通过终端使用主机的资源。 终端有字符终端和图形终端两种模式。在linux的图形环境下，我们可以通过鼠标点击来完成所有的管理任务，这是图形界面终端，另外一种就是文本界面的终端，在这个界面的终端下我们可以使用linux命令来控制系统完成响应的工作，而这个文本终端也是服务器常用的模式。 用一句话来说终端就是存在于用户和计算机之间沟通的桥梁，通过终端，用户可以控制计算机完成响应的工作，也可以获得到计算机的反馈 二、打开终端的几种方法第一种，我们登录系统之后就已经打开了图形终端，在图形终端中也给我们提供了一个可以用linux命令控制系统的工具，我们点击屏幕左上角的“活动”就可以找到这个它 1570773103451.png 打开之后我们会看到linux的命令行，在这里面我们可以输入linux命令来进行操作 1570773158443.png 第二种 打开文本终端，这个需要键盘上的组合键[Ctrl] + [Alt] + [F1] - [F6] ，其中F1和F2是两个可供登录的图形终端，F3-F6为文本终端，现在我们使用[Ctrl] + [Alt] + [F3]打开文本终端，然后使用root用户登录 1570773655859.png 这就是在linux中终端的打开方式，那我们接下来看一下有哪些快捷键 三、常用快捷键1、图形界面下通过点击屏幕右上角的“活动”按钮打开的终端 1234567[Shift]+[Ctrl]+t\t以标签的形式打开一个新的终端[Shift]+[Ctrl]+n\t以窗口的形式打开一个新的终端[Shift]+[Ctrl]+w\t关闭标签页[Shift]+[Ctrl]+q\t关闭窗口 如果你想知道额外的快捷键，点击终端上方的文字按钮，会有对应快捷键的提示 1570774251987.png 2、通用快捷键 12345678910111213141516171819Ctrl+r: 实现快速检索使用过的历史命令.Ctrl+a: 光标回到命令行首。 Ctrl+e: 光标回到命令行尾。 ctrl+w: 移除光标前的一个单词Ctrl+k: 删除光标处到行尾的字符。Ctrl+u: 删除整个命令行文本字符。Ctrl+y: 粘贴Ctrl+u，Ctrl+k，Ctrl+w删除的文本。Ctrl+d: 删除提示符所在出的一个字符，在空命令行的情况下可以退出终端。esc+. : 上一个命令的后面的参数Ctrl+b: 光标向行首移动一个字符。Ctrl+f: 光标向行尾移动一个字符。Ctrl+h: 向行首删除一个字符。Ctrl+i: 相当于Tab键。Ctrl+L: 清屏Ctrl+s: 使终端发呆，静止，可以使快速输出的终端屏幕停下来。Ctrl+q: 退出Ctrl+s引起的发呆。Ctrl+z: 使正在运行在终端的任务，运行于后台。 （可用fg恢复）Ctrl+c: 中断终端中正在执行的任务。Tab键: 命令、文件名等自动补全功能。","categories":["Linux","Linux系统管理宝典"]},{"title":"linux网络相关设置","path":"/2023/09/27/Linux系统管理宝典/Linux-网络相关设置/","content":"网络配置文件&#x2F;etc&#x2F;NetworkManager&#x2F;NetworkManager.conf NetworkManager服务配置文件，如果没有特殊需求不建议调整，如果需要调整的话，调整之前备份，调整完成重新启动服务 &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-xx网卡配置文件 123456789101112131415161718192021网卡配置文件中的关键参数[root@zutuanxue ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=&quot;Ethernet&quot;\t网卡类型BOOTPROTO=&quot;dhcp&quot;\tIP获取方式，dhcp/static（none）DEFROUTE=&quot;yes&quot; 是否设置为IPV4默认路由NAME=&quot;ens33&quot;\t连接名称UUID=&quot;b5ecf570-543c-4da7-b082-bdc073b56acb&quot; 网卡识别号DEVICE=&quot;ens33&quot;\t设备名称ONBOOT=&quot;yes&quot; 是否开机自动启动此网络连接额外设置参数NM_CONTROLLED=yes\t是否被NetworkManager服务管理，默认yesIPADDR ip地址NETMASK 子网掩码GATEWAY 定义网关DNS1 dns地址\t优先级高于/etc/resolv.confDNS2 dns地址USERCTL 是否允许普通用户控制此设备PEERDNS 是否允许自动修改dns配置文件/etc/resolv.confPREFIX 掩码长度 &#x2F;etc&#x2F;hostname 主机名配置文件 12[root@zutuanxue ~]# cat /etc/hostname hello &#x2F;etc&#x2F;resolv.conf DNS配置文件 123456[root@zutuanxue ~]# cat /etc/resolv.conf # Generated by NetworkManagersearch localdomainnameserver 192.168.17.2nameserver 202.106.0.20nameserver 114.114.114.114 其它命令 ifconfig命令:查看网卡信息 123456789101112131415[root@zutuanxue ~]# ifconfigens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 连接信息 inet 192.168.1.55 netmask 255.255.255.0 broadcast 192.168.1.255\tIPV4地址信息 inet6 fe80::ea62:91c6:114:18bb prefixlen 64 scopeid 0x20&lt;link&gt;\tIPV6地址信息 ether 00:0c:29:11:47:97 txqueuelen 1000 (Ethernet)\tmac地址 RX packets 174914 bytes 51397660 (49.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 接收到的数据包统计 TX packets 24446 bytes 3114546 (2.9 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0\t发送的数据包统计停用网卡[root@zutuanxue ~]# ifconfig ens37 down启用网卡[root@zutuanxue ~]# ifconfig ens37 up设置一个临时IP[root@zutuanxue ~]# ifconfig ens37 192.168.18.100 route命令：设置路由 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@zutuanxue ~]# route\t-n 以数字的形式显示路由信息\tadd/del 添加/删除路由信息，需要配合下面参数使用\t-net 指定为一个网络\t-host 指定为一台主机\tnetmask 指定掩码\tgw 指定网关\tdev 指定设备\tDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 192.168.1.1 0.0.0.0 UG 102 0 0 ens33192.168.1.0 0.0.0.0 255.255.255.0 U 102 0 0 ens33192.168.20.0 0.0.0.0 255.255.255.0 U 100 0 0 ens37主要信息Destination 目的地址 Gateway 网关Genmask 掩码Flags 标识\tU=启用，H=主机，G=网关\tIface 接口添加路由信息[root@zutuanxue ~]#route add -net 192.168.20.0/24 dev ens37删除路由信息[root@zutuanxue ~]#route del -net 192.168.20.0/24\tdev ens37dhclient获取与释放IP地址[root@zutuanxue ~]# dhclient -r ens37[root@zutuanxue ~]# dhclient ens37ping连通性测试工具[root@zutuanxue ~]# ping\tc 指定次数\tn 以数字的形式显示结果\tf 洪水ping，以最快的速度收发数据包，慎用\t[root@zutuanxue ~]# ping -c 5 -n www.163.comPING z163ipv6.v.bsgslb.cn (111.202.34.27) 56(84) bytes of data.64 bytes from 111.202.34.27: icmp_seq=1 ttl=128 time=5.25 ms64 bytes from 111.202.34.27: icmp_seq=2 ttl=128 time=8.54 ms64 bytes from 111.202.34.27: icmp_seq=3 ttl=128 time=6.22 ms64 bytes from 111.202.34.27: icmp_seq=4 ttl=128 time=5.78 ms64 bytes from 111.202.34.27: icmp_seq=5 ttl=128 time=5.60 ms--- z163ipv6.v.bsgslb.cn ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 13msrtt min/avg/max/mdev = 5.253/6.278/8.536/1.173 ms","categories":["Linux","Linux系统管理宝典"]},{"title":"linux网络故障排查","path":"/2023/09/27/Linux系统管理宝典/Linux-网络故障排查/","content":"在日常使用中，经常会出现无法连通的情况，这个时候我们就需要找到问题出在哪里，这里面给各位提供一个生产环境排查网络故障的大体思路，一般情况下如果遇到网络故障，都是通过筛选的方式一点一点的确定问题所在，首先判断是本机的问题还是网络上其它设备的问题，如果同一网络环境中的其它主机正常的，要去其它网络设备（路由器）上查看一下是否对网络有问题的主机设置了限制，如果没有的话，问题出在本机，这里面我们主要看下下本机容易出现哪些问题导致页面无法访问 一、网线和网卡设置检查网卡的灯是否亮起，普通服务器的话应该是绿灯常亮为正常，交换机绿灯闪烁表示正在传输数据。也可以通过命令ethtool ethX来查看某一网卡的链路是否物理连通。 命令介绍 ethtool 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102[root@zutuanxue ~]# ethtool ens33Settings for ens33:\tSupported ports: [ TP ]\t#接口类型\t#TP RJ45接口双绞线\t#AUI “D”型15针接口\t#BNC 细同轴电缆接口，类似于以前的有线电视 #MII 媒体独立接口，一种以太网行业标准\t#FIBRE\t光纤\tSupported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full #支持的链接模式\tSupported pause frame use: No\t#是否支持暂停帧--一种网卡流量控制技术\tSupports auto-negotiation: Yes\t#是否支持自动协商，网络设备相互告知对方自己的工作方式，包括传输速度，双工状态等，然后选择一个最佳的\tSupported FEC modes: Not reported\t#编码纠错模式，支持编码纠错可提高数据通讯可信度\tAdvertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full #宣告的链接模式\tAdvertised pause frame use: No\t#宣告的是否支持帧暂停\tAdvertised auto-negotiation: Yes\t#宣告的是否支持自动协商\tAdvertised FEC modes: Not reported\t#宣告的是否FEC\tSpeed: 1000Mb/s\t#当前速度\tDuplex: Full\t#全双工还是半双工\tPort: Twisted Pair\t#线缆类型为双绞线\tPHYAD: 0\t#PHY地址，主要指PHY芯片，用来发送和接收数据帧\tTransceiver: internal\t#收发器类型 internal/external（内部外部）是否是板载的\tAuto-negotiation: on\t#自动协商功能开启\tMDI-X: off (auto)\t#自适应功能\tSupports Wake-on: d\t#是否支持远程唤醒 d=禁用，p\\u\\m\\b\\a\\g=不同唤醒方式\tWake-on: d\tCurrent message level: 0x00000007 (7)\tdrv probe link\tLink detected: yes\t#网卡已连接 ##############常用参数#-a 查看网卡中 接收模块RX、发送模块TX和Autonegotiate模块的状态：启动on 或 停用off。主要指接收暂停，发送暂停和自动协商暂停功能，也就是暂停帧，主要用于控制数据路停止发送，可以防止瞬间压力过大导致缓冲区溢出而引发的帧丢失（丢包）#[root@zutuanxue ~]# ethtool -a ens33Pause parameters for ens33:Autonegotiate:\tonRX: offTX: off#-A 修改网卡中 接收模块RX、发送模块TX和Autonegotiate模块的状态：启动on 或 停用off。[root@zutuanxue ~]# ethtool -A ens33 rx/tx/autoneg on#-i 显示网卡驱动的信息，如驱动的名称、版本等。[root@zutuanxue ~]# ethtool -i ens33driver: e1000version: 7.3.21-k8-NAPIfirmware-version: expansion-rom-version: bus-info: 0000:02:01.0supports-statistics: yessupports-test: yessupports-eeprom-access: yessupports-register-dump: yessupports-priv-flags: no#-k 显示网卡各项功能的支持和协议状态，如支持某个协议的功能是否开启等#-p 用于区别不同ethX对应网卡的物理位置，常用的方法是使网卡port上的led不断的闪；N为网卡闪的持续时间，以秒为单位。[root@zutuanxue ~]# ethtool -p ens33 10#-r 如果自动协商状态为on，则重启自动协商功能。[root@zutuanxue ~]# ethtool -r ens33#-S 显示统计参数，如网卡接收/发送的字节数、接收/发送的广播包个数等。[root@zutuanxue ~]# ethtool -S ens33NIC statistics: rx_packets: 609 tx_packets: 130 rx_bytes: 121330 tx_bytes: 16066 rx_broadcast: 0#-s 修改网卡的部分配置，包括网卡速度、单工/全双工模式、mac地址等。\tethtool –s ethX [speed 10|100|1000] #设置网口速率10/100/1000M [duplex half|full] #设置网口半/全双工 [autoneg on|off] #设置网口是否自协商 [port tp|aui|bnc|mii] #设置网口类型[root@zutuanxue ~]# ethtool -s ens33 speed 1000 duplex full autoneg on port tp 二、selinux&amp;防火墙这两个是最容易产生干扰的项目，selinux和防火墙如何关闭，我们在前面的课程中有涉及，这里就不重复了 三、查看网卡ip地址，网关设置使用ifconfig或者nmcli命令查看&#x2F;设置ip地址和网关 四、使用ping命令测试连通性123456789101112131415-c&lt;完成次数&gt;：设置完成要求回应的次数；-f：洪水ping只有root可以使用-i&lt;间隔秒数&gt;：指定收发信息的间隔时间；-n：只输出数值,不尝试去查找主机名-s&lt;数据包大小&gt;：设置数据包的大小；-I 指定源地址（源地址必须是本地网卡上存在的配置）[root@zutuanxuers1 ~]# ping -c 3 -i 0.5 -n -s 1024 -I 192.168.2.220 192.168.2.220PING 192.168.2.220 (192.168.2.220) from 192.168.2.220 : 1024(1052) bytes of data.1032 bytes from 192.168.2.220: icmp_seq=1 ttl=64 time=0.047 ms1032 bytes from 192.168.2.220: icmp_seq=2 ttl=64 time=0.060 ms1032 bytes from 192.168.2.220: icmp_seq=3 ttl=64 time=0.053 ms--- 192.168.2.220 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 13msrtt min/avg/max/mdev = 0.047/0.053/0.060/0.008 ms 五、路由使用route命令查看或设置路由及网关，也可以通过修改静态路由配置文件实现 六、DNS &#x2F;etc&#x2F;hosts&amp;&#x2F;etc&#x2F;resolv.conf nslookup dig host 七、追踪数据包123456789101112131415161718tracepath [参数选项] hostname，域名或 IP地址#替代了以前的traceroute参数选项：-4\t使用IPV4-6\t使用IPV6=tracepath6-l\t设置初始包的大小 默认IPV4 65535，ipv6 128000-m 设置检测数据包的TTL，默认值为30次；-n 显示IP地址，不查主机名。当DNS不起作用时常用到这个参数；-b\t显示主机名和IP地址-p port 探测包使用的基本UDP端口设置为port ，默认值是33434[root@zutuanxuers1 ~]# tracepath -b www.baidu.com -l 1000 -m 5 1: localhost (192.168.0.1) 18.324ms 2: localhost (192.168.1.1) 15.622ms 3: localhost (10.70.0.1) 18.640ms 4: 114.244.94.25 (114.244.94.25) 7.213ms 5: 124.65.56.141 (124.65.56.141) 16.020ms Too many hops: pmtu 1000 Resume: pmtu 1000 八、硬件故障更换硬件","categories":["Linux","Linux系统管理宝典"]},{"title":"linux聚合链路","path":"/2023/09/27/Linux系统管理宝典/Linux-聚合链路/","content":"聚合链路聚合链路是将多块网卡逻辑地连接到一起从而允许故障转移或者提高吞吐率的方法。提高服务器网络可用性。 bond是将多块网卡虚拟成为一块网卡的技术，通过bond技术让多块网卡看起来是一个单独的以太网接口设备并具有相同的ip地址。在linux下配置bond，通过网卡绑定技术既能增加服务器的可靠性，又增加了可用网络宽带，为用户提供不间断的网络服务。team是另一种用来实现连路聚合和方法，类似于bond，team和bond的区别在于，支持hash加密，支持负载均衡，支持8块网卡，更好地支持IPV6 实现方式 bond team bond聚合链路bond聚合链路模式 mod&#x3D;0 ，即：(balance-rr) Round-robin policy（轮询） 聚合口数据报文按包轮询从物理接口转发。 – 负载均衡—所有链路处于负载均衡状态，轮询方式往每条链路发送报文这模式的特点增加了带宽，同时支持容错能力，当有链路出问题，会把流量切换到正常的链路上。 – 性能问题—一个连接或者会话的数据包如果从不同的接口发出的话，中途再经过不同的链路，在客户端很有可能会出现数据包无序到达的问题，而无序到达的数据包需要重新要求被发送，这样网络的吞吐量就会下降。Bond0在大压力的网络传输下，性能增长的并不是很理想。 – 需要交换机进行端口绑定 mod&#x3D;1，即： (active-backup) Active-backup policy（主-备份策略）只有Active状态的物理接口才转发数据报文。 – 容错能力—只有一个slave是激活的(active)。也就是说同一时刻只有一个网卡处于工作状态，其他的slave都处于备份状态，只有在当前激活的slave故障后才有可能会变为激活的(active)。 – 无负载均衡—此算法的优点是可以提供高网络连接的可用性，但是它的资源利用率较低，只有一个接口处于工作状态，在有 N 个网络接口的情况下，资源利用率为1&#x2F;N。 mod&#x3D;2，即：(balance-xor) XOR policy（平衡策略） 聚合口数据报文按源目MAC、源目IP、源目端口进行异或HASH运算得到一个值，根据该值查找接口转发数据报文 – 负载均衡—基于指定的传输HASH策略传输数据包。 容错能力—这模式的特点增加了带宽，同时支持容错能力，当有链路出问题，会把流量切换到正常的链路上。 – 性能问题—该模式将限定流量，以保证到达特定对端的流量总是从同一个接口上发出。既然目的地是通过MAC地址来决定的，因此该模式在“本地”网络配置下可以工作得很好。如果所有流量是通过单个路由器，由于只有一个网关，源和目标mac都固定了，那么这个算法算出的线路就一直是同一条，那么这种模式就没有多少意义了。 – 需要交换机配置为port channel mod&#x3D;3，即：broadcast（广播策略） 这种模式的特点是一个报文会复制两份往bond下的两个接口分别发送出去，当有对端交换机失效，我们感觉不到任何downtime，但此法过于浪费资源；不过这种模式有很好的容错机制。此模式适用于金融行业，因为他们需要高可靠性的网络，不允许出现任何问题。 mod&#x3D;4，即：(802.3ad) IEEE 802.3ad Dynamic link aggregation（IEEE 802.3ad 动态链接聚合） 在动态聚合模式下，聚合组内的成员端口上均启用LACP（链路汇聚控制协议）协议，其端口状态通过该协议自动进行维护。 – 负载均衡—基于指定的传输HASH策略传输数据包。默认算法与blance-xor一样。 – 容错能力—这模式的特点增加了带宽，同时支持容错能力，当有链路出问题，会把流量切换到正常的链路上。对比blance-xor，这种模式定期发送LACPDU报文维护链路聚合状态，保证链路质量。 – 需要交换机支持LACP协议 mod&#x3D;5，即：(balance-tlb) Adaptive transmit load balancing（适配器传输负载均衡） 在每个物理接口上根据当前的负载（根据速度计算）分配外出流量。如果正在接收数据的物理接口口出故障了，另一个物理接口接管该故障物理口的MAC地址。 需要ethtool支持获取每个slave的速率 mod&#x3D;6，即：(balance-alb) Adaptive load balancing（适配器适应性负载均衡） 该模式包含了balance-tlb模式，同时加上针对IPV4流量的接收负载均衡，而且不需要任何switch(交换机)的支持。接收负载均衡是通过ARP协商实现的。bonding驱动截获本机发送的ARP应答，并把源硬件地址改写为bond中某个物理接口的唯一硬件地址，从而使得不同的对端使用不同的硬件地址进行通信。 123456其实mod=6与mod=0的区别：mod=6，先把eth0流量占满，再占eth1，….ethX；而mod=0的话，会发现2个口的流量都很稳定，基本一样的带宽。而mod=6，会发现第一个口流量很高，第2个口只占了小部分流量常用的模式为 0136mode 1、5、6不需要交换机设置mode 0、2、3、4需要交换机设置 案例:使用Bond方式设置聚合链路 环境系统：CentOS8网卡名称： ens33（vmnet4） ens37（vmnet4） step 1： 查看环境 1234[root@zutuanxue ~]# nmcli connection NAME UUID TYPE DEVICE ens33 f035d150-9e89-4ee9-a657-03598d4b0940 ethernet ens33 ens37 7726249d-8281-45e8-a8e3-a6a023c64c66 ethernet ens37 step 2： 创建bond虚拟网卡 123456789[root@zutuanxue ~]# nmcli connection add type bond con-name bond0 ifname bond0 mode 1 ipv4.addresses 192.168.98.200/24 ipv4.method manual autoconnect yes#type：创建的类型，这里选择bond类型#con-name:这里写链接名，就是show中第一列，这里写什么生成的文件就是什么名字#ifname:网卡名，这里bond0是虚拟出来的#mode:选择bond模式，常用的有主备，轮询，广播，还有其他模式，用tab补全可以看到所有，也可以使用数字0-6表示#ipv4.mehod:表示自动还是手动，就是使用dhcp还是自己配置地址，关联配置文件中的BOOTPROTO段#ipv4.address：设置ip地址，注意记得加上掩码#autoconnect 自动连接 step 3： 为bond网卡添加成员（真实网卡） 12345678910111213141516171819202122232425[root@zutuanxue ~]# nmcli connection add type bond-slave ifname ens33 master bond0连接 &quot;bond-slave-ens33&quot; (9fb9b3fa-a477-4a6f-a3c1-79cbfe351c7d) 已成功添加。[root@zutuanxue ~]# nmcli connection add type bond-slave ifname ens37 master bond0连接 &quot;bond-slave-ens37&quot; (2b047e49-b606-4b67-9e5c-f721f1e2ff7a) 已成功添加。#类型为bond-slave,表示这块真实网卡属于一块附属的网卡，原有配置的属性都不能使用了，master表示这块从属网卡属于bond0这个组注意：如果你的网卡没有启用的话需要启用[root@zutuanxue ~]# nmcli connection NAME UUID TYPE DEVICE bond0 55e0afdc-d2a6-4c93-b346-0ce207947b81 bond bond0 bond-slave-ens33 9fb9b3fa-a477-4a6f-a3c1-79cbfe351c7d ethernet ens33 bond-slave-ens37 2b047e49-b606-4b67-9e5c-f721f1e2ff7a ethernet ens37 ens33 f035d150-9e89-4ee9-a657-03598d4b0940 ethernet -- ens37 7726249d-8281-45e8-a8e3-a6a023c64c66 ethernet -- [root@zutuanxue ~]# ifconfigbond0: ether 00:0c:29:a6:ad:95 txqueuelen 1000 (Ethernet) ens33: ether 00:0c:29:a6:ad:95 txqueuelen 1000 (Ethernet) ens37: ether 00:0c:29:a6:ad:95 txqueuelen 1000 (Ethernet)[root@zutuanxue ~]# nmcli connection up bond-slave-ens33连接已成功激活（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/81）[root@zutuanxue ~]# nmcli connection up bond-slave-ens37连接已成功激活（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/82）[root@zutuanxue ~]# nmcli connection up bond0连接已成功激活（master waiting for slaves）（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/83） step 4： 查看链接信息并测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445#查看信息[root@zutuanxue ~]# cat /proc/net/bonding/bond0 Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)Bonding Mode: fault-tolerance (active-backup)#模式Primary Slave: NoneCurrently Active Slave: ens33\t#当前设备MII Status: up\t#启用状态MII Polling Interval (ms): 100Up Delay (ms): 0Down Delay (ms): 0Slave Interface: ens33\t#从接口信息MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:a6:ad:95Slave queue ID: 0Slave Interface: ens37\t#另外一个从接口信息MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:a6:ad:9fSlave queue ID: 0或者[root@zutuanxue ~]# ip addens33: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel master bond0 state UP group default qlen 1000 link/ether 00:0c:29:a6:ad:95 brd ff:ff:ff:ff:ff:ffens37: &lt;BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel master bond0 state UP group default qlen 1000 link/ether 00:0c:29:a6:ad:95 brd ff:ff:ff:ff:ff:ffbond0: &lt;BROADCAST,MULTICAST,MASTER,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 00:0c:29:a6:ad:95 brd ff:ff:ff:ff:ff:ff inet 192.168.98.200/24 brd 192.168.98.255 scope global noprefixroute bond0 valid_lft forever preferred_lft forever#找到另外一台主机使用ping进行测试[root@zutuanxue ~]# nmcli connection down bond-slave-xxx或者直接断开虚拟的网络连接测试还能否ping通 删除 12345678910nmcli connection delete bond0 bond-slave-ens33 bond-slave-ens37注意：在配置聚合链路的时候如果使用虚拟机可能会弹出与mac地址相关的信息提示，可以暂时不用去管，如果测试的时候发现断网卡之后无法ping通，则需要在相关网卡配置文件中添加参数，如：[root@zutuanxue ~]# vim /etc/sysconfig/network-scripts/ifcfg-bond0#添加一行内容BONDING_OPTS=&quot;miimon=100 mode=1 fail_over_mac=1&quot;#miimon：链路检查时间为100ms#mode：模式为1，要与bond的模式相同#fail_over_mac=1 mac地址跟随正常工作的网卡，当第一块网卡挂掉之后，自动将mac地址调整为第二块网卡的mac以上操作只有在虚拟机的环境中使用，生产环境一般不需要 team聚合链路案例:使用team方式设置聚合链路 环境系统：CentOS8网卡名称： ens33（vmnet4） ens37（vmnet4） step 1： 建立 12345678910[root@zutuanxue ~]# nmcli connection add type team con-name team0 ifname team0 config &#x27;&#123;&quot;runner&quot;:&#123;&quot;name&quot;:&quot;activebackup&quot;,&quot;hwaddr_policy&quot;:&quot;by_active&quot;&#125;&#125;&#x27; ipv4.addresses 192.168.98.200/24 ipv4.method manual autoconnect yes#JSON语法格式如下：’&#123;“runner”:&#123;“name”:“METHOD”&#125;&#125;’其中METHOD 是以下的其中一个broadcast=mode3roundrobin=mode0activebackup=mode1loadbalance=mode256lacp=mode4#&quot;hwaddr_policy&quot;:&quot;by_active&quot;：硬件地址跟随活跃的网卡，也就是未故障的网卡#聚合链路获取mac的地址有两种方式,一种是从第一个活跃网卡中获取mac地址，然后其余的SLAVE网卡的mac地址都使用该mac地址;另一种是使用hwaddr_policy参数，team使用当前活跃网卡的mac地址，mac地址随活跃网卡的转换而变，虚机不支持第一种获取MAC地址的方式。 step 2： 添加网卡 12[root@zutuanxue ~]# nmcli connection add type team-slave ifname ens33 master team0[root@zutuanxue ~]# nmcli connection add type team-slave ifname ens37 master team0 step 3： 启用连接 123[root@zutuanxue ~]# nmcli connection up team-slave-ens33[root@zutuanxue ~]# nmcli connection up team-slave-ens37[root@zutuanxue ~]# nmcli connection up team0 step 4： 查看状态 1234567891011121314151617181920[root@zutuanxue ~]# teamdctl team0 statsetup: runner: activebackupports: ens33 link watches: link summary: up instance[link_watch_0]: name: ethtool link: up down count: 0 ens37 link watches: link summary: up instance[link_watch_0]: name: ethtool link: up down count: 0runner: active port: ens37","categories":["Linux","Linux系统管理宝典"]},{"title":"linux网络管理","path":"/2023/09/27/Linux系统管理宝典/Linux-网络管理/","content":"现代人的生活越来越依赖网络，对于一个操作系统来讲，网络功能的支持和管理就更为重要了，本节课我们一起来看一下在CentOS8中如何对网络进行管理 NetworkManager和常用工具和基本用法NetworkManager介绍在linux系统中传统的网络管理方法是用过一个叫network的服务来实现，在CentOS7中依然有这个服务的身影，但是到了CentOS8中已经不使用network这个服务了，而是使用了一个叫NetworkManager的服务，这个服务可以简化我们管理有线和无线连接的工作，除此之外它还能管理不同类型的网络，包括物理网卡，虚拟网卡，以太网，非以太网等 常用工具 nmcli：命令行工具 nmtui：文本图形界面工具 cockpit：基于web的管理工具 nmcli基本用法nmcli命令的用法类似linux中以前的ip命令，而且支持tab补全，另外也可以使用-h或者–help获取帮助 123456789101112131415161718192021[root@zutuanxue ~]# nmcli -h[root@zutuanxue ~]# nmcli connection -h可以看到，在不同的阶段获取到的帮助内容是不一样的，具体的用法我们后面会看到nmcli这个工具有两个常用的命令nmcli connection（nmcli c）\t与连接相关的操作[root@zutuanxue network-scripts]# nmcli connection NAME UUID TYPE DEVICE连接名 设备的UUID（通用唯一识别码） 设备类型 设备名称ens33 b5ecf570-543c-4da7-b082-bdc073b56acb ethernet ens33 ens37 077945cb-1d12-4c06-bba3-562426336b67 ethernet -- 在查看时，有颜色的字体标注的是处于活跃状态的网卡，也就是连接的，正常颜色字体标记的是非活跃状态的网卡，也就是未连接的，未连接的不生效nmcli device\t（nmcli d） 与设备相关的操作[root@zutuanxue network-scripts]# nmcli device DEVICE TYPE STATE CONNECTION 设备名 设备类型 设备状态 连接名称ens33 ethernet 已连接 ens33 ens37 ethernet 已断开 -- lo loopback 未托管 -- 在日常使用中这两个命令相互配合，通过nmcli device可以查看到有哪些网络设备是被NetworkManager托管，通过nmcli connection控制网络设备的连接状态 使用nmcli命令设置网卡信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154查看网卡信息[root@zutuanxue ~]# nmcli ens33: 已连接 to ens33\t#设备状态和名称 &quot;Intel 82545EM&quot;\t#设备型号 ethernet (e1000), 00:0C:29:11:47:97, 硬件, mtu 1500 ip4 默认 inet4 192.168.1.55/24 route4 0.0.0.0/0 route4 192.168.1.0/24 inet6 fe80::ea62:91c6:114:18bb/64 route6 fe80::/64 route6 ff00::/8为网卡设置静态IP[root@zutuanxue ~]# nmcli connection add type ethernet con-name ens-test1 ifname ens37 ipv4.addresses 192.168.18.100/24 ipv4.gateway 192.168.18.1 ipv4.method manual 连接 &quot;ens-test1&quot; (da7fdc9a-e7cc-4a1c-8b2c-7751ed2fc4d2) 已成功添加。启用新添加的连接[root@zutuanxue ~]# nmcli connection up ens-test1 连接已成功激活（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/16） 查看连接状态[root@zutuanxue ~]# nmcli connection NAME UUID TYPE DEVICE ens33 b5ecf5... ethernet ens33 ens-test1 da7fdc... ethernet ens37 ens37 077945... ethernet -- 为网卡设置动态IP[root@zutuanxue ~]# nmcli connection add type ethernet con-name ens-test2 ifname ens37 ipv4.method auto连接 &quot;ens-test2&quot; (25b9dd2f-a4c0-452d-bd22-992cf12b55b2) 已成功添加。[root@zutuanxue ~]# nmcli connection up ens-test2 连接已成功激活（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/17）[root@zutuanxue ~]# nmcli connection NAME UUID TYPE DEVICE ens33 b5ec... ethernet ens33 ens-test2 25b9... ethernet ens37 ens37 0779... ethernet -- ens-test1 da7f... ethernet -- 交互式设置IP地址[root@zutuanxue ~]# nmcli connection edit ens-test1 nmcli&gt; goto ipv4.addresses nmcli ipv4.addresses&gt; change编辑 &quot;addresses&quot; 值：192.168.20.100/24您是否也要将 &quot;ipv4.method&quot; 设为 &quot;manual&quot;？[yes]：yesnmcli ipv4.addresses&gt; backnmcli ipv4&gt; save成功地更新了连接 &quot;ens-test1&quot; (da7fdc9a-e7cc-4a1c-8b2c-7751ed2fc4d2)。nmcli ipv4&gt; activate 正在监视连接激活（按任意键继续）连接已成功激活（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/18）nmcli ipv4&gt; quit[root@zutuanxue ~]# nmcli ens37: 已连接 to ens-test1 &quot;Intel 82545EM&quot; ethernet (e1000), 00:0C:29:11:47:A1, 硬件, mtu 1500 ip4 默认 inet4 192.168.20.100/24 route4 192.168.20.0/24 route4 192.168.18.1/32 route4 0.0.0.0/0 inet6 fe80::11c3:e0a4:f62e:9f31/64 route6 fe80::/64 route6 ff00::/8启用和停用[root@zutuanxue ~]# nmcli connection up ens-test1 连接已成功激活（D-Bus 活动路径：...[root@zutuanxue ~]# nmcli connection down ens-test1 成功停用连接 &quot;ens-test1&quot;（D-Bus 活动路...删除连接[root@zutuanxue ~]# nmcli connection delete ens-test1 成功删除连接 &quot;ens-test1&quot; (4fc43f65-ea53-43a1-85d4-692e425fcd7d)。[root@zutuanxue ~]# nmcli connection NAME UUID TYPE DEVICE ens33 b5ec...\tethernet ens33 ens37 0779...\tethernet ens37 [root@zutuanxue ~]# nmcli connection showNAME UUID TYPE DEVICE ens33 b5ec... ethernet ens33 ens37 0779... ethernet ens37 重新加载设置(不会立即生效)[root@zutuanxue ~]# nmcli connection reload重新加载指定的设置(不会立即生效)[root@zutuanxue ~]# nmcli connection load /etc/sysconfig/network-scripts/ifcfg-ens37生效方法 启用设备[root@zutuanxue ~]# nmcli connection up ens37连接已成功激活（D-Bus 活动路径...或者连接设备并更新设备[root@zutuanxue ~]# nmcli device connect ens37 [root@zutuanxue ~]# nmcli device reapply ens37查看设备&amp;查看设备的详细信息[root@zutuanxue ~]# nmcli device DEVICE TYPE STATE CONNECTION ens37 ethernet 已连接 ens37 ens33 ethernet 已连接 ens33 lo loopback 未托管 -- [root@zutuanxue ~]# nmcli device show ens33GENERAL.DEVICE: ens33GENERAL.TYPE: ethernetGENERAL.HWADDR: 00:0C:29:11:47:97GENERAL.MTU: 1500GENERAL.STATE: 100（已连接）GENERAL.CONNECTION: ens33GENERAL.CON-PATH: /org/freedesktop/NetworkMana...WIRED-PROPERTIES.CARRIER: 开IP4.ADDRESS[1]: 192.168.1.55/24IP4.GATEWAY: --IP4.ROUTE[1]: dst = 192.168.1.0/24, nh = 0.0.0.0, mt = 102IP4.DNS[1]: 202.106.0.20IP4.DNS[2]: 114.114.114.114IP6.ADDRESS[1]: fe80::ea62:91c6:114:18bb/64IP6.GATEWAY: --IP6.ROUTE[1]: dst = fe80::/64, nh = ::, mt = 102IP6.ROUTE[2]: dst = ff00::/8, nh = ::, mt = 256, table=255连接/断开网卡[root@zutuanxue ~]# nmcli device connect/disconnect ens37开启/关闭无线网络[root@zutuanxue ~]# nmcli radio all on/off开启/关闭NetworkManager的网络管理功能[root@zutuanxue ~]# nmcli networking on/off监控网络状态[root@zutuanxue ~]# nmcli monitor (ctrl+c结束)ens37: 停用中网络管理器现在处于 &quot;已连接（仅本地）&quot; 状态连接性现在是 &quot;受限&quot;ens37: 已断开询问NetworkManager网络连接状态(默认等待30秒)[root@zutuanxue ~]# nm-online 正在连接............... 30s [online] 使用其他网络管理方式配置网络 nmtui 1[root@zutuanxue ~]# nmtui image20191128171950048.png cockpit 12345678[root@zutuanxue ~]# rpm -qa | grep cockpitcockpit-packagekit-184.1-1.el8.noarchcockpit-system-185-2.el8.noarchcockpit-185-2.el8.x86_64cockpit-bridge-185-2.el8.x86_64cockpit-ws-185-2.el8.x86_64cockpit-storaged-184.1-1.el8.noarch[root@zutuanxue ~]# systemctl start cockpit image20191128172456779.png image20191128172540728.png","categories":["Linux","Linux系统管理宝典"]},{"title":"linux路由管理","path":"/2023/09/27/Linux系统管理宝典/Linux-路由管理/","content":"在前面的课程中我们知道使用route命令可以添加主机的路由信息，但是一旦系统重启相关的设置信息就会丢失,那么如何设置一个重启也不会丢失的路由信息呢? 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[root@zutuanxue ~]# ifconfigens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.98.200 netmask 255.255.255.0 broadcast 192.168.98.255 inet6 fe80::2386:3dbd:531c:7bc1 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:a6:ad:95 txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 37 bytes 4386 (4.2 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0ens37: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.123.123 netmask 255.255.255.0 broadcast 192.168.123.255 inet6 fe80::a848:f674:db3b:a83e prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:a6:ad:9f txqueuelen 1000 (Ethernet) RX packets 5 bytes 1758 (1.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 38 bytes 4390 (4.2 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0#我现在有两块网卡,这两块网卡的ip地址分别是192.168.98.200和192.168.123.123,假如发送到192.168.1.0/24这个网段的数据包需要通过200这块网卡发送出去,而发送到192.168.100.0/24这个网段的数据包需要通过123这块网卡发送出去,我该如何设置呢?使用命令的话我们可以[root@zutuanxue ~]# route add -net 192.168.1.0/24 gateway 192.168.98.1 dev ens33[root@zutuanxue ~]# route add -net 192.168.100.0/24 gateway 192.168.123.1 dev ens37[root@zutuanxue ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.0 192.168.98.1 255.255.255.0 UG 0 0 0 ens33192.168.98.0 0.0.0.0 255.255.255.0 U 100 0 0 ens33192.168.100.0 192.168.123.1 255.255.255.0 UG 0 0 0 ens37192.168.123.0 0.0.0.0 255.255.255.0 U 101 0 0 ens37#这种方式只是临时的,我们来看一下该如何永久添加[root@zutuanxue ~]# route del -net 192.168.100.0/24 gateway 192.168.123.1 dev ens37[root@zutuanxue ~]# route del -net 192.168.1.0/24 gateway 192.168.98.1 dev ens33[root@zutuanxue ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.98.0 0.0.0.0 255.255.255.0 U 100 0 0 ens33192.168.123.0 0.0.0.0 255.255.255.0 U 101 0 0 ens37[root@zutuanxue ~]# vim /etc/sysconfig/network-scripts/route-ens33192.168.1.0/24 via 192.168.98.1 dev ens33[root@zutuanxue ~]# vim /etc/sysconfig/network-scripts/route-ens37192.168.100.0/24 via 192.168.123.1 dev ens37[root@zutuanxue ~]# systemctl restart NetworkManager[root@zutuanxue ~]# nmcli connection down ens33 ens37 成功停用连接 &quot;ens33&quot;（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/1）成功停用连接 &quot;ens37&quot;（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/2）[root@zutuanxue ~]# nmcli connection up ens33 连接已成功激活（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/3）[root@zutuanxue ~]# nmcli connection up ens37连接已成功激活（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/4）[root@zutuanxue network-scripts]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.0 192.168.98.1 255.255.255.0 UG 100 0 0 ens33192.168.98.0 0.0.0.0 255.255.255.0 U 100 0 0 ens33192.168.100.0 192.168.123.1 255.255.255.0 UG 101 0 0 ens37192.168.123.0 0.0.0.0 255.255.255.0 U 101 0 0 ens37","categories":["Linux","Linux系统管理宝典"]},{"title":"linux计划任务","path":"/2023/09/27/Linux系统管理宝典/Linux-计划任务/","content":"一、什么是计划任务每个人在生活当中或多或少都有一些工作，有的工作是按照一定周期循环的， 例如每天固定时间的闹铃、工作打卡等等； 有的工作则是临时发生的，例如刚好有亲友到访，需要你在一个特定的时间去车站迎接！ 这个时候 Linux 的计划任务就可以派上场了！ 在不考虑硬件与我们服务器的连接状态下，我们的 Linux 可以帮你提醒很多任务， 那么 Linux 的例行性工作是如何进行的？ Linux 是通过 crontab 与 at 命令来实现的 at ： at 是个可以处理仅执行一次就结束工作的命令，需要一个叫atd的服务支持，所以这个服务要启动 crontab ： crontab 这个命令所设定的工作将会按照一定的周期去执行！ 可循环的时间为分钟、小时、日期、每周、每月等。crontab 除了可以使用命令执行外，也可以通过编辑 &#x2F;etc&#x2F;crontab 来支持。与at相同，crontab也需要一个叫crond的服务 那么计划任务在系统当中到底有什么作用呢？ 1、进行日志的切割 (log rotate)：Linux 会主动的将系统所发生的各种信息都记录到日志中。随着使用时间的增长，日志文件会越来越大！我们知道大型文件不但占容量还会造成读写效能的困扰， 因此适时的将日志文件数据挪一挪，让旧的数据与新的数据分别存放，这样既能记录日志信息又能提高读写效率。这就是 logrotate 的任务！ 2、日志文件分析 logwatch 的任务： 如果系统发生了问题等，绝大部分的错误信息都会被记录到日志文件中， 因此系统管理员的重要任务之一就是分析日志。但你不可能手动通过 vim 等软件去查看日志文件，因为数据量太大！ 我们可以通过一个叫“ logwatch ”的程序分析日志信息，在启动邮件服务的前提下，你的 root 老是会收到标题为 logwatch 的信件 3、建立 locate 的数据库：有时候我们会通过locate命令来查询文件。而文件名数据库是放置到 &#x2F;var&#x2F;lib&#x2F;mlocate&#x2F; 中。 这个数据库也是通过计划任务定期的执行updatedb命令去更新的 4、RPM 软件日志文件的建立： 系统会经常安装或卸载软件包。为了方便查询，系统也会将这些软件包的名称进行记录！ 所以计划任务也会定期帮助我们更新rpm数据库 5、移除临时文件：软件在运行中会产生一些临时文件，但是当这个软件关闭时，这些临时文件可能并不会主动的被删除。有些时候这些文件对于系统来讲没有什么用处了，还占用磁盘空间。系统通过计划任务来定期来删除这些临时文件！ 二、仅执行一次的计划任务首先，我们先来谈谈仅运行一次的计划任务at 2.1、 atd 的启动与 at 运行的方式在使用at之前我们要确保atd服务是运行的，这个需要我们去检查一下，因为并不是所有的发行版linux默认都是开启这个服务的，但是在CentOS中是默认开启的 12345678910111213141516[root@zutuanxue ~]# systemctl status atd● atd.service - Job spooling tools Loaded: loaded (/usr/lib/systemd/system/atd.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2020-01-13 09:34:03 CST; 1h 17min ago#查询atd服务的状态[root@zutuanxue ~]# systemctl is-enabled atdenabled#查询是否开启默认启动如果没有启动[root@zutuanxue ~]# systemctl start atd # 启动[root@zutuanxue ~]# systemctl enable atd#设置为开启启动 at的工作模式 at在运行的时候会将定义好的工作以文本文件的方式写入 &#x2F;var&#x2F;spool&#x2F;at&#x2F; 目录内，该工作便能等待 atd 这个服务的调用，但是出于安全考虑，并不是所有的人都可以使用 at 计划任务！所以系统给我们提供了两个文件 &#x2F;etc&#x2F;at.allow 与 &#x2F;etc&#x2F;at.deny 来进行 at 的使用限制！ 加上这两个文件后， at 的工作情况其实是这样的： 先找寻 &#x2F;etc&#x2F;at.allow 这个文件，写在这个文件中的用户才能使用 at ，没有在这个文件中的用户则不能使用 at (即使没有写在 at.deny 当中)； 如果 &#x2F;etc&#x2F;at.allow 不存在，就寻找 &#x2F;etc&#x2F;at.deny 这个文件，若写在这个 at.deny 的用户则不能使用 at ，而没有在这个 at.deny 文件中的用户，就可以使用 at ； 如果两个文件都不存在，那么只有 root 可以使用 at 这个命令。 在大多数发行版当中，由于假设系统上的所有用户都是可信任的， 因此系统通常会保留一个空的 &#x2F;etc&#x2F;at.deny 文件，允许所有人使用 at 。如果有需要的话可以手动建立at.allow文件 2.2、at的使用单一计划任务的进行就使用 at 这个命令！将 at 加上一个时间即可！基本的语法如下： 12345678910111213141516[root@zutuanxue ~]# at [-mldv] TIME [root@zutuanxue ~]# at -c 工作序号 选项与参数： -m ：当 at 的工作完成后，发邮件通知用户，需要mail服务-l ：at -l 相当于 atq，查看用户使用at定制的工作-d ：at -d 相当于 atrm ，删除一个工作； -v ：详细信息； -c ：查看指定工作的具体内容。 TIME：时间格式 HH:MM ex&gt; 16:00 在今天指定的时刻进行，若该时刻已超过，则明天的这个时间进行此工作。 HH:MM YYYY-MM-DD ex&gt; 16:00 2021-07-30 指定在某年某月的某一天的时间进行该工作！ HH:MM[am|pm] [Month] [Date] ex&gt; 04am Jun 15 另外一种年月日和时间的指定方式 HH:MM[am|pm] + number [minutes|hours|days|weeks] ex&gt; now + 5 minutes 五分钟之后 ex&gt; 04am + 3 days 三天后的上午四点 at在使用过程中的时间指定很重要，另外在使用过程中如果涉及到路径的指定，强烈建议使用绝对路径，定义完成at之后使用键盘上的ctrl+d结束 1、at 的管理 有的时候我用at定义完计划任务之后，发现命令有错误，此时我们就可以使用atq 与 atrm 进行管理。 1234567[root@zutuanxue ~]# atq [root@zutuanxue ~]# atrm 工作编号 [root@zutuanxue at]# atq2\tFri Feb 21 16:00:00 2020 a root# 在 2020-02-21 的 16:00 有一项工作，该项工作是root设置的，工作编号为2[root@zutuanxue ~]# atrm 2 [root@zutuanxue ~]# atq # 没有任何信息，表示该工作被移除了！ 这样，你可以利用 atq 来查询，利用 atrm 来删除，利用 at 来直接定义计划任务但是如果系统当前非常忙碌话，能不能让指定的工作在较闲的时候执行呢？那就是batch！ 2、batch：系统有空时才进行后台任务 batch是at的一个辅助工具，也是利用at进行工作的，只是加入一些判断功能。它会在 CPU 的工作负载小于 0.8 的时候，才执行指定的工作！ 这个负载指的是 CPU 在单一时间点所负责的工作数量。不是 CPU 的使用率！ 比如说，如果我运行一个程序，这个程序可以使CPU 的使用率持续达到 100% ， 但是 CPU 的负载接近与1，因为 CPU 仅负责一个工作，而我同时运行了两个这样的程序，那么 CPU 的使用率还是 100% ，但是工作负载则变成 2 了。 也就是说，当 CPU 的负载越大，CPU 必须要在不同的工作之间进行频繁的切换。所以会非常忙碌！ 而用户还要额外进行 at 完成工作，就不太合理！所以才有 batch 命令的产生！ CentOS从7开始，batch 已经不再支持时间参数了，所以我们在使用batch定制计划任务的时候可以这样输入 12345678root@zutuanxue at]# batchwarning: commands will be executed using /bin/shat&gt; cp /etc/passwd /rootat&gt; &lt;EOT&gt;job 4 at Mon Jan 13 11:31:00 2020[root@zutuanxue at]# cd[root@zutuanxue ~]# ls公共 模板 视频 图片 文档 下载 音乐 桌面 anaconda-ks.cfg initial-setup-ks.cfg passwd 所以，batch可以通过cpu负载自动判断是否可以执行指定的工作。 三、周期执行的计划任务相对于 at 是仅执行一次的工作，周期执行的计划任务则是由 crond这个系统服务来控制的。同样各位在使用的时候也要确认一下此服务的状态 123456[root@zutuanxue ~]# systemctl status crond● crond.service - Command Scheduler Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2020-01-13 09:34:03 CST; 2h 0min ago[root@zutuanxue ~]# systemctl is-enabled crondenabled 3.1、如何使用用户使用的是 crontab 这个命令来定义周期性的计划任务，但是为了安全性的问题， 与 at 同样的，我们可以限制使用 crontab 的用户账号！使用的限制数据有： &#x2F;etc&#x2F;cron.allow：将可以使用 crontab 的账号写入其中，若不在这个文件内的用户则不可使用 crontab； &#x2F;etc&#x2F;cron.deny：将不可以使用 crontab 的账号写入其中，若未记录到这个文件当中的用户，就可以使用 crontab 。 与 at 一样，以优先级来说， &#x2F;etc&#x2F;cron.allow 比 &#x2F;etc&#x2F;cron.deny 要高， 一般系统默认是提供 &#x2F;etc&#x2F;cron.deny ， 你可以将允许使用 crontab 用户写入 &#x2F;etc&#x2F;cron.deny 当中，一个账号一行。crontab 建立计划任务会存放在 &#x2F;var&#x2F;spool&#x2F;cron&#x2F; 目录中， crontab 的使用: 123456789[root@zutuanxue ~]# crontab-u ：只有root可以使用，指定其它用户的名称-e ：建立计划任务 -l ：查看计划任务 -r ：删除所有计划任务，若只删除一项，只能使用-e进行编辑 [root@zutuanxue ~]# crontab -e#执行后会打开一个vim的页面，每个任务一行 0\t12 * * * cp\t/etc/passwd /root分 时 日 月 周 工作内容 编辑完毕之后输入“ :wq ”保存退出， 在cron中每项工作 (每行) 的格式都是具有六个字段，这六个字段的意义为： 意义 分钟 小时 日期 月份 周 命令 范围 0-59 0-23 1-31 1-12 0-7 工作内容 比较有趣的是那个『周』！周的数字为 0 或 7 时，都代表『星期天』的意思！另外，还有一些辅助的字符，大概有底下这些： 特殊字符 含义 *(星号) 代表任何时刻 ,(逗号) 代表分隔时段的意思。如3:00 与 6:00 时，就是：0 3,6 * * * -(减号) 代表一段时间范围内，如：8 点到 12 点之间的每小时的 20 分都进行一项工作：20 8-12 * * * &#x2F;n(斜线) n 代表数字，间隔的单位的意思，如每五分钟进行一次，则：*&#x2F;5 * * * * 也可以写成 0-59&#x2F; 12345678[root@zutuanxue ~]# crontab -l #查看root的计划任务0 16 1 * *\tcp /etc/passwd /rootroot@zutuanxue ~]# crontab -u oracle -l\t#查看指定用户的计划任务no crontab for oracle[root@zutuanxue ~]# crontab -r\t#删除所有计划任务[root@zutuanxue ~]# crontab -lno crontab for root 注意：crontab在使用的时候如果遇到路径，同样建议使用绝对路径，如果只是要删除某个项目，使用 crontab -e 来重新编辑，如果使用 -r 的参数，是会将所有的 crontab 内容都删掉。 3.2、系统的配置文件： &#x2F;etc&#x2F;crontab, &#x2F;etc&#x2F;cron.d&#x2F;*crontab -e是针对用户 来设计的，系统的计划任务是通过&#x2F;etc&#x2F;crontab文件来实现的，我们只要编辑&#x2F;etc&#x2F;crontab 这个文件就可以，由于cron的最低检测时间是分钟，所以编辑好这个文件，系统就会自动定期执行了 123456789101112131415[root@zutuanxue ~]# cat /etc/crontabSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 与crontab -e的内容类似，但是多了几个部分 123456SHELL=/bin/bash shell类型PATH=/sbin:/bin:/usr/sbin:/usr/bin\t执行文件搜索位置MAILTO=root 发生错误时通知邮件发送给谁* * * * * user-name command to be executed#比crontab -e多了一个执行者的身份，因为并不是所有工作都需要root用户去执行 额外的文件 crond有三个相关联的地方，他们分别是： &#x2F;etc&#x2F;crontab 系统计划任务的配置文件 &#x2F;etc&#x2F;cron.d&#x2F; 此目录和下面的几个目录都是系统计划任务存放运行脚本的位置。 &#x2F;etc&#x2F;cron.hourly&#x2F; &#x2F;etc&#x2F;cron.daily&#x2F; &#x2F;etc&#x2F;cron.weekly&#x2F; &#x2F;etc&#x2F;cron.monthly&#x2F; &#x2F;var&#x2F;spool&#x2F;cron&#x2F;* 用户定制的计划任务存放位置 四、anacron有些时候，在cron需要执行相应工作的时候，你的系统关机了，该如何处理？这个时候就需要使用anacron 4.1、什么是 anacronanacron 并不是用来取代 crontab 的，anacron 存在的目的就在于处理由于一些原因导致cron无法完成的工作 其实 anacron 也是每个小时被 crond 执行一次，然后 anacron 再去检测相关的工作任务有没有被执行，如果有未完成的工作， 就执行该工作任务，执行完毕或无须执行任何工作时，anacron 就停止了。我们可以通过&#x2F;etc&#x2F;cron.d&#x2F;0hourly的内容查看到 123456[root@zutuanxue ~]# cat /etc/cron.d/0hourly # Run the hourly jobsSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root01 * * * * root run-parts /etc/cron.hourly 由于 anacron 默认会以一天、七天、一个月为期去检测系统未进行的 crontab 任务，因此对于某些特殊的使用环境非常有帮助。 那么 anacron 又是怎么知道我们的系统何时关机？这就得要使用 anacron 读取的时间记录文件 (timestamps) 了！ anacron 会去分析现在的时间与时间记录文件所记载的上次执行 anacron 的时间，两者比较后若发现有差异， 那就是在某些时刻没有进行 crontab ！此时 anacron 就会开始执行未进行的 crontab 任务了！ 4.2、anacron 与 &#x2F;etc&#x2F;anacrontabanacron 其实是一个程序并非一个服务！这个程序在系统当中已经加入 crontab 的工作！同时 anacron 会每个小时被主动执行一次！所以 anacron 的配置文件应该放置在 &#x2F;etc&#x2F;cron.hourly目录中 12345678[root@zutuanxue ~]# cat /etc/cron.hourly/0anacron #!/bin/sh# Check whether 0anacron was run today already.../usr/sbin/anacron -s实际上，也仅仅是执行anacron -s命令，这个命令会根据/etc/anacrontab文件的定义去执行各项工作 anacrontab 123456789101112131415161718[root@zutuanxue ~]# cat /etc/anacrontab # /etc/anacrontab: configuration file for anacron# See anacron(8) and anacrontab(5) for details.SHELL=/bin/shPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# the maximal random delay added to the base delay of the jobsRANDOM_DELAY=45 #最大随机延迟时间，单位是分钟# the jobs will be started during the following hours onlySTART_HOURS_RANGE=3-22\t#仅执行延迟多少个小时之内的任务#period in days delay in minutes job-identifier command1\t5\tcron.daily nice run-parts /etc/cron.daily7\t25\tcron.weekly nice run-parts /etc/cron.weekly@monthly 45\tcron.monthly nice run-parts /etc/cron.monthly间隔时间(天)\t延迟时间(分钟)\t工作名称\t执行的内容 以 &#x2F;etc&#x2F;cron.daily&#x2F; 那一行的为例 每隔一天，在开机后的第5分钟去执行cron.daily目录下的脚本","categories":["Linux","Linux系统管理宝典"]},{"title":"linux进程管理","path":"/2023/09/27/Linux系统管理宝典/Linux-进程管理/","content":"一、进程介绍在说进程如何管理之前我们要涉及到进程的一些相关概念 什么是进程？进程（Process）是一个程序在其自身的虚拟地址空间中的一次执行活动。之所以要创建进程，就是为了使多个程序可以并发的执行，从而提高系统的资源利用率和吞吐量。简单来说进程就是一个程序的执行活动。 进程和程序有什么不同？ 程序：只是一个静态的指令集合；而进程是一个程序的动态执行过程，它具有生命期，是动态的产生和消亡的。 进程：是资源申请、调度和独立运行的单位，因此，它使用系统中的运行资源；而程序不能申请系统资源、不能被系统调度、也不能作为独立运行的单位，因此，它不占用系统的运行资源。 程序和进程无一一对应的关系。一方面一个程序可以由多个进程所共用，即一个程序在运行过程中可以产生多个进程；另一方面，一个进程在生命期内可以顺序的执行若干个程序。 进程的属性 在Linux系统中总是有很多进程同时在运行，每一个进程都有一个识别号，叫做PID（Process ID），用以区分不同的进程。 除了进程识别号外，每个进程还有另外四个识别号。它们是实际用户识别号（real user ID）、实际组识别号以及有效用户识别号（effect user ID），和有效组识别号（effect group ID）。实际用户识别号和实际组识别号的作用是识别正在运行此进程的用户和组。一个进程的实际用户识别号和实际组识别号就是运行此进程的用户的识别号（UID）和组的识别号（GID）。有效用户识别号和有效组识别号的作用是确定一个进程对其访问的文件的权限和优先权。一般有效用户识别号和有效组识别号和实际用户识别号及实际组识别号相同。除非程序被设置了SUID位或SGID位。 进程间的父子关系 进程之间是有关联性的，有的进程会衍生出额外的进程，这时，这组进程之间就存在了父子关系，衍生出来的进程叫子进程，而原本的进程叫做父进程。 二、linux的工作调度由于linux是一个多人多任务的操作系统，所以用户在使用linux的时候就会出现有些工作我们需要盯着完成的进度，而有些工作我们直接放在后台执行就可以了，这里面我们就涉及到任务的前后台执行的问题，那么，如何将一个任务放到后台去执行呢？ 开启一个在后台执行的工作12345678[root@zutuanxue ~]# cd /[root@zutuanxue /]# tar -czf /tmp/test.tar.gz etc &amp;\t（&amp;表示后台执行）[1] 13568 [1]工作序号；13568进程号（PID）[root@zutuanxue /]# ls tmp/ | grep testtest.tar.gz执行完成后，会在下次敲回车的时候给用户一个反馈[1]+ 已完成 tar -czpf /tmp/test.tar.gz etc 将当前的工作调到后台12345678[root@zutuanxue /]# cd[root@zutuanxue ~]# ls公共 视频 文档 音乐 anaconda-ks.cfg模板 图片 下载 桌面 initial-setup-ks.cfg[root@zutuanxue ~]# vim anaconda-ks.cfg 按键盘上的ctrl+z是调到后台[1]+ 已停止 vim anaconda-ks.cfg 注意由ctrl+z调到后台的工作状态为暂停 那么如何将后台工作的状态更改为运行？如何查看后台有哪些工作呢？ 后台工作的查看及状态的更改123456789101112131415161718192021222324252627282930313233343536[root@zutuanxue ~]# jobs 查看后台工作[1]- 已停止 vim anaconda-ks.cfg[2]+ 已停止 find / -print[root@zutuanxue ~]# jobs -l 查看后台工作，并显示进程号[1]- 13663 停止 vim anaconda-ks.cfg[2]+ 13732 停止 find / -print[root@zutuanxue ~]# jobs -s 仅查看状态为停止的后台工作[1]- 已停止 vim anaconda-ks.cfg[2]+ 已停止 find / -print[root@zutuanxue ~]# jobs -r 仅查看状态为运行的后台工作+：\t当使用命令将后台任务调到前台时，默认调用有此标记的任务，也就是最近被调到后台的-：\t倒数第二个被调到后台的任务[root@zutuanxue ~]# fg %工作序号(%可省略)\t将后台指定的工作调到前台[root@zutuanxue ~]# find / -name \\*a\\* &gt; /tmp/test.txt^Z 执行一个命令，迅速使用ctrl+z将任务调到后台[2]+ 已停止 find / -name \\*a\\* &gt; /tmp/test.txt[root@zutuanxue ~]# bg %2;jobs 连续执行两条命令，1.使用bg命令将之前的工作状态更改为运行；2.立即使用jobs命令查看状态[2]+ find / -name \\*a\\* &gt; /tmp/test.txt &amp;[1]+ 已停止 vim anaconda-ks.cfg[2]- 运行中 find / -name \\*a\\* &gt; /tmp/test.txt &amp;注意：更改后台工作状态和查看后台工作状态的命令也可以在终端分别输入，但是如果命令执行的较快的话可能会出现下面的这种情况，也就是状态显示为已完成[root@zutuanxue ~]# find / -name \\*a\\* &gt; /tmp/test.txt^Z[2]+ 已停止 find / -name \\*a\\* &gt; /tmp/test.txt[root@zutuanxue ~]# jobs[1]- 已停止 vim anaconda-ks.cfg[2]+ 已停止 find / -name \\*a\\* &gt; /tmp/test.txt[root@zutuanxue ~]# bg %2[2]+ find / -name \\*a\\* &gt; /tmp/test.txt &amp;[root@zutuanxue ~]# jobs[1]+ 已停止 vim anaconda-ks.cfg[2]- 已完成 find / -name \\*a\\* &gt; /tmp/test.txt 管理后台工作我们可以通过kill命令配合适当的信号来管理后台的工作，信号是进程间通信的最原始机制，不同的信号，有不同的作用，比如说，一个进程接收到了一个让它打开指定文件的信号，那这个进程就去打开这个文件，而不会去考虑原因 12345678910111213[root@zutuanxue ~]# kill %工作序号 -l 查看 -1 重新加载，systemctl reload servername -2 保存数据并结束\tctrl+c -9 强制结束不管其状态 常用在无法正常终止的程序上 -15 正常结束(默认值) systemctl stop servername[root@zutuanxue ~]# jobs[1]+ 已停止 vim anaconda-ks.cfg[root@zutuanxue ~]# kill -9 %1[1]+ 已停止 vim anaconda-ks.cfg[root@zutuanxue ~]# jobs[1]+ 已杀死 vim anaconda-ks.cfg[root@zutuanxue ~]# jobs 三、进程的查看与管理在linux中，我们可以通过fg、bg、jobs、kill等来对工作进行管理和调度，这些工作都是我们手动执行的，而那些由系统开启的工作该如何管理呢？管理这些后台工作我们可以使用两种命令ps和top 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@zutuanxue ~]# ps #静态进程管理命令,可以帮助我们查看到ps命令在执行那一刻后台进程的状态-A 所有进程，等同于-ax-a 显示所有进程（与终端有关的除外）-x 与参数a一起使用等同于-A-u 显示指定用户的进程-l 长格式-f 完整输出-t 从指定终端启动的进程-C 执行指定命令的进程[root@zutuanxue ~]# ps aux #查看系统后台的所有进程USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.1 252828 11580 ? Ss 10月23 0:04 /us...root 2 0.0 0.0 0 0 ? S 10月23 0:00 [kthreadd]root 3 0.0 0.0 0 0 ? I&lt; 10月23 0:00 [rcu_gp]root 4 0.0 0.0 0 0 ? I&lt; 10月23 0:00 [rcu_par_gp]root 6 0.0 0.0 0 0 ? I&lt; 10月23 0:00 [kworker/0:0H-kblockd]root 8 0.0 0.0 0 0 ? I&lt; 10月23 0:00 [mm_percpu_wq]root 9 0.0 0.0 0 0 ? S 10月23 0:00 [ksoftirqd/0]USER 开启进程的用户PID 进程的识别号%CPU 进程的cpu占用率%MEM 进程的物理内存占用率VSZ 虚拟内存用量，单位KbytesRSS 物理内存占用量\tKbytesTTY 那个终端开启的STAT 进程的状态START 开启时间TIME CPU占用时间COMMAND 执行具体内容[root@zutuanxue ~]# ps -l 查看当前用户开启的进程F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD0 S 0 5191 5189 0 80 0 - 6994 - pts/1 00:00:02 bash0 R 0 14972 5191 0 80 0 - 11240 - pts/1 00:00:00 psF\t进程标识\t4=权限为root 1=从父进程派生出来但是没有执行\t5=1+4 0=没有被设置S\t进程状态\tR=运行\tS=睡眠，可被唤醒\tD=睡眠，不可被唤醒（资源不足引起）T=停止 Z=僵尸进程UID\t用户识别号PID\t进程识别号PPID\t父进程号C cpu使用率 %PRI 内核调度优先级NI 用户设置优先级ADDR\t加载到内存的位置，如果是运行的会用-表示SZ 用掉的内存页的大小，1个内存页=4096Bytes 也就是6994x4=27976K内存WCHAN\t当前进程在哪个内核函数上睡眠，-表示正在运行，没有睡眠TTY 由哪个终端开启的\tpts/n=图形界面或远程 ttyn=字符界面 ?=系统进程TIME\t用掉的CPU时间CMD 执行的命令 ps只能显示它运行的那一刻的进程的统计信息，如果你想动态的查看就需要使用top top动态查看 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990[root@zutuanxue ~]# top-d 指定两次刷新的时间间隔,默认是3秒-p 后面跟进程号，查看指定进程的状态,最多20个PID-n 刷新指定次数后退出-b 批量模式，可以让top将内容输出到指定的位置top的按键? 显示帮助空格&amp;enter 刷新E 切换统计信息部分，内存显示的单位e 切换任务列表的内存显示的单位l 显示或隐藏摘要信息中的负载统计(第一行内容)t 切换显示或隐藏摘要信息中任务和CPU统计信息(第2，3行内容)m 切换显示或隐藏摘要信息中内存统计(第4，5行内容)u 查看指定用户的进程M 根据内存排序P 根据cpu排序N 根据PID排序R 反向排序F/f 调整任务列表显示的内容，默认只有PID，USER，PR，NI....COMMAND等这些，可 以自定义还需要显示哪些内容，如果显示的列比较多可以使用&lt;/&gt;进行左右移动shift+&lt;/&gt;按照下一列的内容排序，比如说当前按照PID排序如果按下shift+&gt;，则按照用户名 排序，再次按下就会按照PR排序，一次类推 T 根据cpu使用时间排序k 杀死进程r 修改进程的nice值（优先级）z 将不同的位置标记颜色x 高亮显示排序字段y 高亮显示正在运行的任务b 将高亮显示部分加上背景色Z 自定义颜色L 搜索指定字段，&amp;下一个H 在进程和线程间切换显示和统计方式，默认为进程V 树形显示统计信息J 显示内容左对齐或右对齐c 切换COMMAND列的显示形式，程序名/命令格式i 显示或隐藏空闲进程u/U 查看指定用户的进程d 设置刷新间隔,默认3秒刷新一次W 将当前的设置写入到~/.config/procps/toprc中q 退出top[root@zutuanxue ~]# top -d 11 top - 18:57:05 up 12:56, 3 users, load average: 0.00, 0.00, 0.002 Tasks: 280 total, 1 running, 279 sleeping, 0 stopped, 0 zombie3 %Cpu(s): 1.5 us,1.5 sy,0.0 ni,97.0 id,0.0 wa,0.0 hi,0.0 si,0.0 st4 MiB Mem : 3918.6 total, 160.1 free, 1264.5 used, 2494.0 buff/cache5 MiB Swap: 2048.0 total, 2048.0 free, 0.0 used. 2356.6 avail Mem 67PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 244408 13740 9100 S 0.0 0.3 0:08.77 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.04 kthreadd 3 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 rcu_gp 4 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 cu_par_gp 1-6行显示的内容为1\t当前时间为18：57：05；系统一共开机12小时56分；当前有3个用户登录；系统在1，5，15分钟的平均负载，越小表示系统越空闲2\t系统中进程的统计信息 总计280个，1个运行，279睡眠，0个停止，0个僵尸3\tcpu的负载\t按键盘上的“1”可以按照CPU核心数显示 us: 用户空间进程占用CPU时间百分比 sy:\t内核进程占用CPU时间百分比 ni:\t用户空间内改变过优先级的进程占用CPU时间百分比 id:\t空闲CPU时间百分比(100%表示系统完全空闲) wa: I/O等待占用的CPU时间百分比 hi: 硬件中断占用CPU时间百分比 si:\t软件中断占用CPU时间百分比 st:\t虚拟化hypervisor从当前虚拟机偷走的时间（如果这个值很高的话,说明你的提 供商的CPU资源有限,而你没能抢过别人,很有可能就是VPS提供商超售了.）4&amp;5\t物理内存和虚拟内存相关的统计信息，尤其要注意swap，如果被大量占用，说明你物理内 存不足了6\t在top中输入命令时，会显示在这里7\t系统进程的信息\tPID:\t进程ID USER 进程所有者\tPR 进程优先级\tNI nice值，负数表示高优先级，正数表示低优先级\tVIRT 虚拟内存使用量，单位为KB。\tRES 进程使用的、未被换出的物理内存大小，单位为KB。\tSHR 进程使用共享内存大小，单位为KB。\tS 进程状态\t%CPU 进程对CPU的使用率。\t%MEM 进程对内存的使用率\tTIME+ 进程使用CPU时间总结，单位秒。\tCOMMAND\t命令 top显示的内容有些看不到怎么办？[root@zutuanxue ~]# top -b -n1 &gt; /tmp/top.txt有些时候想查看的进程资源占用很低，在top中显示的比较靠后，怎么办？[root@zutuanxue ~]# top -d 2 -p 3562Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombie%Cpu(s): 2.2 us, 3.9 sy, 0.0 ni, 93.3 id, 0.0 wa, 0.5 hi, 0.1 si, 0.0 stMiB Mem : 3918.6 total, 1495.1 free, 1407.0 used, 1016.5 buff/cacheMiB Swap: 2048.0 total, 2048.0 free, 0.0 used. 2258.4 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 3562 root 20 0 49296 6380 4448 S 0.0 0.2 0:00.08 bash 上面所提到的两个查看系统进程的命令，静态的ps和动态的top，他们所显示的内容比较多，有的时候我只想查看一下进程之间的关系，这个时候我可以使用另外的一条命令 12345678910111213141516171819202122232425262728293031323334353637[root@zutuanxue ~]# pstree\tA 进程之间使用ASCII字符连接\tU 进程之间使用UTF-8编码连接\tp 显示进程号\tu 显示用户[root@zutuanxue ~]# pstree -A | moresystemd-+-ModemManager---2*[&#123;ModemManager&#125;] |-NetworkManager---2*[&#123;NetworkManager&#125;] |-VGAuthService |-accounts-daemon---2*[&#123;accounts-daemon&#125;] |-alsactl |-atd |-auditd-+-sedispatch | `-2*[&#123;auditd&#125;][root@zutuanxue ~]# pstree -U | moresystemd─┬─ModemManager───2*[&#123;ModemManager&#125;] ├─NetworkManager───2*[&#123;NetworkManager&#125;] ├─VGAuthService ├─accounts-daemon───2*[&#123;accounts-daemon&#125;] ├─alsactl ├─atd ├─auditd─┬─sedispatch │ └─2*[&#123;auditd&#125;][root@zutuanxue ~]# pstree -pu | moresystemd(1)-+-ModemManager(916)-+-&#123;ModemManager&#125;(943) | `-&#123;ModemManager&#125;(949) |-NetworkManager(1040)-+-&#123;NetworkManager&#125;(1050) | `-&#123;NetworkManager&#125;(1053) |-VGAuthService(902) |-accounts-daemon(1010)-+-&#123;accounts-daemon&#125;(1013) | `-&#123;accounts-daemon&#125;(1015) |-alsactl(909) |-atd(1076) |-auditd(862)-+-sedispatch(864) | |-&#123;auditd&#125;(863) | `-&#123;auditd&#125;(865) |-avahi-daemon(910,avahi)---avahi-daemon(953) 我们现在可以通过三种方法来查看后台的进程，那么后台的进程该如何管理呢？管理后台的进程，除了我们前面提到的kill命令之外还可以使用killall 12345678910111213141516[root@zutuanxue ~]# kill PID需要注意的是，kill后面如果加的是%num代表杀死后台指定序号的工作，如果不加%代表的是杀死指定进程号的进程，这两个是有区别的[root@zutuanxue ~]# killall\te 精确匹配，最多不能超过15个字符\ti 询问用户是否杀死指定名称的进程\tI 进程的名称忽略大小写[root@zutuanxue ~]# cat /dev/zero &gt; /dev/null &amp;[1] 102245[root@zutuanxue ~]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD0 S 0 3562 3559 0 80 0 - 12324 - pts/1 00:00:00 bash0 R 0 102245 3562 97 80 0 - 1908 - pts/1 00:00:01 cat0 R 0 102246 3562 0 80 0 - 11240 - pts/1 00:00:00 ps[root@zutuanxue ~]# killall -ei cat杀死 cat(102870) ? (y/N) y[1]+ 已终止 cat /dev/zero &gt; /dev/null 四、进程的优先级之前我们在查看进程的时候看到两个东西，一个是PRI一个是NI，这两个东西是用来控制进程的优先级，而优先级又决定了CPU先处理谁的数据，后处理谁的数据。一起来看下如何调整进程的优先级 1234[root@zutuanxue ~]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD0 S 0 3562 3559 0 80 0 - 12522 - pts/1 00:00:00 bash0 R 0 85520 3562 0 80 0 - 11240 - pts/1 00:00:00 ps linux当中的每一个程序都有一个优先级，也就是PRI，这个数值越小则代表优先级越高，而PRI这个值是由内核控制的，用户无法更改，用户如果想调整程序的优先级就只能调整NI的值，所以linux中优先级的算法就是 新的优先级&#x3D;旧的优先级+NI的值，比如说我bash那个进程，PRI是80，并且假定内核不会动态调整这个值，如果我将NI值更改为-10的话，那么新的PRI的值就是70，数值变小，意味着这个进程的优先级提高了。但是如果内核在这个过程中动态调整了，最终的值就不确定了。 这个NI的值都可以设置成多少呢？ root用户：-20~19 普通用户：0~19 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[root@zutuanxue ~]# nice 指定新执行的进程的优先级\t-n 指定优先级[root@zutuanxue ~]# vim 1&amp;[1] 108831[root@zutuanxue ~]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD0 S 0 3562 3559 0 80 0 - 12522 - pts/1 00:00:00 bash0 T 0 108831 3562 0 80 0 - 9058 - pts/1 00:00:00 vim0 R 0 108832 3562 0 80 0 - 11240 - pts/1 00:00:00 ps[1]+ 已停止 vim 1[root@zutuanxue ~]# nice -n 10 vim 2&amp;[2] 109328[root@zutuanxue ~]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD0 S 0 3562 3559 0 80 0 - 12522 - pts/1 00:00:00 bash0 T 0 108831 3562 0 80 0 - 9058 - pts/1 00:00:00 vim0 T 0 109328 3562 0 90 10 - 9058 - pts/1 00:00:00 vim0 R 0 109396 3562 0 80 0 - 11240 - pts/1 00:00:00 ps[2]+ 已停止 nice -n 10 vim 2[root@zutuanxue ~]# nice -n -20 vim 3 &amp;[3] 109470[root@zutuanxue ~]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD0 S 0 3562 3559 0 80 0 - 12522 - pts/1 00:00:00 bash0 T 0 108831 3562 0 80 0 - 9058 - pts/1 00:00:00 vim0 T 0 109328 3562 0 90 10 - 9058 - pts/1 00:00:00 vim4 T 0 109470 3562 0 60 -20 - 9058 - pts/1 00:00:00 vim0 R 0 109471 3562 0 80 0 - 11240 - pts/1 00:00:00 ps[3]+ 已停止 nice -n -20 vim 3那如何调整一个已经启动的进程的优先级呢？[root@zutuanxue ~]# vim 1 &amp;[1] 115098[root@zutuanxue ~]# vim 2 &amp;[2] 115099[1]+ 已停止 vim 1[root@zutuanxue ~]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD0 S 0 3562 3559 0 80 0 - 12522 - pts/1 00:00:00 bash0 T 0 115098 3562 0 80 0 - 9058 - pts/1 00:00:00 vim0 T 0 115099 3562 0 80 0 - 9058 - pts/1 00:00:00 vim0 R 0 115100 3562 0 80 0 - 11240 - pts/1 00:00:00 ps[2]+ 已停止 vim 2[root@zutuanxue ~]# renice 10 115098115098 (process ID) 旧优先级为 0，新优先级为 10[root@zutuanxue ~]# renice -10 115099115099 (process ID) 旧优先级为 0，新优先级为 -10[root@zutuanxue ~]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD0 S 0 3562 3559 0 80 0 - 12522 - pts/1 00:00:00 bash0 T 0 115098 3562 0 90 10 - 9058 - pts/1 00:00:00 vim0 T 0 115099 3562 0 70 -10 - 9058 - pts/1 00:00:00 vim0 R 0 115736 3562 0 80 0 - 11240 - pts/1 00:00:00 ps","categories":["Linux","Linux系统管理宝典"]},{"title":"逻辑卷实战案例-swap分区","path":"/2023/09/27/Linux系统管理宝典/Linux-逻辑卷实战案例-swap分区/","content":"swap分区在系统的运行内存不够用的时候，把运行内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到swap分区中，等到那些程序要运行时，再从Swap分区中恢复保存的数据到内存中。可以缓解物理内存不足的压力，如果物理内存不足，还没有swap空间，会宕机 扩容swap空间方法1： 增加一个设备（硬盘，分区，逻辑卷）来扩容swap空间 123456789101112131415161718192021222324252627282930313233343536查看swap空间大小：[root@zutuanxue ~]# free -m total used free shared buff/cache availableMem: 3918 1309 2002 15 606 2358Swap: 2047 0 2047[root@zutuanxue ~]# swapon -s文件名 类型 大小 已用\t权限/dev/dm-1 partition 2097148 0 -2[root@zutuanxue ~]# mkswap /dev/sdb4正在设置交换空间版本 1，大小 = 2 GiB (2147479552 个字节)无标签，UUID=8235e59a-1043-4251-8694-ba619cb36f1c[root@zutuanxue ~]# blkid /dev/sdb4/dev/sdb4: UUID=&quot;8...c&quot; TYPE=&quot;swap&quot; PARTUUID=&quot;b...e&quot;//激活swap分区。swap空间不能手动挂载[root@zutuanxue ~]# swapon /dev/sdb4[root@zutuanxue ~]# swapon -s文件名 类型 大小 已用\t权限/dev/dm-1 partition\t2097148 0 -2/dev/sdb4 partition\t2097148 0 -3[root@zutuanxue ~]# free -m total used free shared buff/cache availableSwap: 4095 0 4095LVM形式[root@zutuanxue ~]# mkswap /dev/vg1/swap #创建swap[root@zutuanxue ~]# swapon /dev/vg1/swap #开启swap[root@zutuanxue ~]# lvextend -L 4G\t/dev/vg1/swap\t#放大LVM形式的swap[root@zutuanxue ~]# swapoff /dev/vg1/swap #关闭lvm形式的swap[root@zutuanxue /]# mkswap /dev/vg1/lv-swap\t#重新制作swap[root@zutuanxue ~]# swapon /dev/vg1/swap #开启lvm形式的swap[root@zutuanxue ~]# free -m\t#确认swap分区是否放大 方法2： 使用dd命令模拟大文件来扩容swap 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@zutuanxue ~]# dd if=/dev/zero of=/tmp/swapfile bs=1M count=2048if=源文件,in file指定从哪里读入数据of=目标文件，out file指定将数据写入什么位置bs=复制数据的大小，block sizecount=复制的个数注意：1. 一般可以使用dd命令做块设备文件的备份2. /dev/zero 特殊设备，一般用来模拟一个大文件，源源不断的二进制的数据流;/dev/null 空设备，类似黑洞步骤：1. 使用dd命令模拟大文件# dd if=/dev/zero of=/tmp/swapfile bs=1M count=20482. 格式化大文件[root@zutuanxue ~]# mkswap /tmp/swapfile mkswap: /tmp/swapfile：不安全的权限 0644，建议使用 0600。正在设置交换空间版本 1，大小 = 2 GiB (2147479552 个字节)无标签，UUID=3d855316-c97c-42ca-9c52-9df26a4517a0 [root@zutuanxue ~]# ll /tmp/swapfile -rw-r--r-- 1 root root 2147483648 12月 10 21:02 /tmp/swapfile[root@zutuanxue ~]# chmod 600 /tmp/swapfile 3.激活大文件[root@zutuanxue ~]# swapon -p1 /tmp/swapfile-p：指定优先级，数字越大优先级越高，-1~327674. 查看[root@zutuanxue ~]# swapon -s文件名 类型 大小 已用\t权限/dev/dm-1 partition\t2097148 268\t-2/dev/sdb4 partition\t2097148 0 -3/tmp/swapfile file 2097148 0 1[root@zutuanxue ~]# free -m total used free shared buff/cache availableSwap: 6143 0 6143如果开机自动挂载，需要修改文件：/etc/fstab[root@zutuanxue ~]# vim /etc/fstab /dev/sda4 swap swap defaults 0 0/tmp/swapfile swap swap dfaults,pri=1 0 0[root@zutuanxue ~]# swapon -a关闭swap[root@zutuanxue ~]# swapoff /dev/sdb4[root@zutuanxue ~]# swapoff /tmp/swapfile或者#关闭所有swap****慎用*****[root@zutuanxue ~]# swapoff -a","categories":["Linux","Linux系统管理宝典"]},{"title":"linux软件包管理","path":"/2023/09/27/Linux系统管理宝典/Linux-软件包管理/","content":"在linux系统中我们经常涉及到软件包的删除和添加，那一起来看下在linux系统中软件包的管理方式都有哪些 rpm软件 yum软件仓库 源码软件 一、rpm软件包rpm的介绍前面的课程我们提到过源码包安装需要解决系统环境、权限等等，这些对于初学者而言都是噩梦一般的存在，所以linux厂商推出了一种类似windows系统中的安装方式，有开发者直接在已知的系统中编译好，使用者可以直接下载并进行安装，升级，卸载等操作。在linux中能够提供这些功能的软件有两种，rpm和dpkg，而在CentOS中使用的是RPM rpm最早是由redhat开发出来，由于很好用，所以很多发行版也利用rpm来进行软件包的管理。RPM全名RedHat Package Manager，最大的特点就是把需要安装的软件提前编译，打包，然后在rpm包里面存放了用以记录软件依赖关系的相关数据，当用户安装时，优先查看这些数据，如果系统满足数据要求就安装软件包，否则不能安装，安装完成后，将软件包相关信息记录到rpm自己的数据库中，便于查询和卸载等。所以说rpm的优点是方便安装，卸载，查询，缺点就是只能在指定的操作系统上使用，所以不同厂商的rpm包，甚至同一厂商不同版本操作系统的rpm包都不通用。 rpm包的命名 12345678dhcp-server-\t4.3.6 -30 .el8 .x86_64 .rpm软件名称 版本 编译次数 适用的系统 适用的平台 后缀名软件名 就是软件包的名称版本 每次更新版本号都会改变，用来帮助用户判断软件包新旧的编译次数 也是帮助用户判断软件包新旧的适用的系统 在哪个系统上可以安装，CentOS和rhel的多数软件包都是通用的适用的平台 指的是硬件平台，比如如果你是32位的CPU就无法安装这个软件包 rpm的使用rpm包的相关文件一般都会放在对应的目录中，比如rpm包安装后，配置文件会放在&#x2F;etc下，执行文件会放在&#x2F;usr&#x2F;bin下，链接库文件会放在&#x2F;usr&#x2F;lib下，帮助与说明文档会放在&#x2F;usr&#x2F;share&#x2F;man和&#x2F;usr&#x2F;share&#x2F;doc目录下 安装 123456789101112131415161718[root@zutuanxue Packages]# rpm -ivh dhcp-server-4.3.6-30.el8.x86_64.rpm -i 安装-v 显示详细信息-h 显示安装进度-e 卸载-U 升级，如果系统中有低版本的就会升级，如果系统没有安装相应的包，则安装-F 有条件的升级，会检测用户指定的软件包是否已安装到linux中--nodeps 忽略软件包之间的依赖关系--replacefiles 覆盖文件--replacepkgs 修复--force 强制--test 测试-q 查询指定的软件包是否安装-qi 查看指定的软件包的信息，包括开发商，版本，说明-ql 查看指定软件包中所包含的文件列表-qc 查看指定软件包的配置文件-qa 查看本机安装的所有包-qf 查看一个文件归属于哪个已安装的软件包 rpm的内容我们就介绍到这里，接下来我们看下一个yum 二、yum软件仓库yum的介绍YUM（Yellow dog Updater, Modified）是一个基于rpm却更胜于rpm的管理工具，让你可以更轻松的管理Red Hat Enterprise Linux系统中的软件。你可以使用YUM来安装或卸载软件、也可以利用YUM来更新你的系统，更可以利用YUM来搜索一个尚未安装的软件。不管是安装、更新或者删除，YUM都会自动的帮你解决软件间的依赖性问题。通过YUM会比单纯使用rpm来得更加方便。 YUM包含下列几项组件： YUM下载源：如果把所有RPM文件放在某一个目录中，这个目录就可称为“YUM下载源（YUM Repository）”。你也可以把YUM下载源，通过HTTP、FTP等方式分享给其他计算机使用；当然，你也可以直接使用别人建好的YUM下载源来取得需安装的软件。 YUM工具：YUM提供了一个名为yum的命令，你可以使用yum来使用YUM提供的众多功能。 YUM插件：YUM还允许第三方厂商（3rd Party）开发YUM的插件（Plug-in），让用户可以任意的扩充YUM的功能，比如说有的插件可以帮助选择最快的yum源 YUM缓存：YUM运行时，会从YUM下载源获得软件信息与文件，并且暂存于本机的硬盘上。这个暂存的目录，称为“YUM缓存（YUM cache）”。缓存目录为&#x2F;var&#x2F;cache&#x2F;yum yum的使用yum源的配置 由于yum有下载源这个东西，所以我们在使用yum之前需要告诉它去什么地方获取这些软件包，也就是说需要先配置一个yum源 123456789101112131415161718192021222324252627282930[root@zutuanxue ~]# cd /etc/yum.repos.d/[root@zutuanxue yum.repos.d]# lsCentOS-AppStream.repo CentOS-CR.repo CentOS-fasttrack.repo CentOS-Sources.repoCentOS-Base.repo CentOS-Debuginfo.repo CentOS-Media.repo CentOS-Vault.repoCentOS-centosplus.repo CentOS-Extras.repo CentOS-PowerTools.repo在CentOS8中yum的下载源配置文件统一都放到/etc/yum.repos.d/目录下，在这个目录中有些默认的下载源我不使用这些自带的下载源，我想配置一个自己的下载源，让yum使用光盘镜像里的软件包,为了避免干扰，我们把这些自带的下载源都放到一个目录里[root@zutuanxue yum.repos.d]# mkdir repos[root@zutuanxue yum.repos.d]# lsCentOS-AppStream.repo CentOS-CR.repo CentOS-fasttrack.repo CentOS-Sources.repoCentOS-Base.repo CentOS-Debuginfo.repo CentOS-Media.repo CentOS-Vault.repoCentOS-centosplus.repo CentOS-Extras.repo CentOS-PowerTools.repo repos[root@zutuanxue yum.repos.d]# mv *.repo repos[root@zutuanxue yum.repos.d]# clear[root@zutuanxue yum.repos.d]# lsrepos然后使用vim命令建立自己的下载源配置文件[root@zutuanxue repos]# vim server.repo[server-BaseOS] yum源的名称name=server-BaseOS 完整名称enabled=1 是否启用gpgcheck=0 是否检查rpm包的数字签名baseurl=file:///mnt/BaseOS\t下载源地址[server-AppStream]name=server-AppStreamenabled=1gpgcheck=0baseurl=file:///mnt/AppStream[root@zutuanxue ~]# mount /dev/cdrom /mnt/ 将光盘挂载到指定位置由于CentOS8的软件包存放在光盘根目录的BaseOS和AppStream目录中，所以这里面为了保证需要的软件包能正确安装我们配置了两个yum源，这两部分内容你可以放到一个文件里，也可以分别放在两个文件中 以上就是yum源配置文件，我们接下来看下如何建立下载源目录 12345678910111213141516171819将下载好的rpm软件包存放到一个指定的目录中[root@zutuanxue ~]# cp /mnt/AppStream/Packages/* myrepo/从光盘镜像中安装createrepo工具[root@zutuanxue ~]# yum install createrepo利用createrepo工具生成软件包之间的依赖关系数据文件[root@zutuanxue ~]# createrepo myself/建立针对此目录的下载源配置文件[root@zutuanxue ~]# vim /etc/yum.repos.d/myrepo.repo[myself]name=packagesenabled=1gpgcheck=0baseurl=file:///root/myself从新的下载源安装软件包[root@zutuanxue ~]# yum install httpd yum插件安装 12345678[root@zutuanxue ~]# yum install 插件名称插件配置文件存放位置/etc/yum/pluginconf.d/xxx.conf插件的启用和停用修改/etc/yum/pluginconf.d/xxx.conf文件中的enabled字段 1=启用 0=停用[root@zutuanxue ~]# yum [OPTIONS...] COMMAND [ARGVS...]-y 如果遇到问题，代替回答yes--installroot=/path 指定软件包安装的根目录 清除yum缓存 12345678910111213[root@zutuanxue ~]# yum clean all如果有些时候你发现yum运行不太正常，这可能是yum缓存数据错误导致的，所以你需要将yum的缓存清除查看软件包[root@zutuanxue ~]# yum list查看有哪些可用组[root@zutuanxue ~]# yum grouplist 查看dhcp-server这个包的信息 [root@zutuanxue ~]# yum info dhcp-server 搜索dhcp-server这个软件包[root@zutuanxue ~]# yum search dhcp-server yum安装 12345安装dhcp-server软件包[root@zutuanxue ~]# yum install dhcp-server -y 安装一组软件包[root@zutuanxue ~]# yum groupinstall &#x27;系统工具&#x27; -y 卸载软件包 12345删除一个软件包[root@zutuanxue ~]# yum remove dhcp-server -y 删除一组软件包[root@zutuanxue ~]# yum groupremove &#x27;系统工具&#x27; -y 使用epel源 EPEL是一个自由开源的附加软件包仓库，可用于 CentOS 和 RHEL 服务器。顾名思义，EPEL 仓库提供了额外的软件包，这些软件在 CentOS 8 和 RHEL 8 的默认软件包仓库中不可用。 安装epel源 epel地址：https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm 1[root@zutuanxue ~]# yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm 三、源码包的安装在linux系统中，很多新版本的软件包的更新都会优先提供tar包版本的，然后各linux厂商拿到这个tar包之后再给自己的操作系统提供官方的rpm或者dpkg类型的软件包，而这种tar工具打包的软件包我们一般称之为源码包，在这些源码包中一般包含有，程序源代码文件，配置文件（configure），安装使用说明（INSTALL,HOWTO,README） 那这种tar包源码包如何安装呢？简单的流程就是 获取软件包 解压文件 检查当前系统是否满足软件包安装需求 使用gcc进行编译，生成主要的二进制文件 将二进制文件安装到主机 这些步骤看起来很简单，但是在使用过程中有很多问题需要解决，比如说需要解决系统环境，权限问题等等，不同类型的软件在安装方法上会有差异，但是整体步骤就是我们上面所提到的。接下来我们通过一个案例来学习源码安装软件。 案例：源码安装一个nginx软件 获取软件包软件包获取的方式有很多，最常见的就是拷贝或者下载这两种方式，拷贝咱们就不说了，因为用的太多了；接下来我给大家说一下如何从网络下载软件包。 wget命令：文本界面的下载命令 1234567891011[root@zutuanxue ~]# wget http://nginx.org/download/nginx-1.19.3.tar.gz--2020-10-11 15:59:45-- http://nginx.org/download/nginx-1.19.3.tar.gz正在解析主机 nginx.org (nginx.org)... 3.125.197.172, 52.58.199.22, 2a05:d014:edb:5704::6, ...正在连接 nginx.org (nginx.org)|3.125.197.172|:80... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：1052581 (1.0M) [application/octet-stream]正在保存至: “nginx-1.19.3.tar.gz”nginx-1.19.3.tar.gz 100%[===================&gt;] 1.00M 21.4KB/s 用时 43s 2020-10-11 16:00:28 (24.1 KB/s) - 已保存 “nginx-1.19.3.tar.gz” [1052581/1052581]) 解压软件包 12345[root@zutuanxue ~]# tar xf nginx-1.19.3.tar.gz[root@zutuanxue ~]# ls公共 视频 文档 音乐 anaconda-ks.cfg nginx-1.19.3模板 图片 下载 桌面 initial-setup-ks.cfg nginx-1.19.3.tar.gz configure命令：检查当前系统是否满足软件包安装需求,这步的主要目的： – 检查环境 是否 满足安装条件 依赖解决 – 指定安装方式 配置文件 命令文件 各种文件放哪里 开启模块功能【内置模块 三方模块】 – 指定软件安装在那里 123456789101112131415161718192021222324252627282930313233343536373839404142- 安装GCC编译软件 以及nginx依赖，有人问我为啥要安装pcre-devel zlib-devel这两个包，因为你不了解，如果你自己安装过一次就知道在检查当前系统的时候会报错，说没有这两个软件，这里我就直接装上了。大家学习的时候可以试试，是不是我说的这样。[root@zutuanxue ~]# yum -y install gcc pcre-devel zlib-devel- 检查系统是否满足安装需求[root@zutuanxue ~]# cd nginx-1.19.3/[root@zutuanxue nginx-1.19.3]# ./configure --prefix=/usr/local/nginxchecking for OS + Linux 4.18.0-193.el8.x86_64 x86_64checking for C compiler ... found + using GNU C compiler + gcc version: 8.3.1 20191121 (Red Hat 8.3.1-5) (GCC) checking for gcc -pipe switch ... foundchecking for -Wl,-E switch ... foundchecking for gcc builtin atomic operations ... foundchecking for C99 variadic macros ... foundchecking for gcc variadic macros ... found.........此处省略10000个字Configuration summary + using system PCRE library + OpenSSL library is not used + using system zlib library nginx path prefix: &quot;/usr/local/nginx&quot; nginx binary file: &quot;/usr/local/nginx/sbin/nginx&quot; nginx modules path: &quot;/usr/local/nginx/modules&quot; nginx configuration prefix: &quot;/usr/local/nginx/conf&quot; nginx configuration file: &quot;/usr/local/nginx/conf/nginx.conf&quot; nginx pid file: &quot;/usr/local/nginx/logs/nginx.pid&quot; nginx error log file: &quot;/usr/local/nginx/logs/error.log&quot; nginx http access log file: &quot;/usr/local/nginx/logs/access.log&quot; nginx http client request body temporary files: &quot;client_body_temp&quot; nginx http proxy temporary files: &quot;proxy_temp&quot; nginx http fastcgi temporary files: &quot;fastcgi_temp&quot; nginx http uwsgi temporary files: &quot;uwsgi_temp&quot; nginx http scgi temporary files: &quot;scgi_temp&quot;备注：/configure --prefix=/usr/local/nginx--prefix= 指定软件安装到哪个目录 make命令：使用gcc进行编译，生成主要的二进制文件 123456789101112131415[root@zutuanxue nginx-1.19.3]# make -j4make -f objs/Makefilemake[1]: 进入目录“/root/nginx-1.19.3”cc -c -pipe -O -W -Wall -Wpointer-arith -Wno-unused-parameter -Werror -g -I src/core -I src/event -I src/event/modules -I src/os/unix -I objs \\\t-o objs/src/core/ngx_inet.o \\\tsrc/core/ngx_inet.c ...........省略过程-ldl -lpthread -lcrypt -lpcre -lz \\-Wl,-Emake[1]: 离开目录“/root/nginx-1.19.3”备注： make -j4-j 指定几个cpu一起编译 -j4 那就是4个一起干活，默认一个干活，这样速度更快 make install 命令将二进制文件安装到主机 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@zutuanxue nginx-1.19.3]# make installmake -f objs/Makefile installmake[1]: 进入目录“/root/nginx-1.19.3”test -d &#x27;/usr/local/nginx&#x27; || mkdir -p &#x27;/usr/local/nginx&#x27;test -d &#x27;/usr/local/nginx/sbin&#x27; \\\t|| mkdir -p &#x27;/usr/local/nginx/sbin&#x27;test ! -f &#x27;/usr/local/nginx/sbin/nginx&#x27; \\\t|| mv &#x27;/usr/local/nginx/sbin/nginx&#x27; \\ &#x27;/usr/local/nginx/sbin/nginx.old&#x27;cp objs/nginx &#x27;/usr/local/nginx/sbin/nginx&#x27;test -d &#x27;/usr/local/nginx/conf&#x27; \\\t|| mkdir -p &#x27;/usr/local/nginx/conf&#x27;cp conf/koi-win &#x27;/usr/local/nginx/conf&#x27;cp conf/koi-utf &#x27;/usr/local/nginx/conf&#x27;cp conf/win-utf &#x27;/usr/local/nginx/conf&#x27;test -f &#x27;/usr/local/nginx/conf/mime.types&#x27; \\\t|| cp conf/mime.types &#x27;/usr/local/nginx/conf&#x27;cp conf/mime.types &#x27;/usr/local/nginx/conf/mime.types.default&#x27;test -f &#x27;/usr/local/nginx/conf/fastcgi_params&#x27; \\\t|| cp conf/fastcgi_params &#x27;/usr/local/nginx/conf&#x27;cp conf/fastcgi_params \\\t&#x27;/usr/local/nginx/conf/fastcgi_params.default&#x27;test -f &#x27;/usr/local/nginx/conf/fastcgi.conf&#x27; \\\t|| cp conf/fastcgi.conf &#x27;/usr/local/nginx/conf&#x27;cp conf/fastcgi.conf &#x27;/usr/local/nginx/conf/fastcgi.conf.default&#x27;test -f &#x27;/usr/local/nginx/conf/uwsgi_params&#x27; \\\t|| cp conf/uwsgi_params &#x27;/usr/local/nginx/conf&#x27;cp conf/uwsgi_params \\\t&#x27;/usr/local/nginx/conf/uwsgi_params.default&#x27;test -f &#x27;/usr/local/nginx/conf/scgi_params&#x27; \\\t|| cp conf/scgi_params &#x27;/usr/local/nginx/conf&#x27;cp conf/scgi_params \\\t&#x27;/usr/local/nginx/conf/scgi_params.default&#x27;test -f &#x27;/usr/local/nginx/conf/nginx.conf&#x27; \\\t|| cp conf/nginx.conf &#x27;/usr/local/nginx/conf/nginx.conf&#x27;cp conf/nginx.conf &#x27;/usr/local/nginx/conf/nginx.conf.default&#x27;test -d &#x27;/usr/local/nginx/logs&#x27; \\\t|| mkdir -p &#x27;/usr/local/nginx/logs&#x27;test -d &#x27;/usr/local/nginx/logs&#x27; \\\t|| mkdir -p &#x27;/usr/local/nginx/logs&#x27;test -d &#x27;/usr/local/nginx/html&#x27; \\\t|| cp -R html &#x27;/usr/local/nginx&#x27;test -d &#x27;/usr/local/nginx/logs&#x27; \\\t|| mkdir -p &#x27;/usr/local/nginx/logs&#x27;make[1]: 离开目录“/root/nginx-1.19.3” 到此我们就把nginx安装到&#x2F;usr&#x2F;local目录下了,可以使用ls命令看看有没有东西 12[root@zutuanxue nginx-1.19.3]# ls /usr/local/nginx/conf html logs sbin 验证安装 软件已经安装了，我们看看结果吧！ 12启动软件[root@zutuanxue nginx-1.19.3]# /usr/local/nginx/sbin/nginx 打开虚拟机浏览器输入:http://localhost回车 nginx访问.png 四、CentOS 8 dnf命令dnf介绍DNF是新一代的rpm软件包管理器。最早出现在 Fedora 18 这个发行版中，在Fedora 22中正式取代了yum DNF器克服了YUM的一些瓶颈，提升了包括用户体验，内存占用，依赖分析，运行速度等多方面的内容。 dnf安装在CentOS7中需要单独安装 12yum install epel-release -yyum install dnf 在CentOS8中系统默认使用的是DNF，我们所看到的yum只是dnf的一个软连接 1234[root@zutuanxue ~]# which yum/usr/bin/yum[root@zutuanxue ~]# ll /usr/bin/yum lrwxrwxrwx. 1 root root 5 5月 14 2019 /usr/bin/yum -&gt; dnf-3 相关目录和使用 目录 &#x2F;etc&#x2F;dnf&#x2F;dnf.conf 配置文件 &#x2F;etc&#x2F;dnf&#x2F;aliases.d&#x2F; 为相关命令定义别名的如dnf alias add rm&#x3D;remove &#x2F;etc&#x2F;dnf&#x2F;modules.d&amp;&#x2F;etc&#x2F;dnf&#x2F;modules.defaults.d 模块的设置 &#x2F;etc&#x2F;dnf&#x2F;plugins&#x2F; 插件的设置 &#x2F;etc&#x2F;dnf&#x2F;protected.d&#x2F; 受保护的软件包的设置 &#x2F;etc&#x2F;dnf&#x2F;vars&#x2F; 变量设置 dnf用法展示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384查看DNF的版本[root@zutuanxue ~]# dnf --version 查看dnf的可用软件仓库[root@zutuanxue ~]# dnf repolist 查看所有软件仓库[root@zutuanxue ~]# dnf repolist all\t查看已安装的软件包[root@zutuanxue ~]# dnf list installed 查看可安装的软件包[root@zutuanxue ~]# dnf list available 搜索dhcp-server[root@zutuanxue ~]# dnf search dhcp-server 查询一个文件是由哪个软件包提供的[root@zutuanxue ~]# dnf provides /usr/sbin/dhclient查询软件包详细信息[root@zutuanxue ~]# dnf info dhcp-server\t安装软件包[root@zutuanxue ~]# dnf install dhcp-server 升级软件包[root@zutuanxue ~]# dnf update systemd\t检查软件包的更新[root@zutuanxue ~]# dnf check-update\t升级所有可升级的软件包[root@zutuanxue ~]# dnf update 升级所有可升级的软件包[root@zutuanxue ~]# dnf upgrade 卸载软件包[root@zutuanxue ~]# dnf remove dhcp-server\t[root@zutuanxue ~]# dnf erase dhcp-server 删除无用孤立的软件包[root@zutuanxue ~]# dnf autoremove\t清除缓存中的无用数据[root@zutuanxue ~]# dnf clean all\t获取某一个命令的帮助[root@zutuanxue ~]# dnf help clean\t获取dnf命令的帮助[root@zutuanxue ~]# dnf help 查看历史命令[root@zutuanxue ~]# dnf history 重新执行历史命令中的第19条[root@zutuanxue ~]# dnf history redo 19\t查看软件包组[root@zutuanxue ~]# dnf grouplist 安装一组软件包[root@zutuanxue ~]# dnf groupinstall &#x27;系统工具&#x27; 升级一组软件包[root@zutuanxue ~]# dnf groupupdate &#x27;系统工具&#x27;\t删除一组软件包[root@zutuanxue ~]# dnf groupremove &#x27;系统工具&#x27;\t从特定的软件仓库安装软件包[root@zutuanxue ~]# dnf --enablerepo=epel install zabbix将软件包更新到最新的稳定版[root@zutuanxue ~]# dnf distro-sync重新安装指定的软件包[root@zutuanxue ~]# dnf reinstall dhcp-server降级软件包[root@zutuanxue ~]# dnf downgrade dhcp-server","categories":["Linux","Linux系统管理宝典"]},{"title":"逻辑卷实战案例-逻辑卷扩容","path":"/2023/09/27/Linux系统管理宝典/Linux-逻辑卷实战案例-逻辑卷扩容/","content":"案例需求将&#x2F;lv1目录动态扩容到3G 案例思路 查看&#x2F;lv1目录所对应的逻辑卷是哪一个 &#x2F;dev&#x2F;mapper&#x2F;vg1-lv1 查看当前逻辑卷所在的卷组vg1剩余空间是否足够 如果vg1空间不够，得先扩容卷组，再扩容逻辑卷 如果vg1空间足够，直接扩容逻辑卷 案例实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475步骤：1. 查看/lv1目录属于哪个卷组[root@zutuanxue /]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/vg1-lv1 2.4G 7.5M 2.3G 1% /lv1[root@zutuanxue /]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- &lt;17.00g swap cl -wi-ao---- 2.00g lv1 vg1 -wi-ao---- 2.50g lv2 vg1 -wi-a----- 200.00m lv3 vg1 -wi-a----- 664.00m 2. 卷组的剩余空间[root@zutuanxue /]# vgs VG #PV #LV #SN Attr VSize VFree cl 1 2 0 wz--n- &lt;19.00g 0 vg1 2 4 0 wz--n- 3.99g 664.00m结果：当前卷组空间不足我扩容3. 扩容逻辑卷所在的卷组1）首先得有物理设备 /dev/sdb32) 将物理设备做成物理卷[root@zutuanxue /]# pvcreate /dev/sdb3 Physical volume &quot;/dev/sdb3&quot; successfully created.[root@zutuanxue /]# pvs PV VG Fmt Attr PSize PFree /dev/sda2 cl lvm2 a-- &lt;19.00g 0 /dev/sdb1 vg1 lvm2 a-- &lt;2.00g 0 /dev/sdb2 vg1 lvm2 a-- &lt;2.00g 464.00m /dev/sdb3 lvm2 --- 2.00g 2.00g 3）将物理卷加入到卷组中（卷组扩容）[root@zutuanxue /]# vgextend vg1 /dev/sdb3 Volume group &quot;vg1&quot; successfully extended[root@zutuanxue /]# pvs PV VG Fmt Attr PSize PFree /dev/sda2 cl lvm2 a-- &lt;19.00g 0 /dev/sdb1 vg1 lvm2 a-- &lt;2.00g 0 /dev/sdb2 vg1 lvm2 a-- &lt;2.00g 464.00m /dev/sdb3 vg1 lvm2 a-- &lt;2.00g &lt;2.00g 注意：正常情况下，应该先将/dev/sdb3物理设备创建为物理卷再加入到卷组中；如果直接加入卷组，系统会自动帮你将其做成物理卷。[root@zutuanxue /]# vgs VG #PV #LV #SN Attr VSize VFree cl 1 2 0 wz--n- &lt;19.00g 0 vg1 3 4 0 wz--n- &lt;5.99g &lt;2.45g4. 扩容逻辑卷[root@zutuanxue /]# lvextend -L 3G /dev/vg1/lv1 -L 3G最终的大小或者[root@zutuanxue /]# lvextend -L +1.5G /dev/vg1/lv1 -L +1.5G 扩容1.5G5. 查看结果[root@zutuanxue /]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root cl -wi-ao---- &lt;17.00g swap cl -wi-ao---- 2.00g lv1 vg1 -wi-ao---- 3.00g 已经扩容到了3G [root@zutuanxue /]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/vg1-lv1 2.4G 7.5M 2.3G 1% /lv1 实际并没有改变6. 同步文件系统[root@zutuanxue /]# resize2fs /dev/vg1/lv1 #该命令适用于ext分区[root@manage01 ~]# xfs_growfs /dev/vg1/lv1 #该命令适用于xfs分区7. 再次查看验证[root@zutuanxue /]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/vg1-lv1 2.9G 7.5M 2.8G 1% /lv1 扩容成功","categories":["Linux","Linux系统管理宝典"]},{"title":"逻辑卷实战案例-逻辑卷应用","path":"/2023/09/27/Linux系统管理宝典/Linux-逻辑卷实战案例-逻辑卷应用/","content":"案例需求：创建一个2.5G大小的逻辑卷 案例思路： 物理的设备 将物理设备做成物理卷 创建卷组并将物理卷加入其中 创建逻辑卷 格式化逻辑卷 挂载使用 案例实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154步骤：1. 物理设备[root@zutuanxue ~]# lsblk /dev/sdbNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsdb 8:16 0 20G 0 disk ├─sdb1 8:17 0 2G 0 part /disk1├─sdb2 8:18 0 2G 0 part ├─sdb3 8:19 0 2G 0 part ├─sdb4 8:20 0 2G 0 part └─sdb5 8:21 0 2G 0 part 2. 创建物理卷[root@zutuanxue ~]# pvcreate /dev/sdb&#123;1,2&#125; Physical volume &quot;/dev/sdb1&quot; successfully created. Physical volume &quot;/dev/sdb2&quot; successfully created.查看物理卷：[root@zutuanxue ~]# pvs PV VG Fmt Attr PSize PFree /dev/sda2 cl lvm2 a-- &lt;19.00g 0 /dev/sdb1 lvm2 --- 2.00g 2.00g /dev/sdb2 lvm2 --- 2.00g 2.00g[root@zutuanxue ~]# pvscan PV /dev/sda2 VG cl lvm2 [&lt;19.00 GiB / 0 free] PV /dev/sdb1 lvm2 [2.00 GiB] PV /dev/sdb2 lvm2 [2.00 GiB] Total: 3 [&lt;23.00 GiB] / in use: 1 [&lt;19.00 GiB] / in no VG: 2 [4.00 GiB][root@zutuanxue ~]# pvdisplay /dev/sdb1 &quot;/dev/sdb1&quot; is a new physical volume of &quot;2.00 GiB&quot; --- NEW Physical volume --- PV Name /dev/sdb1 #物理卷名称 VG Name #卷组名称 PV Size 2.00 GiB #大小 Allocatable NO #是否已分配出去 PE Size 0 #PE大小 Total PE 0 #PE总数 Free PE 0 #空闲PE Allocated PE 0 #可分配PE PV UUID 3M4...lT #UUID3. 创建卷组并将物理卷加入其中[root@zutuanxue ~]# vgcreate vg1 /dev/sdb&#123;1,2&#125; Volume group &quot;vg1&quot; successfully created查看卷组信息：[root@zutuanxue ~]# vgs vg1 VG #PV #LV #SN Attr VSize VFree vg1 2 0 0 wz--n- 3.99g 3.99g [root@zutuanxue ~]# vgscan\t#扫描系统中有哪些卷组 Reading all physical volumes. This may take a while... Found volume group &quot;vg1&quot; using metadata type lvm2 Found volume group &quot;cl&quot; using metadata type lvm2 [root@zutuanxue ~]# vgdisplay vg1 --- Volume group --- VG Name vg1 System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 1 VG Access read/write VG Status resizable MAX LV 0 Cur LV 0 Open LV 0 Max PV 0 Cur PV 2 Act PV 2 VG Size 3.99 GiB #卷组大小 PE Size 4.00 MiB #PE大小 Total PE 1022 #PE数量 Alloc PE / Size 0/0 #已分配的PE/容量 Free PE / Size 1022/3.99 GiB\t#可分配的PE/容量 VG UUID CQ6p...K9I4. 创建逻辑卷[root@zutuanxue ~]# lvcreate -n lv1 -L 2.5G vg1 Logical volume &quot;lv1&quot; created.在操作系统层面映射两个地方：[root@zutuanxue ~]# ll /dev/mapper/vg1-lv1 lrwxrwxrwx 1 root root 7 12月 10 05:47 /dev/mapper/vg1-lv1 -&gt; ../dm-2[root@zutuanxue ~]# ll /dev/vg1/lv1 lrwxrwxrwx 1 root root 7 12月 10 05:47 /dev/vg1/lv1 -&gt; ../dm-2[root@zutuanxue ~]# ll /dev/dm-2 brw-rw---- 1 root disk 253, 2 12月 10 05:47 /dev/dm-2lvcreate参数-n：指定逻辑卷的名字-L：指定逻辑卷的大小-l：指定逻辑卷的大小举例：-l 100 100个PE，每个PE大小默认4M，故逻辑卷大小为400M-l 50%free 卷组剩余空间的50%[root@zutuanxue ~]# vgs vg1 VG #PV #LV #SN Attr VSize VFree vg1 2 1 0 wz--n- 3.99g 1.49g 创建大小为200M的逻辑卷lv02;每个PE为4M，-l 50指定50个PE,大小为200M[root@zutuanxue ~]# lvcreate -n lv2 -l 50 vg1 Logical volume &quot;lv2&quot; created.[root@zutuanxue ~]# vgs vg1 VG #PV #LV #SN Attr VSize VFree vg1 2 2 0 wz--n- 3.99g &lt;1.30g[root@manage01 ~]# lvs /dev/vg01/lv02 LV VG Attr LSize Pool Origin Data% Move Log Cpy%Sync Convert lv02 vg01 -wi-a----- 200.00m 创建大小为剩余卷组vg01空间的50%的逻辑卷lv03[root@zutuanxue ~]# lvcreate -n lv3 -l 50%free vg1 Logical volume &quot;lv3&quot; created.[root@zutuanxue ~]# vgs vg1 VG #PV #LV #SN Attr VSize VFree vg1 2 3 0 wz--n- 3.99g 664.00m查看逻辑卷的信息：[root@zutuanxue ~]# lvs /dev/vg1/lv1 LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg1 -wi-a----- 2.50g [root@zutuanxue ~]# lvs /dev/vg1/lv2 LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv2 vg1 -wi-a----- 200.00m [root@zutuanxue ~]# lvs /dev/vg1/lv3 LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv3 vg1 -wi-a----- 664.00m [root@zutuanxue ~]# lvdisplay /dev/vg1/lv1 --- Logical volume --- LV Path /dev/vg1/lv1 LV Name lv1 VG Name vg1 LV UUID jj9Sj1-zHuo-qpBZ-Dkk1-LVYB-HyUH-LQ6edW LV Write Access read/write LV Creation host, time localhost.localdomain, 2019-12-10 05:46:59 -0500 LV Status available # open 0 LV Size 2.50 GiB Current LE 640 Segments 2 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2 5. 格式化逻辑卷[root@zutuanxue ~]# mkfs.ext4 /dev/vg1/lv1 6. 挂载使用1）创建一个空的挂载点[root@zutuanxue /]# mkdir /lv12）挂载使用[root@zutuanxue /]# mount /dev/vg1/lv1 /lv1/","categories":["Linux","Linux系统管理宝典"]},{"title":"逻辑卷实战案例-其他常见操作","path":"/2023/09/27/Linux系统管理宝典/Linux-逻辑卷实战案例-其他常见操作/","content":"LVM中有PV出现了坏道123456789101112131415161718192021222324252627282930313233#LVM中有PV出现了坏道#数据拷贝 将/dev/sdc1拷贝到/dev/sdd1[root@zutuanxue ~]#lvchange -an /dev/baism/abc[root@zutuanxue ~]# pvmove /dev/sdc1 /dev/sdd1 /dev/sdc1: Moved: 2.7% /dev/sdc1: Moved: 100.0%[root@zutuanxue ~]# vgchange -a n /dev/baism 0 logical volume(s) in volume group &quot;baism&quot; now active[root@zutuanxue ~]# vgreduce baism /dev/sdc1 Removed &quot;/dev/sdc1&quot; from volume group &quot;baism&quot;[root@zutuanxue ~]# vgchange -a y /dev/baism 1 logical volume(s) in volume group &quot;baism&quot; now active[root@zutuanxue ~]#lvchange -ay /dev/baism/abc#卷组迁移#导出卷组 old machine[root@zutuanxue ~]# vgexport /dev/baism Volume group &quot;baism&quot; successfully exported#导入卷组 new machine[root@zutuanxue ~]# pvscan[root@zutuanxue ~]# vgimport /dev/baism Volume group &quot;baism&quot; successfully imported[root@zutuanxue ~]# vgchange -a y /dev/baism 1 logical volume(s) in volume group &quot;baism&quot; now active[root@zutuanxue ~]#lvchange -ay /dev/baism/abc volume merged lv合并123456789101112root@zutuanxue lvm]# vgcreate baism1 /dev/sdc1 Volume group &quot;baism1&quot; successfully created[root@zutuanxue lvm]# vgcreate baism2 /dev/sdd1 Volume group &quot;baism2&quot; successfully created[root@zutuanxue lvm]# vgmerge -v baism1 baism2 Checking for volume group &quot;baism1&quot; Checking for volume group &quot;baism2&quot; Archiving volume group &quot;baism2&quot; metadata (seqno 1). Archiving volume group &quot;baism1&quot; metadata (seqno 1). Writing out updated volume group Creating volume group backup &quot;/etc/lvm/backup/baism1&quot; (seqno 2). Volume group &quot;baism2&quot; successfully merged into &quot;baism1&quot; volume spilt lv分割12345[root@zutuanxue ~]# vgsplit baism1 baism2 /dev/sdd1 New volume group &quot;baism2&quot; successfully split from &quot;baism1&quot;baism1 Old volumebaism2 New volume /dev/sdd1 逻辑卷从旧机器迁移到新机器1234567891011121314151617181920212223242526272829303132333435#########Backing Up Volume Group Metadata:当创建vg的时候，系统默认会自动备份Metadata。/etc/lvm/backup下面存放的是metadata的备份信息，而/etc/lvm/archive下面存放的是metadata的archive信息。[root@zutuanxue backup]# pwd/etc/lvm/backup[root@zutuanxue backup]# strings baism2# Generated by LVM2 version 2.02.87(2)-rhel7 (2011-10-12): Mon Jan 14 22:27:02 2013contents = &quot;Text Format Volume Group&quot;version = 1description = &quot;Created *after* executing &#x27;vgsplit baism1 baism2 /dev/sdd1&#x27;&quot; #warncreation_host = &quot;rhel7&quot; # Linux rhel7 2.6.32-220.el6.x86_64 #1 SMP Wed Nov 9 08:03:13 EST 2011 x86_64creation_time = 1358173622 # Mon Jan 14 22:27:02 2013baism2 &#123; id = &quot;Ft0eD7-oVca-mwY6-6FeK-TwW2-hTrj-aYxYbq&quot; seqno = 2 status = [&quot;RESIZEABLE&quot;, &quot;READ&quot;, &quot;WRITE&quot;] flags = [] extent_size = 8192 # 4 Megabytes max_lv = 0 max_pv = 0 metadata_copies = 0 physical_volumes &#123; pv0 &#123; id = &quot;m7aKrr-D0r9-jOJ2-aK51-ec25-4rwH-4ccbbh&quot; device = &quot;/dev/sdd1&quot; # Hint only status = [&quot;ALLOCATABLE&quot;] flags = [] dev_size = 4192902 # 1.99933 Gigabytes pe_start = 2048 pe_count = 511 # 1.99609 Gigabytes","categories":["Linux","Linux系统管理宝典"]},{"title":"linux隐藏权限","path":"/2023/09/27/Linux系统管理宝典/Linux-隐藏权限/","content":"隐藏权限的介绍有时候你发现即时使用的是root用户也不能修改某个文件，大部分原因是因为使用过chattr命令锁定了该文件，这个命令的作用很大，通过chattr可以提高系统的安全性，但是这个命令并不适合所有的目录，如&#x2F;dev,&#x2F;tmp,&#x2F;var。与我们前面看到的chmod这些命令修改权限不同的是chattr修改的是更底层的属性，这里面我们所提到的隐藏权限指的就是使用chattr来设置属性 隐藏权限的设置和查看chattr的用户与我们之前讲的chmod，chow这些命令相似，都是直接对需要修改的文件进行操作就可以了 chattr命令：为文件设置隐藏权限 123456789命令选项+ 增加权限- 删除权限= 赋予什么权限，文件最终权限A 文件或目录的atime不可被修改S 硬盘I/O同步选项，功能类似sync。a 只能向文件中添加数据，而不能删除，多用于服务器日志文件安全，只有root才能设定这个属性。d 文件不能成为dump程序的备份目标。i 设定文件不能被删除、改名、设定链接关系，同时不能写入或新增内容。 lsattr命令: 查看文件隐藏权限 通过案例学习命令用法： 12345678910111213给file1文件添加AaiSd权限[root@zutuanxue test]# chattr +AaiSd file1查看文件file1隐藏权限[root@zutuanxue test]# lsattr file1 --S-iadA---------- file1设置删除file1文件隐藏权限- 可以使用-号 - 可以使用=为空设置[root@zutuanxue test]# chattr = file1[root@zutuanxue test]# lsattr file1 ------------------ file1 通过上面的例子可以看到查看的时候使用的是lsattr，chattr还有很多参数，各位可以在man手册中获取到帮助，另外有些参数的使用是有局限性的。","categories":["Linux","Linux系统管理宝典"]},{"title":"逻辑卷实战案例-逻辑卷裁剪","path":"/2023/09/27/Linux系统管理宝典/Linux-逻辑卷实战案例-逻辑卷裁剪/","content":"案例需求将lv1逻辑卷由原来的3G缩小为2G 案例思路1、卸载逻辑卷2、扫描逻辑卷3、裁剪率lv1文件系统4、裁剪逻辑卷lv15、挂载使用 案例实现ext分区逻辑卷裁剪12345678[root@zutuanxue /]# umount /lv1[root@zutuanxue /]# e2fsck -f /dev/vg1/lv1 检验文件系统[root@zutuanxue /]# resize2fs /dev/vg1/lv1 2G\t裁剪文件系统到2G[root@zutuanxue /]# lvreduce /dev/vg1/lv1 -L 2G\t裁剪逻辑卷[root@zutuanxue /]# mount /dev/vg1/lv1 /lv1/ 挂载使用[root@zutuanxue /]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/vg1-lv1 2.0G 9.0M 1.8G 1% /lv1 xfs分区逻辑卷裁剪案例思路：1、将lv2的文件系统格式化为xfs2、将&#x2F;dev&#x2F;vg1&#x2F;lv2挂载到&#x2F;lv23、在&#x2F;lv2中建立一个文件，写入内容4、备份数据5、卸载分区并裁剪逻辑卷6、格式化裁剪后的逻辑卷7、导入数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475761)备份数据命令xfsdump2）备份数据[root@zutuanxue /]# xfsdump -f /root/lv2.img /lv2#挂载点目录后面不要加&quot;/&quot;xfsdump: using file dump (drive_simple) strategyxfsdump: version 3.1.8 (dump format 3.0) - type ^C for status and control ============================= dump label dialog ==============================please enter label for this dump session (timeout in 300 sec) -&gt; lv2session label entered: &quot;lv2&quot; --------------------------------- end dialog ---------------------------------xfsdump: level 0 dump of localhost.localdomain:/lv2xfsdump: dump date: Tue Dec 10 06:33:44 2019xfsdump: session id: 15936371-b967-4c2c-8995-49eb702792fexfsdump: session label: &quot;lv2&quot;xfsdump: ino map phase 1: constructing initial dump listxfsdump: ino map phase 2: skipping (no pruning necessary)xfsdump: ino map phase 3: skipping (only one dump stream)xfsdump: ino map construction completexfsdump: estimated dump size: 20800 bytes ============================= media label dialog =============================please enter label for media in drive 0 (timeout in 300 sec) -&gt; lv2media label entered: &quot;lv2&quot; --------------------------------- end dialog ---------------------------------xfsdump: creating dump session media file 0 (media 0, file 0)xfsdump: dumping ino mapxfsdump: dumping directoriesxfsdump: dumping non-directory filesxfsdump: ending media filexfsdump: media file size 21016 bytesxfsdump: dump size (non-dir files) : 0 bytesxfsdump: dump complete: 14 seconds elapsedxfsdump: Dump Summary:xfsdump: stream 0 /root/lv2.img OK (success)xfsdump: Dump Status: SUCCESS3)裁剪[root@zutuanxue ~]# umount /lv2[root@zutuanxue ~]# lvreduce /dev/vg1/lv2 -L 100M WARNING: Reducing active logical volume to 2.00 GiB. THIS MAY DESTROY YOUR DATA (filesystem etc.)Do you really want to reduce vg01/lv01? [y/n]: y Size of logical volume vg01/lv01 changed from 7.00 GiB (1792 extents) to 2.00 GiB (512 extents). Logical volume vg01/lv01 successfully resized.4）格式化[root@zutuanxue ~]# mkfs.xfs -f /dev/vg1/lv2[root@zutuanxue ~]# mount /dev/vg1/lv2 /lv25）恢复数据 -f source[root@zutuanxue ~]# xfsrestore -f /root/lv2.img /lv2...xfsrestore: Restore Status: SUCCESSroot@zutuanxue ~]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/vg1-lv2 95M 6.0M 89M 7% /lv2[root@zutuanxue ~]# cat /lv2/filea hahaha","categories":["Linux","Linux系统管理宝典"]},{"title":"逻辑卷常用命令","path":"/2023/09/27/Linux系统管理宝典/Linux-逻辑卷常用命令/","content":"一、物理卷管理1.1、物理卷的创建:pvcreate命令12345678pvcreate [命令选项] [参数]将物理分区转换为物理卷命令选项-f：强制创建物理卷，不需要用户确认；-u：指定设备的UUID；-y：所有的问题都回答“yes”；-Z：是否利用前4个扇区。 1.2、物理卷的移除:pvremove命令1234567pvremove [命令选项] [参数]将物理卷转换为普通linux分区命令选项-d 调试模式-f 强制删除-y 对提问回答“yes” 1.3、物理卷查看命令:pvscan12pvs 显示PV简况pvdisplay 显示PV详细信息 1.4、物理卷扫描命令:pvscan1pvscan 扫描pv设备 删除物理卷: pvremove12# 删除PV sdb1 sdc1[root@zutuanxue ~]# pvremove /dev/sdb1 /dev/sdc1 二、卷组管理将多个物理卷组成一个卷组，形成一个存储池 2.1、卷组创建：vgcreate命令12# 将pv sdb1 sdc1创建成卷组VG1000 PE大小为32M[root@zutuanxue ~]# vgcreate -s 32 vg1000 /dev/sdb1 /dev/sdc1 2.2、删除卷组中的PV：vgreduce命令12# 将vg1000卷组中的PV sdb1删除[root@zutuanxue ~]# vgreduce /dev/vg1000 /dev/sdb1 2.3、扩容卷组：vgextend命令12# 将pv sdb1 加入卷组vg1000[root@zutuanxue ~]# vgextend /dev/vg1000 /dev/sdb1 2.4、删除卷组：vgremove命令12# 删除vg1000卷组[root@zutuanxue ~]# vgremove /dev/vg1000/ 三、逻辑卷管理3.1、逻辑卷创建:lvcreate命令12# 从卷组vg1000上创建一个lv99的逻辑卷，容量为3G。[root@zutuanxue ~]# lvcreate -n lv99 -L 3G /dev/vg1000 3.2、逻辑卷扩容: lvextend命令12345# 注意扩容顺序，不能颠倒# a、扩容逻辑卷[root@zutuanxue ~]# lvextend -L 3.5G /dev/vg1000/lv99# b、扩容文件系统[root@zutuanxue ~]# resize2fs /dev/vg1000/lv99 3.3、逻辑卷缩小：lvreduce命令1234567# 注意扩容顺序，不能颠倒# a、扫描逻辑卷文件系统，清晰该逻辑卷的使用情况，注意只能缩未使用的空间[root@zutuanxue ~]# e2fsck -f /dev/vg1000/lv99# b、缩小文件系统[root@zutuanxue ~]# resize2fs /dev/vg1000/lv99 2G# c、缩小逻辑卷[root@zutuanxue ~]# lvreduce -L 2G /dev/vg1000/lv99 (lvresize) 3.4、逻辑卷移除12345#remove LVM# 卸载分区[root@zutuanxue ~]# umount /dev/vg1000/lv99# 删除逻辑卷[root@zutuanxue ~]# lvremove /dev/vg1000/lv99 注意： PE 和 LE的说明及应用策略 PE（physicalextent）每一个物理卷被划分为称为PE(PhysicalExtents)的基本单元，具有唯一编号的PE是可以被LVM寻址的最小单元。PE的大小是可配置的，默认为4MB。 LE（logicalextent）逻辑卷也被划分为被称为LE(LogicalExtents)的可被寻址的基本单位。在同一个卷组中，LE的大小和PE是相同的，并且一一对应。 设置使用大小为4MB的PE（默认为4MB），这表示卷组上创建的所有逻辑卷都以4MB为增量单位来进行扩充 或缩减。由于内核原因，PE大小决定了逻辑卷的最大大小，4MB的PE决定了单个逻辑卷最大容量为256GB，若希望使用大于256G的逻辑卷则创建卷组 时指定更大的PE。PE大小范围为8KB到512MB，并且必须总是2的倍数","categories":["Linux","Linux系统管理宝典"]},{"title":"Samba文件服务器","path":"/2023/09/27/数据安全之企业存储/Samba文件服务器/","content":"一、samba介绍在早期的网络世界当中，不同主机的文件传输大多使用FTP来进行。不过FTP却有个小小的问题， 那就是你无法直接修改主机上面的文件内容！也就是说，你想要更改Linux主机上面的某个文件时，你必须要将该文件下载后才能修改。在日常办公环境中，操作系统除了windows以外，还有linux或者UNIX。windows和linux或UNIX之间共享文件是无法直接完成的，为了解析不同系统之间的文件和打印机等资源的共享，我们今天来介绍一下samba服务。他可以解决不同系统平台之间的共享问题。 Samba是在Linux和UNIX系统上实现SMB协议的一个免费软件，由服务器及客户端程序构成，也是一个C&#x2F;S软件。 1SMB（Server Messages Block，信息服务块）是一种在局域网上共享文件和打印机的一种通信协议，它为局域网内的不同计算机之间提供文件及打印机等资源的共享服务。SMB协议是客户机/服务器型协议，客户机通过该协议可以访问服务器上的共享文件系统、打印机及其他 应用场景文件与打印机共享： samba的主要功能，samba进程实现资源共享，将文件和打印机甚至是设备（如：CDROM）发布到网络中，以供用户访问 身份验证和权限验证： 对用户身份进行验证及权限设置，通过加密的方式保护共享文件和打印机 名称解析： 通过nmbd服务实现名称解析，将NetBIOS名称解析为IP地址 浏览服务： 在局域中，samba可以成为本地主浏览器，保存可用 资源列表，当用户访问时，会提供浏览列表 SAMBA与NetBIOSsamba是构建在NetBIOS这个协议之上的，而NetBIOS最早是从IBM诞生的，目的是让局域网内的计算机能够进行网络连接，由于不是针对于大型网络，所以NetBIOS是无法跨路由的。而windows操作系统也支持这个协议，所以在Linux主机上使用SAMBA部署的共享服务是可以使用windows主机访问的。那么SAMBA是不是就不能跨路由提供服务了呢？并不是，我们可以通过一个叫NetBIOS over TCP&#x2F;IP的技术实现跨路由的SAMBA服务，但是目前SAMBA还是在局域网用的较多 SAMBA的相关守护进程nmbd：使用UDP的137、138来提供名称解析服务（NetBIOS） smbd：管理共享和数据传输，使用的端为TCP的139、445 SAMBA的工作流程1、协议协商 image20200306095957499.png 客户端在访问服务器时，发送negprot请求，告知服务器自己所支持的SMB类型，samba服务器根据客户端的情况，选择最优的SMB类型并作出回应 2、建立连接 image20200306100342210.png 当SMB类型确认后，客户端会发送session setup指令数据包，提交账号和密码，请求与samba服务器建立连接，如果客户端通过身份验证，服务器会作出回应，并为用户分配一个唯一的UID，在客户端与服务器通信时使用。 3、访问共享资源 image20200306101103005.png 当客户端需要访问共享资源时，会发送tree connect数据包，告知服务器需要访问的共享资源的名称，如果设置允许，samba服务器会为每个客户端与共享资源连接分配一个TID(线程标识符)，客户端就可以访问相应的共享资源 4、断开连接 image20200306101521438.png 共享使用完毕，客户端向服务器发送tree disconnect报文关闭对共享的访问，与服务器断开连接 相关软件包samba 主程序包，服务端需要 samba-client 客户端工具包 samba-common 通用工具和库文件，客户端服务器端都需要安装 相关文件 &#x2F;etc&#x2F;samba&#x2F;smb.conf 主配置文件 &#x2F;etc&#x2F;samba&#x2F;smb.conf.example 模板文件 &#x2F;var&#x2F;log&#x2F;samba&#x2F;log.nmbd nmbd进程的解析信息 &#x2F;var&#x2F;log&#x2F;samba&#x2F;log.smbd 记录用户的访问记录、服务器的问题 二、samba安装部署a、安装软件包 1[root@node1 ~]# dnf install samba samba-client -y b、设置服务开机启动 123[root@node1 ~]# systemctl enable nmb.service smb.service Created symlink /etc/systemd/system/multi-user.target.wants/nmb.service → /usr/lib/systemd/system/nmb.service.Created symlink /etc/systemd/system/multi-user.target.wants/smb.service → /usr/lib/systemd/system/smb.service. c、开启服务 1[root@node1 ~]# systemctl start nmb smb 三、samba配置文件详解主配文件路径: &#x2F;etc&#x2F;samba&#x2F;smb.conf 模板文件：&#x2F;etc&#x2F;samba&#x2F;smb.conf.example 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425[root@baism ~]# cat smb.conf.example # This is the main Samba configuration file. For detailed information about the# options listed here, refer to the smb.conf(5) manual page. Samba has a huge# number of configurable options, most of which are not shown in this example.## The Samba Wiki contains a lot of step-by-step guides installing, configuring,# and using Samba:# https://wiki.samba.org/index.php/User_Documentation## In this file, lines starting with a semicolon (;) or a hash (#) are# comments and are ignored. This file uses hashes to denote commentary and# semicolons for parts of the file you may wish to configure.## NOTE: Run the &quot;testparm&quot; command after modifying this file to check for basic# syntax errors.##---------------#SAMBA selinux相关设置，如果你开启了selinux，请注意下面的说明###Security-Enhanced Linux (SELinux) Notes:## Turn the samba_domain_controller Boolean on to allow a Samba PDC to use the# useradd and groupadd family of binaries. Run the following command as the# root user to turn this Boolean on:如果你在域环境中使用samba那么请设置下面的bool值# setsebool -P samba_domain_controller on## Turn the samba_enable_home_dirs Boolean on if you want to share home# directories via Samba. Run the following command as the root user to turn this# Boolean on:#假如希望通过samba共享用户家目录请设置下面的bool值# setsebool -P samba_enable_home_dirs on## If you create a new directory, such as a new top-level directory, label it# with samba_share_t so that SELinux allows Samba to read and write to it. Do# not label system directories, such as /etc/ and /home/, with samba_share_t, as# such directories should already have an SELinux label.#加入你想将目录通过samba共享，请确认其目录标签为sambe_share_t# Run the &quot;ls -ldZ /path/to/directory&quot; command to view the current SELinux# label for a given directory.## Set SELinux labels only on files and directories you have created. Use the# chcon command to temporarily change a label:标签设置方法# chcon -t samba_share_t /path/to/directory## Changes made via chcon are lost when the file system is relabeled or commands# such as restorecon are run.## Use the samba_export_all_ro or samba_export_all_rw Boolean to share system# directories. To share such directories and only allow read-only permissions:对共享目录的权限的bool设置，只读或读写# setsebool -P samba_export_all_ro on# To share such directories and allow read and write permissions:# setsebool -P samba_export_all_rw on## To run scripts (preexec/root prexec/print command/...), copy them to the# /var/lib/samba/scripts/ directory so that SELinux will allow smbd to run them.# Note that if you move the scripts to /var/lib/samba/scripts/, they retain# their existing SELinux labels, which may be labels that SELinux does not allow# smbd to run. Copying the scripts will result in the correct SELinux labels.# Run the &quot;restorecon -R -v /var/lib/samba/scripts&quot; command as the root user to# apply the correct SELinux labels to these files.##--------------##======================= Global Settings =====================================全局设置，对整个服务都生效[global]网络设置# ----------------------- Network-Related Options -------------------------## workgroup = the Windows NT domain name or workgroup name, for example, MYGROUP.## server string = the equivalent of the Windows NT Description field.## netbios name = used to specify a server name that is not tied to the hostname,# maximum is 15 characters.## interfaces = used to configure Samba to listen on multiple network interfaces.# If you have multiple interfaces, you can use the &quot;interfaces =&quot; option to# configure which of those interfaces Samba listens on. Never omit the localhost# interface (lo).## hosts allow = the hosts allowed to connect. This option can also be used on a# per-share basis.## hosts deny = the hosts not allowed to connect. This option can also be used on# a per-share basis.#定义计算机的工作组,如果希望和windows共享，可以设置为workgroup，这样就可以在windows的网上邻居中找到linux计算机 workgroup = MYGROUP对samba服务器的描述信息 server string = Samba Server Version %v设置netbios计算机名称; netbios name = MYSERVERsamba使用本机的那块网卡; interfaces = lo eth0 192.168.12.2/24 192.168.13.2/24允许那个网段访问samba服务器共享，还可以使用“hosts deny”设置禁止的网段，“hosts allow”的优先级高，表现形式可以是具体的IP地址和域名，还可以是*、？、local、all，也可以使用EXCEPT排除如：hosts allow = 192.168.0. EXCEPT 192.168.0.100; hosts allow = 127. 192.168.12. 192.168.13.#日志选项# --------------------------- Logging Options -----------------------------## log file = specify where log files are written to and how they are split.## max log size = specify the maximum size log files are allowed to reach. Log# files are rotated when they reach the size specified with &quot;max log size&quot;.#samba日志文件路径，%m表示客户端的NetBios名称，还有其它的变量，可以使用man smb.conf通过man手册去查看 # log files split per-machine: log file = /var/log/samba/log.%m日志文件大小，0为不限制，注意不建议这样设置 # maximum size of 50KB per log file, then rotate: max log size = 50独立服务选项# ----------------------- Standalone Server Options ------------------------## security = the mode Samba runs in. This can be set to user, share# (deprecated), or server (deprecated).## passdb backend = the backend used to store user information in. New# installations should use either tdbsam or ldapsam. No additional configuration# is required for tdbsam. The &quot;smbpasswd&quot; utility is available for backwards# compatibility.#samba安全级别share: 不需要账号密码，公开共享user: 需要提供samba账号密码才能访问共享，私密共享server：依靠其他Windows NT/2000或Samba Server来验证用户的账号和密码,是一种代理验证。此种安全模式下,系统管理员可以把所有的Windows用户和口令集中到一个NT系统上,&gt;使用Windows NT进行Samba认证, 远程服务器可以自动认证全部用户和口令,如果认证失败,Samba会使用user级别。domain：如果samba服务器加入到域环境中，验证工作由域控制器完成。ads：具备domain级别的所有功能，并且具备域控制器功能auto:安全级别会受“server role”字段的值影响，“server role”字段默认值为auto（用户通过验证后可以使用），其余的参数决定了samba服务器加入到window域环境中的角色是成员还是域控制器一般情况下我们使用share和user的比较多，除非公司有完整的域环境 security = user用户及密码的管理方式，有三种smbpasswd、tdbsam、ldapsamsmbpasswd:使用samba自带的工具smbpasswd命令为用户（真实用户或虚拟用户）设置密码，密码默认存放在/var/lib/samba/private/smbpasswd文件中，也可以使用“smb passwd file = /etc/samba/smbpasswd&quot;指定密码文件位置 smbpasswd\t-a username\t添加一个用户/修改用户密码 smbpasswd -d username\t禁用用户 smbpasswd -e username\t启用用户 smbpasswd -x username\t删除用户tdbsam：在/var/lib/samba/private建立一个passdb.tdb存放密码，也可以使用“smb passwd file”字段指定存放位置，除了可以使用smbpasswd命令管理用户之外，还可以使用pdbedit命令指定，而且只能是系统用户（真实用户），用户的建立可以使用mksmbpasswd命令建立一个smbpasswd文件，再使用pdbedit将文件里的用户导入数据库cat /etc/passwd | mksmbpasswd &gt; /etc/samba/smbpasswdpdbedit -i smbpasswd:/etc/samba/smbpasswd额外的用法pdbedit -a username：新建Samba账户。pdbedit -x username：删除Samba账户。pdbedit -L：列出Samba用户列表，读取passdb.tdb数据库文件。pdbedit -Lv：列出Samba用户列表的详细信息。pdbedit -c “[D]” –u username：禁用该Samba用户的账号。pdbedit -c “[]” –u username：恢复该Samba用户的账号。ldapsam：基于LDAP的认证方式，首先要有LDAP服务，并且加入到LDAP中 passdb backend = tdbsam域成员选项# ----------------------- Domain Members Options ------------------------## security = must be set to domain or ads.## passdb backend = the backend used to store user information in. New# installations should use either tdbsam or ldapsam. No additional configuration# is required for tdbsam. The &quot;smbpasswd&quot; utility is available for backwards# compatibility.## realm = only use the realm option when the &quot;security = ads&quot; option is set.# The realm option specifies the Active Directory realm the host is a part of.## password server = only use this option when the &quot;security = server&quot;# option is set, or if you cannot use DNS to locate a Domain Controller. The# argument list can include My_PDC_Name, [My_BDC_Name], and [My_Next_BDC_Name]:## password server = My_PDC_Name [My_BDC_Name] [My_Next_BDC_Name]## Use &quot;password server = *&quot; to automatically locate Domain Controllers.#设置域共享; security = domain; passdb backend = tdbsam#定义域名称; realm = MY_REALM#域验证服务器; password server = &lt;NT-Server-Name&gt;#域控选项# ----------------------- Domain Controller Options ------------------------## security = must be set to user for domain controllers.## passdb backend = the backend used to store user information in. New# installations should use either tdbsam or ldapsam. No additional configuration# is required for tdbsam. The &quot;smbpasswd&quot; utility is available for backwards# compatibility.## domain master = specifies Samba to be the Domain Master Browser, allowing# Samba to collate browse lists between subnets. Do not use the &quot;domain master&quot;# option if you already have a Windows NT domain controller performing this task.## domain logons = allows Samba to provide a network logon service for Windows# workstations.## logon script = specifies a script to run at login time on the client. These# scripts must be provided in a share named NETLOGON.## logon path = specifies (with a UNC path) where user profiles are stored.##; security = user; passdb backend = tdbsam让samba成为域的主浏览器; domain master = yes允许samba为windows提供网络登录服务; domain logons = yes # the following login script name is determined by the machine name # (%m):定义客户端在登录时要执行的脚本; logon script = %m.bat # the following login script name is determined by the UNIX user used:; logon script = %u.bat定义记录用户个性化信息的文件存放的位置，空值表示禁用个性化设置; logon path = \\\\%L\\Profiles\\%u # use an empty path to disable profile support:; logon path = # various scripts can be used on a domain controller or a stand-alone # machine to add or delete corresponding UNIX accounts:定义做为域控时，针对于用户和主机的添加、删除时需要执行的具体操作; add user script = /usr/sbin/useradd &quot;%u&quot; -n -g users; add group script = /usr/sbin/groupadd &quot;%g&quot;; add machine script = /usr/sbin/useradd -n -c &quot;Workstation (%u)&quot; -M -d /nohome -s /bin/false &quot;%u&quot;; delete user script = /usr/sbin/userdel &quot;%u&quot;; delete user from group script = /usr/sbin/userdel &quot;%u&quot; &quot;%g&quot;; delete group script = /usr/sbin/groupdel &quot;%g&quot;这些设置选项主要用于SMB网络中进行浏览时，设置samba服务器的行为。缺省情况不让 samba服务器参加broswser的推举过程，为了使得samba服务器能成为browser，就需要设定local master =yes。然后samba服务就可以根据os level设置的权重进行推举，缺省的os level为0，这个权重不会赢得推举。但可以取消注释，将os level设置为33，这将在与所有Windows计算机（包括Windows NT）的推举竞赛中获得胜利，因为NT server的权重为32。设置比33更高的权重，只是在不同的samba 服务器之间进行选择时才有意义。#preferred master 可以设置自己优先成为浏览服务器候选人## ----------------------- Browser Control Options ----------------------------## local master = when set to no, Samba does not become the master browser on# your network. When set to yes, normal election rules apply.## os level = determines the precedence the server has in master browser# elections. The default value should be reasonable.## preferred master = when set to yes, Samba forces a local browser election at# start up (and gives itself a slightly higher chance of winning the election).#; local master = no; os level = 33; preferred master = yes##wins服务，如果网络中配置了wins服务器可以在此设置wins相关项#----------------------------- Name Resolution -------------------------------## This section details the support for the Windows Internet Name Service (WINS).## Note: Samba can be either a WINS server or a WINS client, but not both.## wins support = when set to yes, the NMBD component of Samba enables its WINS# server.## wins server = tells the NMBD component of Samba to be a WINS client.## wins proxy = when set to yes, Samba answers name resolution queries on behalf# of a non WINS capable client. For this to work, there must be at least one# WINS server on the network. The default is no.## dns proxy = when set to yes, Samba attempts to resolve NetBIOS names via DNS# nslookups.设置nmb进程支持wins服务; wins support = yes设置wins服务器ip; wins server = w.x.y.z设置wins代理IP; wins proxy = yes设置Samba服务器是否在无法联系WINS服务器时通过DNS去解析主机的NetBIOS名; dns proxy = yes该部分包括Samba服务器打印机相关设置# --------------------------- Printing Options -----------------------------## The options in this section allow you to configure a non-default printing# system.## load printers = when set you yes, the list of printers is automatically# loaded, rather than setting them up individually.## cups options = allows you to pass options to the CUPS library. Setting this# option to raw, for example, allows you to use drivers on your Windows clients.## printcap name = used to specify an alternative printcap file.#是否启用共享打印机 load printers = yes cups options = raw打印机配置文件; printcap name = /etc/printcap # obtain a list of printers automatically on UNIX System V systems:; printcap name = lpstat打印机的系统类型,现在支持的打印系统有：bsd, sysv, plp, lprng, aix, hpux, qnx,cups; printing = cups该部分包括Samba服务器如何保留从Windows客户端复制或移动到Samba服务器共享目录文件的Windows文件属性的相关配置.# --------------------------- File System Options ---------------------------## The options in this section can be un-commented if the file system supports# extended attributes, and those attributes are enabled (usually via the# &quot;user_xattr&quot; mount option). These options allow the administrator to specify# that DOS attributes are stored in extended attributes and also make sure that# Samba does not change the permission bits.## Note: These options can be used on a per-share basis. Setting them globally# (in the [global] section) makes them the default for all shares.当Windows客户端将文件复制或移动到Samba服务器共享目录时，是否保留文件在Windows中的存档属性。默认no。; map archive = no当Windows客户端将文件复制或移动到Samba服务器共享目录时，是否保留文件在Windows中的隐藏属性。默认no。; map hidden = no当Windows客户端将文件复制或移动到Samba服务器共享目录时，是否保留文件在Windows中的只读属性。默认为no。; map read only = no当Windows客户端将文件复制或移动到Samba服务器共享目录时，是否保留文件在Windows中的系统文件属性。默认为no。; map system = no当Windows客户端将文件复制或移动到Samba服务器共享目录时，是否保留文件在Windows中的相关属性（只读、系统、隐藏、存档属性）。默认为yes。; store dos attributes = yes共享设置#============================ Share Definitions ==============================#用户家目录共享#共享名称[homes]描述 comment = Home Directories是否为隐藏共享 browseable = no是否允许写入 writable = yes允许访问该共享资源的smb用户，@组; valid users = %S; valid users = MYDOMAIN\\%S打印机共享[printers]描述 comment = All Printers路径 path = /var/spool/samba是否可浏览，no类似隐藏共享 browseable = no是否支持guest访问，和public指令类似 guest ok = no是否可写 writable = no是否允许打印 printable = yes# Un-comment the following and create the netlogon directory for Domain Logons:; [netlogon]; comment = Network Logon Service; path = /var/lib/samba/netlogon; guest ok = yes; writable = no; share modes = no# Un-comment the following to provide a specific roaming profile share.# The default is to use the user&#x27;s home directory:; [Profiles]; path = /var/lib/samba/profiles; browseable = no; guest ok = yes# A publicly accessible directory that is read only, except for users in the# &quot;staff&quot; group (which have write permissions):; [public]; comment = Public Stuff; path = /home/samba; public = yes; writable = no; printable = no定义允许哪些smb用户写入，+和@表示一个组; write list = +staff 四、samba文件共享案例拓扑图 环境：两台安装CentOS8的主机，关闭selinux，关闭防火墙 **案例需求:** 1)、新建文件夹/common 2)、在server上配置SMB服务 3)、您的 SMB 服务器必须是 workgroup 工作组的一个成员 4)、共享 /common 目录 共享名必须为 common 5 image20200306155842923.png、只有 192.168.11.0网段内的客户端可以访问 common 共享 6）、common 必须是可以浏览的 7）、用户hello 必须能够读取共享中的内容，如果需要的话，验证的密码是 hello 8）、用户 test 必须能够拥有写权限，如果需要的话，验证的密码是 test a、创建共享目录 1[root@node1 ~]# mkdir /common b、设置共享目录权限，因为默认权限是755除了管理员外，其他人只能读不能写，本实验中要求test能写，所以其他人加写权限。在samba中共享目录的权限除了看samba服务的设置之外，还要看系统的权限设置，系统针对于权限不一致的处理方式是取交集。所以各位在建立共享时一定要注意权限方面的问题 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@node1 ~]# chmod 757 /common[root@node1 ~]# cd /etc/samba/[root@node1 ~]# vim /etc/samba/smb.conf# read the smb.conf manpage.# Run &#x27;testparm&#x27; to verify the config is correct after# you modified it.[global] #设置工作组为workgroup workgroup = workgroup security = user passdb backend = tdbsam printing = cups printcap name = cups load printers = yes cups options = raw[homes] comment = Home Directories valid users = %S, %D%w%S browseable = no read only = no inherit acls = yes[printers] comment = All Printers path = /var/tmp printable = yes create mask = 0600 browseable = no#共享设置，参考配置文件详解理解以下选项[common] comment = samba file share test path = /common\t#绝对路径 browseable = yes hosts allow = 192.168.11.0/255.255.255.0 valid users = hello,test writable = no write list = test public = no c、重启服务生效 1[root@node1 ~] systemctl restart smb nmb d、创建samba用户使用useradd命令创建hello和test用户并设置密码 123456[root@node1 ~]# smbpasswd -a helloNew SMB password:Retype new SMB password:[root@node1 ~]# smbpasswd -a testNew SMB password:Retype new SMB password: 共享指令拓展 1234567891011121314151617valid users 指定能够进入此资源的特定用户和组invalid users 指定不能够使用该共享资源的用户和组read list 指定只能读取该共享资源的用户和组。 write list 指定能读取和写该共享资源的用户和组。 admin list 指定能管理该共享资源（包括读写和权限赋予等）的用户和组。 public 指明该共享资源是否能给游客帐号访问，这个开关有时候也叫guest ok，所以有的配置文件中出现guest ok = yes其实和public = yes是一样的。 hide dot files 指明是不是像unix那样隐藏以“.”号开头的文件。 create mask 指明新建立的文件的属性，一般是0755。 directory mode 指明新建立的目录的属性，一般是0755。 sync always 指明对该共享资源进行写操作后是否进行同步操作。 preserve case 指明保持大小写。yes/no case sensitive 指明是否对大小写敏感，一般选no,不然可能引起错误。 default case 指明缺省的文件名是全部大写还是小写。upper/lower force user 强制把建立文件的属主是谁。如果我有一个目录，让来宾用户可以写，那么来宾用户就可以删除，如果我用 force user=王老师 强制建立文件的属主是 王老师 ，同时限制create mask=0755，这样来宾用户就不能删除了wide links 指明是否允许共享外符号连接，比如共享资源里面有个连接指向非共享资源里面的文件或者目录，如果设置wide links = no将使该连接不可用。 max connections = n 设定同时连接数是n。 delete readonly 指明能否删除共享资源里面已经被定义为只读的文件 五、共享案例-客户端访问共享创建好了共享了，如果用户希望访问samba共享，windows用户通过网上邻居或者在运行中输出[\\IP\\共享名]的方式访问samba共享，也可以通过网络映射的方式将共享挂载的本地。linux或者UNIX用户则可以使用samba提供的客户端smbclient或者通过CIFS协议将共享挂载到本地。 smbclient 客户端命令 123456smbclient - 类似FTP操作方式的访问SMB/CIFS服务器资源的客户端常用命令选项-L 此选项允许你查看服务器上可以获得的服务资源-U|--user=username[%password] 这个参数指定程序联接时使用的用户名或者用户名和密码，如果没指定%password，将提示用户输入。-W|--workgroup=domain 设置用户名的SMB域。这个选项越过了smb.conf配置文件中的默认域。-N 如果指定了这个选项，就会省略通常的口令提示。当访问无需口令的服务资源时它很有用。 任务需求linux下访问samba共享 a、客户端信息 123456789[root@slave ~]# ifconfig ens33ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.11.116 netmask 255.255.255.0 broadcast 192.168.11.255 inet6 fe80::20c:29ff:fe8e:ea58 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:8e:ea:58 txqueuelen 1000 (Ethernet) RX packets 5166 bytes 3736352 (3.5 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 2311 bytes 297960 (290.9 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 b、使用smbclient访问共享，验证第四点教学案例设置 1234567891011121314151617181920212223测试用户 hello[root@manage01 ~]# smbclient //192.168.11.16/common -U helloEnter SAMBA\\hello&#x27;s password: 或[root@manage01 ~]# smbclient //192.168.11.16/common -U hello%helloTry &quot;help&quot; to get a list of possible commands.smb: \\&gt; lssmb: \\&gt; lcd /etc/smb: \\&gt; put passwd 写入失败NT_STATUS_ACCESS_DENIED opening remote file \\passwd 测试用户test[root@manage01 ~]# smbclient //192.168.11.16/common -U test%test Try &quot;help&quot; to get a list of possible commands.smb: \\&gt; lcd /etc/smb: \\&gt; put passwdputting file passwd as \\passwd (728.2 kb/s) (average 728.2 kb/s) 可以上传smb: \\&gt; exitsamba命令类似于ftp文本界面命令，参考之前的vsftp使用。 c、linux挂载共享 123456789[root@manage01 ~]# mkdir /opt/samba_share[root@manage01 ~]# mount -o username=hello,password=hello -t cifs //192.168.11.16/common /opt/samba_share[root@manage01 ~]# cd /opt/samba_share/[root@manage01 ~]# mount......//192.168.11.16/common on /opt/samba_share type cifs (rw,relatime,vers=default,cache=strict,username=hello,domain=,uid=0,noforceuid,gid=0,noforcegid,addr=192.168.11.16,file_mode=0755,dir_mode=0755,soft,nounix,serverino,mapposix,rsize=1048576,wsize=1048576,echo_interval=60,actimeo=1)[root@manage01 ~]# ls /mnt/samba_share/initial-setup-ks.cfg passwd d、windows访问共享 打开开始菜单如下输入 image20200306180124957.png 回车以后出现下图，输入账号密码 image20200306180151262.png 点击确定按钮 image20200306180244476.png 六、用户账号映射与访问控制账号映射 samba的用户帐号信息是保存在smbpasswd文件中，而 且可以访问samba服务器的帐号也必须对应一个同名的系 统帐号。基于这一点，所以，对于一些hacker来说，只要 知道samba服务器samba帐号，就等于是知道了Linux系 统帐号，只要crack其samba帐号密码加以利用就可以攻 击samba服务器。所以我们要使用用户帐号映射这个功能 来解决这个问题 用户帐号映射这个功能需要建立一个帐号映射关系表，里 面记录了samba帐号和虚拟帐号的对应关系，客户端访问 samba服务器时就使用虚拟来登录。 编辑主配置文件&#x2F;etc&#x2F;samba&#x2F;smb.conf在global下添加一行字段username map &#x3D; &#x2F;etc&#x2F;samba&#x2F;smbusers 开启用户帐号映射功能。 image20200306183028366.png 编辑&#x2F;etc&#x2F;samba&#x2F;smbusers smbusers文件保存帐号映射关系，其有固 定格式: samba帐号 &#x3D; 虚拟帐号(映射帐号) image20200306183052382.png 重新启动服务 访问控制 对于samba服务器的安全性，我们已经说过可以使用valid users字段去实现用户访问控制，但是如果企业庞大，存在大量用户的话，这种方法操作起来就显得比较麻烦比如samba服务器共享出一个目录来访问，但是要禁止某个IP子网或某个域的客户端访问此资源，这样情况使用valid users字段就无法实现客户端访问控制。使用hosts allow和hosts deny两个字段来实现该功能。而用好这两个字段关键在于熟悉和清楚它们的使用方法和作用范围 1）hosts allow 和 hosts deny 字段的使用 123hosts allow 字段定义允许访问的客户端 hosts deny 字段定义禁止访问的客户端 2）使用IP地址进行限制 比如公司内部samba服务器上共享了一个目录sales，这个目录是存放销售部的共享目录，公司规定192.168.0.0&#x2F;24这个网段的IP地址禁止访问此sales共享目录，但是其中192.168.0.24这个IP地址可以访问。 12345hosts deny = 192.168.0. 172.16.hosts allow = 192.168.0.24hosts deny = 192.168.0. 表示禁止所有来自192.168.0.0/24网段的IP地址访问 hosts allow = 192.168.0.24 表示允许192.168.0.24这个IP地址访问 当host deny和hosts allow字段同时出现并定义内容相互冲突时，hosts allow优先。现在设置的意思就是禁止C类地址192.168.0.0/24网段主机访问，但是允许192.168.0.24主机访问。如果后面的内容有多个时，需要用空格隔开，也可以是域名，如：.hello.com 如果我们规定所有人不能访问security目录，只允许192.168.0.0网段的IP地址可以访问，但是192.168.0.10及192.168.0.78的主机是要禁止访问。我们可以使用hosts deny禁止所有用户访问，再设置hosts allow允许192.168.0.0网段主机，但当hosts deny和hosts allow同时出现而且冲突的时候，hosts allow生效，如果这样，那么允许192.168.0.0网段的IP地址可以访问，但192.168.0.100及192.168.0.78的主机禁止访问就无法生效了 123hosts allow = 192.168.0. EXCEPT 192.168.0.100 192.168.0.78 表示允许192.168.0.0网段IP地址访问，但是192.168.0.100和192.168.0.78除外 七、SAMBA的排错Linux 服务一般排错方法1、错误信息 一般仔细看下显示的错误信息，根据错误提示一般就可以判断问题出在 什么地方。 2、配置文件 第2个我们可以查配置文件，有时可能误操作导致配置失误，服务无法正 常运行，我们可以通过检查配置文件来确认问题。现在很多服务的软件 包有自带配置文件检查工具，我们可以通过这些工具对配置文件进行检 查 3、日志文件如果服务出现问题，我们还可以使用 tail -f命令来动态监控日志文件 Samba排错 1、使用testparm命令检查，软件包有自带的配置文件检查工具，我们可以使testparm 命令检测smb.conf文件的语法，如果报错，说明smb.conf文 件设置有错误，这样我们可以根据提示信息来修改主配置文 件和独立配置文件。 12345678[root@node1 ~]# testparm /etc/samba/smb.confLoad smb config files from /etc/samba/smb.confrlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384)Processing section &quot;[homes]&quot;Processing section &quot;[printers]&quot;Processing section &quot;[common]&quot;Loaded services file OK.Server role: ROLE_STANDALONE 2、使用ping命令测试 samba服务器主配置文件排除错误后重启 smb服务，如果客户端仍然 无法连 接samba服务器，我们在客户端可以使用 ping命令进行测试,这个我们微软的系统中排障一样，根据出现的不同情况可以进行分析。 (1)如果没有收到任何提示，说明客户端 TCP&#x2F;IP协议安装有问题，需要重 新安装客户端 TCP&#x2F;IP 协议，然后重新测试。 (2)如果提示“host not found ”则检查客户端DNS或者&#x2F;etc&#x2F;hosts文件有没正确设置，确保客户端能够使用名称访问 samba服务器。 (3)无法 ping 通还可能是防火墙设置问题，需要重新设置防火墙的 规则，开启samba 与外界联系的端口。(4)当然还有一种低级的情况，那就是由于主机名输入错误导致不 能ping 通 3、使用smbclient命令进行测试 如果客户端与samba服务器可以ping通，说明客户端与服务器间的连接没有问题，如果还是不能访问samba共享资源，可以执行smbclient命令进一步测试服务器端的配置。 如果测试samba服务器正常，并且输入了正确的帐号和密码，那么执行smbclient命令就可以获得共享列表。 1smbclient -L 192.168.0.188 -U joy%123 如果我们看到了错误信息提示“tree connect failed”则说明可以在smb.conf文件中设置了host deny字段拒绝了客户端的IP地址或域 名，我们可以修改smb.conf配置文件允许客户端访问就可以了 如果返回信息是“connection refused ”提示拒绝连接则说明是samba服务器smbd进程可以没有被开启，我们必须确保smbd和 nmbd进程处于开启状态，并使用netstat命令检查netbios所使用的139端口是否处于监听状态。 如果提示“session setup failed ”连接建立失败则说明服务器拒绝了连接请求，这是因为输入的用户名和密码错误引起 有时也会收到比如“Your server software is being unfriendly ”错误信息，提示服务器软 件存在问题，这个故障一般是因为配置 smbd时使用了错误的参数或者启用 smbd时 遇到的类似严重破坏错误，我们可以使用 testparm来检查相应的配置文件并同时检查 相关日志文件。","categories":["Linux","数据安全之企业存储"]},{"title":"NFS文件服务器","path":"/2023/09/27/数据安全之企业存储/NFS文件服务器/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314一、NFS介绍NFS就是Network File System的缩写，最早由Sun公司所发展出来的.最大的功能就是可以通过网络，让不同的主机能共享文件。在NFS的应用中，本地NFS的客户端应用可以透明地读写位于远端NFS服务器上的文件，就像访问本地文件一样。NFS优势：可以把服务器上的文件像本地一样的操作，节省本地的存储空间nfs配置简单，而且服务本身对系统资源占用较少nfs服务可以支持很多其它的服务，如kickstart，配合在一起，可以实现更多功能应用场景共享存储服务器： 图片服务器、视频服务器等家目录漫游：域用户家目录服务器文件服务器：内容文件存储服务器工作原理NFS体系有两个主要部分：NFS服务端机器：通过NFS协议将文件共享到网络。NFS客户端机器：通过网络挂载NFS共享目录到本地。NFS服务器与客户端在进行数据传输时，需要先确定端口，而这个端口的确定需要借助RPC(Remote Procedure Call,远程过程调用)协议的协助。RPC最主要的功能就是在指定每个NFS服务所对应的端口号，并且告知客户端，让客户端可以连接到正确的端口上去。当我们启动NFS服务时会随机取用数个端口，并主动向RPC注册，因此RPC可以知道每个端口对应的NFS，而RPC又是固定使用 port 111监听客户端的需求并且能够准确的告知客户端正确的端口。image20200307151530148.png1.客户端向服务器的111端口发送nfs请求2.RPC找到对应的nfs端口并告知客户端3.客户端知道正确的端口后，直接与nfs server端建立连接二、安装部署[root@zutuanxue ~]# rpm -qa | grep nfs-utilsnfs-utils-2.3.3-14.el8.x86_64#管理用户登录及文件权限[root@zutuanxue ~]# rpm -qa | grep rpcbindrpcbind-1.2.5-3.el8.x86_64#管理端口[root@zutuanxue ~]# systemctl is-enabled rpcbindenabled#检查rpcbind服务的状态[root@zutuanxue ~]# systemctl enable nfs-server.service Created symlink /etc/systemd/system/multi-user.target.wants/nfs-server.service → /usr/lib/systemd/system/nfs-server.service. [root@zutuanxue ~]# systemctl start nfs-server.service #设置开机启动，并启动nfs服务相关文件/etc/exports： 共享配置文件，用来设置共享/etc/nfs.conf： nfs服务的配置文件，可以设置端口和超时时间等，大多数时候不需要修改/etc/sysconfig/nfs： 端口设置文件，重启服务后系统会自动调整nfs.conf内容/var/lib/nfs/etab: 记录nfs共享的完整权限设定值三、配置说明/etc/exports格式：共享目录 客户端(权限1，权限2）共享目录：在本地的位置（绝对路径）客户端：一台主机，一群主机（IP地址、网段、主机名、域名）权限：ro 只读访问（默认） rw 读写访问 sync 将数据同步写入内存缓冲区与磁盘中，效率低，但可以保证数据的一致性；（默认） async 将数据先保存在内存缓冲区中，必要时才写入磁盘；secure 客户端只能使用小于1024的端口连接（默认） insecure 允许客户端使用大于1024的端口连接 wdelay 检查是否有相关的写操作，如果有则将这些写操作一起执行，这样可以提高效率（默认）；no_wdelay 若有写操作则立即执行，应与sync配合使用；hide 在NFS共享目录中不共享其子目录（默认） no_hide 共享NFS目录的子目录 subtree_check 如果共享目录是子目录时，强制NFS检查父目录的权限（默认） no_subtree_check 和上面相对，不检查父目录权限 all_squash 共享文件的UID和GID映射匿名用户anonymous，适合公用目录。 no_all_squash 保留共享文件的UID和GID（默认） root_squash root用户的所有请求映射成如anonymous用户一样的权限（默认） no_root_squash root用户具有根目录的完全管理访问权限 anonuid=xxx 指定NFS服务器/etc/passwd文件中匿名用户的UID anongid=xxx 指定NFS服务器/etc/passwd文件中匿名用户的GID相关命令exportfs - 管理NFS共享文件系统列表\t-a 发布获取消所有目录共享。\t-r 重新挂载/etc/exports里面的共享目录,同时更新/etc/exports 和/var/lib/nfs/xtab的内容\t-u 取消一个或多个目录的共享。\t-v 输出详细信息。\t-o options,...\t指定一系列共享选项(如rw,async,root_squash)\t-i 忽略/etc/exports和/etc/exports.d目录下文件。此时只有命令行中给定选项和默认选项会生效。例如：#exportfs -rv //重新挂载共享目录，并且显示。#exportfs -au\t//卸载所有共享目录。showmount\t可以在server/client上使用此命令来查看server#showmount\t[-ae]\thostname/ip-a或--all 以 host:dir 这样的格式来显示客户主机名和挂载点目录。-d或--directories 仅显示被客户挂载的目录名。-e或--exports[root@zutuanxue ~]# showmount -eExport list for manage01:/opt *四、NFS共享案例案例需求新建目录/ro，/rw以只读的方式共享目录 /ro 同时只能被 192.168.98.0 域中的系统访问以读写的方式共享目录 /rw 能被 192.168.98.0 域中的系统访问实验环境两台安装了CentOS8的主机，关闭selinux，关闭防火墙zutuanxue: NFS servernode1: NFS clientimage20200307195109955.png创建共享目录[root@zutuanxue ~]# mkdir /ro[root@zutuanxue ~]# mkdir /rw由于客户端挂载用户是nfsnobody，本题要求客户端挂载后可读写，我们是用root用户建立的目录，所以要给其他人7的权限[root@zutuanxue ~]# chmod 757 /rw/ 通过/etc/exports文件定义共享目录[root@zutuanxue ~]# cat /etc/exports/ro 192.168.98.0/24(ro)/rw 192.168.98.0/24(rw)启动nfs服务[root@zutuanxue ~]# systemctl restart nfs-server.service [root@zutuanxue opt]# ps aux | egrep &quot;rpc|nfs&quot;rpc.nfsd（nfsd）：基本的NFS守护进程（2049端口），主要负责登录权限检测。rpc.mountd（mountd）：负责管理NFS的文件系统，对客户端存取服务器的文件进行一系列的管理。rpc.rquotad（rquotad）：提供远程磁盘限额服务。rpc.lockd（nlockmgr）：用于管理文件的锁定，防止多个客户端同时写入某个文件时产生的冲突。rpc.statd（staus）：用来检查共享目录的一致性如果服务之前已经启动可以重新加载所有共享[root@zutuanxue ~]# exportfs -rvexporting 192.168.98.0/24:/rwexporting 192.168.98.0/24:/ro查看共享目录[root@zutuanxue ~]# exportfs -v/ro 192.168.98.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,ro,secure,root_squash,no_all_squash)/rw 192.168.98.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,root_squash,no_all_squash)五、客户端访问使用showmount命令查看远程nfs服务器共享目录[root@node1 ~]# showmount -e 192.168.98.200Export list for 192.168.98.200:/protected 192.168.98.0/24/public 192.168.98.0/24新建挂载点[root@node1 ~]# mkdir /mnt/ro[root@node1 ~]# mkdir /mnt/rw挂载NFS服务器共享目录[root@node1 ~]# mount -t nfs 192.168.98.200:/ro /mnt/ro/[root@node1 ~]# mount -t nfs 192.168.98.200:/rw /mnt/rw/验证挂载[root@node1 ~]# mount | grep mnt测试权限[root@node1 ~]# touch /mnt/ro/testtouch: 无法创建&quot;/mnt/public/test&quot;: 只读文件系统[root@node1 ~]# touch /mnt/rw/test[root@node1 ~]# ls /mnt/rw/ -l总用量 0-rw-r--r-- 1 nfsnobody nfsnobody 0 2月 28 11:52 test如果需要开机挂载的话可以修改/etc/fstab192.168.98.200:/ro /mnt/ro nfs defaults 0 0192.168.98.200:/rw /mnt/rw nfs defaults 0 0温馨提示：还可以使用前面课程提到过的autofs实现自动挂载六、nfs固定端口nfs工作需要的端口除了2049和111之外还有额外的端口，而这些端口都是随机的，所以在有安全防护的时候，为了保证NFS可以正常工作就需要将这些随机的端口固定我们可以使用rpcinfo命令来查看nfs的端口[root@zutuanxue ~]# rpcinfo -p program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper 100000 4 udp 111 portmapper 100000 3 udp 111 portmapper 100000 2 udp 111 portmapper 100024 1 udp 37242 status 100024 1 tcp 39231 status 100005 1 udp 20048 mountd 100005 1 tcp 20048 mountd 100005 2 udp 20048 mountd 100005 2 tcp 20048 mountd 100005 3 udp 20048 mountd 100005 3 tcp 20048 mountd 100003 3 tcp 2049 nfs 100003 4 tcp 2049 nfs 100227 3 tcp 2049 nfs_acl 100021 1 udp 41958 nlockmgr 100021 3 udp 41958 nlockmgr 100021 4 udp 41958 nlockmgr 100021 1 tcp 35847 nlockmgr 100021 3 tcp 35847 nlockmgr 100021 4 tcp 35847 nlockmgr重启nfs服务[root@zutuanxue ~]# systemctl restart nfs-server.service 再次查看端口[root@zutuanxue ~]# rpcinfo -p program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper 100000 4 udp 111 portmapper 100000 3 udp 111 portmapper 100000 2 udp 111 portmapper 100024 1 udp 37242 status 100024 1 tcp 39231 status 100005 1 udp 20048 mountd 100005 1 tcp 20048 mountd 100005 2 udp 20048 mountd 100005 2 tcp 20048 mountd 100005 3 udp 20048 mountd 100005 3 tcp 20048 mountd 100003 3 tcp 2049 nfs 100003 4 tcp 2049 nfs 100227 3 tcp 2049 nfs_acl 100021 1 udp 45032 nlockmgr 100021 3 udp 45032 nlockmgr 100021 4 udp 45032 nlockmgr 100021 1 tcp 36303 nlockmgr 100021 3 tcp 36303 nlockmgr 100021 4 tcp 36303 nlockmgr你会发现除了2049和111之外的端口都是在随机变化的，而这些随机变化的端口会在我们进行安全设置的时候带来困扰，所以我们需要讲端口固定[root@zutuanxue ~]# vim /etc/sysconfig/nfsMOUNTD_PORT=10001　#　rpc.mountd使用的端口STATD_PORT=10002\t# rpc.statd使用的端口LOCKD_TCPPORT=10003\t# nlockmgr使用的TCP端口（rpc.lockd）LOCKD_UDPPORT=10003\t# nlockmgr使用的UDP端口RQUOTAD_PORT=10004\t#\trpc.rquotad使用的端口重新启动服务[root@zutuanxue ~]# systemctl restart nfs-server.service nfs-convert.service [root@zutuanxue ~]# rpcinfo -p program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper 100000 4 udp 111 portmapper 100000 3 udp 111 portmapper 100000 2 udp 111 portmapper 100005 1 udp 10001 mountd 100005 1 tcp 10001 mountd 100005 2 udp 10001 mountd 100005 2 tcp 10001 mountd 100005 3 udp 10001 mountd 100005 3 tcp 10001 mountd 100024 1 udp 10002 status 100024 1 tcp 10002 status 100003 3 tcp 2049 nfs 100003 4 tcp 2049 nfs 100227 3 tcp 2049 nfs_acl 100021 1 udp 10003 nlockmgr 100021 3 udp 10003 nlockmgr 100021 4 udp 10003 nlockmgr 100021 1 tcp 10003 nlockmgr 100021 3 tcp 10003 nlockmgr 100021 4 tcp 10003 nlockmgr注意：如果之前没有启动过nfs服务的话，直接启动就可以，如果之前启动过nfs服务，需要同时重启nfs-convert服务，将我们刚才调整的设置写入到nfs.conf配置文件中，启动完成之后我们之前设置的/etc/sysconfig/nfs文件的名称会改为nfs.rpmsavexxxxxxxxxx27 1[root@zutuanxue ~]# systemctl restart nfs-server.service nfs-convert.service 2[root@zutuanxue ~]# rpcinfo -p3 program vers proto port service4 100000 4 tcp 111 portmapper5 100000 3 tcp 111 portmapper6 100000 2 tcp 111 portmapper7 100000 4 udp 111 portmapper8 100000 3 udp 111 portmapper9 100000 2 udp 111 portmapper10 100005 1 udp 10001 mountd11 100005 1 tcp 10001 mountd12 100005 2 udp 10001 mountd13 100005 2 tcp 10001 mountd14 100005 3 udp 10001 mountd15 100005 3 tcp 10001 mountd16 100024 1 udp 10002 status17 100024 1 tcp 10002 status18 100003 3 tcp 2049 nfs19 100003 4 tcp 2049 nfs20 100227 3 tcp 2049 nfs_acl21 100021 1 udp 10003 nlockmgr22 100021 3 udp 10003 nlockmgr23 100021 4 udp 10003 nlockmgr24 100021 1 tcp 10003 nlockmgr25 100021 3 tcp 10003 nlockmgr26 100021 4 tcp 10003 nlockmgr27注意：如果之前没有启动过nfs服务的话，直接启动就可以，如果之前启动过nfs服务，需要同时重启nfs-convert服务，将我们刚才调整的设置写入到nfs.conf配置文件中，启动完成之后我们之前设置的/etc/sysconfig/nfs文件的名称会改为nfs.rpmsave","categories":["Linux","数据安全之企业存储"]},{"title":"分布式存储-GlusterFS","path":"/2023/09/27/数据安全之企业存储/分布式存储-GlusterFS/","content":"一、分布式存储介绍我们知道NAS是远程通过网络共享目录, SAN是远程通过网络共享块设备。那么分布式存储你可以看作拥有多台存储服务器连接起来的存储输出端。把这多台存储服务器的存储合起来做成一个整体再通过网络进行远程共享,共享的方式有目录(文件存储),块设备(块存储),对象网关或者说一个程序接口(对象存储)。 常见的分布式存储开源软件有:GlusterFS,Ceph,HDFS,MooseFS,FastDFS等。 分布式存储一般都有以下几个优点: 扩容方便，轻松达到PB级别或以上 提升读写性能或数据高可用 避免单个节点故障导致整个架构问题 价格相对便宜，大量的廉价设备就可以组成，比光纤SAN这种便宜很多 二、GlusterFS介绍glusterfs是一个免费,开源的分布式文件系统（它属于文件存储类型）。主要由 Z RESEARCH 公司负责开发。GlusterFS 具有强大的横向扩展能力，通过扩展能够支持数PB存储容量和处理数千客户端。GlusterFS 可以将物理分布的存储资源聚集在一起，使用单一全局命名空间来管理数据，可为各种不同的数据负载提供优异的性能。 GlusterFS 主要由存储服务器（Brick Server）、客户端以及 NFS&#x2F;Samba 存储网关组成。在GlusterFS 架构中没有元数据服务器组件，这是其最大的设计这点，对于提升整个系统的性能、可靠性和稳定性都有着决定性的意义。 GlusterFS 支持 TCP&#x2F;IP 和 高速网络互联。客户端可通过原生 GlusterFS 协议访问数据，其他没有运行 GlusterFS 客户端的终端可通过 NFS&#x2F;CIFS 标准协议通过存储网关访问数据。存储服务器主要提供基本的数据存储功能，客户端弥补了没有元数据服务器的问题，承担了更多的功能，包括数据卷管理、I&#x2F;O 调度、文件定位、数据缓存等功能，利用 FUSE（File system in User Space）模块将 GlusterFS 挂载到本地文件系统之上，来访问系统数据。 三、raid级别回顾raid级别有很多种，下面主要介绍常用的几种: raid0 读写性能佳，坏了其中一块，数据挂掉，可靠性低（stripe条带化），磁盘利用率100％ **raid1** 镜像备份（mirror raid0.png，同一份数据完整的保存在多个磁盘上，写的性能不佳，可靠性高，读的性能还行，磁盘利用率50% raid1.png raid10 先做raid 1 再做raid 0 raid10.png raid5 由多块磁盘做raid 5，磁盘利用率为n-1&#x2F;n, 其中一块放校验数据，允许坏一块盘，数据可以利用校验值来恢复 raid5.png raid6 在raid5的基础上再加一块校验盘，进一步提高数据可靠性 raid6.png 1注意：生产环境中最常用的为raid5和raid10 GlusterFS名词解释 Brick: 最基本的存储单元，表示为trusted storage pool中输出的目录，供客户端挂载用，一般表示方式为“主机名:目录名” Volume: 一个卷。在逻辑上由N个bricks组成. FUSE: Unix-like OS上的可动态加载的模块，允许用户不用修改内核即可创建自己的文件系统。 四、GlusterFS卷类型基本卷 distribute volume分布式卷 默认： image20200227101111403.png 说明：根据hash算法，将文件随机存储在一个的brick上，文件不能拆分。此时volume的容量是所有brick的和；方便扩展空间，但无冗余保护；由于使用本地文件系统进行存储（brick server 的本地文件系统），存取效率不高；受限于本地文件系统对单文件容量的限制，支持超大型文件系统有问题。 stripe volume 条带卷： image20200227101206255.png 说明：每个文件被分片数据块，然后以round robin的方式将每个chunk存储到1个brick，相当于raid0；比如，对于一个文件，奇数行存储在第一个brick上，偶数行存储在第二个brick。单一超大容量文件可被分片，不受brick server本地文件系统的限制；分布式读写性能较高，但分片随机读写可能会导致硬盘iops较高；无冗余，1个server节点故障会导致所有数据丢失。 replica volume 复制卷(类似Raid 1)： image20200227101247582.png 说明：每个文件同步复制镜像到多个brick，相当于文件级raid1，一个是存储一个是备份；读性能提升，写性能下降；提升数据可靠性，但磁盘利用率低；如果两台存储服务器不同，就会出现木桶效应 复合卷 distribute replica volume 分布式复制卷： image20200227121736499.png 说明：是分布式卷与复制卷的组合，兼具两者的功能，若干brick组成1个复制卷，另外若干brick组成其他复制卷；单个文件在复制卷内数据保持副本，不同文件在不同复制卷之间进行哈希分布 distribute stripe volume分布式条带卷： image20200227101726471.png 说明：分布式卷与条带卷的组合，兼具两者的功能，若干brick组成1个条带卷，另外若干brick组成其他条带卷；单个文件在条带卷内数据以条带的形式存储，不同文件在不同条带卷之间进行哈希分布； striped replicated volume条带镜像卷： image20200227125132180.png 说明：条带与复制卷的组合，兼具两者的功能，若干brick组成1个复制卷，另外若干brick组成其他复制卷；单个文件以条带的形式存储在2个或多个复制集（replicated sets ），复制集内文件分片以副本的形式保存； distribute stripe replica volume 混合卷： 三种基本卷的复合卷，分布式卷，条带与复制卷的组合，兼具三者的功能 dispersed volume： 分散式（冗余式），例如，数据保存在10个brick中，每个brick有1T，10个brick中有3个是作为冗余brick，作为数据校验，不做存储。此时volume只有7T，volume中允许有3个brick损坏 五、glusterfs集群目前为止stripe（条带）类型已经用的越来越少，我们以一个案例说明distribute（分布式），replica（复制），distribute replica（分布式复制），dispersed（冗余）四种常用的类型如何使用 学习案例案例需求: 部署一个glusterfs存储集群 集群部署: 案例步骤 部署集群 创建卷并启动 客户端连接挂载 实验拓扑图GfusterFS集群.png 计算机名称 IP地址 角色 manage01 192.168.98.200 client node1 192.168.98.201 storage_node node2 192.168.98.202 storage_node node3 192.168.98.203 storage_node node4 192.168.98.204 storage_node node5 192.168.98.205 storage_node 实验环境 CentOS8系统 关闭防火墙 关闭selinux 网络连通 时间同步 实验步骤时间同步 12345678910111213[root@manage01 ~]# vim /etc/chrony.confserver 192.168.98.200 iburstdriftfile /var/lib/chrony/driftmakestep 1.0 3rtcsyncallow 192.168.98.0/24local stratum 10leapsectz right/UTClogdir /var/log/chronybindaddress 192.168.98.200[root@manage01 ~]# systemctl restart chronyserver 192.168.98.200 iburst[root@node1 ~]# systemctl restart chronyd.service gluster集群部署 1、安装软件[ 安装软件、启动服务] 2、部署集群 存储端设置 a、所有存储机器,设置Yum源，安装gluster 12345678910111213141516171819202122232425262728293031323334#官方源地址https://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-rhel8.repo[root@node2 ~]#vim /etc/yum.repos.d/glusterfs.repo # Place this file in your /etc/yum.repos.d/ directory[glusterfs-rhel8]name=GlusterFS is a clustered file-system capable of scaling to several petabytes.baseurl=https://download.gluster.org/pub/gluster/glusterfs/7/LATEST/RHEL/el-$releasever/$basearch/enabled=1skip_if_unavailable=1gpgcheck=1gpgkey=https://download.gluster.org/pub/gluster/glusterfs/7/rsa.pub[glusterfs-noarch-rhel8]name=GlusterFS is a clustered file-system capable of scaling to several petabytes.baseurl=https://download.gluster.org/pub/gluster/glusterfs/7/LATEST/RHEL/el-$releasever/noarchenabled=1skip_if_unavailable=1gpgcheck=1gpgkey=https://download.gluster.org/pub/gluster/glusterfs/7/rsa.pub[glusterfs-source-rhel8]name=GlusterFS is a clustered file-system capable of scaling to several petabytes. - Sourcebaseurl=https://download.gluster.org/pub/gluster/glusterfs/7/LATEST/RHEL/el-$releasever/SRPMSenabled=0skip_if_unavailable=1gpgcheck=1gpgkey=https://download.gluster.org/pub/gluster/glusterfs/7/rsa.pub[root@node1 yum.repos.d]# vim /etc/yum.repos.d/CentOS-PowerTools.repo [PowerTools]name=CentOS-$releasever - PowerToolsmirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=PowerTools&amp;infra=$infra#baseurl=http://mirror.centos.org/$contentdir/$releasever/PowerTools/$basearch/os/gpgcheck=1enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial b、安装glusterfs软件包，并启动服务 123[root@node2 ~]# dnf install glusterfs-server[root@node2 ~]# systemctl enable glusterd[root@node2 ~]# systemctl start glusterd glusterfs集群组成 brick端：manager&#x2F;node client端：挂载存储业务机器 1234567891011121314151617181920212223242526272829303132333435[root@node2 ~]# gluster peer help#将node节点加入集群[root@node2 ~]# gluster peer probe node1peer probe: success. #从集群中删除node[root@node2 ~]# gluster peer detach node4All clients mounted through the peer which is getting detached need to be remounted using one of the other active peers in the trusted storage pool to ensure client gets notification on any changes done on the gluster configuration and if the same has been done do you want to proceed? (y/n) ypeer detach: success#查看集群信息[root@node2 ~]# gluster peer status[root@node2 ~]# gluster pool list[root@node2 ~]# gluster peer statusNumber of Peers: 2Hostname: node1Uuid: 809111f4-8a0e-40fb-af53-d2d8a56cd41eState: Peer in Cluster (Connected)Hostname: 192.168.98.203Uuid: 7396a19d-a2a7-4b27-86d3-12c89ac4df39State: Peer in Cluster (Connected)或者[root@node2 ~]# gluster pool listUUID Hostname State809111f4-8a0e-40fb-af53-d2d8a56cd41e\tnode1 Connected 7396a19d-a2a7-4b27-86d3-12c89ac4df39\t192.168.98.203\tConnected 0ace00a1-0612-4395-ac9b-f1516207ead1\tlocalhost Connected c、所有storage服务器建立连接，成为一个集群 12345678910111213141516171819202122232425264个storage服务器建立连接不用两两连接，只需要找其中1个,连接另外3个各一次就OK了##集群管理#将node节点加入集群[root@node2 ~]# gluster peer probe node1peer probe: success. [root@node2 ~]# gluster peer probe node4peer probe: success. [root@node2 ~]# gluster peer probe node3 --这里使用ip,主机名,主机名别名都可以然后在所有存储上都可以使用下面命令来验证检查[root@node2 ~]# gluster peer statusNumber of Peers: 3Hostname: node1Uuid: 809111f4-8a0e-40fb-af53-d2d8a56cd41eState: Peer in Cluster (Connected)Hostname: 192.168.98.203Uuid: 7396a19d-a2a7-4b27-86d3-12c89ac4df39State: Peer in Cluster (Connected)Hostname: node4Uuid: b2ea8b19-658c-40ec-84b4-6568c627eefdState: Peer in Cluster (Connected) 注意: 如果这一步建立连接有问题（一般问题会出现在网络连接,防火墙,selinux,主机名绑定等); 如果想重做这一步，可以使用gluster peer detach xxxxx [force] 来断开连接，重新做 存储收集 必须是一个文件夹 1）一块磁盘[分区 格式化 挂载到节点上的指定目录] 一个磁盘文件[分区 格式化 挂载到节点上的指定目录] 3）分区上的一个文件夹 d、所有storage服务器准备存储目录 1[root@node2 ~]# mkdir /opt/data&#123;1..5&#125; e、创建存储卷,创建存储卷(在任意一个storage服务器上做) 1234567glusterfs支持多种卷Distribut卷 分布卷Replica卷 复制卷Disperse卷 冗余卷注意：从6.0版本开始之前和Striped卷相关的卷类型就全部废弃了。https://docs.gluster.org/en/latest/Administrator%20Guide/Setting%20Up%20Volumes/ Replica卷 文件同步复制到多个brick上，文件级RAID 1，具有容错能力，写性能下降，读性能提升。缺点是磁盘利用率低。 12345678910111213141516171819202122232425#创建一个replica卷(raid1) 数据会在每个brick上存储一份#复制卷类似raid1 所有一般会选择两台来完成,文件保存两份，如果希望保存多个机器，可以用多台机器，这里用两台。[root@node2 ~]# gluster volume create gv1-replica replica 2 node&#123;1..2&#125;:/opt/data forcevolume create: gv1-replica: success: please start the volume to access datareplica 代表创建的是镜像卷 2 代表2个台机器 由于使用的是根分区 所以要加上强制 force#查看卷创建情况[root@node2 ~]# gluster volume info gv1-replica Volume Name: gv1-replicaType: ReplicateVolume ID: f93a83dc-9ed6-43fe-99e4-5346d5d1d702Status: CreatedSnapshot Count: 0Number of Bricks: 1 x 2 = 2Transport-type: tcpBricks:Brick1: node1:/opt/dataBrick2: node2:/opt/dataOptions Reconfigured:transport.address-family: inetnfs.disable: onperformance.client-io-threads: off Distribut卷—数据随机存储在某个brick 文件通过hash算法分布到所有brick server上，这种卷是glusterfs的基础和最大特点。优点是容量大，缺点是没冗余。 123456789101112131415161718192021222324#如果不指定创建卷的类型，则默认是Distribute卷，可以是多个机器。#分布卷数据随机存储在某个brick,一般是应用在不需要冗余的环境。[root@node2 ~]# gluster volume create gv2-distribute node&#123;1..3&#125;:/opt/data2 forcevolume create: gv2-distribute: success: please start the volume to access data#查看卷[root@node2 ~]# gluster volume info gv2-distribute Volume Name: gv2-distributeType: DistributeVolume ID: 079a2f5c-23ac-43f8-9f54-f6a454a53706Status: CreatedSnapshot Count: 0Number of Bricks: 3Transport-type: tcpBricks:Brick1: node1:/opt/data2Brick2: node2:/opt/data2Brick3: node3:/opt/data2Options Reconfigured:transport.address-family: inetnfs.disable: on Disperse 卷( 冗余卷) disperse卷是v3.6版本后发布的一种卷模式，类似于raid5&#x2F;6,分布式分散卷 disperse必须大于2,大于4才可以有一块redundancy盘 大于5块可有redundancy盘两块 文件分片存储在各个硬盘上，但有部分硬盘用于冗余用途，数量可以指定。比如一共10块硬盘，2块盘用于冗余，那么就可以承受同时损坏两块硬盘，总容量是8块盘。 优点是在冗余和性能之间取得平衡 123456789101112131415161718192021222324#创建卷(raid5 raid6) #建议不少于4个机器[root@node2 ~]# gluster volume create gv3-disperse disperse 4 node&#123;1..4&#125;:/opt/data3 forceThere isn&#x27;t an optimal redundancy value for this configuration. Do you want to create the volume with redundancy 1 ? (y/n) y 指定一个磁盘为校验磁盘volume create: gv3-disperse: success: please start the volume to access data#查看卷信息[root@node2 ~]# gluster volume info gv3-disperse Volume Name: gv3-disperseType: DisperseVolume ID: 754523b3-7e8e-4133-bb77-60c2247711d9Status: CreatedSnapshot Count: 0Number of Bricks: 1 x (3 + 1) = 4Transport-type: tcpBricks:Brick1: node1:/opt/data3Brick2: node2:/opt/data3Brick3: node3:/opt/data3Brick4: node4:/opt/data3Options Reconfigured:transport.address-family: inetnfs.disable: on distribute replica 分布复制卷 123456789101112131415161718192021222324#创建分布复制卷，机器为偶数#每两个分布卷组成一个复制卷,创建两个复制卷 [root@node2 ~]# gluster volume create gv2-distribute-replica replica 2 node&#123;1..4&#125;:/opt/data4 forcevolume create: gv2-distribute-replica: success: please start the volume to access data#查看磁盘信息[root@node2 ~]# gluster volume info gv2-distribute-replica Volume Name: gv2-distribute-replicaType: Distributed-ReplicateVolume ID: 90d70fef-54a9-4555-98ad-0d1a342f6763Status: CreatedSnapshot Count: 0Number of Bricks: 2 x 2 = 4Transport-type: tcpBricks:Brick1: node1:/opt/data4Brick2: node2:/opt/data4Brick3: node3:/opt/data4Brick4: node4:/opt/data4Options Reconfigured:transport.address-family: inetnfs.disable: onperformance.client-io-threads: off f、启动卷 gluster volume star 卷名称 12345678910111213141516#查看卷[root@node2 ~]# gluster volume listgv1-replicagv2-distributegv2-distribute-replicagv3-disperse#启动卷[root@node2 ~]# gluster volume start gv1-replicavolume start: gv1-replica: success[root@node2 ~]# gluster volume start gv2-distributevolume start: gv2-distribute: success[root@node2 ~]# gluster volume start gv2-distribute-replicavolume start: gv2-distribute-replica: success[root@node2 ~]# gluster volume start gv3-dispersevolume start: gv3-disperse: success 存储卷管理-卷的增删改查 12345678910111213141516171819202122232425262728293031323334353637383940#[root@node2 ~]# gluster volume help 打印帮助信息#卷的创建 gluster volume create[root@node2 ~]# gluster volume create &lt;NEW-VOLNAME&gt; [stripe &lt;COUNT&gt;] [replica &lt;COUNT&gt; [arbiter &lt;COUNT&gt;]] [disperse [&lt;COUNT&gt;]] [disperse-data &lt;COUNT&gt;] [redundancy &lt;COUNT&gt;] [transport &lt;tcp|rdma|tcp,rdma&gt;] &lt;NEW-BRICK&gt;... [force]&lt;NEW-VOLNAME&gt; 卷名[stripe &lt;COUNT&gt;] [replica &lt;COUNT&gt; [arbiter &lt;COUNT&gt;]] [disperse [&lt;COUNT&gt;]] [disperse-data &lt;COUNT&gt;] 卷类型\tstripe 条带\treplica 复制\t什么都不加 默认分布\tdisperse 冗余\tredundancy 校验磁盘\ttransport 传输方式 tcp rdma内存\tforce 强制，如果存储在根分区#卷删除[root@node2 ~]# gluster volume delete &lt;VOLNAME&gt;#卷查看[root@node2 ~]# gluster volume list #卷列表[root@node2 ~]# gluster volume info [&lt;VOLNAME&gt; | all] #卷详细信息[root@node2 ~]# gluster volume status [&lt;VOLNAME&gt; | all] #卷启动或关闭的状态信息#扩容卷[root@node2 ~]# gluster volume add-brick &lt;VOLNAME&gt; [&lt;stripe|replica&gt; &lt;COUNT&gt; [arbiter &lt;COUNT&gt;]] &lt;NEW-BRICK&gt; ... [force]#缩减卷[root@node2 ~]# gluster volume remove-brick #卷启动[root@node2 ~]# gluster volume start &lt;VOLNAME&gt;#卷关闭[root@node2 ~]# gluster volume stop &lt;VOLNAME&gt;#卷替换[root@node2 ~]# gluster volume replace-brick 客户端设置挂载分布式卷 客户端安装软件 12[root@manage01 ~]# dnf install glusterfs glusterfs-fuse -y#客户端在安装软件的时候注意版本，如果服务端与客户端使用的版本不一致，会导致挂载失败 客户端挂载，验证上述卷数据存储方式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#建立挂载点并挂载[root@manage01 ~]# mkdir /opt/gluster_disk&#123;1..4&#125;[root@manage01 ~]# mount -t glusterfs node1:/gv1-replica /opt/gluster_disk1/[root@manage01 ~]# mount -t glusterfs node1:/gv2-distribute /opt/gluster_disk2[root@manage01 ~]# mount -t glusterfs node1:/gv2-distribute-replica /opt/gluster_disk3[root@manage01 ~]# mount -t glusterfs node1:/gv3-disperse /opt/gluster_disk4#查看挂载[root@manage01 ~]# mount |grep &quot;gluster&quot;node1:/gv1-replica on /opt/gluster_disk1 type fuse.glusterfs (rw,relatime,user_id=0,group_id=0,default_permissions,allow_other,max_read=131072)node1:/gv2-distribute on /opt/gluster_disk2 type fuse.glusterfs (rw,relatime,user_id=0,group_id=0,default_permissions,allow_other,max_read=131072)node1:/gv2-distribute-replica on /opt/gluster_disk3 type fuse.glusterfs (rw,relatime,user_id=0,group_id=0,default_permissions,allow_other,max_read=131072)node1:/gv3-disperse on /opt/gluster_disk4 type fuse.glusterfs (rw,relatime,user_id=0,group_id=0,default_permissions,allow_other,max_read=131072)#分别存储数据[root@manage01 ~]# dd if=/dev/zero of=/opt/gluster_disk1/file bs=1M count=100记录了100+0 的读入记录了100+0 的写出104857600字节(105 MB)已复制，1.281 秒，81.9 MB/秒[root@manage01 ~]# dd if=/dev/zero of=/opt/gluster_disk2/file bs=1M count=100记录了100+0 的读入记录了100+0 的写出104857600字节(105 MB)已复制，0.974837 秒，108 MB/秒[root@manage01 ~]# dd if=/dev/zero of=/opt/gluster_disk3/file bs=1M count=100记录了100+0 的读入记录了100+0 的写出104857600字节(105 MB)已复制，1.53898 秒，68.1 MB/秒[root@manage01 ~]# dd if=/dev/zero of=/opt/gluster_disk4/file bs=1M count=100记录了100+0 的读入记录了100+0 的写出104857600字节(105 MB)已复制，1.80071 秒，58.2 MB/秒#验证#复制卷 数据每个节点都存储了一份[root@node1 ~]# ls /opt/data -lh总用量 100M-rw-r--r-- 2 root root 100M 7月 7 08:51 file[root@node2 ~]# ls /opt/data -lh总用量 100M-rw-r--r-- 2 root root 100M 7月 7 08:51 file#分布卷 数据存在了node1[root@node1 ~]# ls /opt/data2 -lh总用量 100M-rw-r--r-- 2 root root 100M 7月 7 08:51 file[root@node2 ~]# ls /opt/data2 -lh总用量 0[root@node3 ~]# ls /opt/data2 -lh总用量 0#冗余卷 发现数据平均分布在每个存储节点[root@node1 ~]# ls /opt/data3 -lh总用量 34M-rw-r--r-- 2 root root 34M 7月 7 08:52 file[root@node2 ~]# ls /opt/data3 -lh总用量 34M-rw-r--r-- 2 root root 34M 7月 7 08:52 file[root@node3 ~]# ls /opt/data3 -lh总用量 34M-rw-r--r-- 2 root root 34M 7月 7 08:52 file[root@node4 ~]# ls /opt/data3/ -lh总用量 34M-rw-r--r-- 2 root root 34M 7月 7 08:52 file#分布复制卷 发现数据存在了node3 node4 这对复制卷上，[root@node1 ~]# ls /opt/data4 -lh总用量 0[root@node2 ~]# ls /opt/data4 -lh总用量 0[root@node3 ~]# ls /opt/data4 -lh总用量 100M-rw-r--r-- 2 root root 100M 7月 7 08:51 file[root@node4 ~]# ls /opt/data4/ -lh总用量 100M-rw-r--r-- 2 root root 100M 7月 7 08:51 file 删除卷 删除卷中数据 客户端卸载 在任意一个节点执行删除 验证删除 实践练习 删除卷中数据 1[root@manage01 ~]# rm -rf /opt/gluster_disk1/* 客户端卸载 1[root@manage01 ~]# umount /opt/gluster_disk1/ 卷删除 12345#3.在任意一个节点删除[root@node1 ~]# gluster volume stop gv1-replica [root@node1 ~]# gluster volume delete gv1-replicaDeleting volume will erase all information about the volume. Do you want to continue? (y/n) yvolume delete: gv1-replica: failed: Volume vg0 does not exist 验证删除 12[root@node1 ~]# gluster volume info gv1-replicaVolume gv1-replica does not exist 在线裁减与在线扩容 在线裁减要看是哪一种模式的卷，比如stripe模式就不允许在线裁减。下面我以distributed卷来做裁减与扩容 在线扩容 12345678910111213141516171819202122232425262728293031323334353637383940#查看卷[root@node2 ~]# gluster volume info gv2-distribute Volume Name: gv2-distributeType: DistributeVolume ID: 079a2f5c-23ac-43f8-9f54-f6a454a53706Status: StartedSnapshot Count: 0Number of Bricks: 3Transport-type: tcpBricks:Brick1: node1:/opt/data2Brick2: node2:/opt/data2Brick3: node3:/opt/data2Options Reconfigured:transport.address-family: inetnfs.disable: on#扩容[root@node2 ~]# gluster volume add-brick gv2-distribute node4:/opt/data2 forcevolume add-brick: success#验证[root@node2 ~]# gluster volume info gv2-distribute Volume Name: gv2-distributeType: DistributeVolume ID: 079a2f5c-23ac-43f8-9f54-f6a454a53706Status: StartedSnapshot Count: 0Number of Bricks: 4Transport-type: tcpBricks:Brick1: node1:/opt/data2Brick2: node2:/opt/data2Brick3: node3:/opt/data2Brick4: node4:/opt/data2Options Reconfigured:transport.address-family: inetnfs.disable: on 在线裁减(注意要remove没有数据的brick) 12345678910111213141516171819202122232425262728#裁剪卷.[root@node2 ~]# gluster volume remove-brick gv2-distribute node4:/opt/data2 forceRemove-brick force will not migrate files from the removed bricks, so they will no longer be available on the volume.Do you want to continue? (y/n) yvolume remove-brick commit force: success#查看验证[root@node2 ~]# gluster volume info gv2-distribute Volume Name: gv2-distributeType: DistributeVolume ID: 079a2f5c-23ac-43f8-9f54-f6a454a53706Status: StartedSnapshot Count: 0Number of Bricks: 3Transport-type: tcpBricks:Brick1: node1:/opt/data2Brick2: node2:/opt/data2Brick3: node3:/opt/data2Options Reconfigured:performance.client-io-threads: ontransport.address-family: inetnfs.disable: on关于裁剪卷,线上几乎不会裁剪，基本上都是扩容，而且裁剪只能裁剪没有数据的，否则可能数据丢失。所以，有些卷是不支持裁剪的。 在线替换卷 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@node2 ~]# gluster volume listgv1-replicagv2-distributegv2-distribute-replicagv3-disperse[root@node2 ~]# gluster volume info gv1-replica #查看源信息 Volume Name: gv1-replicaType: ReplicateVolume ID: f93a83dc-9ed6-43fe-99e4-5346d5d1d702Status: StartedSnapshot Count: 0Number of Bricks: 1 x 2 = 2Transport-type: tcpBricks:Brick1: node1:/opt/dataBrick2: node2:/opt/dataOptions Reconfigured:transport.address-family: inetnfs.disable: onperformance.client-io-threads: off#卷替换[root@node2 ~]# gluster volume replace-brick gv1-replica node2:/opt/data node4:/opt/data commit forcevolume replace-brick: success: replace-brick commit force operation successful#验证替换[root@node2 ~]# gluster volume info gv1-replica Volume Name: gv1-replicaType: ReplicateVolume ID: f93a83dc-9ed6-43fe-99e4-5346d5d1d702Status: StartedSnapshot Count: 0Number of Bricks: 1 x 2 = 2Transport-type: tcpBricks:Brick1: node1:/opt/dataBrick2: node4:/opt/dataOptions Reconfigured:transport.address-family: inetnfs.disable: onperformance.client-io-threads: off 拓展:4个存储想扩容为5个存储怎么做? 123456789101112131415161718192021222324答案: 第5个存储服务器安装服务器软件包，启动服务，然后gluster peer probe storage5加入集群#加入集群[root@node2 ~]# gluster peer probe node5peer probe: success. [root@node2 ~]# gluster peer statusNumber of Peers: 4Hostname: node1Uuid: 809111f4-8a0e-40fb-af53-d2d8a56cd41eState: Peer in Cluster (Connected)Hostname: 192.168.98.203Uuid: 7396a19d-a2a7-4b27-86d3-12c89ac4df39State: Peer in Cluster (Connected)Hostname: node4Uuid: b2ea8b19-658c-40ec-84b4-6568c627eefdState: Peer in Cluster (Connected)Hostname: node5Uuid: 82f424cb-1c7d-4057-8f40-f236015f8940State: Peer in Cluster (Connected)","categories":["Linux","数据安全之企业存储"]},{"title":"DHCP配置","path":"/2023/09/26/Linux配置文件/dhcp/DHCP/","content":"1234567891011121314151617181920212223242526## DHCP Server Configuration file.# see /usr/share/doc/dhcp*/dhcpd.conf.example# see dhcpd.conf(5) man pageddns-update-style interim;ignore client-updates;authoritative;allow booting;allow bootp;allow unknown-clients;# A slightly different configuration for an internal subnet. subnet 192.168.100.0 netmask 255.255.255.0&#123; range 192.168.100.20 192.168.100.80; option domain-name-servers 192.168.100.2; option domain-name &quot;server1.example.com&quot;; option routers 192.168.100.1; option broadcast-address 192.168.100.255; default-lease-time 600; max-lease-time 7200; # PXE SERVER IP next-server 192.168.100.130; # DHCP server ip filename &quot;pxelinux.0&quot;; &#125;","categories":["Linux","DHCP"]},{"title":"MySQL数据库备份mysqldump","path":"/2023/09/25/Linux系统管理宝典/Linux-MySQL数据库备份mysqldump/","content":"@TOC 前言MySQL是一个广泛使用的开源关系型数据库管理系统，可用于存储和管理数据。为了保护数据，我们需要定期备份数据库，以便在数据丢失或损坏时可以恢复数据。在本文中，我将介绍如何使用mysqldump命令来备份MySQL数据库。 一、关于备份热备份和冷备份热备份是指在MySQL服务器运行时进行备份，这种备份方式不会中断MySQL服务器的正常运行。备份过程中，MySQL服务器仍然可以读写数据库。这种备份方式比较简单，适合数据量不是很大的情况。 冷备份是指在MySQL服务器停止运行时进行备份，这种备份方式需要将MySQL服务器停止运行一段时间，等待备份完成后再启动MySQL服务器。这种备份方式适合数据量较大的情况，因为备份时间较长，备份过程中MySQL服务器无法读写数据库。 一般来说，MySQL备份建议使用多种备份方式相结合，比如使用热备份进行备份，使用冷备份进行灾备。 MySQL备份种类 完全备份（Full Backup）：包含数据表、索引、触发器、存储过程、视图、数据文件等所有内容。 增量备份（Incremental Backup）：只包含最近一次完全备份之后修改过的数据，可以快速恢复最新的数据。 差异备份（Differential Backup）：与增量备份类似，只包含最近一次完全备份之后修改过的数据，但可以通过两个差异备份之间的差异进行恢复，更加高效。 压缩备份（Compressed Backup）：通过对数据进行压缩，减少备份文件的大小，便于存储和传输。 远程备份（Remote Backup）：通过网络传输数据到远程服务器，可以实现数据的分布式备份和恢复。 磁盘备份（Disk Backup）：将MySQL数据库文件和配置文件备份到磁盘上，可以实现快速恢复数据，但恢复速度相对较慢。 文件备份（File Backup）：将MySQL数据库文件和配置文件备份到文件中，可以通过网络传输到其他服务器进行恢复。 不同的备份种类适用于不同的场景，需要根据实际情况进行选择。 二、mysqldump使用步骤通常情况下， mysqldump 是 MySQL 内置的备份工具，可以用来备份和导出MySQL数据库。该工具通过生成一个包含数据库中所有表和表结构的SQL脚本文件，从而实现了数据备份和导出的功能。该脚本文件可以被用来还原MySQL数据库，或者在不同的MySQL服务器之间进行迁移。 常见参数mysqldump是MySQL的备份工具，可以将MySQL数据库的结构和数据备份到指定的文件中。使用mysqldump备份MySQL数据库非常方便，以下是一些常用的mysqldump命令和选项： mysqldump命令用于备份MySQL数据库，语法如下 1mysqldump [OPTIONS] DATABASE [TABLE [TABLE ...]] &gt; DUMPFILE 其中，DATABASE是要备份的数据库名，TABLE是要备份的表名，多个表名之间用空格分隔，–skip-opt选项可以忽略优化选项，–all-databases选项可以备份所有数据库。 常用选项： * b：备份二进制日志文件。 * h HOST：备份数据库所在主机的主机名或IP地址。 * u USERNAME：备份数据库所用的用户名。 * p PASSWORD：备份数据库所用的密码。 * r：将备份文件复制到指定的位置。 * t：只备份指定的数据表，而不备份数据表的其他信息，例如索引、触发器等。 * n：只备份表结构，而不备份表的数据。 备份完成后，可以使用mysql命令加上用户名和密码连接到备份的数据库，查看备份文件中包含的内容，例如： 1mysql -u USERNAME -p PASSWORD DATABASE 创建备份文件使用以下命令创建一个名为 backup.sql 的备份文件： 1mysqldump -u root -p your_database_name &gt; backup.sql 其中，root 是 MySQL 的超级用户，your\\_database\\_name 是要备份的数据库名称。\\&gt; backup.sql 是将备份文件写入 backup.sql 文件中。 执行备份命令如果你需要备份多个数据库或者多个表，可以在 mysqldump 命令中指定相应的选项。以下是备份多个数据库的命令示例： 1mysqldump -u root -p -B your_database_name1 your_database_name2 &gt; backup.sql 其中，\\-B 选项表示备份多个数据库。 检查备份文件备份完成后，可以在 backup.sql 文件中查看备份文件的内容。 恢复数据使用以下命令恢复备份文件中的数据： 1mysql -u root -p your_database_name &lt; backup.sql 其中，root 是 MySQL 的超级用户，your\\_database\\_name 是要恢复的数据库名称。&lt; backup.sql 是从备份文件中读取数据。 注意：在执行恢复命令前，一定要确保已经创建了相应的数据库和表。以上就是使用 mysqldump 进行数据备份和恢复的基本教程。 mysqldump –help123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355[root@mysql5_7 ~]# mysqldump --helpmysqldump Ver 10.13 Distrib 5.7.43, for Linux (x86_64)Copyright (c) 2000, 2023, Oracle and/or its affiliates.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Dumping structure and contents of MySQL databases and tables.Usage: mysqldump [OPTIONS] database [tables]OR mysqldump [OPTIONS] --databases [OPTIONS] DB1 [DB2 DB3...]OR mysqldump [OPTIONS] --all-databases [OPTIONS]Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnfThe following groups are read: mysqldump clientThe following options may be given as the first argument:--print-defaults Print the program argument list and exit.--no-defaults Don&#x27;t read default options from any option file, except for login file.--defaults-file=# Only read default options from the given file #.--defaults-extra-file=# Read this file after the global files are read.--defaults-group-suffix=# Also read groups with concat(group, suffix)--login-path=# Read this path from the login file. -A, --all-databases Dump all the databases. This will be same as --databases with all databases selected. -Y, --all-tablespaces Dump all the tablespaces. -y, --no-tablespaces Do not dump any tablespace information. --add-drop-database Add a DROP DATABASE before each create. --add-drop-table Add a DROP TABLE before each create. (Defaults to on; use --skip-add-drop-table to disable.) --add-drop-trigger Add a DROP TRIGGER before each create. --add-locks Add locks around INSERT statements. (Defaults to on; use --skip-add-locks to disable.) --allow-keywords Allow creation of column names that are keywords. --apply-slave-statements Adds &#x27;STOP SLAVE&#x27; prior to &#x27;CHANGE MASTER&#x27; and &#x27;START SLAVE&#x27; to bottom of dump. --bind-address=name IP address to bind to. --character-sets-dir=name Directory for character set files. -i, --comments Write additional information. (Defaults to on; use --skip-comments to disable.) --compatible=name Change the dump to be compatible with a given mode. By default tables are dumped in a format optimized for MySQL. Legal modes are: ansi, mysql323, mysql40, postgresql, oracle, mssql, db2, maxdb, no_key_options, no_table_options, no_field_options. One can use several modes separated by commas. Note: Requires MySQL server version 4.1.0 or higher. This option is ignored with earlier server versions. --compact Give less verbose output (useful for debugging). Disables structure comments and header/footer constructs. Enables options --skip-add-drop-table --skip-add-locks --skip-comments --skip-disable-keys --skip-set-charset. -c, --complete-insert Use complete insert statements. -C, --compress Use compression in server/client protocol. -a, --create-options Include all MySQL specific create options. (Defaults to on; use --skip-create-options to disable.) -B, --databases Dump several databases. Note the difference in usage; in this case no tables are given. All name arguments are regarded as database names. &#x27;USE db_name;&#x27; will be included in the output. -#, --debug[=#] This is a non-debug version. Catch this and exit. --debug-check This is a non-debug version. Catch this and exit. --debug-info This is a non-debug version. Catch this and exit. --default-character-set=name Set the default character set. --delete-master-logs Delete logs on master after backup. This automatically enables --master-data. -K, --disable-keys &#x27;/*!40000 ALTER TABLE tb_name DISABLE KEYS */; and &#x27;/*!40000 ALTER TABLE tb_name ENABLE KEYS */; will be put in the output. (Defaults to on; use --skip-disable-keys to disable.) --dump-slave[=#] This causes the binary log position and filename of the master to be appended to the dumped data output. Setting the value to 1, will printit as a CHANGE MASTER command in the dumped data output; if equal to 2, that command will be prefixed with a comment symbol. This option will turn --lock-all-tables on, unless --single-transaction is specified too (in which case a global read lock is only taken a short time at the beginning of the dump - don&#x27;t forget to read about --single-transaction below). In all cases any action on logs will happen at the exact moment of the dump.Option automatically turns --lock-tables off. -E, --events Dump events. -e, --extended-insert Use multiple-row INSERT syntax that include several VALUES lists. (Defaults to on; use --skip-extended-insert to disable.) --fields-terminated-by=name Fields in the output file are terminated by the given string. --fields-enclosed-by=name Fields in the output file are enclosed by the given character. --fields-optionally-enclosed-by=name Fields in the output file are optionally enclosed by the given character. --fields-escaped-by=name Fields in the output file are escaped by the given character. -F, --flush-logs Flush logs file in server before starting dump. Note that if you dump many databases at once (using the option --databases= or --all-databases), the logs will be flushed for each database dumped. The exception is when using --lock-all-tables or --master-data: in this case the logs will be flushed only once, corresponding to the moment all tables are locked. So if you want your dump and the log flush to happen at the same exact moment you should use --lock-all-tables or --master-data with --flush-logs. --flush-privileges Emit a FLUSH PRIVILEGES statement after dumping the mysql database. This option should be used any time the dump contains the mysql database and any other database that depends on the data in the mysql database for proper restore. -f, --force Continue even if we get an SQL error. -?, --help Display this help message and exit. --hex-blob Dump binary strings (BINARY, VARBINARY, BLOB) in hexadecimal format. -h, --host=name Connect to host. --ignore-error=name A comma-separated list of error numbers to be ignored if encountered during dump. --ignore-table=name Do not dump the specified table. To specify more than one table to ignore, use the directive multiple times, once for each table. Each table must be specified with both database and table names, e.g., --ignore-table=database.table. --include-master-host-port Adds &#x27;MASTER_HOST=&lt;host&gt;, MASTER_PORT=&lt;port&gt;&#x27; to &#x27;CHANGE MASTER TO..&#x27; in dump produced with --dump-slave. --insert-ignore Insert rows with INSERT IGNORE. --lines-terminated-by=name Lines in the output file are terminated by the given string. -x, --lock-all-tables Locks all tables across all databases. This is achieved by taking a global read lock for the duration of the whole dump. Automatically turns --single-transaction and --lock-tables off. -l, --lock-tables Lock all tables for read. (Defaults to on; use --skip-lock-tables to disable.) --log-error=name Append warnings and errors to given file. --master-data[=#] This causes the binary log position and filename to be appended to the output. If equal to 1, will print it as a CHANGE MASTER command; if equal to 2, that command will be prefixed with a comment symbol. This option will turn --lock-all-tables on, unless --single-transaction is specified too (in which case a global read lock is only taken a short time at the beginning of the dump; don&#x27;t forget to read about --single-transaction below). In all cases, any action on logs will happen at the exact moment of the dump. Option automatically turns --lock-tables off. --max-allowed-packet=# The maximum packet length to send to or receive from server. --net-buffer-length=# The buffer size for TCP/IP and socket communication. --no-autocommit Wrap tables with autocommit/commit statements. -n, --no-create-db Suppress the CREATE DATABASE ... IF EXISTS statement that normally is output for each dumped database if --all-databases or --databases is given. -t, --no-create-info Don&#x27;t write table creation info. -d, --no-data No row information. -N, --no-set-names Same as --skip-set-charset. --opt Same as --add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, and --disable-keys. Enabled by default, disable with --skip-opt. --order-by-primary Sorts each table&#x27;s rows by primary key, or first unique key, if such a key exists. Useful when dumping a MyISAM table to be loaded into an InnoDB table, but will make the dump itself take considerably longer. -p, --password[=name] Password to use when connecting to server. If password is not given it&#x27;s solicited on the tty. -P, --port=# Port number to use for connection. --protocol=name The protocol to use for connection (tcp, socket, pipe, memory). -q, --quick Don&#x27;t buffer query, dump directly to stdout. (Defaults to on; use --skip-quick to disable.) -Q, --quote-names Quote table and column names with backticks (`). (Defaults to on; use --skip-quote-names to disable.) --replace Use REPLACE INTO instead of INSERT INTO. -r, --result-file=name Direct output to a given file. This option should be used in systems (e.g., DOS, Windows) that use carriage-return linefeed pairs (\\r ) to separate text lines. This option ensures that only a single newline is used. -R, --routines Dump stored routines (functions and procedures). --set-charset Add &#x27;SET NAMES default_character_set&#x27; to the output. (Defaults to on; use --skip-set-charset to disable.) --set-gtid-purged[=name] Add &#x27;SET @@GLOBAL.GTID_PURGED&#x27; to the output. Possible values for this option are ON, OFF and AUTO. If ON is used and GTIDs are not enabled on the server, an error is generated. If OFF is used, this option does nothing. If AUTO is used and GTIDs are enabled on the server, &#x27;SET @@GLOBAL.GTID_PURGED&#x27; is added to the output. If GTIDs are disabled, AUTO does nothing. If no value is supplied then the default (AUTO) value will be considered. --single-transaction Creates a consistent snapshot by dumping all tables in a single transaction. Works ONLY for tables stored in storage engines which support multiversioning (currently only InnoDB does); the dump is NOT guaranteed to be consistent for other storage engines. While a --single-transaction dump is in process, to ensure a valid dump file (correct table contents and binary log position), no other connection should use the following statements: ALTER TABLE, DROP TABLE, RENAME TABLE, TRUNCATE TABLE, as consistent snapshot is not isolated from them. Option automatically turns off --lock-tables. --dump-date Put a dump date to the end of the output. (Defaults to on; use --skip-dump-date to disable.) --skip-mysql-schema Skip adding DROP DATABASE for mysql schema. --skip-opt Disable --opt. Disables --add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, and --disable-keys. -S, --socket=name The socket file to use for connection. --secure-auth Refuse client connecting to server if it uses old (pre-4.1.1) protocol. Deprecated. Always TRUE --ssl-mode=name SSL connection mode. --ssl Deprecated. Use --ssl-mode instead. (Defaults to on; use --skip-ssl to disable.) --ssl-verify-server-cert Deprecated. Use --ssl-mode=VERIFY_IDENTITY instead. --ssl-ca=name CA file in PEM format. --ssl-capath=name CA directory. --ssl-cert=name X509 cert in PEM format. --ssl-cipher=name SSL cipher to use. --ssl-key=name X509 key in PEM format. --ssl-crl=name Certificate revocation list. --ssl-crlpath=name Certificate revocation list path. --tls-version=name TLS version to use, permitted values are: TLSv1, TLSv1.1, TLSv1.2 --server-public-key-path=name File path to the server public RSA key in PEM format. --get-server-public-key Get server public key -T, --tab=name Create tab-separated textfile for each table to given path. (Create .sql and .txt files.) NOTE: This only works if mysqldump is run on the same machine as the mysqld server. --tables Overrides option --databases (-B). --triggers Dump triggers for each dumped table. (Defaults to on; use --skip-triggers to disable.) --tz-utc SET TIME_ZONE=&#x27;+00:00&#x27; at top of dump to allow dumping of TIMESTAMP data when a server has data in different time zones or data is being moved between servers with different time zones. (Defaults to on; use --skip-tz-utc to disable.) -u, --user=name User for login if not current user. -v, --verbose Print info about the various stages. -V, --version Output version information and exit. -w, --where=name Dump only selected records. Quotes are mandatory. -X, --xml Dump a database as well formed XML. --plugin-dir=name Directory for client-side plugins. --default-auth=name Default authentication client-side plugin to use. --enable-cleartext-plugin Enable/disable the clear text authentication plugin.Variables (--variable-name=value)and boolean options &#123;FALSE|TRUE&#125; Value (after reading options)--------------------------------- ----------------------------------------all-databases FALSEall-tablespaces FALSEno-tablespaces FALSEadd-drop-database FALSEadd-drop-table TRUEadd-drop-trigger FALSEadd-locks TRUEallow-keywords FALSEapply-slave-statements FALSEbind-address (No default value)character-sets-dir (No default value)comments TRUEcompatible (No default value)compact FALSEcomplete-insert FALSEcompress FALSEcreate-options TRUEdatabases FALSEdefault-character-set utf8delete-master-logs FALSEdisable-keys TRUEdump-slave 0events FALSEextended-insert TRUEfields-terminated-by (No default value)fields-enclosed-by (No default value)fields-optionally-enclosed-by (No default value)fields-escaped-by (No default value)flush-logs FALSEflush-privileges FALSEforce FALSEhex-blob FALSEhost (No default value)ignore-error (No default value)include-master-host-port FALSEinsert-ignore FALSElines-terminated-by (No default value)lock-all-tables FALSElock-tables TRUElog-error (No default value)master-data 0max-allowed-packet 25165824net-buffer-length 1046528no-autocommit FALSEno-create-db FALSEno-create-info FALSEno-data FALSEorder-by-primary FALSEport 0quick TRUEquote-names TRUEreplace FALSEroutines FALSEset-charset TRUEsingle-transaction FALSEdump-date TRUEskip-mysql-schema FALSEsocket (No default value)secure-auth TRUEssl TRUEssl-verify-server-cert FALSEssl-ca (No default value)ssl-capath (No default value)ssl-cert (No default value)ssl-cipher (No default value)ssl-key (No default value)ssl-crl (No default value)ssl-crlpath (No default value)tls-version (No default value)server-public-key-path (No default value)get-server-public-key FALSEtab (No default value)triggers TRUEtz-utc TRUEuser (No default value)verbose FALSEwhere (No default value)plugin-dir (No default value)default-auth (No default value)enable-cleartext-plugin FALSE 总结本文介绍了使用mysqldump命令备份MySQL数据库的方法和步骤。mysqldump是MySQL的备份工具，可以备份整个MySQL数据库或者单个表。备份种类包括完全备份、增量备份、差异备份、压缩备份、远程备份、磁盘备份和文件备份。文章详细介绍了安装mysqldump、创建备份文件、执行备份命令、检查备份文件和恢复数据的步骤。备份完成后，可以查看备份文件的内容，并使用mysql命令恢复备份文件中的数据。文章最后总结了使用mysqldump备份和恢复MySQL数据库的基本教程。","categories":["Linux","MySQL数据库实战"]},{"title":"Linux下命令find命令文件查找","path":"/2023/09/25/Linux系统管理宝典/Linux-下命令find命令文件查找/","content":"我自风情万种，何必与世相争；我自心清如水，又何须为烦恼所困？ @TOC 前言find命令是Linux系统中的一个常用命令，用于在指定的目录中查找符合条件的文件或目录。 一、find 命令使用介绍find 命令是 Linux 和 Unix 系统中常用的文件查找工具。它可以在指定目录及其子目录中查找符合指定条件的文件或目录，并将结果输出到终端。find 命令的语法如下： find [path] [expression] 其中： path：查找的起始目录，可以是绝对路径或相对路径。如果不指定 path，则默认从当前目录开始查找。 expression：用来指定查找的条件，可以是一些简单的逻辑运算符（如 \\-name, \\-type, \\-size, \\-mtime, \\-user, \\-group 等），也可以是一些复杂的文件名匹配模式（如通配符 \\*、?、\\[ \\] 等）。 \\-name：指定文件名模式，如 \\*.txt 表示查找所有以 .txt 结尾的文件。 \\-type：指定文件类型，如 \\-type f 表示查找所有文件，\\-type d 表示查找所有目录。 \\-size：指定文件大小范围，如 \\-size +10M 表示查找所有大小大于 10M 的文件。 \\-mtime：指定文件修改时间范围，如 \\-mtime -7 表示查找所有最近 7 天内修改过的文件。 \\-user：指定文件所有者，如 \\-user haoze表示查找所有所有者为 haoze 的文件。 \\-group：指定文件所属组，如 \\-group example 表示查找所有所属组为 example 的文件。 以下是一些示例： .代表的是相对路径当前目录，相对路径与绝对的路径的区别可以理解为在 Linux中凡是以&#x2F;开头的目录均为绝对路径 查找当前目录及其子目录中所有以 .txt 结尾的文件：1find . -name &quot;*.txt&quot; 查找当前目录及其子目录中所有文件大小大于 1M 的文件：1find . -type f -size +1M 查找当前目录及其子目录中所有修改时间在最近 7 天内的文件： 1find . -type f -mtime -7 查找当前目录及其子目录中所有所属组为 example 的文件： 1find . -group example 以上为 find 命令的基本用法，还有很多高级用法可以查阅官方文档了解。 二、Linux文件权限4位数含义 普通权限： image RWX对应的权限是： r:4 w:2 x:1， 所以777就代表 rwxrwxrwx 12345678910[root@server /]# ls -l | head -5total 32lrwxrwxrwx. 1 root root 7 Jul 2 14:51 bin -&gt; usr/bin#777权限dr-xr-xr-x. 5 root root 4096 Jul 2 14:53 boot#555权限drwxr-xr-x 20 root root 3240 Aug 9 16:08 dev#755权限drwxr-xr-x. 77 root root 8192 Aug 9 16:08 etc#755权限 高级权限 suid,sgid,sticky 0777最前面的0，代表高级权限suid,sgid,sticky分为属主权限、属组权限、其他人权限suid:0变为4、guid:0变为2、sticky:0变为1suid, sgid和sticky是Linux系统中用于限制文件和目录的用户和组的三种权限。 suid权限 suid权限是指文件或目录可以使其他用户以执行命令的方式来使用它们。当文件具有suid权限时，文件的所有者可以将文件或目录赋予其他用户，这些用户可以以root用户的身份来执行该文件或目录。 suid权限可以通过在文件上运行chmod +s命令来设置。例如，下面的命令将file.txt文件设置为具有suid权限： 123456[root@mysql5_7 ~]# ls -l file.txt-rw-r--r-- 1 root root 0 Aug 9 20:33 file.txt #初始权限[root@mysql5_7 ~]# chmod u+s file.txt[root@mysql5_7 ~]# ll file.txt-rwSr--r-- 1 root root 0 Aug 9 20:33 file.txt #可以看到多了个s权限 [root@mysql5_7 ~]# chmod u-s file.txt #取消权限 sgid权限 sgid权限是指文件或目录的所有者和组可以使用它们。如果没有写权限, 则这个目录下的所有文件都不能被删除, 同时也不能添加新的文件. 如果希望用户能够添加文件但同时不能删除文件 sgid权限可以通过在文件上运行chmod +s命令来设置。例如，下面的命令将file.txt文件设置为具有sgid权限： 1234[root@mysql5_7 ~]# chmod g+s file.txt[root@mysql5_7 ~]# ll file.txt-rw-r-Sr-- 1 root root 0 Aug 9 20:33 file.txt[root@mysql5_7 ~]# chmod g-s file.txt sticky权限 sticky权限是指只有文件或目录的拥有者和组用户才能进行写操作。当文件或目录具有sticky权限时，只有文件或目录的拥有者和组用户才能在文件或目录上进行写操作。其他用户可以读取和执行该文件或目录，但无法进行写操作。 设置该位后， 就算用户对目录具有写权限，也不能删除该文件。 sticky权限可以通过在文件上运行chmod +t命令来设置。例如，下面的命令将file.txt文件设置为具有sticky权限： 1234[root@mysql5_7 ~]# chmod o+t file.txt[root@mysql5_7 ~]# ll file.txt-rw-r--r-T 1 root root 0 Aug 9 20:33 file.txt[root@mysql5_7 ~]# chmod o-t file.txt 总结本文介绍了Linux系统中常用的find命令的使用介绍以及高级用法，同时解释了Linux文件权限4位数的含义，包括普通权限、高级权限suid、sgid和sticky，以及如何设置它们。find命令可以在指定目录及其子目录中查找符合指定条件的文件或目录，并将结果输出到终端。通过对命令语法和常用示例的介绍，可以更好地了解和运用find命令。","categories":["Linux","基础操作"]},{"title":"Linux中/etc/issue、/etc/motd文件","path":"/2023/09/25/Linux系统管理宝典/Linux-中motd文件/","content":"@TOC 前言在Linux操作系统中，/etc/issue和/etc/motd文件都是系统管理员可以使用来显示系统信息和欢迎信息的关键文件。这些文件通常位于&#x2F;etc目录中，是用户在登录时第一个看到的内容。&#x2F;etc&#x2F;issue文件提供了一些基本的系统信息，例如操作系统名称、版本号、内核版本等。而&#x2F;etc&#x2F;motd文件则通常包含了一些系统管理员可以添加的欢迎信息、系统安全提示或者重要公告等。这些文件对于系统的安全性、稳定性和可用性都有很大的影响，因此系统管理员需要对它们进行适当的配置和维护。 登录前欢迎语&#x2F;etc&#x2F;issue文件用来显示Linux系统的基本信息，例如发行版本、内核版本、安装日期等。当用户登录到Linux系统时，该文件将被用来显示欢迎信息。 实验 [root@mysql5_7 ~]# vim /etc/issue \\S Kernel \\r on an \\m \\d &lt;Welcome to Mysql.server&gt; :wq #保存退出 测试，这个需要系统登录看，用远程工具看不到 image 以下是&#x2F;etc&#x2F;issue文件的一些常见选项说明： 12345678910111213141516171819 ：换行符，用于在欢迎信息中添加新行。\\l：显示本地终端设备名称。\\m：显示计算机的硬件架构。\\s：显示操作系统的名称。\\r：显示内核的版本号。\\t：显示当前时间。\\u：显示当前用户名。\\v：显示操作系统的发行版本号。\\\\：显示反斜杠字符。其他自定义文本：可以在文件中添加其他自定义文本或标记。 使用这些选项，你可以根据需要定制并个性化系统登录时的欢迎信息。例如，可以使用\\s和\\v选项来显示操作系统的名称和发行版本号，\\l选项来显示本地终端设备名称，以及\\t选项来显示当前时间等。 登录后欢迎语&#x2F;etc&#x2F;motd文件用来显示Linux系统的欢迎信息。当用户第一次登录到Linux系统时，该文件将被用来显示欢迎信息。 实验 [root@mysql5_7 ~]# vim /etc/motd &quot;Welcome to MySql.server &quot; :wq #保存退出 测试，可以看到成功了 image 总结这篇文章讨论了Linux系统中&#x2F;etc&#x2F;issue和&#x2F;etc&#x2F;motd文件的作用。&#x2F;etc&#x2F;issue文件用来显示Linux系统的基本信息，例如发行版本、内核版本和安装日期等，在用户登录前会显示欢迎信息。&#x2F;etc&#x2F;motd文件则用来显示Linux系统的欢迎信息，在用户第一次登录后会显示该文件中的内容。","categories":["Linux","基础操作"]},{"title":"Linux文件权限策略setfacl命令","path":"/2023/09/25/Linux系统管理宝典/Linux-文件权限策略setfacl命令/","content":"“春风得意马蹄疾，一日看尽长安花。” ——《登高》 杜甫 @toc 前言Linux的文件权限策略使用setfacl命令来管理的。setfacl命令允许用户在文件和目录上添加、删除和修改权限。它可以根据用户、组、用户组和其他条件来定义文件和目录的权限。 命令语法setfacl命令的语法如下： 1[root@mysql5_7 ~]# setfacl -m user:username permissions file/directory 其中，-m选项用于添加或修改权限，user:username表示要授予权限的用户名，permissions表示要授予或修改的权限。 例如，如果要授予用户 test读、写和执行权限，可以使用以下命令： 1setfacl -m user:test:rwx file.txt 要列出当前文件和目录的所有权限，可以使用 getfacl 命令： 1234567[root@mysql5_7 ~]# getfacl file.txt# file: file.txt# owner: root# group: rootuser::rw-group::r--other::r-- 这将列出file.txt文件的所有权限，并将它们打印到终端上。 操作案例创建了一个名为test的用户。 1[root@mysql5_7 ~]# useradd test 使用getfacl命令查看file.txt文件的ACL权限。 1234567[root@mysql5_7 ~]# getfacl file.txt# file: file.txt# owner: root# group: rootuser::rw-group::r--other::r-- 使用setfacl命令将test用户添加到file.txt文件的ACL权限中，并赋予读写权限。 1[root@mysql5_7 ~]# setfacl -m user:test:rw file.txt 使用echo命令并通过管道方式将密码”123456”传递给passwd命令，将test用户的密码更改为”123456”。 123[root@mysql5_7 ~]# echo &quot;123456&quot; | passwd --stdin testChanging password for user test.passwd: all authentication tokens updated successfully. 使用ls -l命令查看file.txt文件的详细权限信息。 12[root@mysql5_7 ~]# ls -l file.txt-rw-rw-r--+ 1 root root 0 Aug 9 20:33 file.txt 使用chmod命令将file.txt文件的权限修改为只有root用户有访问权限。 12[root@mysql5_7 ~]# chmod 000 file.txt 使用ls -l命令再次查看file.txt文件的详细权限信息。 12[root@mysql5_7 ~]# ls -l file.txt----------+ 1 root root 0 Aug 9 20:33 file.txt 使用su命令切换到test用户。 123[root@mysql5_7 ~]# su test[test@mysql5_7 root]$ lsls: cannot open directory .: Permission denied 尝试使用ls命令查看根目录下的文件，但因权限不足而失败。 使用usermod命令将test用户添加到wheel组（提权）。 1[root@mysql5_7 /]# usermod test -G wheel 使用echo命令将”1234567”写入file.txt文件。 1[test@mysql5_7 /]$ echo &quot;1234567&quot; &gt; file.txt 使用cat命令查看file.txt文件的内容。 12[test@mysql5_7 /]$ cat file.txt1234567 创建了一个名为test2的用户。 1234[root@mysql5_7 /]# useradd test2[root@mysql5_7 /]# echo &quot;123456&quot; | passwd --stdin test2Changing password for user test2.passwd: all authentication tokens updated successfully. 使用ls -l命令查看file.txt文件的详细权限信息，发现已经对其他用户进行了限制。 12345678[test2@mysql5_7 /]$ ls -l file.txt----rwx---+ 1 root root 8 Aug 11 23:41 file.txt[test2@mysql5_7 /]$ vim file.txt[test2@mysql5_7 /]$ cat file.txtcat: file.txt: Permission denied[test2@mysql5_7 /]$ echo &quot;12334&quot; &gt; file.txtbash: file.txt: Permission denied[test2@mysql5_7 /]$ 使用vim命令尝试编辑file.txt文件，但因权限不足而失败。 使用cat命令尝试查看file.txt文件的内容，但因权限不足而失败。 使用echo命令尝试向file.txt文件写入内容，但因权限不足而失败 删除 test 用户，策略也会相应地被删除 123456789101112[root@mysql5_7 /]# userdel -r test[root@mysql5_7 /]# getfacl file.txt# file: file.txt# owner: root# group: rootuser::---user:1000:rwxgroup::r--mask::rwxother::---# 可以看到用户策略消失了 要删除所有权限，可以使用以下命令： 1setfacl -u username:username file.txt 其中，-u选项用于删除权限。 除了-m选项之外，setfacl命令还可以使用其他选项来指定其他权限和条件。有关setfacl命令的完整语法和选项 123456789101112131415161718192021[root@mysql5_7 ~]# setfacl --helpsetfacl 2.2.51 -- set file access control listsUsage: setfacl [-bkndRLP] &#123; -m|-M|-x|-X ... &#125; file ... -m, --modify=acl modify the current ACL(s) of file(s) -M, --modify-file=file read ACL entries to modify from file -x, --remove=acl remove entries from the ACL(s) of file(s) -X, --remove-file=file read ACL entries to remove from file -b, --remove-all remove all extended ACL entries -k, --remove-default remove the default ACL --set=acl set the ACL of file(s), replacing the current ACL --set-file=file read ACL entries to set from file --mask do recalculate the effective rights mask -n, --no-mask don&#x27;t recalculate the effective rights mask -d, --default operations apply to the default ACL -R, --recursive recurse into subdirectories -L, --logical logical walk, follow symbolic links -P, --physical physical walk, do not follow symbolic links --restore=file restore ACLs (inverse of `getfacl -R&#x27;) --test test mode (ACLs are not modified) -v, --version print version and exit -h, --help this help text 总结本文介绍了Linux中使用setfacl命令来管理文件和目录的权限策略。setfacl命令允许用户添加、删除和修改文件和目录的权限，并根据用户、组、用户组和其他条件来定义权限。文章给出了setfacl命令的语法和示例，以及如何使用getfacl命令列出当前文件和目录的所有权限，并使用setfacl -u username:username命令删除所有权限。此外，文章还提到了setfacl命令的其他选项和完整语法。要了解更多相关信息，请参阅Linux文档或相关文档。","tags":["Linux基础操作"],"categories":["Linux","基础操作"]},{"title":"Linux 磁盘挂载","path":"/2023/09/25/Linux系统管理宝典/Linux-磁盘挂载方式/","content":"人生自是有情痴，此恨不关风与月。 @[TOC](Linux 磁盘挂载) 一、Linux 磁盘自动挂载首先为虚拟机添加几块磁盘作为实验备用 在这里插入图片描述 添加磁盘后使用lsblk命令进行查看 [root@disk ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 60G 0 disk ├─sda1 8:1 0 500M 0 part /boot └─sda2 8:2 0 59.5G 0 part ├─centos-root 253:0 0 38.6G 0 lvm / ├─centos-swap 253:1 0 2G 0 lvm [SWAP] └─centos-home 253:2 0 18.9G 0 lvm /home sr0 11:0 1 4G 0 rom [root@disk ~]# 可以看到磁盘未加载，使用万能的重启大法reboot,init 6,shutdown -r now等，重启虚拟机即可,重启完毕后可以看到新添加的硬盘已经加载好了 [root@disk ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 60G 0 disk ├─sda1 8:1 0 500M 0 part /boot └─sda2 8:2 0 59.5G 0 part ├─centos-root 253:0 0 38.6G 0 lvm / ├─centos-swap 253:1 0 2G 0 lvm [SWAP] └─centos-home 253:2 0 18.9G 0 lvm /home sdb 8:16 0 60G 0 disk sdc 8:32 0 60G 0 disk sdd 8:48 0 60G 0 disk sr0 11:0 1 1024M 0 rom 使用 fdisk进行分区 [root@disk ~]# fdisk /dev/sdb Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Device does not contain a recognized partition table Building a new DOS disklabel with disk identifier 0x1d66e12e. Command (m for help): p Disk /dev/sdb: 64.4 GB, 64424509440 bytes, 125829120 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x1d66e12e Device Boot Start End Blocks Id System Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p Partition number (1-4, default 1): First sector (2048-125829119, default 2048): Using default value 2048 Last sector, +sectors or +size&#123;K,M,G&#125; (2048-125829119, default 125829119): Using default value 125829119 Partition 1 of type Linux and of size 60 GiB is set Command (m for help): p Disk /dev/sdb: 64.4 GB, 64424509440 bytes, 125829120 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x1d66e12e Device Boot Start End Blocks Id System /dev/sdb1 2048 125829119 62913536 83 Linux Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. 根目录下创建了一个名为&#x2F;mnt&#x2F;sdb的目录，并对&#x2F;dev&#x2F;sdb1进行了ext4文件系统格式化。 文件系统类型：ext4 [root@disk ~]# mkdir /mnt/sdb [root@disk ~]# mkfs.ext4 /dev/sdb1 mke2fs 1.42.9 (28-Dec-2013) Filesystem label= OS type: Linux Block size=4096 (log=2) Fragment size=4096 (log=2) Stride=0 blocks, Stripe width=0 blocks 3932160 inodes, 15728384 blocks 786419 blocks (5.00%) reserved for the super user First data block=0 Maximum filesystem blocks=2164260864 480 block groups 32768 blocks per group, 32768 fragments per group 8192 inodes per group Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424 Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): done Writing superblocks and filesystem accounting information: done 配置&#x2F;etc&#x2F;fstab文件实现开机自动挂载 在配置文件/etc/fstab后追加/dev/sdb1 /mnt/sdb ext4 defaults 0 0 [root@disk ~]# vim /etc/fstab # # /etc/fstab # Created by anaconda on Sun Jul 2 14:40:36 2023 # # Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=8f90bf6f-fc6f-47e6-938e-d53602078619 /boot xfs defaults 0 0 /dev/mapper/centos-home /home xfs defaults 0 0 /dev/mapper/centos-swap swap swap defaults 0 0 /dev/sdb1 /mnt/sdb ext4 defaults 0 0 参数解释： 第1列:挂载设备 (1)/dev/sda5 (2)UUID=设备的uuid rhel6/7的默认写法 同一台机器内唯一的一个设备标识 第2列:挂载点 第3列:文件系统类型 第4列:文件系统属性 第5列:是否对文件系统进行磁带备份：0 不备份 第6列:是否检查文件系统：0 不检查 使用 mount 命令挂载 [root@disk ~]# mount /dev/sdb1 /mnt/sdb/ [root@disk ~]# mount -a #开机自动挂载 二、根目录扩容首先，使用lsblk命令查看当前系统的磁盘和分区情况。 [root@server /]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP] sdb 8:16 0 20G 0 disk ├─sdb1 8:17 0 5G 0 part /mnt/sdb1 ├─sdb2 8:18 0 5G 0 part /mnt/sdb2 ├─sdb3 8:19 0 5G 0 part /mnt/sdb3 ├─sdb4 8:20 0 1K 0 part └─sdb5 8:21 0 5G 0 part /mnt/sdb5 sdc 8:32 0 20G 0 disk └─sdc1 8:33 0 2G 0 part [SWAP] sdd 8:48 0 20G 0 disk sde 8:64 0 20G 0 disk └─vg2-lv2 253:2 0 26G 0 lvm /mnt/lv2 sdf 8:80 0 20G 0 disk └─vg1-lv1 253:3 0 1G 0 lvm sdg 8:96 0 20G 0 disk └─vg2-lv2 253:2 0 26G 0 lvm /mnt/lv2 sdh 8:112 0 20G 0 disk sr0 11:0 1 4.4G 0 rom 确认需要扩容的根分区所在的逻辑卷名称和卷组名称。根据示例中的输出，根分区的逻辑卷名称是centos-root，卷组名称是centos。 [root@server /]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- &lt;17.00g swap centos -wi-ao---- 2.00g lv1 vg1 -wi-a----- 1.00g lv2 vg2 -wi-ao---- 26.00g [root@server /]# pvcreate /dev/sdd Physical volume &quot;/dev/sdd&quot; successfully created. [root@server /]# vgextend centos /dev/sdd Volume group &quot;centos&quot; successfully extended 使用lvextend命令对逻辑卷进行扩容。例如，要将根分区扩容15GB，可以执行以下命令：lvextend -L +15G /dev/centos/root [root@server /]# vgs VG #PV #LV #SN Attr VSize VFree centos 2 2 0 wz--n- 38.99g &lt;20.00g vg1 1 1 0 wz--n- &lt;20.00g &lt;19.00g vg2 2 1 0 wz--n- 39.99g 13.99g [root@server /]# lvextend -L +15G /dev/centos/root Size of logical volume centos/root changed from &lt;17.00 GiB (4351 extents) to &lt;32.00 GiB (8191 extents). Logical volume centos/root successfully resized. 扩容完成后，使用df -Th命令检查根分区的大小是否已经扩容。 [root@server /]# df -Th Filesystem Type Size Used Avail Use% Mounted on devtmpfs devtmpfs 974M 0 974M 0% /dev tmpfs tmpfs 991M 0 991M 0% /dev/shm tmpfs tmpfs 991M 11M 980M 2% /run tmpfs tmpfs 991M 0 991M 0% /sys/fs/cgroup /dev/mapper/centos-root xfs 17G 5.7G 12G 34% / /dev/sdb3 ext4 4.8G 20M 4.6G 1% /mnt/sdb3 /dev/sdb1 ext4 4.8G 20M 4.6G 1% /mnt/sdb1 /dev/sdb2 ext4 4.8G 20M 4.6G 1% /mnt/sdb2 /dev/sdb5 ext4 4.8G 20M 4.6G 1% /mnt/sdb5 /dev/sda1 xfs 1014M 213M 802M 21% /boot tmpfs tmpfs 199M 12K 199M 1% /run/user/42 tmpfs tmpfs 199M 0 199M 0% /run/user/0 /dev/mapper/vg2-lv2 ext4 26G 45M 25G 1% /mnt/lv2 如果根分区是XFS文件系统，还需要执行xfs_growfs命令来调整文件系统大小。例如，执行以下命令：xfs_growfs /dev/centos/root [root@server /]# xfs_growfs /dev/centos/root meta-data=/dev/mapper/centos-root isize=512 agcount=4, agsize=1113856 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=4455424, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 4455424 to 8387584 使用df -Th命令再次检查根分区的大小，确保扩容操作已成功完成。 [root@server /]# df -Th Filesystem Type Size Used Avail Use% Mounted on devtmpfs devtmpfs 974M 0 974M 0% /dev tmpfs tmpfs 991M 0 991M 0% /dev/shm tmpfs tmpfs 991M 11M 980M 2% /run tmpfs tmpfs 991M 0 991M 0% /sys/fs/cgroup /dev/mapper/centos-root xfs 32G 5.7G 27G 18% / /dev/sdb3 ext4 4.8G 20M 4.6G 1% /mnt/sdb3 /dev/sdb1 ext4 4.8G 20M 4.6G 1% /mnt/sdb1 /dev/sdb2 ext4 4.8G 20M 4.6G 1% /mnt/sdb2 /dev/sdb5 ext4 4.8G 20M 4.6G 1% /mnt/sdb5 /dev/sda1 xfs 1014M 213M 802M 21% /boot tmpfs tmpfs 199M 12K 199M 1% /run/user/42 tmpfs tmpfs 199M 0 199M 0% /run/user/0 /dev/mapper/vg2-lv2 ext4 26G 45M 25G 1% /mnt/lv2 三、添加交换分区使用dd工具将/dev/zero设备中的内容写入到/mnt/swap.iso文件中，写入的块大小为1GB，总共写入1个块。 这个命令的目的是创建一个1GB大小的名为swap.iso的文件，并将其写入到/mnt目录下。/dev/zero是一个特殊的文件，读取它会返回无限的空字节。通过将其内容写入到文件中，相当于创建了一个全是0的文件。 [root@disk ~]# dd if=/dev/zero of=/mnt/swap.iso bs=1G count=1 1+0 records in 1+0 records out 1073741824 bytes (1.1 GB) copied, 12.4315 s, 86.4 MB/s 通常情况下，这样的操作是为了创建一个临时的交换文件（swap file），用于作为交换分区（swap partition）的替代品，用于虚拟内存的扩展。 [root@disk ~]# mkswap /mnt/swap.iso Setting up swapspace version 1, size = 1048572 KiB no label, UUID=084d2529-f7ac-49c1-9d07-2ad6da7410df [root@disk ~]# vim /etc/fstab /mnt/swap.iso swap swap defaults 0 0 [root@disk ~]# swapon -a swapon: /mnt/swap.iso: insecure permissions 0644, 0600 suggested. #这个警告是由于你的交换文件（swap file）的权限设置被认为不安全导致的。默认情况下，建议将交换文件设置为 0600 权限。 要更改交换文件的权限，你可以使用以下命令： [root@disk ~]# chmod 0600 /mnt/swap.iso #这将设置交换文件的权限为 0600，只允许所有者读取和写入，而禁止其他用户的访问。这样设置后，再次运行 swapon 命令应该就不会再出现不安全权限的警告了 [root@disk ~]# swapon -a [root@disk ~]# swapon -s Filename Type Size Used Priority /dev/dm-1 partition 2097148 0 -2 /mnt/swap.iso file 1048572 0 -3 [root@disk ~]# 到此挂载完成，在实际使用中使用交换分区，最好使用专门的分区，而不是一个文件。 总结本文介绍了Linux磁盘挂载的基本操作和配置方法，包括虚拟机添加磁盘、分区格式化、配置fstab文件、开机自动挂载，根目录扩容和添加交换分区等。文章详细介绍了每个步骤的具体操作和注意事项。","categories":["Linux","基础操作"]},{"title":"sysctl","path":"/2023/09/25/Linux配置文件/sysctl/sysctl/","content":"可以通过&#x2F;etc&#x2F;sysctl.conf控制和配置Linux内核及网络设置。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# 避免放大攻击net.ipv4.icmp_echo_ignore_broadcasts = 1# 开启恶意icmp错误消息保护net.ipv4.icmp_ignore_bogus_error_responses = 1# 开启SYN洪水攻击保护net.ipv4.tcp_syncookies = 1# 开启并记录欺骗，源路由和重定向包net.ipv4.conf.all.log_martians = 1net.ipv4.conf.default.log_martians = 1# 处理无源路由的包net.ipv4.conf.all.accept_source_route = 0net.ipv4.conf.default.accept_source_route = 0# 开启反向路径过滤net.ipv4.conf.all.rp_filter = 1net.ipv4.conf.default.rp_filter = 1# 确保无人能修改路由表net.ipv4.conf.all.accept_redirects = 0net.ipv4.conf.default.accept_redirects = 0net.ipv4.conf.all.secure_redirects = 0net.ipv4.conf.default.secure_redirects = 0# 不充当路由器net.ipv4.ip_forward = 0net.ipv4.conf.all.send_redirects = 0net.ipv4.conf.default.send_redirects = 0# 开启execshildkernel.exec-shield = 1kernel.randomize_va_space = 1# IPv6设置net.ipv6.conf.default.router_solicitations = 0net.ipv6.conf.default.accept_ra_rtr_pref = 0net.ipv6.conf.default.accept_ra_pinfo = 0net.ipv6.conf.default.accept_ra_defrtr = 0net.ipv6.conf.default.autoconf = 0net.ipv6.conf.default.dad_transmits = 0net.ipv6.conf.default.max_addresses = 1# 优化LB使用的端口# 增加系统文件描述符限制fs.file-max = 65535# 允许更多的PIDs (减少滚动翻转问题); may break some programs 32768kernel.pid_max = 65536# 增加系统IP端口限制net.ipv4.ip_local_port_range = 2000 65000# 增加TCP最大缓冲区大小net.ipv4.tcp_rmem = 4096 87380 8388608net.ipv4.tcp_wmem = 4096 87380 8388608# 增加Linux自动调整TCP缓冲区限制# 最小，默认和最大可使用的字节数# 最大值不低于4MB，如果你使用非常高的BDP路径可以设置得更高# Tcp窗口等net.core.rmem_max = 8388608net.core.wmem_max = 8388608net.core.netdev_max_backlog = 5000net.ipv4.tcp_window_scaling = 1","categories":["Linux","基础操作"]},{"path":"/2023/07/11/构建可视化数据分析系统-ELK/ELK收集nginx access_log日志/","content":"一、案例分析公司为了每天都能够随时看到公司WEB业务的实时运行情况，希望运维通过分析access.log日志信息，实时展示一下数据给公司的运营部门： 统计不同返回值的数量 统计访问前5名的IP地址 统计每日PV 统计每日UV ……. 二、nginx access_log定义json格式日志 部署nginx 设置nginx 访问日志为json格式 a、部署nginx服务 123456[root@node4 ~]# tar xf nginx-*.rpm[root@node4 ~]# cd nginx-*.rpm[root@node4 ~]# yum -y install pcre-devel zlib-devel gcc-*[root@node4 ~]# ./configure --prefix=/usr/local[root@node4 ~]# make[root@node4 ~]# make install b、设置nginx 访问日志为json格式 由于ES是基于json来处理数据的，所以给ES的数据就必须是JSON数据，只有这样才能通过json将数据进行分析、统计。为了能让ES能分析access.log日志，我们让nginx直接将该日志的格式设置为json格式。 1234567891011121314[root@node4 ~]# vim /usr/local/nginx/conf/nginx.conflog_format main_json &#x27;&#123;&quot;@timestamp&quot;:&quot;$time_local&quot;,&#x27;&#x27;&quot;N_client_ip&quot;: &quot;$remote_addr&quot;,&#x27;&#x27;&quot;N_request&quot;: &quot;$request&quot;,&#x27;&#x27;&quot;N_request_time&quot;: &quot;$request_time&quot;,&#x27;&#x27;&quot;N_status&quot;: &quot;$status&quot;,&#x27;&#x27;&quot;N_bytes&quot;: &quot;$body_bytes_sent&quot;,&#x27;&#x27;&quot;N_user_agent&quot;: &quot;$http_user_agent&quot;,&#x27;&#x27;&quot;N_x_forwarded&quot;: &quot;$http_x_forwarded_for&quot;,&#x27;&#x27;&quot;N_referer&quot;: &quot;$http_referer&quot;&#x27;&#x27;&#125;&#x27;; access_log logs/access.log main_json; 三、日志收集filebeat设置-修改配置文件定义日志收集 123456789101112131415161718192021[root@node4 ~]# egrep -v &quot;(#|^$)&quot; /etc/filebeat/filebeat.yml filebeat.inputs:- type: log enabled: true paths: - /usr/local/nginx/logs/access.log #添加以下两行，定义收集的是json日志 json.keys_under_root: true json.overwrite_keys: truefilebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1setup.kibana: host: &quot;192.168.98.200:5601&quot;output.logstash: hosts: [&quot;192.168.98.203:5044&quot;]processors: - add_host_metadata: ~ - add_cloud_metadata: ~ logstash设置-配置业务文件，接收Filebeat发送的数据，然后将数据发送给ES 12345678910111213141516[root@node3 conf.d]# cat f_to_e.conf input &#123; beats &#123; port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;192.168.98.202:9200&quot;] index =&gt; &quot;nginx-%&#123;+YYYY.MM.dd&#125;&quot; &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; kibana创建索引，添加nginx数据 四、kibana展示统计不同返回值的数量 饼图 统计访问前5名的IP地址 柱形图 统计每日PV 仪表盘 统计每日UV 计数 52nginx_access.png"},{"path":"/2023/07/11/构建可视化数据分析系统-ELK/ELK-收集mysql slow 日志/","content":"案例分析开发和DBA为了能够实时掌握mysql的运行情况，需要对mysql中执行的sql指令大于1秒的统计出来，并且通过ELK分析，统计，实时查看。通过分析可以让DBA能够优化数据库，能够提升运行速度。 一、MySQL设置a、mysql安装 1安装脚本 mysql默认root密码更改 1[root@node4 mysql]# mysql_secure_installation b、mysql slow日志开启 1234567#开启slow logslow_query_log=1slow_query_log_file=/usr/local/mysql/mysql-slow.loglong-query-time=1#允许使用Load data命令secure_file_priv=&#x27;&#x27; 重启mysql生效 123[root@node4 mysql]# /etc/init.d/mysql.server restartShutting down MySQL.. SUCCESS! Starting MySQL. SUCCESS! c、生成测试数据 1[root@node4 mysql]# seq 1 10000000 &gt; /tmp/big 导入数据 1234mysql&gt; create table db1.t1(id int(11));mysql&gt; load data infile &#x27;/tmp/big&#x27; into table db1.t1;Query OK, 10000000 rows affected (21.73 sec)Records: 10000000 Deleted: 0 Skipped: 0 Warnings: 0 生成slow日志 1234567mysql&gt; select * from db1.t1 where id=8;+------+| id |+------+| 8 |+------+1 row in set (3.46 sec) 查看slow 日志 1234567891011121314151617181920212223242526272829303132[root@node4 mysql]# cat mysql-slow.log /usr/local/mysql/bin/mysqld, Version: 5.7.28-log (MySQL Community Server (GPL)). started with:Tcp port: 0 Unix socket: /tmp/mysql.sockTime Id Command Argument/usr/local/mysql/bin/mysqld, Version: 5.7.28-log (MySQL Community Server (GPL)). started with:Tcp port: 0 Unix socket: /tmp/mysql.sockTime Id Command Argument# Time: 2020-02-18T13:15:34.406907Z# User@Host: root[root] @ localhost [] Id: 2# Query_time: 21.729690 Lock_time: 0.005813 Rows_sent: 0 Rows_examined: 0SET timestamp=1582031734;load data infile &#x27;/tmp/big&#x27; into table db1.t1;# Time: 2020-02-18T13:16:03.022224Z# User@Host: root[root] @ localhost [] Id: 2# Query_time: 3.458640 Lock_time: 0.004334 Rows_sent: 1 Rows_examined: 10000000SET timestamp=1582031763;select * from db1.t1 where id=8;# Time: 2020-02-18T13:23:11.893639Z# User@Host: root[root] @ localhost [] Id: 3# Query_time: 3.583976 Lock_time: 0.000412 Rows_sent: 1 Rows_examined: 10000000SET timestamp=1582032191;select * from db1.t1 where id=88;# Time: 2020-02-18T13:23:17.347380Z# User@Host: root[root] @ localhost [] Id: 3# Query_time: 3.557843 Lock_time: 0.000113 Rows_sent: 1 Rows_examined: 10000000SET timestamp=1582032197;select * from db1.t1 where id=888;# Time: 2020-02-18T13:23:22.470483Z# User@Host: root[root] @ localhost [] Id: 3# Query_time: 3.498105 Lock_time: 0.000173 Rows_sent: 1 Rows_examined: 10000000SET timestamp=1582032202;select * from db1.t1 where id=8888; 二、数据收集###a、mysql slow日志格式整理收集 通过filebeat多行模式收集mysql slow日志 12345678910111213141516171819202122232425262728293031[root@node4 ~]# egrep -v &quot;^#|^$| #&quot; /etc/filebeat/filebeat.yml filebeat.inputs:- type: log enabled: true paths: - /usr/local/mysql/mysql-slow.log #开启多行收集 multiline.pattern: &quot;^# User@Host:&quot; multiline.negate: true multiline.match: after filebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1setup.kibana:output.logstash: hosts: [&quot;192.168.98.203:5044&quot;]processors: - add_host_metadata: ~ - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~参数说明multiline.pattern：正则表达式，去匹配指定的一行，这里去匹配的以“# User@Host:”开头的那一行；multiline.negate：取值true 或 false；默认是false，就是将multiline.pattern匹配到的那一行合并到上一行；如果配置是true，就是将除了multiline.pattern匹的那一行的其他所有行合并到其上一行；multiline.match：after 或 before，就是指定将要合并到上一行的内容，合并到上一行的末尾或开头； logstash中的数据是这样存储的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&#123; &quot;host&quot; =&gt; &#123; &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;name&quot; =&gt; &quot;node4&quot;, &quot;os&quot; =&gt; &#123; &quot;family&quot; =&gt; &quot;redhat&quot;, &quot;name&quot; =&gt; &quot;CentOS Linux&quot;, &quot;kernel&quot; =&gt; &quot;4.18.0-80.el8.x86_64&quot;, &quot;codename&quot; =&gt; &quot;Core&quot;, &quot;version&quot; =&gt; &quot;8 (Core)&quot;, &quot;platform&quot; =&gt; &quot;centos&quot; &#125;, &quot;containerized&quot; =&gt; false, &quot;id&quot; =&gt; &quot;d8100d9fc21041ae9364bbb1ca84da02&quot;, &quot;architecture&quot; =&gt; &quot;x86_64&quot; &#125;, &quot;log&quot; =&gt; &#123; &quot;offset&quot; =&gt; 4629, &quot;file&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/usr/local/mysql/mysql-slow.log&quot; &#125; &#125;, &quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot; ], &quot;@timestamp&quot; =&gt; 2020-02-19T02:50:06.763Z, &quot;input&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;log&quot; &#125;, #这里有一个message行，记录了时间 &quot;message&quot; =&gt; &quot;# Time: 2020-02-19T02:50:05.740090Z&quot;, &quot;ecs&quot; =&gt; &#123; &quot;version&quot; =&gt; &quot;1.4.0&quot; &#125;, &quot;agent&quot; =&gt; &#123; &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;type&quot; =&gt; &quot;filebeat&quot;, &quot;ephemeral_id&quot; =&gt; &quot;3736821d-5c17-429a-a8af-0a9b28ba87b7&quot;, &quot;version&quot; =&gt; &quot;7.6.0&quot;, &quot;id&quot; =&gt; &quot;060fdb52-cc79-463e-9cbf-f7d8fee5db89&quot; &#125;, &quot;@version&quot; =&gt; &quot;1&quot;&#125;&#123; &quot;log&quot; =&gt; &#123; &quot;file&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/usr/local/mysql/mysql-slow.log&quot; &#125;, &quot;offset&quot; =&gt; 4665, &quot;flags&quot; =&gt; [ [0] &quot;multiline&quot; ] &#125;, &quot;host&quot; =&gt; &#123; &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;name&quot; =&gt; &quot;node4&quot;, &quot;os&quot; =&gt; &#123; &quot;family&quot; =&gt; &quot;redhat&quot;, &quot;name&quot; =&gt; &quot;CentOS Linux&quot;, &quot;kernel&quot; =&gt; &quot;4.18.0-80.el8.x86_64&quot;, &quot;codename&quot; =&gt; &quot;Core&quot;, &quot;version&quot; =&gt; &quot;8 (Core)&quot;, &quot;platform&quot; =&gt; &quot;centos&quot; &#125;, &quot;containerized&quot; =&gt; false, &quot;id&quot; =&gt; &quot;d8100d9fc21041ae9364bbb1ca84da02&quot;, &quot;architecture&quot; =&gt; &quot;x86_64&quot; &#125;, &quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot; ], &quot;@timestamp&quot; =&gt; 2020-02-19T02:50:06.763Z, &quot;input&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;log&quot; &#125;, ####看这里message!mysql slow日志这样才的 &quot;message&quot; =&gt; &quot;# User@Host: root[root] @ localhost [] Id: 2 # Query_time: 4.764090 Lock_time: 0.001112 Rows_sent: 1 Rows_examined: 10000000 SET timestamp=1582080605; select * from db1.t1 where id=1;&quot;, &quot;ecs&quot; =&gt; &#123; &quot;version&quot; =&gt; &quot;1.4.0&quot; &#125;, &quot;agent&quot; =&gt; &#123; &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;type&quot; =&gt; &quot;filebeat&quot;, &quot;version&quot; =&gt; &quot;7.6.0&quot;, &quot;ephemeral_id&quot; =&gt; &quot;3736821d-5c17-429a-a8af-0a9b28ba87b7&quot;, &quot;id&quot; =&gt; &quot;060fdb52-cc79-463e-9cbf-f7d8fee5db89&quot; &#125;, &quot;@version&quot; =&gt; &quot;1&quot;&#125; b、使用grok插件格式化数据 grok是一种采用组合多个预定义的正则表达式，用来匹配分割文本并映射到关键字的工具。通常用来对日志数据进行预处理。logstash的filter模块中grok插件是其实现之一。 处理思路： 12341、第一个message数据行，没有用到，删除；2、第二个message数据行的数据做json格式；3、时间根据第二个message数据行中的时间戳转换；4、数据已经做成json格式了，自然第二个message也没用了，删除第二个message行； 通过不断测试，查看Logstash中的数据存储 1、第一个message数据行，没有用到，删除； 2、第二个message数据行的数据做json格式； 3、时间根据第二个message数据行中的时间戳转换； 12345678910111213141516171819202122232425262728293031filter &#123;#2、将第二个message数据格式化为json格斯grok &#123; match =&gt; [ &quot;message&quot;, &quot;(?m)^# User@Host: %&#123;USER:query_user&#125;\\[[^\\]]+\\] @ (?:(?&lt;query_host&gt;\\S*) )?\\[(?:%&#123;IP:query_ip&#125;)?\\]\\s+Id:\\s+%&#123;NUMBER:row_id:int&#125;\\s*# Query_time: %&#123;NUMBER:query_time:float&#125;\\s+Lock_time: %&#123;NUMBER:lock_time:float&#125;\\s+Rows_sent: %&#123;NUMBER:rows_sent:int&#125;\\s+Rows_examined: %&#123;NUMBER:rows_examined:int&#125;\\s*(?:use %&#123;DATA:database&#125;;\\s*)?SET timestamp=%&#123;NUMBER:timestamp&#125;;\\s*(?&lt;query&gt;(?&lt;action&gt;\\w+)\\s+.*)&quot; ] &#125;#1、匹配&quot;message&quot; =&gt; &quot;# Time: &quot;数据行[第一个message]，添加一个标签 dropgrok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;# Time: &quot; &#125; add_tag =&gt; [ &quot;drop&quot; ] tag_on_failure =&gt; [] &#125;#1、删除标签为drop的数据行 if &quot;drop&quot; in [tags] &#123; drop &#123;&#125; &#125;#3、匹配message中的时间戳，根据亚洲/上海的格式生成本地时间 date &#123; match =&gt; [&quot;mysql.slowlog.timestamp&quot;, &quot;UNIX&quot;, &quot;YYYY-MM-dd HH:mm:ss&quot;] target =&gt; &quot;@timestamp&quot; timezone =&gt; &quot;Asia/Shanghai&quot; &#125; ruby &#123; code =&gt; &quot;event.set(&#x27;[@metadata][today]&#x27;, Time.at(event.get(&#x27;@timestamp&#x27;).to_i).localtime.strftime(&#x27;%Y.%m.%d&#x27;))&quot; &#125;&#125; logstash中数据存储 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&#123; &quot;agent&quot; =&gt; &#123; &quot;ephemeral_id&quot; =&gt; &quot;3736821d-5c17-429a-a8af-0a9b28ba87b7&quot;, &quot;type&quot; =&gt; &quot;filebeat&quot;, &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;version&quot; =&gt; &quot;7.6.0&quot;, &quot;id&quot; =&gt; &quot;060fdb52-cc79-463e-9cbf-f7d8fee5db89&quot; &#125;, #看这里，根据时间戳生成的时间 &quot;@timestamp&quot; =&gt; 2020-02-19T03:01:46.833Z, &quot;input&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;log&quot; &#125;, &quot;query_host&quot; =&gt; &quot;localhost&quot;, &quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot; ], &quot;row_id&quot; =&gt; 2, ###看这里，第二个message数据 &quot;message&quot; =&gt; &quot;# User@Host: root[root] @ localhost [] Id: 2 # Query_time: 4.448631 Lock_time: 0.000213 Rows_sent: 1 Rows_examined: 10000000 SET timestamp=1582081300; select * from db1.t1 where id=1;&quot;, &quot;@version&quot; =&gt; &quot;1&quot;, ###从这往下看，能看到这里面夹杂这生成的json数据 #row_id query_time lock_time rows_examined query query_user等都是 &quot;query_time&quot; =&gt; 4.448631, &quot;lock_time&quot; =&gt; 0.000213, &quot;ecs&quot; =&gt; &#123; &quot;version&quot; =&gt; &quot;1.4.0&quot; &#125;, &quot;rows_examined&quot; =&gt; 10000000, &quot;query&quot; =&gt; &quot;select * from db1.t1 where id=1;&quot;, &quot;log&quot; =&gt; &#123; &quot;flags&quot; =&gt; [ [0] &quot;multiline&quot; ], &quot;offset&quot; =&gt; 5346, &quot;file&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/usr/local/mysql/mysql-slow.log&quot; &#125; &#125;, &quot;host&quot; =&gt; &#123; &quot;name&quot; =&gt; &quot;node4&quot;, &quot;os&quot; =&gt; &#123; &quot;codename&quot; =&gt; &quot;Core&quot;, &quot;name&quot; =&gt; &quot;CentOS Linux&quot;, &quot;family&quot; =&gt; &quot;redhat&quot;, &quot;version&quot; =&gt; &quot;8 (Core)&quot;, &quot;kernel&quot; =&gt; &quot;4.18.0-80.el8.x86_64&quot;, &quot;platform&quot; =&gt; &quot;centos&quot; &#125;, &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;architecture&quot; =&gt; &quot;x86_64&quot;, &quot;id&quot; =&gt; &quot;d8100d9fc21041ae9364bbb1ca84da02&quot;, &quot;containerized&quot; =&gt; false &#125;, &quot;action&quot; =&gt; &quot;select&quot;, &quot;rows_sent&quot; =&gt; 1, &quot;timestamp&quot; =&gt; &quot;1582081300&quot;, &quot;query_user&quot; =&gt; &quot;root&quot;&#125; 通过grok插件，实现日志过滤 关于正则表达式内容，参考shell脚本中的正则表达式一章 1234补充知识点空格匹配 \\s回车匹配 \\s*非空格匹配 \\S [大写] grok中的语法 123456789101112grok匹配规则%&#123;数据类型：变量名&#125;例如 5.12 可能是一个事件的持续时间,192.168.98.200可能是请求的client地址。所以这两个值可以用 %&#123;NUMBER:duration&#125; %&#123;IP:client&#125; 来匹配。自定义数据类型(?&lt;字段名&gt;表达式)例如，日志有一个student_id 为一个长度为10或11个字符的十六进制值。使用下列语法可以获取该片段，并把值赋予student_id(?&lt;student_id&gt;[0-9A-F]&#123;10,11&#125;)具体参考https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html 删除第二个message数据 1234567891011121314151617181920212223242526272829303132333435filter &#123;#1、将第二个message数据格式化为json格斯grok &#123; match =&gt; [ &quot;message&quot;, &quot;(?m)^# User@Host: %&#123;USER:query_user&#125;\\[[^\\]]+\\] @ (?:(?&lt;query_host&gt;\\S*) )?\\[(?:%&#123;IP:query_ip&#125;)?\\]\\s+Id:\\s+%&#123;NUMBER:row_id:int&#125;\\s*# Query_time: %&#123;NUMBER:query_time:float&#125;\\s+Lock_time: %&#123;NUMBER:lock_time:float&#125;\\s+Rows_sent: %&#123;NUMBER:rows_sent:int&#125;\\s+Rows_examined: %&#123;NUMBER:rows_examined:int&#125;\\s*(?:use %&#123;DATA:database&#125;;\\s*)?SET timestamp=%&#123;NUMBER:timestamp&#125;;\\s*(?&lt;query&gt;(?&lt;action&gt;\\w+)\\s+.*)&quot; ] &#125;#匹配&quot;message&quot; =&gt; &quot;# Time: &quot;数据行[第一个message]，添加一个标签 dropgrok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;# Time: &quot; &#125; add_tag =&gt; [ &quot;drop&quot; ] tag_on_failure =&gt; [] &#125;#删除标签为drop的数据行 if &quot;drop&quot; in [tags] &#123; drop &#123;&#125; &#125;#匹配message中的时间戳，根据亚洲/上海的格式生成本地时间 date &#123; match =&gt; [&quot;mysql.slowlog.timestamp&quot;, &quot;UNIX&quot;, &quot;YYYY-MM-dd HH:mm:ss&quot;] target =&gt; &quot;@timestamp&quot; timezone =&gt; &quot;Asia/Shanghai&quot; &#125; ruby &#123; code =&gt; &quot;event.set(&#x27;[@metadata][today]&#x27;, Time.at(event.get(&#x27;@timestamp&#x27;).to_i).localtime.strftime(&#x27;%Y.%m.%d&#x27;))&quot; &#125;#删除message字段 mutate &#123; remove_field =&gt; [ &quot;message&quot; ] &#125;&#125; 实现过滤后，logstash数据存储状态 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&#123; &quot;lock_time&quot; =&gt; 0.000226, &quot;host&quot; =&gt; &#123; &quot;name&quot; =&gt; &quot;node4&quot;, &quot;architecture&quot; =&gt; &quot;x86_64&quot;, &quot;os&quot; =&gt; &#123; &quot;name&quot; =&gt; &quot;CentOS Linux&quot;, &quot;family&quot; =&gt; &quot;redhat&quot;, &quot;platform&quot; =&gt; &quot;centos&quot;, &quot;kernel&quot; =&gt; &quot;4.18.0-80.el8.x86_64&quot;, &quot;version&quot; =&gt; &quot;8 (Core)&quot;, &quot;codename&quot; =&gt; &quot;Core&quot; &#125;, &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;id&quot; =&gt; &quot;d8100d9fc21041ae9364bbb1ca84da02&quot;, &quot;containerized&quot; =&gt; false &#125;, &quot;rows_examined&quot; =&gt; 10000000, &quot;action&quot; =&gt; &quot;select&quot;, &quot;rows_sent&quot; =&gt; 1, &quot;tags&quot; =&gt; [ [0] &quot;beats_input_codec_plain_applied&quot; ], &quot;row_id&quot; =&gt; 2, &quot;log&quot; =&gt; &#123; &quot;file&quot; =&gt; &#123; &quot;path&quot; =&gt; &quot;/usr/local/mysql/mysql-slow.log&quot; &#125;, &quot;flags&quot; =&gt; [ [0] &quot;multiline&quot; ], &quot;offset&quot; =&gt; 5119 &#125;, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;ecs&quot; =&gt; &#123; &quot;version&quot; =&gt; &quot;1.4.0&quot; &#125;, &quot;input&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;log&quot; &#125;, ###看这里下面数据,数据已经被定义为json格式了， &quot;query_host&quot; =&gt; &quot;localhost&quot;, &quot;@timestamp&quot; =&gt; 2020-02-19T02:57:11.812Z, &quot;query_time&quot; =&gt; 4.377673, &quot;query_user&quot; =&gt; &quot;root&quot;, &quot;query&quot; =&gt; &quot;select * from db1.t1 where id=1;&quot;, &quot;timestamp&quot; =&gt; &quot;1582081027&quot;, &quot;agent&quot; =&gt; &#123; &quot;type&quot; =&gt; &quot;filebeat&quot;, &quot;version&quot; =&gt; &quot;7.6.0&quot;, &quot;hostname&quot; =&gt; &quot;node4&quot;, &quot;id&quot; =&gt; &quot;060fdb52-cc79-463e-9cbf-f7d8fee5db89&quot;, &quot;ephemeral_id&quot; =&gt; &quot;3736821d-5c17-429a-a8af-0a9b28ba87b7&quot; &#125;&#125; c、logstash将数据交给elasticsearch 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@node3 conf.d]# cat mysql_logstash_es.conf#采集数据input &#123;\tbeats &#123; port =&gt; 5044 &#125;&#125;#过滤filter &#123;grok &#123; match =&gt; [ &quot;message&quot;, &quot;(?m)^# User@Host: %&#123;USER:query_user&#125;\\[[^\\]]+\\] @ (?:(?&lt;query_host&gt;\\S*) )?\\[(?:%&#123;IP:query_ip&#125;)?\\]\\s+Id:\\s+%&#123;NUMBER:row_id:int&#125;\\s*# Query_time: %&#123;NUMBER:query_time:float&#125;\\s+Lock_time: %&#123;NUMBER:lock_time:float&#125;\\s+Rows_sent: %&#123;NUMBER:rows_sent:int&#125;\\s+Rows_examined: %&#123;NUMBER:rows_examined:int&#125;\\s*(?:use %&#123;DATA:database&#125;;\\s*)?SET timestamp=%&#123;NUMBER:timestamp&#125;;\\s*(?&lt;query&gt;(?&lt;action&gt;\\w+)\\s+.*)&quot; ] &#125; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;# Time: &quot; &#125; add_tag =&gt; [ &quot;drop&quot; ] tag_on_failure =&gt; [] &#125; if &quot;drop&quot; in [tags] &#123; drop &#123;&#125; &#125; date &#123; match =&gt; [&quot;mysql.slowlog.timestamp&quot;, &quot;UNIX&quot;, &quot;YYYY-MM-dd HH:mm:ss&quot;] target =&gt; &quot;@timestamp&quot; timezone =&gt; &quot;Asia/Shanghai&quot; &#125; ruby &#123; code =&gt; &quot;event.set(&#x27;[@metadata][today]&#x27;, Time.at(event.get(&#x27;@timestamp&#x27;).to_i).localtime.strftime(&#x27;%Y.%m.%d&#x27;))&quot; &#125; mutate &#123; remove_field =&gt; [ &quot;message&quot; ] &#125;&#125;#输出到esoutput &#123; elasticsearch&#123; hosts =&gt; [&quot;192.168.98.201:9200&quot;] index =&gt; &quot;zutuanxue_node4_mysql-%&#123;+YYYY.MM.dd&#125;&quot; &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 三、kibana展示绘制图表 query_time分布 统计slow日志数量"},{"title":"公众号原点独白","path":"/wiki/stellar/index.html","content":"原点独白是我从2020年开始运营的账号。 转眼间，它就要4岁啦，然后悄悄告诉你们，聊天界面发消息我都可以看的见，快来和我一起聊聊天呗～ 如果你喜欢原点独白的话，希望能把它分享给你的朋友们。 有你们的帮助和支持，原点独白才会走得更远。 期待能够在这里认识更多新面孔。"},{"path":"/images/index.html","content":"如果宇宙中真有什么终极的逻辑，那就是我们终有一天会在舰桥上重逢，直到生命终结。文章项目知识库主站 日常风景点点滴滴"},{"title":"日常","path":"/more/index.html","content":"📖学习心理学与行为科学：《思考，快与慢》(作者：丹尼尔·卡尼曼)、《乌合之众》(作者：古斯塔夫·勒庞)、《影响力》(作者：罗伯特·西奥迪尼)🎶听音乐啦啦啦🏃跑步哈哈哈"},{"title":"关于","path":"/about/index.html","content":"Linux 命令行 学习 Linux 的第一步：当然是从 Linux 命令入手了。 📖 内容 查看 Linux 命令帮助信息 - 关键词：help, whatis, info, which, whereis, man Linux 文件目录管理 - 关键词：cd, ls, pwd, mkdir, rmdir, tree, touch, ln, rename, stat, file, chmod, chown, locate, find, cp, mv, rm Linux 文件内容查看命令 - 关键词：cat, head, tail, more, less, sed, vi, grep Linux 文件压缩和解压 - 关键词：tar, gzip, zip, unzip Linux 用户管理 - 关键词：groupadd, groupdel, groupmod, useradd, userdel, usermod, passwd, su, sudo Linux 系统管理 - 关键词：reboot, exit, shutdown, date, mount, umount, ps, kill, systemctl, service, crontab Linux 网络管理 - 关键词：关键词：curl, wget, telnet, ip, hostname, ifconfig, route, ssh, ssh-keygen, firewalld, iptables, host, nslookup, nc&#x2F;netcat, ping, traceroute, netstat Linux 硬件管理 - 关键词：df, du, top, free, iotop Linux 软件管理 - 关键词：rpm, yum, apt-get 📚 资料 命令行的艺术 Linux命令大全 linux-command 🚪 传送门◾ 💧 钝悟的 IT 知识图谱 ◾ 🎯 钝悟的博客 ◾"}]