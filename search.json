[{"title":"DNS配置","path":"/2023/09/27/dns/DNS配置/","content":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148./configure --prefix=/usr/local/bind/ --with-openssl=/usr/ --sysconfdir=/etc/ --with-libtool --enable-threads--prefix=/usr/local/bind #指定bind9的安装目录,默认是/usr/local--enable-threads #开启多线程的支持；如果你的系统有多个CPU，那么可以使用这个选项--disable-openssl-version-check #关闭openssl的检查--with-openssl=/usr/local/openssl #指定openssl的安装路径--sysconfdir=/etc/ #设置named.conf配置文件放置的目录，默认是--prefix选项指定的目录下的/etc下--localstatdir=/var #设置 run/named.pid 放置的目录，默认是--prefix选项指定的目录下的/var下--with-libtool #BIND的库文件编译为动态共享库文件，这个选项默认是未选择的。 如果不选这个选项，那么编译后的named命令会比较大，lib目录 中的库文件都是.a后缀的 --disable-chroot #禁用chroot，不建议使用，默认开启此功能make &amp;&amp; make install#添加系统变量vi ~/.bash_profilePATH=$PATH:$HOME/bin:/usr/local/bind/bin:/usr/local/bind/bin:/usr/local/bind/sbin #修改本行source ~/.bash_profile #使修改生效 #添加运行用户useradd -r named # -r 添加系统用户#启用chrootmkdir -p /var/named/chroot/&#123;var,etc,dev&#125;mkdir /var/named/chroot/var/run#创建虚拟设备cd /var/named/chroot/devmknod random c 1 8 mknod zero c 1 5 mknod null c 1 3#修改run目录属主chown -R named:named /var/named/chroot/var/run #named 要向run目录写入pid文件#生成rndc.conf ，以便使用rndc命令管理bindrndc-confgen将生成的内容分别写入/etc/named.conf和/etc/rndc.conf #这里在测试中，named.conf是写入chroot之后的etc而rndc.conf写如chroot之后的etc却提示找不到，写入真实的/etc下则正常#创建配置文件vi /var/named/chroot/etc/named.confkey &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;BM+rI8Ra3mpKKtIlYpGEAQ==&quot;; &#125;;controls &#123; inet 127.0.0.1 port 953 allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;options &#123; directory &quot;/var&quot;; pid-file &quot;/var/run/named.pid&quot;; version &quot;bind 9.9.3&quot;; allow-query &#123;any;&#125;; forwarders &#123; #如果想让dns同时可以解析外网，可使用forward功能； 192.168.1.253; &#125;;&#125;;zone &quot;.&quot; IN &#123; type hint; file &quot;named.root&quot;;&#125;;zone &quot;lxy.com&quot; IN &#123; type master; file &quot;named.lxy.com&quot;;&#125;;vi /etc/rndc.confkey &quot;rndc-key&quot; &#123; algorithm hmac-md5; secret &quot;BM+rI8Ra3mpKKtIlYpGEAQ==&quot;;&#125;;options &#123; default-key &quot;rndc-key&quot;; default-server 127.0.0.1; default-port 953;&#125;;#ZONE文件内容：vi /var/named/chroot/var/named.lxy.kk #正解析的zone，如果想让dns可以解析外网，就不要包含.com等合法域，不然在试图解析合法域名的时候服务器会在本地寻找记录，当然是找 不到的，它会告诉你找不到，而不会去向forward请求。$TTL 86400@ IN SOA lxy.kk. root.lxy.kk. ( 2008080804 ; 28800 ; 14400 ; 3600000 ; 86400 ) ;@ IN NS dns.lxy.kk.@ IN MX 10 mail.lxy.kk.dns IN A 192.168.127.129mail IN A 192.168.127.130www IN A 192.168.127.129vi /var/named/chroot/named.127.0.0 #反向解析的zone$TTL 86400@ IN SOA dns.lxy.kk. root.lxy.kk. ( 2008080804 ; 28800 ; 14400 ; 3600000 ; 86400 ) ;@ IN NS dns.lxy.kk.1 IN PTR localhost.#启动服务named -c /etc/named.conf -t /var/named/chroot -u named #注意这里的/etc/实际指的是chroot下的etc,因为已经使用-t指定了chroot到的目录，named将视chroot为根目录#rndcrndc reload | status等","categories":["Linux","DNS"]},{"title":"DHCP配置","path":"/2023/09/26/dhcp/DHCP/","content":"1234567891011121314151617181920212223242526## DHCP Server Configuration file.# see /usr/share/doc/dhcp*/dhcpd.conf.example# see dhcpd.conf(5) man pageddns-update-style interim;ignore client-updates;authoritative;allow booting;allow bootp;allow unknown-clients;# A slightly different configuration for an internal subnet. subnet 192.168.100.0 netmask 255.255.255.0&#123; range 192.168.100.20 192.168.100.80; option domain-name-servers 192.168.100.2; option domain-name &quot;server1.example.com&quot;; option routers 192.168.100.1; option broadcast-address 192.168.100.255; default-lease-time 600; max-lease-time 7200; # PXE SERVER IP next-server 192.168.100.130; # DHCP server ip filename &quot;pxelinux.0&quot;; &#125;","categories":["Linux","DHCP"]},{"title":"MySQL数据库备份mysqldump","path":"/2023/09/25/MySQL数据库备份mysqldump/","content":"@TOC 前言MySQL是一个广泛使用的开源关系型数据库管理系统，可用于存储和管理数据。为了保护数据，我们需要定期备份数据库，以便在数据丢失或损坏时可以恢复数据。在本文中，我将介绍如何使用mysqldump命令来备份MySQL数据库。 一、关于备份热备份和冷备份热备份是指在MySQL服务器运行时进行备份，这种备份方式不会中断MySQL服务器的正常运行。备份过程中，MySQL服务器仍然可以读写数据库。这种备份方式比较简单，适合数据量不是很大的情况。 冷备份是指在MySQL服务器停止运行时进行备份，这种备份方式需要将MySQL服务器停止运行一段时间，等待备份完成后再启动MySQL服务器。这种备份方式适合数据量较大的情况，因为备份时间较长，备份过程中MySQL服务器无法读写数据库。 一般来说，MySQL备份建议使用多种备份方式相结合，比如使用热备份进行备份，使用冷备份进行灾备。 MySQL备份种类 完全备份（Full Backup）：包含数据表、索引、触发器、存储过程、视图、数据文件等所有内容。 增量备份（Incremental Backup）：只包含最近一次完全备份之后修改过的数据，可以快速恢复最新的数据。 差异备份（Differential Backup）：与增量备份类似，只包含最近一次完全备份之后修改过的数据，但可以通过两个差异备份之间的差异进行恢复，更加高效。 压缩备份（Compressed Backup）：通过对数据进行压缩，减少备份文件的大小，便于存储和传输。 远程备份（Remote Backup）：通过网络传输数据到远程服务器，可以实现数据的分布式备份和恢复。 磁盘备份（Disk Backup）：将MySQL数据库文件和配置文件备份到磁盘上，可以实现快速恢复数据，但恢复速度相对较慢。 文件备份（File Backup）：将MySQL数据库文件和配置文件备份到文件中，可以通过网络传输到其他服务器进行恢复。 不同的备份种类适用于不同的场景，需要根据实际情况进行选择。 二、mysqldump使用步骤通常情况下， mysqldump 是 MySQL 内置的备份工具，可以用来备份和导出MySQL数据库。该工具通过生成一个包含数据库中所有表和表结构的SQL脚本文件，从而实现了数据备份和导出的功能。该脚本文件可以被用来还原MySQL数据库，或者在不同的MySQL服务器之间进行迁移。 常见参数mysqldump是MySQL的备份工具，可以将MySQL数据库的结构和数据备份到指定的文件中。使用mysqldump备份MySQL数据库非常方便，以下是一些常用的mysqldump命令和选项： mysqldump命令用于备份MySQL数据库，语法如下 1mysqldump [OPTIONS] DATABASE [TABLE [TABLE ...]] &gt; DUMPFILE 其中，DATABASE是要备份的数据库名，TABLE是要备份的表名，多个表名之间用空格分隔，–skip-opt选项可以忽略优化选项，–all-databases选项可以备份所有数据库。 常用选项： * b：备份二进制日志文件。 * h HOST：备份数据库所在主机的主机名或IP地址。 * u USERNAME：备份数据库所用的用户名。 * p PASSWORD：备份数据库所用的密码。 * r：将备份文件复制到指定的位置。 * t：只备份指定的数据表，而不备份数据表的其他信息，例如索引、触发器等。 * n：只备份表结构，而不备份表的数据。 备份完成后，可以使用mysql命令加上用户名和密码连接到备份的数据库，查看备份文件中包含的内容，例如： 1mysql -u USERNAME -p PASSWORD DATABASE 创建备份文件使用以下命令创建一个名为 backup.sql 的备份文件： 1mysqldump -u root -p your_database_name &gt; backup.sql 其中，root 是 MySQL 的超级用户，your\\_database\\_name 是要备份的数据库名称。\\&gt; backup.sql 是将备份文件写入 backup.sql 文件中。 执行备份命令如果你需要备份多个数据库或者多个表，可以在 mysqldump 命令中指定相应的选项。以下是备份多个数据库的命令示例： 1mysqldump -u root -p -B your_database_name1 your_database_name2 &gt; backup.sql 其中，\\-B 选项表示备份多个数据库。 检查备份文件备份完成后，可以在 backup.sql 文件中查看备份文件的内容。 恢复数据使用以下命令恢复备份文件中的数据： 1mysql -u root -p your_database_name &lt; backup.sql 其中，root 是 MySQL 的超级用户，your\\_database\\_name 是要恢复的数据库名称。&lt; backup.sql 是从备份文件中读取数据。 注意：在执行恢复命令前，一定要确保已经创建了相应的数据库和表。以上就是使用 mysqldump 进行数据备份和恢复的基本教程。 mysqldump –help123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355[root@mysql5_7 ~]# mysqldump --helpmysqldump Ver 10.13 Distrib 5.7.43, for Linux (x86_64)Copyright (c) 2000, 2023, Oracle and/or its affiliates.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Dumping structure and contents of MySQL databases and tables.Usage: mysqldump [OPTIONS] database [tables]OR mysqldump [OPTIONS] --databases [OPTIONS] DB1 [DB2 DB3...]OR mysqldump [OPTIONS] --all-databases [OPTIONS]Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnfThe following groups are read: mysqldump clientThe following options may be given as the first argument:--print-defaults Print the program argument list and exit.--no-defaults Don&#x27;t read default options from any option file, except for login file.--defaults-file=# Only read default options from the given file #.--defaults-extra-file=# Read this file after the global files are read.--defaults-group-suffix=# Also read groups with concat(group, suffix)--login-path=# Read this path from the login file. -A, --all-databases Dump all the databases. This will be same as --databases with all databases selected. -Y, --all-tablespaces Dump all the tablespaces. -y, --no-tablespaces Do not dump any tablespace information. --add-drop-database Add a DROP DATABASE before each create. --add-drop-table Add a DROP TABLE before each create. (Defaults to on; use --skip-add-drop-table to disable.) --add-drop-trigger Add a DROP TRIGGER before each create. --add-locks Add locks around INSERT statements. (Defaults to on; use --skip-add-locks to disable.) --allow-keywords Allow creation of column names that are keywords. --apply-slave-statements Adds &#x27;STOP SLAVE&#x27; prior to &#x27;CHANGE MASTER&#x27; and &#x27;START SLAVE&#x27; to bottom of dump. --bind-address=name IP address to bind to. --character-sets-dir=name Directory for character set files. -i, --comments Write additional information. (Defaults to on; use --skip-comments to disable.) --compatible=name Change the dump to be compatible with a given mode. By default tables are dumped in a format optimized for MySQL. Legal modes are: ansi, mysql323, mysql40, postgresql, oracle, mssql, db2, maxdb, no_key_options, no_table_options, no_field_options. One can use several modes separated by commas. Note: Requires MySQL server version 4.1.0 or higher. This option is ignored with earlier server versions. --compact Give less verbose output (useful for debugging). Disables structure comments and header/footer constructs. Enables options --skip-add-drop-table --skip-add-locks --skip-comments --skip-disable-keys --skip-set-charset. -c, --complete-insert Use complete insert statements. -C, --compress Use compression in server/client protocol. -a, --create-options Include all MySQL specific create options. (Defaults to on; use --skip-create-options to disable.) -B, --databases Dump several databases. Note the difference in usage; in this case no tables are given. All name arguments are regarded as database names. &#x27;USE db_name;&#x27; will be included in the output. -#, --debug[=#] This is a non-debug version. Catch this and exit. --debug-check This is a non-debug version. Catch this and exit. --debug-info This is a non-debug version. Catch this and exit. --default-character-set=name Set the default character set. --delete-master-logs Delete logs on master after backup. This automatically enables --master-data. -K, --disable-keys &#x27;/*!40000 ALTER TABLE tb_name DISABLE KEYS */; and &#x27;/*!40000 ALTER TABLE tb_name ENABLE KEYS */; will be put in the output. (Defaults to on; use --skip-disable-keys to disable.) --dump-slave[=#] This causes the binary log position and filename of the master to be appended to the dumped data output. Setting the value to 1, will printit as a CHANGE MASTER command in the dumped data output; if equal to 2, that command will be prefixed with a comment symbol. This option will turn --lock-all-tables on, unless --single-transaction is specified too (in which case a global read lock is only taken a short time at the beginning of the dump - don&#x27;t forget to read about --single-transaction below). In all cases any action on logs will happen at the exact moment of the dump.Option automatically turns --lock-tables off. -E, --events Dump events. -e, --extended-insert Use multiple-row INSERT syntax that include several VALUES lists. (Defaults to on; use --skip-extended-insert to disable.) --fields-terminated-by=name Fields in the output file are terminated by the given string. --fields-enclosed-by=name Fields in the output file are enclosed by the given character. --fields-optionally-enclosed-by=name Fields in the output file are optionally enclosed by the given character. --fields-escaped-by=name Fields in the output file are escaped by the given character. -F, --flush-logs Flush logs file in server before starting dump. Note that if you dump many databases at once (using the option --databases= or --all-databases), the logs will be flushed for each database dumped. The exception is when using --lock-all-tables or --master-data: in this case the logs will be flushed only once, corresponding to the moment all tables are locked. So if you want your dump and the log flush to happen at the same exact moment you should use --lock-all-tables or --master-data with --flush-logs. --flush-privileges Emit a FLUSH PRIVILEGES statement after dumping the mysql database. This option should be used any time the dump contains the mysql database and any other database that depends on the data in the mysql database for proper restore. -f, --force Continue even if we get an SQL error. -?, --help Display this help message and exit. --hex-blob Dump binary strings (BINARY, VARBINARY, BLOB) in hexadecimal format. -h, --host=name Connect to host. --ignore-error=name A comma-separated list of error numbers to be ignored if encountered during dump. --ignore-table=name Do not dump the specified table. To specify more than one table to ignore, use the directive multiple times, once for each table. Each table must be specified with both database and table names, e.g., --ignore-table=database.table. --include-master-host-port Adds &#x27;MASTER_HOST=&lt;host&gt;, MASTER_PORT=&lt;port&gt;&#x27; to &#x27;CHANGE MASTER TO..&#x27; in dump produced with --dump-slave. --insert-ignore Insert rows with INSERT IGNORE. --lines-terminated-by=name Lines in the output file are terminated by the given string. -x, --lock-all-tables Locks all tables across all databases. This is achieved by taking a global read lock for the duration of the whole dump. Automatically turns --single-transaction and --lock-tables off. -l, --lock-tables Lock all tables for read. (Defaults to on; use --skip-lock-tables to disable.) --log-error=name Append warnings and errors to given file. --master-data[=#] This causes the binary log position and filename to be appended to the output. If equal to 1, will print it as a CHANGE MASTER command; if equal to 2, that command will be prefixed with a comment symbol. This option will turn --lock-all-tables on, unless --single-transaction is specified too (in which case a global read lock is only taken a short time at the beginning of the dump; don&#x27;t forget to read about --single-transaction below). In all cases, any action on logs will happen at the exact moment of the dump. Option automatically turns --lock-tables off. --max-allowed-packet=# The maximum packet length to send to or receive from server. --net-buffer-length=# The buffer size for TCP/IP and socket communication. --no-autocommit Wrap tables with autocommit/commit statements. -n, --no-create-db Suppress the CREATE DATABASE ... IF EXISTS statement that normally is output for each dumped database if --all-databases or --databases is given. -t, --no-create-info Don&#x27;t write table creation info. -d, --no-data No row information. -N, --no-set-names Same as --skip-set-charset. --opt Same as --add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, and --disable-keys. Enabled by default, disable with --skip-opt. --order-by-primary Sorts each table&#x27;s rows by primary key, or first unique key, if such a key exists. Useful when dumping a MyISAM table to be loaded into an InnoDB table, but will make the dump itself take considerably longer. -p, --password[=name] Password to use when connecting to server. If password is not given it&#x27;s solicited on the tty. -P, --port=# Port number to use for connection. --protocol=name The protocol to use for connection (tcp, socket, pipe, memory). -q, --quick Don&#x27;t buffer query, dump directly to stdout. (Defaults to on; use --skip-quick to disable.) -Q, --quote-names Quote table and column names with backticks (`). (Defaults to on; use --skip-quote-names to disable.) --replace Use REPLACE INTO instead of INSERT INTO. -r, --result-file=name Direct output to a given file. This option should be used in systems (e.g., DOS, Windows) that use carriage-return linefeed pairs (\\r ) to separate text lines. This option ensures that only a single newline is used. -R, --routines Dump stored routines (functions and procedures). --set-charset Add &#x27;SET NAMES default_character_set&#x27; to the output. (Defaults to on; use --skip-set-charset to disable.) --set-gtid-purged[=name] Add &#x27;SET @@GLOBAL.GTID_PURGED&#x27; to the output. Possible values for this option are ON, OFF and AUTO. If ON is used and GTIDs are not enabled on the server, an error is generated. If OFF is used, this option does nothing. If AUTO is used and GTIDs are enabled on the server, &#x27;SET @@GLOBAL.GTID_PURGED&#x27; is added to the output. If GTIDs are disabled, AUTO does nothing. If no value is supplied then the default (AUTO) value will be considered. --single-transaction Creates a consistent snapshot by dumping all tables in a single transaction. Works ONLY for tables stored in storage engines which support multiversioning (currently only InnoDB does); the dump is NOT guaranteed to be consistent for other storage engines. While a --single-transaction dump is in process, to ensure a valid dump file (correct table contents and binary log position), no other connection should use the following statements: ALTER TABLE, DROP TABLE, RENAME TABLE, TRUNCATE TABLE, as consistent snapshot is not isolated from them. Option automatically turns off --lock-tables. --dump-date Put a dump date to the end of the output. (Defaults to on; use --skip-dump-date to disable.) --skip-mysql-schema Skip adding DROP DATABASE for mysql schema. --skip-opt Disable --opt. Disables --add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, and --disable-keys. -S, --socket=name The socket file to use for connection. --secure-auth Refuse client connecting to server if it uses old (pre-4.1.1) protocol. Deprecated. Always TRUE --ssl-mode=name SSL connection mode. --ssl Deprecated. Use --ssl-mode instead. (Defaults to on; use --skip-ssl to disable.) --ssl-verify-server-cert Deprecated. Use --ssl-mode=VERIFY_IDENTITY instead. --ssl-ca=name CA file in PEM format. --ssl-capath=name CA directory. --ssl-cert=name X509 cert in PEM format. --ssl-cipher=name SSL cipher to use. --ssl-key=name X509 key in PEM format. --ssl-crl=name Certificate revocation list. --ssl-crlpath=name Certificate revocation list path. --tls-version=name TLS version to use, permitted values are: TLSv1, TLSv1.1, TLSv1.2 --server-public-key-path=name File path to the server public RSA key in PEM format. --get-server-public-key Get server public key -T, --tab=name Create tab-separated textfile for each table to given path. (Create .sql and .txt files.) NOTE: This only works if mysqldump is run on the same machine as the mysqld server. --tables Overrides option --databases (-B). --triggers Dump triggers for each dumped table. (Defaults to on; use --skip-triggers to disable.) --tz-utc SET TIME_ZONE=&#x27;+00:00&#x27; at top of dump to allow dumping of TIMESTAMP data when a server has data in different time zones or data is being moved between servers with different time zones. (Defaults to on; use --skip-tz-utc to disable.) -u, --user=name User for login if not current user. -v, --verbose Print info about the various stages. -V, --version Output version information and exit. -w, --where=name Dump only selected records. Quotes are mandatory. -X, --xml Dump a database as well formed XML. --plugin-dir=name Directory for client-side plugins. --default-auth=name Default authentication client-side plugin to use. --enable-cleartext-plugin Enable/disable the clear text authentication plugin.Variables (--variable-name=value)and boolean options &#123;FALSE|TRUE&#125; Value (after reading options)--------------------------------- ----------------------------------------all-databases FALSEall-tablespaces FALSEno-tablespaces FALSEadd-drop-database FALSEadd-drop-table TRUEadd-drop-trigger FALSEadd-locks TRUEallow-keywords FALSEapply-slave-statements FALSEbind-address (No default value)character-sets-dir (No default value)comments TRUEcompatible (No default value)compact FALSEcomplete-insert FALSEcompress FALSEcreate-options TRUEdatabases FALSEdefault-character-set utf8delete-master-logs FALSEdisable-keys TRUEdump-slave 0events FALSEextended-insert TRUEfields-terminated-by (No default value)fields-enclosed-by (No default value)fields-optionally-enclosed-by (No default value)fields-escaped-by (No default value)flush-logs FALSEflush-privileges FALSEforce FALSEhex-blob FALSEhost (No default value)ignore-error (No default value)include-master-host-port FALSEinsert-ignore FALSElines-terminated-by (No default value)lock-all-tables FALSElock-tables TRUElog-error (No default value)master-data 0max-allowed-packet 25165824net-buffer-length 1046528no-autocommit FALSEno-create-db FALSEno-create-info FALSEno-data FALSEorder-by-primary FALSEport 0quick TRUEquote-names TRUEreplace FALSEroutines FALSEset-charset TRUEsingle-transaction FALSEdump-date TRUEskip-mysql-schema FALSEsocket (No default value)secure-auth TRUEssl TRUEssl-verify-server-cert FALSEssl-ca (No default value)ssl-capath (No default value)ssl-cert (No default value)ssl-cipher (No default value)ssl-key (No default value)ssl-crl (No default value)ssl-crlpath (No default value)tls-version (No default value)server-public-key-path (No default value)get-server-public-key FALSEtab (No default value)triggers TRUEtz-utc TRUEuser (No default value)verbose FALSEwhere (No default value)plugin-dir (No default value)default-auth (No default value)enable-cleartext-plugin FALSE 总结本文介绍了使用mysqldump命令备份MySQL数据库的方法和步骤。mysqldump是MySQL的备份工具，可以备份整个MySQL数据库或者单个表。备份种类包括完全备份、增量备份、差异备份、压缩备份、远程备份、磁盘备份和文件备份。文章详细介绍了安装mysqldump、创建备份文件、执行备份命令、检查备份文件和恢复数据的步骤。备份完成后，可以查看备份文件的内容，并使用mysql命令恢复备份文件中的数据。文章最后总结了使用mysqldump备份和恢复MySQL数据库的基本教程。"},{"title":"Linux下命令find命令文件查找","path":"/2023/09/25/Linux下命令find命令文件查找/","content":"我自风情万种，何必与世相争；我自心清如水，又何须为烦恼所困？ @TOC 前言find命令是Linux系统中的一个常用命令，用于在指定的目录中查找符合条件的文件或目录。 一、find 命令使用介绍find 命令是 Linux 和 Unix 系统中常用的文件查找工具。它可以在指定目录及其子目录中查找符合指定条件的文件或目录，并将结果输出到终端。find 命令的语法如下： find [path] [expression] 其中： path：查找的起始目录，可以是绝对路径或相对路径。如果不指定 path，则默认从当前目录开始查找。 expression：用来指定查找的条件，可以是一些简单的逻辑运算符（如 \\-name, \\-type, \\-size, \\-mtime, \\-user, \\-group 等），也可以是一些复杂的文件名匹配模式（如通配符 \\*、?、\\[ \\] 等）。 \\-name：指定文件名模式，如 \\*.txt 表示查找所有以 .txt 结尾的文件。 \\-type：指定文件类型，如 \\-type f 表示查找所有文件，\\-type d 表示查找所有目录。 \\-size：指定文件大小范围，如 \\-size +10M 表示查找所有大小大于 10M 的文件。 \\-mtime：指定文件修改时间范围，如 \\-mtime -7 表示查找所有最近 7 天内修改过的文件。 \\-user：指定文件所有者，如 \\-user haoze表示查找所有所有者为 haoze 的文件。 \\-group：指定文件所属组，如 \\-group example 表示查找所有所属组为 example 的文件。 以下是一些示例： .代表的是相对路径当前目录，相对路径与绝对的路径的区别可以理解为在 Linux中凡是以&#x2F;开头的目录均为绝对路径 查找当前目录及其子目录中所有以 .txt 结尾的文件：1find . -name &quot;*.txt&quot; 查找当前目录及其子目录中所有文件大小大于 1M 的文件：1find . -type f -size +1M 查找当前目录及其子目录中所有修改时间在最近 7 天内的文件： 1find . -type f -mtime -7 查找当前目录及其子目录中所有所属组为 example 的文件： 1find . -group example 以上为 find 命令的基本用法，还有很多高级用法可以查阅官方文档了解。 二、Linux文件权限4位数含义 普通权限： image RWX对应的权限是： r:4 w:2 x:1， 所以777就代表 rwxrwxrwx 12345678910[root@server /]# ls -l | head -5total 32lrwxrwxrwx. 1 root root 7 Jul 2 14:51 bin -&gt; usr/bin#777权限dr-xr-xr-x. 5 root root 4096 Jul 2 14:53 boot#555权限drwxr-xr-x 20 root root 3240 Aug 9 16:08 dev#755权限drwxr-xr-x. 77 root root 8192 Aug 9 16:08 etc#755权限 高级权限 suid,sgid,sticky 0777最前面的0，代表高级权限suid,sgid,sticky分为属主权限、属组权限、其他人权限suid:0变为4、guid:0变为2、sticky:0变为1suid, sgid和sticky是Linux系统中用于限制文件和目录的用户和组的三种权限。 suid权限 suid权限是指文件或目录可以使其他用户以执行命令的方式来使用它们。当文件具有suid权限时，文件的所有者可以将文件或目录赋予其他用户，这些用户可以以root用户的身份来执行该文件或目录。 suid权限可以通过在文件上运行chmod +s命令来设置。例如，下面的命令将file.txt文件设置为具有suid权限： 123456[root@mysql5_7 ~]# ls -l file.txt-rw-r--r-- 1 root root 0 Aug 9 20:33 file.txt #初始权限[root@mysql5_7 ~]# chmod u+s file.txt[root@mysql5_7 ~]# ll file.txt-rwSr--r-- 1 root root 0 Aug 9 20:33 file.txt #可以看到多了个s权限 [root@mysql5_7 ~]# chmod u-s file.txt #取消权限 sgid权限 sgid权限是指文件或目录的所有者和组可以使用它们。如果没有写权限, 则这个目录下的所有文件都不能被删除, 同时也不能添加新的文件. 如果希望用户能够添加文件但同时不能删除文件 sgid权限可以通过在文件上运行chmod +s命令来设置。例如，下面的命令将file.txt文件设置为具有sgid权限： 1234[root@mysql5_7 ~]# chmod g+s file.txt[root@mysql5_7 ~]# ll file.txt-rw-r-Sr-- 1 root root 0 Aug 9 20:33 file.txt[root@mysql5_7 ~]# chmod g-s file.txt sticky权限 sticky权限是指只有文件或目录的拥有者和组用户才能进行写操作。当文件或目录具有sticky权限时，只有文件或目录的拥有者和组用户才能在文件或目录上进行写操作。其他用户可以读取和执行该文件或目录，但无法进行写操作。 设置该位后， 就算用户对目录具有写权限，也不能删除该文件。 sticky权限可以通过在文件上运行chmod +t命令来设置。例如，下面的命令将file.txt文件设置为具有sticky权限： 1234[root@mysql5_7 ~]# chmod o+t file.txt[root@mysql5_7 ~]# ll file.txt-rw-r--r-T 1 root root 0 Aug 9 20:33 file.txt[root@mysql5_7 ~]# chmod o-t file.txt 总结本文介绍了Linux系统中常用的find命令的使用介绍以及高级用法，同时解释了Linux文件权限4位数的含义，包括普通权限、高级权限suid、sgid和sticky，以及如何设置它们。find命令可以在指定目录及其子目录中查找符合指定条件的文件或目录，并将结果输出到终端。通过对命令语法和常用示例的介绍，可以更好地了解和运用find命令。","categories":["Linux","基础操作"]},{"title":"Linux文件权限策略setfacl命令","path":"/2023/09/25/Linux文件权限策略setfacl命令/","content":"“春风得意马蹄疾，一日看尽长安花。” ——《登高》 杜甫 @toc 前言Linux的文件权限策略使用setfacl命令来管理的。setfacl命令允许用户在文件和目录上添加、删除和修改权限。它可以根据用户、组、用户组和其他条件来定义文件和目录的权限。 命令语法setfacl命令的语法如下： 1[root@mysql5_7 ~]# setfacl -m user:username permissions file/directory 其中，-m选项用于添加或修改权限，user:username表示要授予权限的用户名，permissions表示要授予或修改的权限。 例如，如果要授予用户 test读、写和执行权限，可以使用以下命令： 1setfacl -m user:test:rwx file.txt 要列出当前文件和目录的所有权限，可以使用 getfacl 命令： 1234567[root@mysql5_7 ~]# getfacl file.txt# file: file.txt# owner: root# group: rootuser::rw-group::r--other::r-- 这将列出file.txt文件的所有权限，并将它们打印到终端上。 操作案例创建了一个名为test的用户。 1[root@mysql5_7 ~]# useradd test 使用getfacl命令查看file.txt文件的ACL权限。 1234567[root@mysql5_7 ~]# getfacl file.txt# file: file.txt# owner: root# group: rootuser::rw-group::r--other::r-- 使用setfacl命令将test用户添加到file.txt文件的ACL权限中，并赋予读写权限。 1[root@mysql5_7 ~]# setfacl -m user:test:rw file.txt 使用echo命令并通过管道方式将密码”123456”传递给passwd命令，将test用户的密码更改为”123456”。 123[root@mysql5_7 ~]# echo &quot;123456&quot; | passwd --stdin testChanging password for user test.passwd: all authentication tokens updated successfully. 使用ls -l命令查看file.txt文件的详细权限信息。 12[root@mysql5_7 ~]# ls -l file.txt-rw-rw-r--+ 1 root root 0 Aug 9 20:33 file.txt 使用chmod命令将file.txt文件的权限修改为只有root用户有访问权限。 12[root@mysql5_7 ~]# chmod 000 file.txt 使用ls -l命令再次查看file.txt文件的详细权限信息。 12[root@mysql5_7 ~]# ls -l file.txt----------+ 1 root root 0 Aug 9 20:33 file.txt 使用su命令切换到test用户。 123[root@mysql5_7 ~]# su test[test@mysql5_7 root]$ lsls: cannot open directory .: Permission denied 尝试使用ls命令查看根目录下的文件，但因权限不足而失败。 使用usermod命令将test用户添加到wheel组（提权）。 1[root@mysql5_7 /]# usermod test -G wheel 使用echo命令将”1234567”写入file.txt文件。 1[test@mysql5_7 /]$ echo &quot;1234567&quot; &gt; file.txt 使用cat命令查看file.txt文件的内容。 12[test@mysql5_7 /]$ cat file.txt1234567 创建了一个名为test2的用户。 1234[root@mysql5_7 /]# useradd test2[root@mysql5_7 /]# echo &quot;123456&quot; | passwd --stdin test2Changing password for user test2.passwd: all authentication tokens updated successfully. 使用ls -l命令查看file.txt文件的详细权限信息，发现已经对其他用户进行了限制。 12345678[test2@mysql5_7 /]$ ls -l file.txt----rwx---+ 1 root root 8 Aug 11 23:41 file.txt[test2@mysql5_7 /]$ vim file.txt[test2@mysql5_7 /]$ cat file.txtcat: file.txt: Permission denied[test2@mysql5_7 /]$ echo &quot;12334&quot; &gt; file.txtbash: file.txt: Permission denied[test2@mysql5_7 /]$ 使用vim命令尝试编辑file.txt文件，但因权限不足而失败。 使用cat命令尝试查看file.txt文件的内容，但因权限不足而失败。 使用echo命令尝试向file.txt文件写入内容，但因权限不足而失败 删除 test 用户，策略也会相应地被删除 123456789101112[root@mysql5_7 /]# userdel -r test[root@mysql5_7 /]# getfacl file.txt# file: file.txt# owner: root# group: rootuser::---user:1000:rwxgroup::r--mask::rwxother::---# 可以看到用户策略消失了 要删除所有权限，可以使用以下命令： 1setfacl -u username:username file.txt 其中，-u选项用于删除权限。 除了-m选项之外，setfacl命令还可以使用其他选项来指定其他权限和条件。有关setfacl命令的完整语法和选项 123456789101112131415161718192021[root@mysql5_7 ~]# setfacl --helpsetfacl 2.2.51 -- set file access control listsUsage: setfacl [-bkndRLP] &#123; -m|-M|-x|-X ... &#125; file ... -m, --modify=acl modify the current ACL(s) of file(s) -M, --modify-file=file read ACL entries to modify from file -x, --remove=acl remove entries from the ACL(s) of file(s) -X, --remove-file=file read ACL entries to remove from file -b, --remove-all remove all extended ACL entries -k, --remove-default remove the default ACL --set=acl set the ACL of file(s), replacing the current ACL --set-file=file read ACL entries to set from file --mask do recalculate the effective rights mask -n, --no-mask don&#x27;t recalculate the effective rights mask -d, --default operations apply to the default ACL -R, --recursive recurse into subdirectories -L, --logical logical walk, follow symbolic links -P, --physical physical walk, do not follow symbolic links --restore=file restore ACLs (inverse of `getfacl -R&#x27;) --test test mode (ACLs are not modified) -v, --version print version and exit -h, --help this help text 总结本文介绍了Linux中使用setfacl命令来管理文件和目录的权限策略。setfacl命令允许用户添加、删除和修改文件和目录的权限，并根据用户、组、用户组和其他条件来定义权限。文章给出了setfacl命令的语法和示例，以及如何使用getfacl命令列出当前文件和目录的所有权限，并使用setfacl -u username:username命令删除所有权限。此外，文章还提到了setfacl命令的其他选项和完整语法。要了解更多相关信息，请参阅Linux文档或相关文档。","categories":["Linux","基础操作"]},{"title":"Linux中/etc/issue、/etc/motd文件","path":"/2023/09/25/Linux中motd文件/","content":"@TOC 前言在Linux操作系统中，/etc/issue和/etc/motd文件都是系统管理员可以使用来显示系统信息和欢迎信息的关键文件。这些文件通常位于&#x2F;etc目录中，是用户在登录时第一个看到的内容。&#x2F;etc&#x2F;issue文件提供了一些基本的系统信息，例如操作系统名称、版本号、内核版本等。而&#x2F;etc&#x2F;motd文件则通常包含了一些系统管理员可以添加的欢迎信息、系统安全提示或者重要公告等。这些文件对于系统的安全性、稳定性和可用性都有很大的影响，因此系统管理员需要对它们进行适当的配置和维护。 登录前欢迎语&#x2F;etc&#x2F;issue文件用来显示Linux系统的基本信息，例如发行版本、内核版本、安装日期等。当用户登录到Linux系统时，该文件将被用来显示欢迎信息。 实验 [root@mysql5_7 ~]# vim /etc/issue \\S Kernel \\r on an \\m \\d &lt;Welcome to Mysql.server&gt; :wq #保存退出 测试，这个需要系统登录看，用远程工具看不到 image 以下是&#x2F;etc&#x2F;issue文件的一些常见选项说明： 12345678910111213141516171819 ：换行符，用于在欢迎信息中添加新行。\\l：显示本地终端设备名称。\\m：显示计算机的硬件架构。\\s：显示操作系统的名称。\\r：显示内核的版本号。\\t：显示当前时间。\\u：显示当前用户名。\\v：显示操作系统的发行版本号。\\\\：显示反斜杠字符。其他自定义文本：可以在文件中添加其他自定义文本或标记。 使用这些选项，你可以根据需要定制并个性化系统登录时的欢迎信息。例如，可以使用\\s和\\v选项来显示操作系统的名称和发行版本号，\\l选项来显示本地终端设备名称，以及\\t选项来显示当前时间等。 登录后欢迎语&#x2F;etc&#x2F;motd文件用来显示Linux系统的欢迎信息。当用户第一次登录到Linux系统时，该文件将被用来显示欢迎信息。 实验 [root@mysql5_7 ~]# vim /etc/motd &quot;Welcome to MySql.server &quot; :wq #保存退出 测试，可以看到成功了 image 总结这篇文章讨论了Linux系统中&#x2F;etc&#x2F;issue和&#x2F;etc&#x2F;motd文件的作用。&#x2F;etc&#x2F;issue文件用来显示Linux系统的基本信息，例如发行版本、内核版本和安装日期等，在用户登录前会显示欢迎信息。&#x2F;etc&#x2F;motd文件则用来显示Linux系统的欢迎信息，在用户第一次登录后会显示该文件中的内容。","categories":["Linux","基础操作"]},{"title":"Linux 磁盘挂载","path":"/2023/09/25/Linux 磁盘挂载方式/","content":"人生自是有情痴，此恨不关风与月。 @[TOC](Linux 磁盘挂载) 一、Linux 磁盘自动挂载首先为虚拟机添加几块磁盘作为实验备用 在这里插入图片描述 添加磁盘后使用lsblk命令进行查看 [root@disk ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 60G 0 disk ├─sda1 8:1 0 500M 0 part /boot └─sda2 8:2 0 59.5G 0 part ├─centos-root 253:0 0 38.6G 0 lvm / ├─centos-swap 253:1 0 2G 0 lvm [SWAP] └─centos-home 253:2 0 18.9G 0 lvm /home sr0 11:0 1 4G 0 rom [root@disk ~]# 可以看到磁盘未加载，使用万能的重启大法reboot,init 6,shutdown -r now等，重启虚拟机即可,重启完毕后可以看到新添加的硬盘已经加载好了 [root@disk ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 60G 0 disk ├─sda1 8:1 0 500M 0 part /boot └─sda2 8:2 0 59.5G 0 part ├─centos-root 253:0 0 38.6G 0 lvm / ├─centos-swap 253:1 0 2G 0 lvm [SWAP] └─centos-home 253:2 0 18.9G 0 lvm /home sdb 8:16 0 60G 0 disk sdc 8:32 0 60G 0 disk sdd 8:48 0 60G 0 disk sr0 11:0 1 1024M 0 rom 使用 fdisk进行分区 [root@disk ~]# fdisk /dev/sdb Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Device does not contain a recognized partition table Building a new DOS disklabel with disk identifier 0x1d66e12e. Command (m for help): p Disk /dev/sdb: 64.4 GB, 64424509440 bytes, 125829120 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x1d66e12e Device Boot Start End Blocks Id System Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p Partition number (1-4, default 1): First sector (2048-125829119, default 2048): Using default value 2048 Last sector, +sectors or +size&#123;K,M,G&#125; (2048-125829119, default 125829119): Using default value 125829119 Partition 1 of type Linux and of size 60 GiB is set Command (m for help): p Disk /dev/sdb: 64.4 GB, 64424509440 bytes, 125829120 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x1d66e12e Device Boot Start End Blocks Id System /dev/sdb1 2048 125829119 62913536 83 Linux Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. 根目录下创建了一个名为&#x2F;mnt&#x2F;sdb的目录，并对&#x2F;dev&#x2F;sdb1进行了ext4文件系统格式化。 文件系统类型：ext4 [root@disk ~]# mkdir /mnt/sdb [root@disk ~]# mkfs.ext4 /dev/sdb1 mke2fs 1.42.9 (28-Dec-2013) Filesystem label= OS type: Linux Block size=4096 (log=2) Fragment size=4096 (log=2) Stride=0 blocks, Stripe width=0 blocks 3932160 inodes, 15728384 blocks 786419 blocks (5.00%) reserved for the super user First data block=0 Maximum filesystem blocks=2164260864 480 block groups 32768 blocks per group, 32768 fragments per group 8192 inodes per group Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424 Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): done Writing superblocks and filesystem accounting information: done 配置&#x2F;etc&#x2F;fstab文件实现开机自动挂载 在配置文件/etc/fstab后追加/dev/sdb1 /mnt/sdb ext4 defaults 0 0 [root@disk ~]# vim /etc/fstab # # /etc/fstab # Created by anaconda on Sun Jul 2 14:40:36 2023 # # Accessible filesystems, by reference, are maintained under &#39;/dev/disk&#39; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=8f90bf6f-fc6f-47e6-938e-d53602078619 /boot xfs defaults 0 0 /dev/mapper/centos-home /home xfs defaults 0 0 /dev/mapper/centos-swap swap swap defaults 0 0 /dev/sdb1 /mnt/sdb ext4 defaults 0 0 参数解释： 第1列:挂载设备 (1)/dev/sda5 (2)UUID=设备的uuid rhel6/7的默认写法 同一台机器内唯一的一个设备标识 第2列:挂载点 第3列:文件系统类型 第4列:文件系统属性 第5列:是否对文件系统进行磁带备份：0 不备份 第6列:是否检查文件系统：0 不检查 使用 mount 命令挂载 [root@disk ~]# mount /dev/sdb1 /mnt/sdb/ [root@disk ~]# mount -a #开机自动挂载 二、根目录扩容首先，使用lsblk命令查看当前系统的磁盘和分区情况。 [root@server /]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm [SWAP] sdb 8:16 0 20G 0 disk ├─sdb1 8:17 0 5G 0 part /mnt/sdb1 ├─sdb2 8:18 0 5G 0 part /mnt/sdb2 ├─sdb3 8:19 0 5G 0 part /mnt/sdb3 ├─sdb4 8:20 0 1K 0 part └─sdb5 8:21 0 5G 0 part /mnt/sdb5 sdc 8:32 0 20G 0 disk └─sdc1 8:33 0 2G 0 part [SWAP] sdd 8:48 0 20G 0 disk sde 8:64 0 20G 0 disk └─vg2-lv2 253:2 0 26G 0 lvm /mnt/lv2 sdf 8:80 0 20G 0 disk └─vg1-lv1 253:3 0 1G 0 lvm sdg 8:96 0 20G 0 disk └─vg2-lv2 253:2 0 26G 0 lvm /mnt/lv2 sdh 8:112 0 20G 0 disk sr0 11:0 1 4.4G 0 rom 确认需要扩容的根分区所在的逻辑卷名称和卷组名称。根据示例中的输出，根分区的逻辑卷名称是centos-root，卷组名称是centos。 [root@server /]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- &lt;17.00g swap centos -wi-ao---- 2.00g lv1 vg1 -wi-a----- 1.00g lv2 vg2 -wi-ao---- 26.00g [root@server /]# pvcreate /dev/sdd Physical volume &quot;/dev/sdd&quot; successfully created. [root@server /]# vgextend centos /dev/sdd Volume group &quot;centos&quot; successfully extended 使用lvextend命令对逻辑卷进行扩容。例如，要将根分区扩容15GB，可以执行以下命令：lvextend -L +15G /dev/centos/root [root@server /]# vgs VG #PV #LV #SN Attr VSize VFree centos 2 2 0 wz--n- 38.99g &lt;20.00g vg1 1 1 0 wz--n- &lt;20.00g &lt;19.00g vg2 2 1 0 wz--n- 39.99g 13.99g [root@server /]# lvextend -L +15G /dev/centos/root Size of logical volume centos/root changed from &lt;17.00 GiB (4351 extents) to &lt;32.00 GiB (8191 extents). Logical volume centos/root successfully resized. 扩容完成后，使用df -Th命令检查根分区的大小是否已经扩容。 [root@server /]# df -Th Filesystem Type Size Used Avail Use% Mounted on devtmpfs devtmpfs 974M 0 974M 0% /dev tmpfs tmpfs 991M 0 991M 0% /dev/shm tmpfs tmpfs 991M 11M 980M 2% /run tmpfs tmpfs 991M 0 991M 0% /sys/fs/cgroup /dev/mapper/centos-root xfs 17G 5.7G 12G 34% / /dev/sdb3 ext4 4.8G 20M 4.6G 1% /mnt/sdb3 /dev/sdb1 ext4 4.8G 20M 4.6G 1% /mnt/sdb1 /dev/sdb2 ext4 4.8G 20M 4.6G 1% /mnt/sdb2 /dev/sdb5 ext4 4.8G 20M 4.6G 1% /mnt/sdb5 /dev/sda1 xfs 1014M 213M 802M 21% /boot tmpfs tmpfs 199M 12K 199M 1% /run/user/42 tmpfs tmpfs 199M 0 199M 0% /run/user/0 /dev/mapper/vg2-lv2 ext4 26G 45M 25G 1% /mnt/lv2 如果根分区是XFS文件系统，还需要执行xfs_growfs命令来调整文件系统大小。例如，执行以下命令：xfs_growfs /dev/centos/root [root@server /]# xfs_growfs /dev/centos/root meta-data=/dev/mapper/centos-root isize=512 agcount=4, agsize=1113856 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=4455424, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 4455424 to 8387584 使用df -Th命令再次检查根分区的大小，确保扩容操作已成功完成。 [root@server /]# df -Th Filesystem Type Size Used Avail Use% Mounted on devtmpfs devtmpfs 974M 0 974M 0% /dev tmpfs tmpfs 991M 0 991M 0% /dev/shm tmpfs tmpfs 991M 11M 980M 2% /run tmpfs tmpfs 991M 0 991M 0% /sys/fs/cgroup /dev/mapper/centos-root xfs 32G 5.7G 27G 18% / /dev/sdb3 ext4 4.8G 20M 4.6G 1% /mnt/sdb3 /dev/sdb1 ext4 4.8G 20M 4.6G 1% /mnt/sdb1 /dev/sdb2 ext4 4.8G 20M 4.6G 1% /mnt/sdb2 /dev/sdb5 ext4 4.8G 20M 4.6G 1% /mnt/sdb5 /dev/sda1 xfs 1014M 213M 802M 21% /boot tmpfs tmpfs 199M 12K 199M 1% /run/user/42 tmpfs tmpfs 199M 0 199M 0% /run/user/0 /dev/mapper/vg2-lv2 ext4 26G 45M 25G 1% /mnt/lv2 三、添加交换分区使用dd工具将/dev/zero设备中的内容写入到/mnt/swap.iso文件中，写入的块大小为1GB，总共写入1个块。 这个命令的目的是创建一个1GB大小的名为swap.iso的文件，并将其写入到/mnt目录下。/dev/zero是一个特殊的文件，读取它会返回无限的空字节。通过将其内容写入到文件中，相当于创建了一个全是0的文件。 [root@disk ~]# dd if=/dev/zero of=/mnt/swap.iso bs=1G count=1 1+0 records in 1+0 records out 1073741824 bytes (1.1 GB) copied, 12.4315 s, 86.4 MB/s 通常情况下，这样的操作是为了创建一个临时的交换文件（swap file），用于作为交换分区（swap partition）的替代品，用于虚拟内存的扩展。 [root@disk ~]# mkswap /mnt/swap.iso Setting up swapspace version 1, size = 1048572 KiB no label, UUID=084d2529-f7ac-49c1-9d07-2ad6da7410df [root@disk ~]# vim /etc/fstab /mnt/swap.iso swap swap defaults 0 0 [root@disk ~]# swapon -a swapon: /mnt/swap.iso: insecure permissions 0644, 0600 suggested. #这个警告是由于你的交换文件（swap file）的权限设置被认为不安全导致的。默认情况下，建议将交换文件设置为 0600 权限。 要更改交换文件的权限，你可以使用以下命令： [root@disk ~]# chmod 0600 /mnt/swap.iso #这将设置交换文件的权限为 0600，只允许所有者读取和写入，而禁止其他用户的访问。这样设置后，再次运行 swapon 命令应该就不会再出现不安全权限的警告了 [root@disk ~]# swapon -a [root@disk ~]# swapon -s Filename Type Size Used Priority /dev/dm-1 partition 2097148 0 -2 /mnt/swap.iso file 1048572 0 -3 [root@disk ~]# 到此挂载完成，在实际使用中使用交换分区，最好使用专门的分区，而不是一个文件。 总结本文介绍了Linux磁盘挂载的基本操作和配置方法，包括虚拟机添加磁盘、分区格式化、配置fstab文件、开机自动挂载，根目录扩容和添加交换分区等。文章详细介绍了每个步骤的具体操作和注意事项。","categories":["Linux","基础操作"]},{"title":"sysctl","path":"/2023/09/25/sysctl/sysctl/","content":"可以通过&#x2F;etc&#x2F;sysctl.conf控制和配置Linux内核及网络设置。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# 避免放大攻击net.ipv4.icmp_echo_ignore_broadcasts = 1# 开启恶意icmp错误消息保护net.ipv4.icmp_ignore_bogus_error_responses = 1# 开启SYN洪水攻击保护net.ipv4.tcp_syncookies = 1# 开启并记录欺骗，源路由和重定向包net.ipv4.conf.all.log_martians = 1net.ipv4.conf.default.log_martians = 1# 处理无源路由的包net.ipv4.conf.all.accept_source_route = 0net.ipv4.conf.default.accept_source_route = 0# 开启反向路径过滤net.ipv4.conf.all.rp_filter = 1net.ipv4.conf.default.rp_filter = 1# 确保无人能修改路由表net.ipv4.conf.all.accept_redirects = 0net.ipv4.conf.default.accept_redirects = 0net.ipv4.conf.all.secure_redirects = 0net.ipv4.conf.default.secure_redirects = 0# 不充当路由器net.ipv4.ip_forward = 0net.ipv4.conf.all.send_redirects = 0net.ipv4.conf.default.send_redirects = 0# 开启execshildkernel.exec-shield = 1kernel.randomize_va_space = 1# IPv6设置net.ipv6.conf.default.router_solicitations = 0net.ipv6.conf.default.accept_ra_rtr_pref = 0net.ipv6.conf.default.accept_ra_pinfo = 0net.ipv6.conf.default.accept_ra_defrtr = 0net.ipv6.conf.default.autoconf = 0net.ipv6.conf.default.dad_transmits = 0net.ipv6.conf.default.max_addresses = 1# 优化LB使用的端口# 增加系统文件描述符限制fs.file-max = 65535# 允许更多的PIDs (减少滚动翻转问题); may break some programs 32768kernel.pid_max = 65536# 增加系统IP端口限制net.ipv4.ip_local_port_range = 2000 65000# 增加TCP最大缓冲区大小net.ipv4.tcp_rmem = 4096 87380 8388608net.ipv4.tcp_wmem = 4096 87380 8388608# 增加Linux自动调整TCP缓冲区限制# 最小，默认和最大可使用的字节数# 最大值不低于4MB，如果你使用非常高的BDP路径可以设置得更高# Tcp窗口等net.core.rmem_max = 8388608net.core.wmem_max = 8388608net.core.netdev_max_backlog = 5000net.ipv4.tcp_window_scaling = 1","categories":["Linux","基础操作"]},{"path":"/2023/07/11/部署高可用集群/部署LVS高可用集群/","content":"一、lvs+keepalived高可用集群部署案例需求部署基于LVS DR模式的web高可用集群，实现： 实现数据服务器容错 实现分发器故障切换 任何机器宕机不中断web业务 实验环境六台安装CentOS8的虚拟机一台测试机，两台LVS分发器，一台路由器，两台web服务器，关闭selinux关闭防火墙，停止libvirtd.service服务 角色名称 接口名称 IP地址 client ens33 192.168.1.200 route ens33，ens160 192.168.1.1，192.168.2.1 lvs1 ens33 192.168.2.200，192.168.2.100（VIP） lvs2 ens33 192.168.2.150，192.168.2.100（VIP） rs1 ens33，lo:0 192.168.2.220，192.168.2.100（VIP） rs2 ens33，lo:0 192.168.2.210，192.168.2.100（VIP） 实验拓扑图image20200205130755595.png 实验步骤a、配置客户端 12ens33=192.168.1.200[root@client ~]# route add default gw 192.168.1.1 b、设置路由 1234ens33=192.168.1.1ens160=192.168.2.1[root@route ~]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward c、设置RS的VIP、网关、内核参数 123456789101112131415161718192021RS1[root@rs1 ~]# route add default gw 192.168.2.1[root@rs1 ~]# ifconfig lo:0 192.168.2.100 netmask 255.255.255.255 up[root@rs1 ~]# echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore [root@rs1 ~]# echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce RS2[root@rs2 ~]# route add default gw 192.168.2.1[root@rs2 ~]# ifconfig lo:0 192.168.2.100 netmask 255.255.255.255 up[root@rs2 ~]# echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore [root@rs2 ~]# echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce 安装web服务，生成测试页面RS1[root@rs1 ~]# dnf install httpd -y[root@rs1 ~]# echo &quot;rs1&quot; &gt; /var/www/html/index.html[root@rs1 ~]# systemctl start httpd.serviceRS2[root@rs2 ~]# dnf install httpd -y[root@rs2 ~]# echo &quot;rs2&quot; &gt; /var/www/html/index.html[root@rs2 ~]# systemctl start httpd.service d、设置LVS 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111### LVS1 安装软件包，修改配置文件[root@lvs1 ~]# dnf install ipvsadm keepalived -y[root@lvs1 ~]# vim /etc/keepalived/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; router_id lvs_1&#125;vrrp_instance apache &#123; state MASTER interface ens33 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.2.100/24 &#125;&#125;virtual_server 192.168.2.100 80 &#123; delay_loop 6 lb_algo rr lb_kind DR nat_mask 255.255.255.0# persistence_timeout 50 protocol TCP real_server 192.168.2.210 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 3 connect_port 80 &#125; &#125; real_server 192.168.2.220 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 3 connect_port 80 &#125; &#125;&#125;### 重启keepalived服务[root@lvs1 ~]# systemctl start keepalived.service ### 使用ip add命令查看所设置的VIP是否被设置[root@lvs1 ~]# ip add2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:6d:1c:b3 brd ff:ff:ff:ff:ff:ff inet 192.168.2.200/24 brd 192.168.2.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet 192.168.2.100/24 scope global secondary ens33 valid_lft forever preferred_lft forever inet6 fe80::474:99dd:c899:455f/64 scope link noprefixroute valid_lft forever preferred_lft forever### LVS2\t安装软件包，修改配置文件[root@lvs2 ~]# dnf install ipvsadm keepalived -y[root@lvs2 ~]# vim /etc/keepalived/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; router_id lvs_1&#125;vrrp_instance apache &#123; state BACKUP interface ens33 virtual_router_id 51 priority 10 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.2.100/24 &#125;&#125;virtual_server 192.168.2.100 80 &#123; delay_loop 6 lb_algo rr lb_kind DR nat_mask 255.255.255.0# persistence_timeout 50 protocol TCP real_server 192.168.2.210 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 3 connect_port 80 &#125; &#125; real_server 192.168.2.220 80 &#123; weight 1 TCP_CHECK &#123; connect_timeout 3 connect_port 80 &#125; &#125;&#125;### 重启keepalived服务[root@lvs2 ~]# systemctl start keepalived.service e、客户端测试 12345678910111213141516171819202122232425262728293031323334353637383940414243444546### 客户端验证分发[root@client ~]# elinks http://192.168.2.100 --dump rs1[root@client ~]# elinks http://192.168.2.100 --dump rs2### 停止lvs1的keepalived服务 验证分发器故障切换[root@lvs1 ~]# systemctl stop keepalived.service 使用ip add命令查看VIP是否被释放[root@lvs1 ~]# ip add2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:6d:1c:b3 brd ff:ff:ff:ff:ff:ff inet 192.168.2.200/24 brd 192.168.2.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::474:99dd:c899:455f/64 scope link noprefixroute valid_lft forever preferred_lft forever切换到lvs2查看VIP是否被设置[root@lvs2 ~]# ip add2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:5c:a0:66 brd ff:ff:ff:ff:ff:ff inet 192.168.2.150/24 brd 192.168.2.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet 192.168.2.100/24 scope global secondary ens33 valid_lft forever preferred_lft forever inet6 fe80::5726:cbb9:c37b:d898/64 scope link noprefixroute valid_lft forever preferred_lft forever切换到客户端测试[root@client ~]# elinks http://192.168.2.100 --dump rs1[root@client ~]# elinks http://192.168.2.100 --dump rs2### 停止RS1数据服务器查看数据服务器容错[root@rs1 ~]# systemctl stop httpd切换到客户端测试:用户只能访问到RS1的页面[root@client ~]# elinks http://192.168.2.100 --dump rs1[root@client ~]# elinks http://192.168.2.100 --dump rs1 提示：使用tcpdump命令可以看到vrrp的相关信息发送信息，深度理解VRRP协议 1[root@lvs1 ~]# tcpdump -nn -vvv vrrp"},{"path":"/2023/07/11/部署高可用集群/构建高可用nginx集群/","content":"案例需求部署基于nginx分发器的高可用web集群 分发器故障自动切换 数据服务器自动容错 任何机器宕机不中断web业务 实验拓扑image20200221150137745.png 实验环境 角色 IP client 192.168.0.10 master 192.168.0.40 VIP&#x3D;192.168.0.150 backup 192.168.0.41 VIP&#x3D;192.168.0.150 web1 192.168.0.42 web2 192.168.0.43 实验步骤a、配置nginx集群 1234567891011121314151617181920212223master&amp;backup安装nginx和keepalived修改nginx配置文件[root@master ~]# vim /usr/local/nginx/conf/nginx.confworker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; upstream web &#123; server 192.168.0.42 max_fails=2 fail_timeout=3;#3秒内失败2次，则认为此节点失效 server 192.168.0.43 max_fails=2 fail_timeout=3; &#125;server &#123; listen 80; server_name localhost; location / &#123; proxy_pass http://web; &#125;&#125;&#125; b、配置keepalived 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@master ~]# vim /etc/keepalived/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; router_id NGINX_DEVEL&#125;vrrp_script check_nginx &#123;\t#定义脚本的名称为check_nginx script &quot;/etc/keepalived/nginx_pid.sh&quot;\t#检查对应位置的文件是否存在 interval 2\t#定义执行间隔为2秒 fall 1\t#失败次数为1次&#125;vrrp_instance nginx &#123;\t#定义实例名称为nginx state MASTER\t#定义主机状态 interface ens33\t#定义通信接口，VIP绑定的接口 mcast_src_ip 192.168.0.40\t#定义发送vrrp广播的源地址，模式使用VIP绑定网卡的主IP地址 virtual_router_id 51#定义VRID，主从设备vrid要抑制 priority 100#定义优先级 advert_int 1\t#定义检查间隔，默认1秒 authentication &#123;\t#设置认证，同一vrid的设备要抑制 auth_type PASS\t#认证方式为PASS auth_pass 1111\t#认证密码为1111 &#125; track_script &#123; check_nginx\t#调用在vrrp_script中定义的内容 &#125; virtual_ipaddress &#123; 192.168.0.150/24 &#125;&#125;[root@backup ~]# vim /etc/keepalived/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; router_id NGINX_DEVEL&#125;vrrp_script check_nginx &#123; script &quot;/etc/keepalived/nginx_pid.sh&quot; interval 2 fall 1&#125;vrrp_instance nginx &#123; state BACKUP interface ens33 mcast_src_ip 192.168.0.41 virtual_router_id 51 priority 90 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; track_script &#123; check_nginx &#125; virtual_ipaddress &#123; 192.168.0.150/24 &#125;&#125; c、构建关联脚本 123456789101112131415161718192021222324252627282930313233[root@master ~]# vim /etc/keepalived/nginx_pid.sh#!/bin/bashnginx_kp_check () &#123; nginxpid=`ps -C nginx --no-header |wc -l` if [ $nginxpid -eq 0 ];then /usr/local/nginx/sbin/nginx sleep 1 nginxpid=`ps -C nginx --no-header |wc -l` if [ $nginxpid -eq 0 ];then systemctl stop keepalived fi fi&#125;nginx_kp_check[root@backup ~]# vim /etc/keepalived/nginx_pid.sh #!/bin/bashnginx_kp_check () &#123; nginxpid=`ps -C nginx --no-header |wc -l` if [ $nginxpid -eq 0 ];then /usr/local/nginx/sbin/nginx sleep 1 nginxpid=`ps -C nginx --no-header |wc -l` if [ $nginxpid -eq 0 ];then systemctl stop keepalived fi fi&#125;nginx_kp_check脚本功能说明：统计nginx进程数量，如果进程数量的值等于0，说明nginx挂了，那么执行/usr/local/nginx/sbin/nginx去启动分发器，等待1秒后再次检查进程数量，如果进程数量的值还是等于0，则执行systemctl stop keepalived停止keepalived服务。这样就停止发组播，释放VIP，而备用服务器就开始接手工作了。 集群高可用性测试集群测试：使用客户端正常访问VIP 1234[root@client ~]# curl 192.168.0.150web1[root@client ~]# curl 192.168.0.150web2 在master上down掉nginx服务 1234[root@master ~]# watch -n1 &#x27;killall nginx&#x27;每隔秒执行一次killall nginx命令[root@master ~]# ip add #查看VIP是否还在[root@backup ~]# ip add\t#到backup主机上查看是否有VIP 继续测试 1234[root@client ~]# curl 192.168.0.150web1[root@client ~]# curl 192.168.0.150web2 重启master上的keepalived服务 12[root@master ~]# ip add\t#查看VIP是否飘回来[root@master ~]# lsof -i :80\t#查看nginx是否被启 再次测试 1234[root@client ~]# curl 192.168.0.150web1[root@client ~]# curl 192.168.0.150web2 数据服务器宕机测试 停止web1主机上的web服务 1[root@web1 ~]# systemctl stop httpd 切换到client主机测试 1234[root@client ~]# curl 192.168.0.150web2[root@client ~]# curl 192.168.0.150web2 启动web1主机上的web服务 1[root@web1 ~]# systemctl start httpd 切换到client主机测试 1234[root@client ~]# curl 192.168.0.150web2[root@client ~]# curl 192.168.0.150web1"},{"path":"/2023/07/11/部署高可用集群/keepalived服务器部署/","content":"一、什么是高可用通过前面课程的学习，我们知道LVS、Nginx可以实现很多种不同类型的分发，我们还知道，集群系统存在的作用就是为了解决单点故障的问题。 LVS、Nginx集群的单点故障问题这个单点故障主要体现在两个方面 分发器宕机怎么处理？ 假如nginx服务器挂掉了，那么所有的服务也会跟着瘫痪 。 一种方法是人为监控，发现主分发器宕机后，立马登录备分发器，并给它分配虚ip。 另一种办法是用软件来替代人来监控，自动登录备分发器，分配虚ip。 数据服务器宕机怎么处理？ 分发器可以自动判断数据服务器的存活状态，不对宕机服务器要数据。 二、Keepalived介绍keepalived是使用C语言编写的路由热备软件，该项目主要目标是为linux系统提供简单高效的负载均衡及高可用解决方案。keepalived由一组检查器，根据服务器的健康状况动态的维护和管理服务器池，另外keepalived通过vrrp协议实现高可用架构，vrrp是路由灾备的实现基础。通过前面的课程我们知道，在lvs中只解决了真实服务器的单点故障，但是如果分发器也就是lvs主机发生故障的话，整个集群系统都会崩溃，所以我们需要keepalived来实现集群系统的高可用。我们可以部署两台或更多的分发器，仅有一台调度器做为主服务器，其它的做为备用，当主调度器发生故障时，keepalived可以自动将备用调度器升级为主调度器，从而实现整个集群系统的高负载，高可用。 三、vrrp协议vrrp协议是为了静态路由环境下防止单点故障而设计的主从灾备协议，在主设备发生故障时业务自动切换至从设备，而这一切对于用户而言是透明的。vrrp将两台或多台设备虚拟成一个设备，对外仅提供一个虚拟的IP地址，这些设备在同一时刻仅有一台设备可有拥有该IP地址，而拥有该IP地址的设备就是主设备,其它的就是备用设备。主设备会不断发送自己的状态信息给备用设备，当备用设备接收不到主设备的状态信息时，多个备用设备会根据自身的优先级选择出新的主设备，并拥有所有的业务功能。vrrp协议需要为每个路由设备定义一个虚拟路由ID（VRID）以及优先，所有主备路由设备的VRID必须一样，这样才会被视为同一组设备，而优先级最高的设备就是主路由设备，VRID和优先级的范围为0-255之间的整数，数值越大优先级越高，如果优先级相等，则会对比IP地址，地址越大优先级越高 四、部署keepalived1[root@lvs1 ~]# dnf install keepalived -y 配置文件说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172[root@lvs1 ~]# vim /etc/keepalived/keepalived.conf! Configuration File for keepalived global_defs &#123; #全局配置\tnotification_email &#123; #指定keepalived在发生切换时需要发送email到的对象，一行一个 acassen@firewall.loc\t#指定收件人邮箱 failover@firewall.loc sysadmin@firewall.loc\t&#125;\tnotification_email_from Alexandre.Cassen@firewall.loc #指定发件人\tsmtp_server 192.168.200.1\t#指定smtp服务器地址\tsmtp_connect_timeout 30 #指定smtp连接超时时间\trouter_id LVS_DEVEL #此处注意router_id为负载均衡标识，在局域网内应该是唯一的。\tvrrp_skip_check_adv_addr\tvrrp_strict\tvrrp_garp_interval 0\tvrrp_gna_interval 0&#125;vrrp_instance VI_1 &#123; #虚拟路由的标识符\tstate MASTER #状态只有MASTER和BACKUP两种，并且要大写，MASTER为工作状态，BACKUP是备用状态\tinterface eth0 #通信所使用的网络接口 virtual_router_id 51\t#虚拟路由的ID号，是虚拟路由MAC的最后一位地址 priority 100 #此节点的优先级，主节点的优先级需要比其他节点高 advert_int 1 #通告的间隔时间 authentication &#123; #认证配置 auth_type PASS #认证方式 auth_pass 1111 #认证密码 &#125; virtual_ipaddress &#123; #虚拟ip地址,可以有多个地址，每个地址占一行，不需要子网掩码，同时这个ip 必须与我们在lvs 客户端设定的vip 相一致！ 192.168.200.16 192.168.200.17 192.168.200.18 &#125;&#125; virtual_server 192.168.200.100 443 &#123; #集群所使用的VIP和端口 delay_loop 6 #健康检查间隔，单位为秒 lb_algo rr #lvs调度算法rr|wrr|lc|wlc|lblc|sh|dh nat_mask 255.255.255.0 #VIP掩码 lb_kind NAT #负载均衡转发规则。一般包括DR,NAT,TUN 3种 persistence_timeout 50 #会话保持时间，会话保持，就是把用户请求转发给同一个服务器，不然刚在1上提交完帐号密码，就跳转到另一台服务器2上了 protocol TCP #转发协议，有TCP和UDP两种，一般用TCP，没用过UDP real_server 192.168.200.100 443 &#123; #真实服务器，包括IP和端口号 weight 1 #权重 TCP_CHECK &#123; #通过tcpcheck判断RealServer的健康状态 connect_timeout 3 #连接超时时间 nb_get_retry 3 #重连次数 delay_before_retry 3\t#重连间隔时间 connect_port 23 #健康检查的端口的端口 bindto &lt;ip&gt; &#125; HTTP_GET &#123; #健康检测方式，可选有 SSL_GET、TCP_CHECK、HTTP_GET url &#123; #检查url，可以指定多个 path / #检查的url路径 digest ff20ad2481f97b1754ef3e12ecd3a9cc #需要检查到的内容。检查后的摘要信息。 &#125; url &#123; path /mrtg digest 9b3a0c85a887a256d6939da88aabd8cd &#125; url &#123; path /testurl3/test.jsp digest 640205b7b0fc66c1ea91c463fac6334d &#125; connect_timeout 3 #连接超时时间 nb_get_retry 3 #检测尝试几次 delay_before_retry 3\t#检测的时间间隔 &#125; &#125;&#125;"},{"path":"/2023/07/11/Web服务器-Tomcat/使用nginx发布tomcat站点/","content":"之前我们在访问的时候使用的都是类似http://serverip/test或者http://serverip/jpress这种字样的URL，使用起来比较麻烦，所以呢，我们可以将tomcat和nginx结合在一起，可以通过nginx以下功能发布： 使用nginx url重写 使用nginx的反向代理功能 一、部署tomcat网站通过部署两个tomcat站点，分别采用nginx url rewrite方法和反向代理发布。 设置tomcat1 123[root@zutuanxue ~]# cd /opt/tomcat1/webapps/[root@zutuanxue webapps]# mv ROOT tomcat[root@zutuanxue webapps]# mv jpress ROOT 设置tomcat2 123[root@zutuanxue ~]# cd /opt/tomcat2/webapps/[root@zutuanxue webapps]# mv ROOT tomcat[root@zutuanxue webapps]# mv test ROOT 二、使用rewrite实现2.1、部署nginx1[root@zutuanxue ~]# dnf install nginx -y 2.2、设置nginx配置文件1234567891011121314151617181920[root@zutuanxue ~]# vim /etc/nginx/nginx.conf[root@zutuanxue ~]# sed -i &#x27;/#/d&#x27; /etc/nginx/nginx.conf[root@zutuanxue ~]# sed -i &#x27;/^$/d&#x27; /etc/nginx/nginx.confserver &#123; listen 80; listen [::]:80; server_name www.a.com; location / &#123; rewrite ^/$ http://127.0.0.1:8080/jpress break; &#125; &#125; server &#123; listen 80; listen [::]:80;127.0.0.1 server_name www.b.com; location / &#123; rewrite ^/$ http://127.0.0.1:8081/test break; &#125; &#125;[root@zutuanxue ~]# systemctl restart nginx 2.3、修改测试机的hosts文件123[root@zutuanxue conf]# vim /etc/hosts192.168.98.200 www.a.com192.168.98.200 www.b.com 2.4、 打开浏览器直接访问域名测试测试方法：打开浏览器输入之前设置好的域名http://www.a.comhttp://www.b.com查看是否能访问到对应的网站内容，能看到说明实验成功。 三、使用反向代理实现3.1、设置nginx配置文件1234567891011121314151617181920212223242526272829303132333435363738user nginx;worker_processes auto;error_log /var/log/nginx/error.log;pid /run/nginx.pid;include /usr/share/nginx/modules/*.conf;events &#123; worker_connections 1024;&#125;http &#123; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; include /etc/nginx/conf.d/*.conf; server &#123; listen 80; listen [::]:80; server_name www.a.com; location / &#123; proxy_pass http://127.0.0.1:8080; &#125; &#125; server &#123; listen 80; listen [::]:80; server_name www.b.com; location / &#123; proxy_pass http://127.0.0.1:8081; &#125; &#125;&#125; 3.2、打开浏览器直接访问域名测试测试方法：打开浏览器输入之前设置好的域名http://www.a.comhttp://www.b.com查看是否能访问到对应的网站内容，能看到说明实验成功。"},{"path":"/2023/07/11/Web服务器-Tomcat/Tomcat部署在windows服务器/","content":"一、软件包获得tomcat：https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-9/v9.0.31/bin/apache-tomcat-9.0.31-windows-x64.zip jdk：https://www.oracle.com/java/technologies/javase-jdk11-downloads.html 二、安装jdk11image20200312092554544.png image20200312092614272.png image20200312092633326.png image20200312092648470.png image20200312092715347.png image20200312092735514.png image20200312092806792.png image20200312092836684.png image20200312092855640.png image20200312093114211.png image20200312093147558.png image20200312093219637.png image20200312093335434.png 如果使用java -version看到的还是以前的提示，重启一下系统 image20200312093515212.png 三、安装tomcat解压tomcat的压缩包并进入到bin目录下 image20200312094402600.png 四、访问tomcat默认网站打开浏览器输入: http://localhost:8080 image20200313140037287.png 看到这个页面说明部署成功了！完美！"},{"path":"/2023/07/11/Web服务器-Tomcat/Tomcat部署在linux服务器/","content":"一、下载软件包tomcat：https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-9/v9.0.31/bin/apache-tomcat-9.0.31.zip jdk：https://www.oracle.com/java/technologies/javase-downloads.html 如何想使用tomcat9的话，官方要求JRE的版本必须是8以上的，所以在安装之前，我们需要确认一下本机的版本,如果满足需求的话可以直接安装tomcat 二、安装JDK123456789101112131415161718192021222324# 1、查看当前是否安装过jdk[root@zutuanxue ~]# java -versionbash: java: 未找到命令...文件搜索失败: Cannot update read-only repo#系统提示没有找到命令，意味着没有安装相关软件包，所以我们要安装# 2、安装jdk[root@zutuanxue ~]# rpm -ivh jdk-13.0.2_linux-x64_bin.rpm 警告：jdk-13.0.2_linux-x64_bin.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID ec551f03: NOKEYVerifying... ################################# [100%]准备中... ################################# [100%]正在升级/安装... 1:jdk-13.0.2-2000:13.0.2-ga ################################# [100%]# 3、验证：安装完成后再次查看[root@zutuanxue ~]# java -versionjava version &quot;13.0.2&quot; 2020-01-14Java(TM) SE Runtime Environment (build 13.0.2+8)#java的运行环境，也叫jreJava HotSpot(TM) 64-Bit Server VM (build 13.0.2+8, mixed mode, sharing) #JVM java的虚拟机，可以使Java语言在不同平台上运行时不需要重新编译。Java语言使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的字节码就可以了，这样就可以在多种平台上不加修改地运行。很多语言都采用了这种类似的思路，才使得他们具有可移植性，比如说python 三、安装Tomcat12345678910111213141516171819202122232425262728293031323334353637383940414243# 1、tomcat 安装我们可以看到tomcat软件包的名称包含有apache字样，原因很简单，它是由apache资助的项目[root@zutuanxue ~]# unzip apache-tomcat-9.0.31.zip -d /opt/[root@zutuanxue ~]# cd /opt/[root@zutuanxue opt]# mv apache-tomcat-9.0.31 tomcat1解压完成，改个名就可以使用了，因为tomcat是一个二进制包，什么意思呢？就类似于我们下载游戏的时候的硬盘版，什么是硬盘版？解压就能玩，所以这个tomcat我们就压之后就可以使用了，不需要安装。[root@zutuanxue bin]# sh startup.sh Cannot find ./catalina.shThe file is absent or does not have execute permissionThis file is needed to run this program# 2、启动tomcat ## tomcat启动命令目录[root@zutuanxue bin]# pwd/opt/tomcat1/bin ## 启动tomcat[root@zutuanxue bin]# chmod +x catalina.sh [root@zutuanxue bin]# sh startup.sh Using CATALINA_BASE: /opt/tomcat1Using CATALINA_HOME: /opt/tomcat1Using CATALINA_TMPDIR: /opt/tomcat1/tempUsing JRE_HOME: /usrUsing CLASSPATH: /opt/tomcat1/bin/bootstrap.jar:/opt/tomcat1/bin/tomcat-juli.jarTomcat started.[root@zutuanxue webapps]# netstat -antp | grep javatcp6 0 0 127.0.0.1:8005 :::* LISTEN 46987/java tcp6 0 0 :::8080 :::* LISTEN 46987/java tomcat的两个端口8005 是关闭tomcat使用的端口，可以使用telnet serverip 8005 然后输入大写的SHUTDOWN关闭tomcat，所以建议更改端口 或者把引号中了命令改成不容易记忆的，个人推荐改命令，因为改端口没有告诉负责网络安全的同事就会给你屏蔽掉………8080 连接端口8009 AJP协议使用的端口，tomcat的优势是处理jsp页面 但是对于图片，静态页面处理能力特别差，相对于apache来说，那么这个时候怎么办 做个分流 jsp页面由tomcat完成，静态的页面 图片由AJP来完成，AJP是定向包协议 使用二进制格式来传输可读性文本，在server.xml配置文件中默认不生效 访问默认首页 http://localhost:8080 tomcat默认页.png 注意: tomcat的访问端口是8080 123456789提示：如果之前系统中安装过java环境的话，可能会出现即便安装完成新的jdk之后，使用java -version命令所查询的结果依然是老版本的，这个问题是由于环境变量引起的，所以需要修改环境变量设置文件[root@zutuanxue ~]# vim /root/.bash_profile #####javaJAVA_HOME=/usr/java/jdk-13.0.2#对应自己安装的版本PATH=$JAVA_HOME/bin:$PATH:$HOME/binCLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jarexport PATH JAVA_HOME CLASSPATH CATALINA_HOME"},{"path":"/2023/07/11/Web服务器-Tomcat/Tomcat调优/","content":"tomcat的优化可以提高网站的并发能力，体现个人的价值，tomcat在java项目中的使用率非常高，所以在生产环境对tomcat的优化也就变得非常必要了，一般情况下tomcat的优化主要从两个方面入手，一个是自身配置，另一个是tomcat所运行的jvm虚拟机的优化，优化的工作可以从安装完tomcat就开始着手 一、AJP优化在前面的课程中我们提到了一个叫AJP的协议，同时我们也知道了这个AJP的作用，但是在生产环境中一般使用的是nginx+tomcat的架构，所以大多数时候用不到AJP协议，所以我们可以禁用它，而在我们的server.xml文件中这个AJP默认就是禁用的,如果是其它版本最好看一下 12345678[root@zutuanxue conf]# vim /opt/tomcat1/conf/server.xml &lt;!-- &lt;Connector protocol=&quot;AJP/1.3&quot; address=&quot;::1&quot; port=&quot;8009&quot; redirectPort=&quot;8443&quot; /&gt; --&gt; 二、运行模式优化tomcat的运行模式有3种： bio 性能非常低下，没有经过任何优化处理和支持，适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。 nio nio(new I&#x2F;O)，是Java SE 1.4及后续版本提供的一种新的I&#x2F;O操作方式它拥有比传统I&#x2F;O操作(bio)更好的并发运行性能。Tomcat9默认使用nio运行模式。适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂。AIO(NIO2)使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。 apr 安装起来最困难，但是从操作系统级别来解决异步的IO问题，大幅度的提高性能 进入tomcat的服务器状态页面查看默认的模式 image20200313202144717.png 如果默认使用的是bio模式 1234设置使用nio模式[root@zutuanxue logs]# vim /opt/tomcat1/conf/server.xml&lt;Connector port=&quot;8080&quot;protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; apr运行模式APR(Apache portable Run-time libraries，Apache可移植运行库)的目的如其名称一样，主要为上层的应用程序提供一个可以跨越多操作系统平台使用的底层支持接口库。可以大大地提高Tomcat对静态文件的处理性能。 也是在Tomcat上运行高并发应用的首选模式。 系统自带的软件包不是最新的，且缺少相关软件包，所以我们选择源码包安装 所需软件包 apr-1.7.0.tar.gz 主程序包 包含了通用开发组件 apr-iconv-1.2.2.tar.gz 用于实现iconv编码 apr-util-1.6.1.tar.gz 额外的开发组件 tomcat-native.tar.gz 关联tomcat和apr的组件 arp相关软件包下载 https://mirrors.cnnic.cn/apache/apr/ tomcat-native在tomcat安装目录的bin下 部署apr环境step 1 环境准备 1[root@zutuanxue ~]# dnf install -y apr-devel openssl-devel gcc make expat-devel libtool step 2 安装apr主程序包 1234[root@zutuanxue ~]# tar fx apr-1.7.0.tar.gz [root@zutuanxue ~]# cd apr-1.7.0/[root@zutuanxue ~]# ./configure --prefix=/usr/local/apr[root@zutuanxue apr-1.7.0]# make -j4 &amp;&amp; make install step 3 安装apr-iconv 1234[root@zutuanxue ~]# tar fx apr-iconv-1.2.2.tar.gz [root@zutuanxue ~]# cd apr-iconv-1.2.2/[root@zutuanxue ~]# ./configure --with-apr=/usr/local/apr --prefix=/usr/local/apr-iconv[root@zutuanxue apr-iconv-1.2.2]# make -j4 &amp;&amp; make install step 4 安装apr-util 1234[root@zutuanxue ~]# tar fx apr-util-1.6.1.tar.gz [root@zutuanxue ~]# cd apr-util-1.6.1/[root@zutuanxue ~]# ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr --with-apr-iconv=/usr/local/apr-iconv/bin/apriconv[root@zutuanxue apr-util-1.6.1]# make -j4 &amp;&amp; make install step 5 安装tomcat-native 12345[root@zutuanxue ~]# cd /opt/tomcat1/bin/[root@zutuanxue bin]# tar fx tomcat-native.tar.gz [root@zutuanxue bin]# cd tomcat-native-1.2.23-src/native[root@zutuanxue tomcat-native-1.2.23-src]# ./configure --with-apr=/usr/local/apr --with-java-home=/usr/java/jdk-13.0.2[root@zutuanxue tomcat-native-1.2.23-src]# make -j4 &amp;&amp; make install step 6 修改并加载环境变量 123[root@zutuanxue ~]# echo &#x27;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/apr/libexport LD_RUN_PATH=$LD_RUN_PATH:/usr/local/apr/lib&#x27; &gt;&gt; /etc/profile[root@zutuanxue ~]# source /etc/profile step 7 修改tomcat配置文件 1234[root@zutuanxue ~]# vim /opt/tomcat1/conf/server.xml protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; step 8 测试 123456#为了避免干扰先执行关闭[root@zutuanxue ~]# sh /opt/tomcat1/bin/shutdown.sh #测试[root@zutuanxue ~]# sh /opt/tomcat1/bin/catalina.sh run#如果没有问题可以看到14-Mar-2020 00:22:23.894 信息 [main] org.apache.coyote.AbstractProtocol.start 开始协议处理句柄[&quot;http-apr-8080&quot;] image20200314122328676.png 1234注意：如果非root用户启动失败，把apr环境变量在当前用户的.bash_profile中写一份[root@zutuanxue ~]# echo &#x27;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/apr/libexport LD_RUN_PATH=$LD_RUN_PATH:/usr/local/apr/lib&#x27; &gt;&gt; /root/.bash_profile[root@zutuanxue ~]# source /root/.bash_profile 其它优化参数12345678910111213141516[root@zutuanxue logs]# vim /opt/tomcat1/conf/server.xml &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1 enableLookups=&quot;false&quot; maxThreads=&quot;1000&quot; minSpareThreads=&quot;100&quot; acceptCount=&quot;900&quot; disableUploadTimeout=&quot;true&quot; connectionTimeout=&quot;20000&quot; URIEncoding=&quot;UTF-8&quot; redirectPort=&quot;8443&quot;compression=&quot;on&quot; compressionMinSize=&quot;1024&quot; useSendfile=&quot;false&quot; noCompressionUserAgents=&quot;mozilla, traviata&quot; compressibleMimeType=&quot;text/html,text/xml,text/plain,text/css,text/javascript,application/javascript &quot; /&gt;maxThreads：最大线程数，默认150。增大值避免队列请求过多，导致响应缓慢。minSpareThreads：最小空闲线程数。acceptCount：当处理请求超过此值时，将后来请求放到队列中等待。disableUploadTimeout：禁用上传超时时间connectionTimeout：连接超时，单位毫秒，0代表不限制URIEncoding：URI地址编码使用UTF-8enableLookups：关闭dns解析，提高响应时间compression：启用压缩功能compressionMinSize：最小压缩大小，单位BytecompressibleMimeType ：压缩的文件类型官方参数文档：http://tomcat.apache.org/tomcat-9.0-doc/config/http.html"},{"path":"/2023/07/11/Web服务器-Tomcat/Tomcat多实例/","content":"Tomcat是一个单进程多线程的软件，在很早之前，我们都认为这种模式挺好的，因为早些年的CPU都是单核的，但是现在都是多核心的CPU了,如果还是一个进程的话呢，就比较浪费CPU资源，所以本节课我们要讨论下如果多开几个tomcat，也就是我们本节课要实现的是tomcat的多实例，这样可以提高资源的利用率，在之前的课程中我们提到过tomcat有三个端口8005 8009 8080，其中8005是用来关闭tomcat的端口，8080是访问端口，8009是ajp协议使用的端口，如果我想在一台机器上开启多个tomcat的话，首先要保证的就是端口不能冲突，否则开不了。 Tomcat多实例实现 将之前部署好的tomcat复制一份 123456[root@zutuanxue webapps]# cd /opt/[root@zutuanxue opt]# lstomcat1[root@zutuanxue opt]# cp -r tomcat1 tomcat2[root@zutuanxue opt]# lstomcat1 tomcat2 修改刚刚部署完成的tomcat的相关配置文件 123456[root@zutuanxue opt]# vim tomcat2/conf/server.xml &lt;Server port=&quot;8006&quot; shutdown=&quot;SHUTDOWN&quot;&gt;&lt;Connector port=&quot;8081&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8444&quot; /&gt;#修改端口 启动tomcat 12345678910[root@zutuanxue opt]# sh /opt/tomcat1/bin/startup.sh [root@zutuanxue opt]# sh /opt/tomcat2/bin/startup.sh [root@zutuanxue opt]# netstat -atnpActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp6 0 0 127.0.0.1:8005 :::* LISTEN 16801/java tcp6 0 0 127.0.0.1:8006 :::* tcp6 0 0 :::8080 :::* LISTEN 16801/java tcp6 0 0 :::8081 :::* LISTEN 17776/java 打开浏览器访问测试 image20200313144207263.png image20200313144222035.png 123456789101112注意：如果是不同用户使用的话，考虑到安全方面的问题，记得修改tomcat的用户管理文件。[root@zutuanxue conf]# pwd/opt/tomcat2/conf[root@zutuanxue conf]# vim tomcat-users.xml &lt;role rolename=&quot;manager-gui&quot;/&gt; &lt;role rolename=&quot;manager-script&quot;/&gt; &lt;role rolename=&quot;manager-jmx&quot;/&gt; &lt;role rolename=&quot;manager-status&quot;/&gt; &lt;role rolename=&quot;admin-gui&quot;/&gt; &lt;role rolename=&quot;admin-script&quot;/&gt; &lt;user username=&quot;tomcat&quot; password=&quot;tomcat&quot; roles=&quot;manager-gui,manager-script,manager-jmx,manager-status,admin-gui,admin-script&quot;/&gt;"},{"path":"/2023/07/11/Web服务器-Tomcat/Tomcat发布静态页面/","content":"访问tomcat网站管理页面打开浏览器，在地址栏中输入 http://localhost:8080看到如下页面，该页面是tomcat的默认网站，同时还提供了以下功能 server status 查看服务器的状态，包括linux主机的信息，tomcat的版本信息，资源使用情况等 manager app 管理网站 host manager 虚拟主机的管理 image20200312154145218.png 默认使用这三个功能需要提供账号密码，如果没有可以采用以下的方式去修改配置文件，设置用以访问的账号密码。 在提示登录的界面点击取消，会看到提示 image20200312154227858.png 12345678[root@zutuanxue ~]# vim /opt/tomcat1/conf/tomcat-users.xml &lt;role rolename=&quot;manager-gui&quot;/&gt; &lt;role rolename=&quot;manager-script&quot;/&gt; &lt;role rolename=&quot;manager-jmx&quot;/&gt; &lt;role rolename=&quot;manager-status&quot;/&gt; &lt;role rolename=&quot;admin-gui&quot;/&gt; &lt;role rolename=&quot;admin-script&quot;/&gt; &lt;user username=&quot;tomcat&quot; password=&quot;tomcat&quot; roles=&quot;manager-gui,manager-script,manager-jmx,manager-status,admin-gui,admin-script&quot;/&gt; 设置完成之后重启tomcat就可以登录后台管理页面了，其中在manager app中主要管理的是网站是否发布的操作，start&#x3D;发布网站 stop&#x3D;停止发布网站，reload&#x3D;重新加载，undeploy&#x3D;卸载&#x2F;删除网站（慎用），expire session&#x3D;会话过期时间 image20200312160956755.png 与war文件部署相关的设置，包括定义war文件存放的位置，和上传war文件 1234war是一个可以直接运行的web模块，通常用于网站，打包部署。以Tomcat来说，将war包放置在其\\webapps\\目录下，然后启动Tomcat，这个包就会自动解压，就相当于发布了。war包是Sun提出的一种web应用程序格式，与jar类似，是很多文件的压缩包。war包中的文件按照一定目录结构来组织。简单来说，war包是JavaWeb程序打的包，war包里面包括写的代码编译成的class文件，依赖的包，配置文件，所有的网站页面，包括html，jsp等等。一个war包可以理解为是一个web项目，里面是项目的所有东西。 image20200312161045722.png configuration 定义TLS(安全传输协议)配置文件 diagnostics 检查网站在启动，重新加载或卸载时，是否造成内存溢出，这个操作会触发垃圾回收机制，生产环境中慎用 TLS connector configuration diagnostics 加密诊断，可以帮助用户诊断加密是否有问题 firefox设置中文1[root@zutuanxue ~]# dnf install ibus* -y 添加完整的中文环境后重启 image20200313163452841.png 重启完成为浏览器添加中文后重启浏览器 image20200313163127816.png 再次访问tomcat管理界面就会变成中文 image20200313163617973.png 发布静态页面1234[root@zutuanxue webapps]# pwd/opt/tomcat1/webapps[root@zutuanxue webapps]# mkdir test[root@zutuanxue webapps]# echo &#x27;&lt;%= new java.util.Date() %&gt;&#x27; &gt; test/index.jsp 使用浏览器访问http://ip:8080/test,每次刷新时间都会改变"},{"path":"/2023/07/11/Web服务器-Tomcat/Tomcat压力测试/","content":"Apache JMeter是Apache组织开发的基于Java的压力测试工具。用于对软件做压力测试，它最初被设计用于Web应用测试，但后来扩展到其他测试领域。 它可以用于测试静态和动态资源，例如静态文件、Java 小服务程序、CGI 脚本、Java 对象、数据库、FTP 服务器， 等等。JMeter 可以用于对服务器、网络或对象模拟巨大的负载，来自不同压力类别下测试它们的强度和分析整体性能 JMeter的作用能够对HTTP和FTP服务器进行压力和性能测试， 也可以对任何数据库进行同样的测试（通过JDBC）。 完全的可移植性和100% 纯java。 完全多线程 框架允许通过多个线程并发取样和 通过单独的线程组对不同的功能同时取样。 精心的GUI设计允许快速操作和更精确的计时。 缓存和离线分析&#x2F;回放测试结果。 1下载地址：http://jmeter.apache.org/download_jmeter.cgi JMeter安装使用将下载好的压缩包在windows中解压（需要先安装JDK），解压后进入到bin目录双击jmeter.bat，等待启动 image202003132046066284103573.png 设置中文 image20200313204658512.png 创建测试 image20200313205020894.png 添加线程组，使用线程模拟用户的并发 image20200313205150993.png image20200313205306242.png 1000个线程循环10次，tomcat会收到10000个请求 添加并设置http请求 image20200313205429005.png image20200313205601358.png 添加监控 image20200313205836519.png 启动测试 image20200313205920252.png 查看结果 image20200313210311135.png 12345678910111213141516171819标签：说明是请求类型，如Http，FTP等请求。样本总数：也就是图形报表中的样本数目，总共发送到服务器的样本数目。平均值：也就是图形报表中的平均值，是总运行时间除以发送到服务器的请求数。居中的数值：也就是图形报表中的中间值，是代表时间的数字，有一半的服务器响应时间低于该值而另一半高于该值。90%&amp;95%&amp;99%：有多少请求的响应时间比给出的数值还要小。最小：是代表时间的数字,是服务器响应的最短时间。最大: 是代表时间的数字,是服务器响应的最长时间。异常%:请求的错误百分比。吞吐量:也就是图形报表中的吞吐量，这里是服务器每单位时间处理的请求数，注意查看是秒或是分钟。发送/接收KB/sec:是每秒钟发送/接收的字节数。（时间的单位为ms） 通过上面测试可以看出，tomcat在不做任何调整时，吞吐量为587次&#x2F;秒。这个吞吐量跟接口的业务逻辑关系很大，如果业务逻辑复杂，需要比较长时间计算的，可能吞吐量只有几十次&#x2F;秒，我这里测试的时候没有添加任务业务逻辑，才会出现吞吐量为587次&#x2F;秒的情况。这里的吞吐量最好是经过多次测试取平均值，因为单次测试具有一定的随机性 调整tomcat线程池123[root@zutuanxue bin]# vim /opt/tomcat1/conf/server.xml &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; maxThreads=&quot;1000&quot; minSpareThreads=&quot;200&quot; prestartminSpareThreads=&quot;true&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;#调整最大线程数为1000，最小为200，这个线程的数量要反复调整，然后对比测试结果，找出一个适合自己的值 调整队列1234[root@zutuanxue bin]# vim /opt/tomcat1/conf/server.xml &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; maxThreads=&quot;1000&quot; minSpareThreads=&quot;200&quot; prestartminSpareThreads=&quot;true&quot;\tmaxQueueSize=&quot;100&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;默认情况下，请求发送到tomcat，如果tomcat正忙，那么该请求会一直等待。这样虽然可以保证每个请求都能请求到，但是请求时间就会边长。有些时候，我们也不一定要求请求一定等待，可以设置最大等待队列大小，如果超过就不等待了。这样虽然有些请求是失败的，但是请求时间会虽短。典型的是12306。 参数介绍可以去官网查看：https://tomcat.apache.org/tomcat-9.0-doc/config/executor.html"},{"path":"/2023/07/11/Web服务器-Tomcat/Tomcat介绍/","content":"一、Tomcat介绍Apache Tomcat最早是由Sun开发的，在1999年被捐献给ASF（Apache 软件基金会 Apache Software Foundation），隶属于Jakarta(雅加达)项目，现在已经独立为一个顶级项目。因为Tomcat 技术先进、性能稳定，同时也是一个免费的开放源代码的Web 应用服务器，因而深受Java 爱好者的喜爱并得到了部分软件开发商的认可，被很多企业普遍使用，也是开发和调试JSP程序的首选。成为目前比较流行的Web 应用服务器。 官方网站：http://tomcat.apache.org/ tomcat的同类产品 Resin 服务器 Resin是Caucho公司的产品，速度非常快。可以显示动态内容，也可以显示静态内容，但是用户数量少，参考文档也少，使用起来不太方便，一旦涉及到相关文件和内容的更新，系统会自动重新部署并重启。 Jetty 服务器 Jetty是一个纯粹的基于Java的web服务器，也是一个开源项目。架构简单，速度快，修改简单，但是对java的支持不如tomcat全面， WebLogic 服务器 WebLogic 是BEA公司的产品，可进一步细分为 WebLogic Server、WebLogic Enterprise 和 WebLogic Portal 等系列，其中 WebLogic Server 的功能特别强大。WebLogic 支持企业级的、多层次的和完全分布式的Web应用，并且服务器的配置简单、界面友好。对于那些正在寻求能够提供Java平台所拥有的一切应用服务器的用户来说，WebLogic是一个十分理想的选择。但是不开源且收费 JBoss、WebSphere 二、Apache nginx tomcat比较Apache是用C写的；Nigix是用C写的；Tomcat是用Java写的。 Tomcat是Apache的拓展，更实质的说是Java应用服务器，用于处理JSP后台语言开发的应用，主要用于处理JSP动态网页。Tomcat 服务器是一个免费的开放源代码的Web 应用服务器（主要用于解析servlet&#x2F;JSP,同时具备http服务）,单纯的Tomcat性能有限，在很多地方表现有欠缺，如活动连接支持、静态内容、大文件和HTTPS等，因此多数都是Apache+Tomcat+JavaSDK的集成。严格的来说，Apache&#x2F;Nginx 应该叫做[HTTP Server]而Tomcat 则是一个「Application Server」，或者更准确的来说，是一个「Servlet&#x2F;JSP」应用的容器（Ruby&#x2F;Python 等其他语言开发的应用也无法直接运行在 Tomcat 上）。 Apache 优点：模块多，功能全面，性能稳定，适合静态HTML 缺点：配置相对复杂，自身不支持动态页面 Nginx 优点：功能较多，负载均衡、反向代理等，速度比Apache快 缺点：轻量级web服务器，功能不如Apache全面 Tomcat 优点：能够处理动态请求，可以独立于Apache运行，支持JSP 缺点：对静态内容和大文件的支持有所欠缺"},{"path":"/2023/07/11/Web服务器-Tomcat/Tomcat 目录与配置文件/","content":"一、tomcat目录说明tomcat主目录 12345678910111213bin：命令，存放不同平台上启动或关闭的脚本BUILDING.txt&amp;RUNNING.txt：使用文档，告诉用户如何搭建conf：各种全局配置文件，最主要的是server.xml和web.xml\tCONTRIBUTING.md：捐赠lib：tomcat需要用到的库，主要是各种jar包LICENSE：许可logs：存放tomcat的日志NOTICE：通知信息README.md：读我文档RELEASE-NOTES：版本信息temp：临时文件 webapps：tomcat的web发布目录，类似于nginx或者apache的html目录 work：tomcat的工作目录，存放的是jsp编译后产生的.class文件及.java文件。清空work目录，然后重启tomcat，可以达到清除缓存的作用。 bin目录 123456789101112131415161718192021222324252627282930bin目录下的文件主要有两类，一个是Linux使用的.sh结尾的文件，另外一个是windows使用的.bat结尾的文件，catalina\ttomcat的设置脚本，也可以启动&amp;关闭tomcat[root@zutuanxue bin]# sh catalina.sh helpUsing CATALINA_BASE: /opt/tomcat1Using CATALINA_HOME: /opt/tomcat1Using CATALINA_TMPDIR: /opt/tomcat1/tempUsing JRE_HOME: /usrUsing CLASSPATH: /opt/tomcat1/bin/bootstrap.jar:/opt/tomcat1/bin/tomcat-juli.jarUsage: catalina.sh ( commands ... )commands: debug Start Catalina in a debugger debug -security Debug Catalina with a security manager jpda start Start Catalina under JPDA debugger run Start Catalina in the current window run -security Start in the current window with security manager start Start Catalina in a separate window start -security Start in a separate window with security manager stop Stop Catalina, waiting up to 5 seconds for the process to end stop n Stop Catalina, waiting up to n seconds for the process to end stop -force Stop Catalina, wait up to 5 seconds and then use kill -KILL if still running stop n -force Stop Catalina, wait up to n seconds and then use kill -KILL if still running configtest Run a basic syntax check on server.xml - check exit code for result version What version of tomcat are you running?Note: Waiting for the process to end and use of the -force option require that $CATALINA_PID is defined[root@zutuanxue bin]# sh catalina.sh stop[root@zutuanxue bin]# sh catalina.sh helpstartup 启动脚本shutdown\t关闭脚本 conf目录 1234567这个目录下主要存放的是与tomcat设置相关的文件，常用的配置文件主要包含server.xml\t可以设置端口号、设置域名或IP、默认加载的项目、请求编码 web.xml\t可以设置tomcat支持的文件类型 context.xml\t可以用来配置数据源之类的 tomcat-users.xml\t用来配置管理tomcat的用户与权限 Catalina 此目录下可以设置默认加载的项目 webapps目录 12345ROOT\ttomcat默认的页面docs\t使用说明文档examples\t例子--tomcat首页中的examples按钮对应的内容host-manager\t首页Host Manager按钮对应的内容manager 首页 Manager App按钮对应的内容 二、tomcat相关配置文件简介server.xml 元素名 属性 解释 server port 指定一个端口，这个端口负责监听关闭tomcat的请求 shutdown 指定向端口发送的命令字符串 service name 指定service的名字 Connector(表示客户端和service之间的连接) port 指定服务器端要创建的端口号，并在这个断口监听来自客户端的请求 minProcessors 服务器启动时创建的处理请求的线程数 maxProcessors 最大可以创建的处理请求的线程数 enableLookups 如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址 redirectPort 指定服务器正在处理http请求时收到了一个SSL传输请求后重定向的端口号 acceptCount 指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理 connectionTimeout 指定超时的时间数(以毫秒为单位) Engine(表示指定service中的请求处理引擎，接收和处理来自Connector的请求) defaultHost 指定缺省的处理请求的主机名，它至少与其中的一个host元素的name属性值是一样的 Context(表示一个web应用程序，通常为WAR文件，关于WAR的具体信息见servlet规范) docBase 应用程序的路径或者是WAR文件存放的路径 path 表示此web应用程序的url的前缀，这样请求的url为http://localhost:8080/path/ reloadable 这个属性非常重要，如果为true，则tomcat会自动检测应用程序的&#x2F;WEB-INF&#x2F;lib 和&#x2F;WEB-INF&#x2F;classes目录的变化，自动装载新的应用程序，我们可以在不重起tomcat的情况下改变应用程序 host(表示一个虚拟主机) name 指定主机名 appBase 应用程序基本目录，即存放应用程序的目录 unpackWARs 如果为true，则tomcat会自动将WAR文件解压，否则不解压，直接从WAR文件中运行应用程序 Logger(表示日志，调试和错误信息) className 指定logger使用的类名，此类必须实现org.apache.catalina.Logger 接口 prefix 指定log文件的前缀 suffix 指定log文件的后缀 timestamp 如果为true，则log文件名中要加入时间，如下例:localhost_log.004-mm-dd.txt Realm(表示存放用户名，密码及role的数据库) className 指定Realm使用的类名，此类必须实现org.apache.catalina.Realm接口 Valve(功能与Logger差不多，其prefix和suffix属性解释和Logger 中的一样) className 指定Valve使用的类名，如用org.apache.catalina.valves.AccessLogValve类可以记录应用程序的访问信息 directory 指定log文件存放的位置 pattern 有两个值，common方式记录远程主机名或ip地址，用户名，日期，第一行请求的字符串，HTTP响应代码，发送的字节数。combined方式比common方式记录的值更多 web.xml 默认Web应用的首页文件的设置 报错文件的设置 session 会话过期时间的设置,单位是分钟 servlet的设置(Java Servlet的简称，称为小服务程序或服务连接器，用Java编写的服务器端程序，具有独立于平台和协议的特性，主要功能在于交互式地浏览和生成数据，生成动态Web内容。) tomcat-users.xml 管理用户配置文件 rolename 定义角色，不同的角色管理权限不同，相当于组 123456manager-gui\t允许访问html接口(即URL路径为/manager/html/*)manager-script\t允许访问纯文本接口(即URL路径为/manager/text/*)manager-jmx\t允许访问JMX代理接口(即URL路径为/manager/jmxproxy/*)manager-status\t允许访问Tomcat只读状态页面(即URL路径为/manager/status/*)admin-gui 允许访问html管理界面admin-script 允许访问文本管理界面 user 定义用户名 123username\t定义用户名password\t设置密码roles 属于那些角色/组"},{"path":"/2023/07/11/Web服务器-Tomcat/Tomcat 发布动态页面/","content":"我们知道tomcat是用来发布jsp网站的，jsp的网站，页面漂亮还安全，上节课我们已经知道如何发布静态页面了，本节课我们一起来看一下如何发布动态页面，我们通过jpress一个使用java开发的建站软件来实现jsp页面 1jpress下载地址：http://jpress.io/download step 1 准备jsp页面 12345678910[root@zutuanxue ~]# mv jpress-v3.2.1.war jpress.war[root@zutuanxue ~]# cp jpress.war /opt/tomcat1/webapps/#重启tomcat[root@zutuanxue ~]# cp jpress.war /opt/tomcat1/webapps/[root@zutuanxue ~]# sh /opt/tomcat1/bin/shutdown.sh [root@zutuanxue ~]# sh /opt/tomcat1/bin/startup.sh #重启之后tomcat会自己将这个war的压缩包解压，生成一个同名的目录 step 2 准备数据库 123456789[root@zutuanxue yum.repos.d]# dnf install mariadb mariadb-server -y[root@zutuanxue yum.repos.d]# systemctl restart mariadb.service [root@zutuanxue ~]# mysql -u root -pEnter password: MariaDB [(none)]&gt; create database jpress charset utf8;MariaDB [(none)]&gt; grant all on jpress.* to jpress@&#x27;localhost&#x27; identified by &#x27;123456&#x27;; step 3 安装jpress image20200313141545372.png image20200313141616340.png image20200313141647962.png image20200313141659536.png image20200313141725515.png image20200313141752995.png image20200313141822315.png"},{"path":"/2023/07/11/Web服务器-Nginx/默认网站/","content":"一、默认网站12345678910111213141516171819202122232425server &#123; listen 80; server_name localhost; location / &#123; root html; index index.html index.htm; #支持目录浏览 autoindex on; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 二、访问控制1234567891011location /a &#123; autoindex on; allow 192.168.12.0/24; deny all; #基于客户端IP做过滤，符合条件的允许访问，不符合的返回404； if ( $remote_addr !~ &quot;192.168.12&quot; ) &#123; #return 404; return http://book.ayitula.com; &#125; &#125; 三、登陆验证12345location /c &#123; auth_basic &quot;登陆验证&quot;; auth_basic_user_file /etc/nginx/htpasswd;&#125; 四、日志管理Nginx访问日志主要有两个参数控制 log_format #用来定义记录日志的格式（可以定义多种日志格式，取不同名字即可） access_log #用来指定日至文件的路径及使用的何种日志格式记录日志 access_log logs&#x2F;access.log main; 12345678910log_format格式变量： $remote_addr #记录访问网站的客户端地址 $remote_user #远程客户端用户名 $time_local #记录访问时间与时区 $request #用户的http请求起始行信息 $status #http状态码，记录请求返回的状态码，例如：200、301、404等 $body_bytes_sent #服务器发送给客户端的响应body字节数 $http_referer #记录此次请求是从哪个连接访问过来的，可以根据该参数进行防盗链设置。 $http_user_agent #记录客户端访问信息，例如：浏览器、手机客户端等 $http_x_forwarded_for #当前端有代理服务器时，设置web节点记录客户端地址的配置，此参数生效的前提是代理服务器也要进行相关的x_forwarded_for设置 自定义一个json格式的访问日志 123456789log_format main_json &#x27;&#123;&quot;@timestamp&quot;:&quot;$time_local&quot;,&#x27;&#x27;&quot;client_ip&quot;: &quot;$remote_addr&quot;,&#x27;&#x27;&quot;request&quot;: &quot;$request&quot;,&#x27;&#x27;&quot;status&quot;: &quot;$status&quot;,&#x27;&#x27;&quot;bytes&quot;: &quot;$body_bytes_sent&quot;,&#x27;&#x27;&quot;x_forwarded&quot;: &quot;$http_x_forwarded_for&quot;,&#x27;&#x27;&quot;referer&quot;: &quot;$http_referer&quot;&#x27;&#x27;&#125;&#x27;;access_log logs/access_json.log main_json; 日志截断 1234567mv access.log access.log.0killall -USR1 \\`cat master.nginx.pid\\`sleep 1gzip access.log.0 五、防盗链123456789location /images/ &#123;alias /data/images/;valid_referers none blocked *.ayitula.com; if ($invalid_referer) &#123; rewrite ^/ http://www.ayitula.com/daolian.gif; #return 403; &#125;&#125;"},{"path":"/2023/07/11/Web服务器-Nginx/虚拟主机/","content":"一、虚拟主机介绍虚拟主机 就是把一台物理服务器划分成多个“虚拟”的服务器，每一个虚拟主机都可以有独立的域名和独立的目录，可以独立发布一个网站。 实验案例： 同时发布两个网站： DocumentRoot &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F;web1 DocumentRoot &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html&#x2F;web2 二、基于IP的虚拟主机应用场景：IP充足的环境，每个网站需要一个IP地址 1234567891011121314server &#123; listen 192.168.11.251:80; location / &#123; root html/web1; index index.html index.htm index.php; &#125;&#125;server &#123; listen 192.168.11.252:80;location / &#123; root html/web2; index index.html index.htm; &#125;&#125; 基于IP的虚拟主机特点 不同IP对应不同网站 访问方便，用户直接使用默认端口即可访问 服务器需要有多个IP地址（一个公网IP大概一年的费用是600左右） 维护方便，基于独立IP的站点，便于监控、维护。 三、基于端口的虚拟主机应用场景：IP不足的环境 优点: 多个网站发布使用该配置方法只需要一个IP，节省IP地址 缺点 端口你是无法告诉公网用户，无法适用于公网客户，适合内部用户 1234567891011121314151617基于端口server &#123; listen 80; #server_name www.zutuanxue.com; location / &#123; root html/web1; index index.html index.htm index.php; &#125;&#125;server &#123; listen 8080; #server_name www.zutuanxue.com; location / &#123; root html/web2; index index.html index.htm; &#125;&#125; 基于端口的虚拟主机特点 不同端口对应不同网站 访问需要加端口 节省IP地址 适合私网运行 四、基于域名的虚拟主机应用场景：一个网站需要有一个域名，目前公网发布网站的首选 12345678910111213141516171819202122基于域名server &#123; listen 80; server_name web1.zutuanxue.com; location / &#123; root html/web1; index index.html index.htm index.php; &#125;&#125;server &#123; listen 80; server_name web2.zutuanxue.com; location / &#123; root html/web2; index index.html index.htm; &#125;&#125; 基于域名的虚拟主机特点 不同域名对应不同网站 需要多个域名 可以是二级或三级域名 每个站点使用默认端口，方便用户访问 只需要一个IP地址，节约成本 适合公网环境"},{"path":"/2023/07/11/Web服务器-Nginx/反向代理/","content":"一、代理介绍代理在网络中使用是比较常见的，比如我们说的最多的就是翻墙软件，比如ss、蓝灯等这些大家常用的软件，他们就是能改代理大家访问国内无法访问的一些国外网站，比如facebook、YouTube等网站。其原理也比较简单： 1）用户将请求发给代理服务器 2）代理服务器代用户去访问数据 3）代理服务器将数据给用户 正常没有代理情况上网 反代1.png 代理服务器场景 反代2.png 代理服务器扮演的就是一个中间人的角色。 代理分为正向代理和反向代理两种类型： 正向代理：代理用户访问其他网站，比如ss，蓝灯。 反向代理：用来发布服务器，比如nginx 树明主要给大家介绍的是反向代理，使用反向代理发布公司的站点。**(国家严厉打击私单乱建翻墙代理服务器)** 二、应用场景1）堡垒机：堡垒机承担所有的外部访问，保护后端服务器的安全 反代堡垒机.png 2）业务发布服务器：将多个服务器通过虚拟主机的方式发布到公网 反代发布服务器.png 3）缓存服务器：CDN加速 ## 三、反向代理原理 \\1) 客户端通过浏览器 发起请求 代理服务器 2）代理服务器 接受请求 \\3) 代理服务器 发起请求 业务服务器 4）业务服务器 接受请求 5）业务服务器 处理请求 \\6 反代缓存服务器.png 业务服务器 响应请求 代理服务器 7）代理服务器 响应请求 客户端 8）客户端通过浏览器渲染请求并展示给用户 四、反向代理实现proxy_pass: nginx反向代理指令 反向代理实现 location &#x2F; { index index.php index.html index.htm; #定义首页索引文件的名称 proxy_pass http://mysvr ;#请求转向mysvr 定义的服务器列表 } 反向代理优化 1234567891011121314151617181920212223proxy_set_header Host $host; #修改请求头，添加Host字段proxy_set_header X-Real-IP $remote_addr; #修改请求头，添加X-Real-IP字段proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #修改请求头，添加X-Forwarded-For字段client_max_body_size 10m; #允许客户端请求的最大单文件字节数client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间\\(代理连接超时\\)proxy_send_timeout 90; #后端服务器数据回传时间\\(代理发送超时\\)proxy_read_timeout 90; #连接成功后，后端服务器响应时间\\(代理接收超时\\)proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传"},{"path":"/2023/07/11/Web服务器-Nginx/下载限速/","content":"一、限速介绍在生产环境中，为了保护WEB服务器的安全，我们都会对用户的访问做出一些限制，保证服务器的安全及资源的合理分配。 限流（rate limiting）是NGINX众多特性中最有用的，也是经常容易被误解和错误配置的，特性之一访问请求限速。该特性可以限制某个用户在一个给定时间段内能够产生的HTTP请求数。请求可以简单到就是一个对于主页的GET请求或者一个登陆表格的POST请求。用于安全目的上，比如减慢暴力密码破解攻击。通过限制进来的请求速率，并且（结合日志）标记出目标URLs来帮助防范DDoS攻击。一般地说，限流是用在保护上游应用服务器不被在同一时刻的大量用户请求湮没 限速说的很笼统，其实限速分为很多种限速方法： 1）下载速度限速 2）单位时间内请求数限制 3）基于客户端的并发连接限速 nginx限速模块 Nginx官方版本限制IP的连接和并发分别有两个模块： limit_req_zone 用来限制单位时间内的请求数，即速率限制,采用的漏桶算法 “leaky bucket”。 limit_req_conn 用来限制同一时间连接数，即并发限制。 二、应用场景下载限速：限制现在速度及并发连接数，应用在下载服务器中，保护带宽及服务器的IO资源。 请求限速：限制单位时间内用户访问请求，防止恶意攻击，保护服务器及资源安全。 三、限速原理漏桶原理 限速漏桶原理.png 123456算法思想是： 水（请求）从上方倒入水桶，从水桶下方流出（被处理）； 来不及流出的水存在水桶中（缓冲），以固定速率流出； 水桶满后水溢出（丢弃）。 这个算法的核心是：缓存请求、匀速处理、多余的请求直接丢弃。 相比漏桶算法，令牌桶算法不同之处在于它不但有一只“桶”，还有个队列，这个桶是用来存放令牌的，队列才是用来存放请求的。 四、限速实现1）单位时间内请求数限制 1234567891011121314151617#基于IP对下载速率做限制 限制每秒处理1次请求，对突发超过5个以后的请求放入缓存区 http &#123; limit_req_zone $binary_remote_addr zone=baism:10m rate=1r/s; server &#123; location /abc &#123; limit_req zone=baism burst=5 nodelay; &#125;&#125;limit_req_zone $binary_remote_addr zone=baism:10m rate=1r/s;第一个参数：$binary_remote_addr 表示通过remote_addr这个标识来做限制，“binary_”的目的是缩写内存占用量，是限制同一客户端ip地址。第二个参数：zone=baism:10m表示生成一个大小为10M，名字为one的内存区域，用来存储访问的频次信息。第三个参数：rate=1r/s表示允许相同标识的客户端的访问频次，这里限制的是每秒1次，还可以有比如30r/m的。limit_req zone=baism burst=5 nodelay;第一个参数：zone=baism 设置使用哪个配置区域来做限制，与上面limit_req_zone 里的name对应。第二个参数：burst=5，重点说明一下这个配置，burst爆发的意思，这个配置的意思是设置一个大小为5的缓冲区当有大量请求（爆发）过来时，超过了访问频次限制的请求可以先放到这个缓冲区内。第三个参数：nodelay，如果设置，超过访问频次而且缓冲区也满了的时候就会直接返回503，如果没有设置，则所有请求会等待排队。 2）限制并发连接数 12345678910111213141516171819#基于IP做连接限制 限制同一IP并发为1limit_conn_zone $binary_remote_addr zone=addr:10m;server &#123; listen 80; server_name localhost; location / &#123; root html; index index.html index.htm; &#125; location /abc &#123; limit_conn addr 1; &#125; &#125;&#125; 3）限制下载速度 1234567891011121314151617下载速度为100kserver &#123; listen 80; server_name localhost; location / &#123; root html; index index.html index.htm; &#125; location /abc &#123; limit_rate 100k; &#125; &#125;&#125; 4）综合案例 限制web服务器请求处理为1秒一个，触发值为5； 限制并发连接数为4; 限制下载速度为100. 12345678910111213141516171819202122232425262728http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65;#基于IP做连接限制 限制同一IP并发为1 下载速度为100Klimit_conn_zone $binary_remote_addr zone=addr:10m;#基于IP对下载速率做限制 限制每秒处理1次请求，对突发超过5个以后的请求放入缓存区 limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server &#123; listen 80; server_name localhost; location / &#123; root html; index index.html index.htm; &#125; location /abc &#123; limit_req zone=one burst=5 nodelay; limit_conn addr 4; limit_rate 100k; &#125; &#125;&#125;"},{"path":"/2023/07/11/Web服务器-Nginx/Nginx安装部署/","content":"一、nginx源码下载官网：http://nginx.org/ 源码包： nginx-1.19.3.tar.gz 源码包下载： wget http://nginx.org/download/nginx-1.19.3.tar.gz -P &#x2F;usr&#x2F;src 二、nginx安装12345678910111213141516171819202122232425262728292.1、下载nginx源码包[root@zutuanxue ~]# wget http://nginx.org/download/nginx-1.19.3.tar.gz -P /usr/src[root@zutuanxue src]# cd /usr/src2.2、安装nginx依赖包[root@zutuanxue ~]# yum -y install gcc pcre-devel zlib-devel - gcc: 源码编译工具 - pcre-devel： nginx url_rewrite 功能提供包 - zlib-devel： nginx 压缩功能提供包\t2.3、解压nginx源码，并进入源码包[root@zutuanxue src]# tar xf nginx-1.19.3.tar.gz[root@zutuanxue src]# cd nginx-1.19.32.4、配置nginx源码[root@zutuanxue nginx-1.19.3]# ./configure --prefix=/usr/local/nginx 配置目的： 1）检查环境 是否 满足安装条件 依赖解决 2）指定安装方式 配置文件 命令文件 各种文件放哪里 开启模块功能【内置模块 三方模块】 3）指定软件安装在那里2.5、编译nginx源码[root@zutuanxue nginx-1.19.3]# make -j42.6、安装nginx[root@zutuanxue nginx-1.19.3]# make install 三、nginx相关目录nginx path prefix: “&#x2F;usr&#x2F;local&#x2F;nginx” nginx binary file: “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx” nginx modules path: “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;modules” nginx configuration prefix: “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf” nginx configuration file: “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf” nginx pid file: “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs&#x2F;nginx.pid” nginx error log file: “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs&#x2F;error.log” nginx http access log file: “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs&#x2F;access.log” 四、nginx启动管理配置文件测试：&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -t Nginx启动：&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx Nginx关闭：killall –s QUIT nginx 五、nginx启动测试nginx安装完毕，接下来就可以启动nginx了，nginx启动后如何测试nginx的启动状态呢？可以通过以下三种方式去测试，这个可以根据自己的习惯选择一种测试就行了。 使用netsata命令查看启动端口 [root@zutuanxue ~]# netstat –ntpl 使用losf命令查看启动端口 [root@zutuanxue ~]# lsof -i :80 使用文本浏览器访问nginx默认网站 [root@zutuanxue ~]# elinks http://IP 测试页面内容如下 nginx默认网站页.png"},{"path":"/2023/07/11/Web服务器-Nginx/Nginx优化/","content":"一、调优的必要性在聊调优之前，我们先要知道为何调优，业务运行和调优的关系。 42967083431970b0eb40b3949278a0d1.png 业务运行：线上业务正常运行，承载了公司业务。监控业务：通过监控业务对线上业务进行监控，及时发现问题。优化业务：通过监控分析，发现业务问题或者瓶颈，及时对业务或者软件就行调整、优化。测试优化：优化完成后，需要对现有的优化进行测试，保证业务在当前优化模式中稳定、高效，能够解决当前问题。这就是业务运行的一个流程，也是我们保证业务稳定、高效、高可用的运维之道。 二、调优的维度和见解分歧 调优类的文章是最难写的，因为我只能告诉你调优的选项，无法告诉你具体的阈值，因为不同的业务运行在不同的机器，所消耗的资源是不同的；又因为场景不同，对应的调优项及阈值是千变万化的，就好比你和你上铺的兄弟都是感冒了，去医院看病开的药却是截然不同的。正是如此，才会出现当很多人看到调优的文章，看到了具体的调优项或者阈值就会浮现出两个字，我不好意思说，配个图吧！大家意会就好。 28a4aaa7cf00a2483492b17857a75176.png Nginx跳跃1、并发优化nginx工作模式：主进程+工作进程 12345678910启动工作进程数量worker_processes 4;#指定运行的核的编号，采用掩码的方式设置编号worker_cpu_affinity 0001 0010 0100 1000;events &#123;单个工作进程维护的请求队列长度 worker_connections 1024;&#125; 2、长连接减少服务器维护因为与客户端建立http连接产生的大量tcp三次握手四次断开的开销 123keepalive_timeout 0; 0代表关闭#keepalive_timeout 100;#keepalive_requests 8192; 3、压缩降低传输时间，增加用户体验度；降低公司带宽费用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647gzip on;gzip_proxied any;gzip_min_length 1k;gzip_buffers 4 8k;gzip_comp_level 6;gzip_types text/plain text/css application/x-javascript application/javascript application/xml; # 开启gzip gzip off; #Nginx做为反向代理的时候启用：\toff – 关闭所有的代理结果数据压缩\texpired – 如果header中包含”Expires”头信息，启用压缩\tno-cache – 如果header中包含”Cache-Control:no-cache”头信息，启用压缩\tno-store – 如果header中包含”Cache-Control:no-store”头信息，启用压缩\tprivate – 如果header中包含”Cache-Control:private”头信息，启用压缩\tno_last_modified – 启用压缩，如果header中包含”Last_Modified”头信息，启用压缩\tno_etag – 启用压缩，如果header中包含“ETag”头信息，启用压缩\tauth – 启用压缩，如果header中包含“Authorization”头信息，启用压缩\tany – 无条件压缩所有结果数据 gzip_proxied any; # 启用gzip压缩的最小文件，小于设置值的文件将不会压缩 gzip_min_length 1k; # gzip 压缩级别，1-9，数字越大压缩的越好，也越占用CPU时间，后面会有详细说明 gzip_comp_level 1; # 进行压缩的文件类型。javascript有多种形式。其中的值可以在 mime.types 文件中找到。 gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png application/vnd.ms-fontobject font/ttf font/opentype font/x-woff image/svg+xml; # 增加响应头”Vary: Accept-Encoding” # 是否在http header中添加Vary: Accept-Encoding，建议开启 gzip_vary on; # 禁用IE 6 gzip gzip_disable &quot;MSIE [1-6]\\.&quot;; # 设置压缩所需要的缓冲区大小 gzip_buffers 32 4k; # 设置gzip压缩针对的HTTP协议版本 gzip_http_version 1.0; 4、静态缓存将部分数据缓存在用户本地磁盘，用户加载时，如果本地和服务器的数据一致，则从本地加载。提升用户访问速度，提升体验度。节省公司带宽成本。 12345expires指令：开启缓存并指定静态缓存时间location ~* \\.(png|gif)$ &#123; expires 1h; &#125;"},{"path":"/2023/07/11/Web服务器-Nginx/Nginx介绍/","content":"一、Nginx介绍Nginx(“engine x”)是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理服务器，也是一个 IMAP&#x2F;POP3&#x2F;SMTP 代理服务器。和apache一样，都是web服务器软件，因为其性能优异，所以被广大运维喜欢。又因为nginx是一个轻量级的web服务器，相比apache来说资源消耗更低。 延伸版本：tengine（淘宝）、openresrt（章亦春）等 http://nginx.org 官网 http://www.nginx.cn/doc/index.html 中文文档 最近大事记： 锤子科技在 T2 鸟巢发布会上将门票收入捐赠给了 OpenResty 开源项目OpenResty(又称：ngx_openresty) 是一个基于 NGINX 的可伸缩的 Web 平台，由中国人章亦春发起，提供了很多高质量的第三方模块 二、为什么选择NginxNginx 是一个高性能的 Web 和反向代理服务器, 它具有有很多非常优越的特性: 作为 Web 服务器：相比 Apache，Nginx 使用更少的资源，支持更多的并发连接，体现更高的效率，这点使 Nginx 尤其受到虚拟主机提供商的欢迎。能够支持高达 50,000 个并发连接数的响应，感谢 Nginx 为我们选择了 epoll and kqueue 作为开发模型. 作为负载均衡服务器：Nginx 既可以在内部直接支持 Rails 和 PHP，也可以支持作为 HTTP代理服务器 对外进行服务。Nginx 用 C 编写, 不论是系统资源开销还是 CPU 使用效率都比 Perlbal 要好的多。 作为邮件代理服务器: Nginx 同时也是一个非常优秀的邮件代理服务器（最早开发这个产品的目的之一也是作为邮件代理服务器），Last.fm 描述了成功并且美妙的使用经验。 Nginx 安装非常的简单，配置文件 非常简洁（还能够支持perl语法），Bugs非常少的服务器: Nginx 启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够在 不间断服务的情况下进行软件版本的升级。 三、Nginx和Apache对比 静态文件处理能力：nginx高于apache 资源消耗：nginx优于apache,因为nginx是异步处理模型，只需要几个进程就能够处理大量在线请求，而apache 2.4仍然是进程模型或者线程模型，即仍然采用大量线程来处理大量在线请求。 Apache支持的模块很多，而且也比较稳定。而nginx由于出现的比较晚，所以在这方面可能比不上Apache。 nginx本身就是一个反向代理服务器，而且支持7层负载均衡。 nginx处理动态页面很鸡肋，一般只用与处理静态页面和反向代理。"},{"path":"/2023/07/11/Web服务器-Nginx/Nginx url 重写/","content":"一、URL重写介绍和apache等web服务软件一样，rewrite的主要功能是实现URL地址的重定向。Nginx的rewrite功能需要PCRE软件的支持，即通过perl兼容正则表达式语句进行规则匹配的。默认参数编译nginx就会支持rewrite的模块，但是也必须要PCRE的支持。 Rewrite功功能是Nginx服务器提供的一个重要功能。几乎是所有的web产品必备技能，用于实现URL重写。URL重写是非常有用的功能，比如它可以在我们在改变网站结构后，不需要客户端修改原来的书签，也不需要其他网站修改对我们网站的友情链接，还可以在一定程度上提高网站的安全性，能够让我们的网站显得更专业。 二、应用场景域名变更 （京东） 用户跳转 （从某个连接跳到另一个连接） 伪静态场景 （便于CDN缓存动态页面数据） 三、URL重写原理URL重写原理.png 四、URL重写URL 模块语法 set 设置变量 if 负责语句中的判断 return 返回返回值或URL break 终止后续的rewrite规则 rewrite 重定向URL set指令 自定义变量Syntax: set $variable value; Default: — Context: server, location, if 12345将http://www.ayitula.com 重写为 http://www.ayitula.com/baismlocation / &#123; set $name baism; rewrite ^(.*)$ http://www.ayitula.com/$name; &#125; if 指令 负责判断Syntax: if (condition) { … } Default: — Context: server, location 条件匹配 #模糊匹配 匹配 !不匹配 ~* 不区分大小写的匹配 #精确匹配 &#x3D; !&#x3D; 123456789location / &#123; root html; index index.html index.htm; if ($http_user_agent ~* &#x27;Chrome&#x27;) &#123; break; return 403; #return http://www.jd.com; &#125; &#125; return 指令 定义返回数据Syntax: return code [text]; return code URL; return URL; Default: — Context: server, location, if 12345678location / &#123; root html; index index.html index.htm; if ($http_user_agent ~* &#x27;Chrome&#x27;) &#123; return 403; #return http://www.jd.com; &#125; &#125; break 指令 停止执行当前虚拟主机的后续rewrite指令集Syntax: break; Default:— Context:server, location, if 12345678location / &#123; root html; index index.html index.htm; if ($http_user_agent ~* &#x27;Chrome&#x27;) &#123; break; return 403; &#125; &#125; rewrite指令 实现重写urlrewrite [flag]; 关键字 正则 替代内容 flag标记 flag: last #本条规则匹配完成后，继续向下匹配新的location URI规则 break #本条规则匹配完成即终止，不再匹配后面的任何规则 redirect #返回302临时重定向，浏览器地址会显示跳转后的URL地址 permanent #返回301永久重定向，浏览器地址栏会显示跳转后的URL地址 重定向就是将网页自动转向重定向，permanent和redirect从定向的区别 301永久性重定向：新网址完全继承旧网址，旧网址的排名等完全清零 301重定向是网页更改地址后对搜索引擎友好的最好方法，只要不是暂时搬移的情况，都建议使用301来做转址。 302临时性重定向：对旧网址没有影响，但新网址不会有排名 搜索引擎会抓取新的内容而保留旧的网址 permanent标志：永久重定向 12345678910域名跳转www.ayitula.com 重写为 www.jd.comserver &#123; listen 80; server_name www.ayitula.com; location / &#123; rewrite ^/$ http://www.jd.com permanent; &#125;&#125; redirect标志：临时重定向 12345678910域名跳转www.ayitula.com 重写为 www.jd.comserver &#123; listen 80; server_name www.ayitula.com; location / &#123; rewrite ^/$ http://www.jd.com redirect; &#125;&#125; break标志： 类似临时重定向 12345678910域名跳转www.ayitula.com 重写为 www.jd.comserver &#123; listen 80; server_name www.ayitula.com; location / &#123; rewrite ^/$ http://www.jd.com break; &#125;&#125; last标志： url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变 last 一般出现在server或if中 根据用户浏览器重写访问目录 12345678910111213141516171819202122232425262728如果是chrome浏览器 就将 http://192.168.10.42/$URI 重写为 http://http://192.168.10.42/chrome/$URI实现 步骤1）URL重写2）请求转给本机locationlocation / &#123;.....if ($http_user_agent ~* &#x27;chrome&#x27;)&#123; #^ 以什么开头 ^a #$ 以什么结尾 c$ #. 除了回车以外的任意一个字符 #* 前面的字符可以出现多次或者不出现 #更多内容看正则表达式 re rewrite ^(.*)$ /chrome/$1 last; &#125; location /chrome &#123; root html ; index index.html; &#125;&#125;"},{"path":"/2023/07/11/Web服务器-Apache/部署lamp-平台集成/","content":"一、平台集成单个软件是无法直接完成我们发布PHP站点的既定任务的，需要我们通过多个软件的通力合作才可以完成，所以我们需要将多个软件关联起来，让彼此各司其职，各干其活。一起完成我们的工作。 linux：系统软件，应用软件平台 apache：接受用户请求，处理静态数据，响应用户请求 php：处理用户的PHP请求 mysql：存储数据 二、平台集成方法 PHP作为模块 PHP作为服务 1.PHP作为模块这种方式是历史最悠久的关联方法，PHP模块默认出于休眠状态，和apache是上下级关系。apache接受了用户PHP请求后去唤醒PHP模块，PHP模块再去处理请求。 2.PHP作为服务这种是apache2.4新增功能，PHP是一个服务，常驻内存。和apache是平级关系，apache接受了用户请求直接通过socket或tcp&#x2F;ip的方式发送给PHP服务，PHP服务直接处理。如果是在同一台机器安装了apache和php建议使用socket方式关联，系统开销最小，并发更大。 三、PHP作为模块[root@zutuanxue php-7.3.4]# .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;php –with-config-file-path&#x3D;&#x2F;usr&#x2F;local&#x2F;php&#x2F;etc –with-mysqli&#x3D;mysqlnd –enable-pdo –with-pdo-mysql&#x3D;mysqlnd –with-iconv-dir&#x3D;&#x2F;usr&#x2F;local&#x2F; –enable-fpm –with-fpm-user&#x3D;www –with-fpm-group&#x3D;www –with-pcre-regex –with-zlib –with-bz2 –enable-calendar –disable-phar –with-curl –enable-dba –with-libxml-dir –enable-ftp –with-gd –with-jpeg-dir –with-png-dir –with-zlib-dir –with-freetype-dir –enable-gd-jis-conv –with-mhash –enable-mbstring –enable-opcache&#x3D;yes –enable-pcntl –enable-xml –disable-rpath –enable-shmop –enable-sockets –enable-zip –enable-bcmath –with-snmp –disable-ipv6 –with-gettext –disable-rpath –disable-debug –enable-embedded-mysqli –with-mysql-sock&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;** –with-apxs2&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;apxs** 在PHP编译的时候需要加上–with-apxs2&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;bin&#x2F;apxs语句，意思是通过apache的apxs命令将PHP生成为一个apache模块。 配置方法 12345678910111213141516171819202122apache修改主配置文件，添加以下行Include conf/extra/php.conf[root@zutuanxue conf]# cat extra/php.conf LoadModule php7_module modules/libphp7.soAddType application/x-httpd-php .php&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web1&quot;&lt;/VirtualHost&gt;&lt;Directory &quot;/usr/local/apache/htdocs/web1&quot;&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted&lt;/Directory&gt;&lt;IfModule dir_module&gt; DirectoryIndex index.php index.html&lt;/IfModule&gt; 四、PHP作为服务tcp sock 模式12345678910111213141516171819202122232425262728291）修改apache子配置文件apache修改主配置文件，添加以下行Include conf/extra/php-fpm.conf[root@zutuanxue conf]# cat extra/php-fpm.confLoadModule proxy_module modules/mod_proxy.soLoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so2）设置虚拟主机 关联php&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web1&quot;&lt;/VirtualHost&gt;&lt;Directory &quot;/usr/local/apache/htdocs/web1&quot;&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted&lt;/Directory&gt;&lt;IfModule dir_module&gt; DirectoryIndex index.php index.html&lt;/IfModule&gt;&lt;FilesMatch \\.php$&gt; SetHandler &quot;proxy:fcgi://127.0.0.1:9000&quot;&lt;/FilesMatch&gt; unix sock模式12345678910111213141516171819202122232425262728291）apache修改主配置文件，添加以下行Include conf/extra/php-fpm.conf[root@zutuanxue conf]# cat extra/php-fpm.confLoadModule proxy_module modules/mod_proxy.soLoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so2）修改PHP-FPM配置文件[root@zutuanxue extra]# egrep &quot;^listen&quot; /usr/local/php/etc/php-fpm.d/www.conflisten = /usr/local/php/etc/php-fpm.socketlisten.backlog = 511#设置UNIX socket 权限listen.owner = www listen.group = wwwlisten.mode = 06603）设置虚拟主机 关联php-fpm&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web1&quot;&lt;FilesMatch &quot;\\.php$&quot;&gt; # Unix sockets require 2.4.7 or later SetHandler &quot;proxy:unix:/usr/local/php/etc/php-fpm.socket|fcgi://localhost/&quot;&lt;/FilesMatch&gt;&lt;/VirtualHost&gt; 五、测试页面1）生成测试页面 echo “” &#x2F;DR&#x2F;phpinfo.php 2）测试 打开浏览器输入 http://ip或者域名/phpinfo.php phpinfo.png"},{"path":"/2023/07/11/Web服务器-Apache/部署lamp-MySQL安装/","content":"一、MySQL介绍瑞典AB公司开发，后来卖给了oracle 一个关系型数据库 中小型数据库，表过大会出现IO性能瓶颈，树明建议单表600万条记录或2G以上就分表 分为企业版和社区版，目前两大版本mysql5.7 和mysql 8.0 二、MySQL安装a、安装前依赖解决 1）cmake命令 2.8以上 https://cmake.org/download/ boost Boost库是一个可移植、提供源代码的C库，作为标准库的后备，是C标准化进程的开发引擎之一 https://www.boost.org/ mysql获得 https://dev.mysql.com/downloads/mysql/ b、MySQL 安装 [root@zutuanxue ~]# yum -y install ncurses-devel gcc-* bzip2-* bison 1)cmake 安装 12345[root@zutuanxue ~]# tar xf cmake-3.6.0-rc1.tar[root@zutuanxue cmake-3.6.0-rc1]# cd cmake-3.6.0-rc1[root@zutuanxue cmake-3.6.0-rc1]# ./configure[root@zutuanxue cmake-3.6.0-rc1]# make[root@zutuanxue cmake-3.6.0-rc1]# make install 2）boost 安装 12[root@zutuanxue ~]# tar xf boost\\_1\\_59\\_0.tar.bz2[root@zutuanxue ~]# mv boost\\_1\\_59\\_0 /usr/local/boost 3)mysql安装 123456789101112131415161718192021222324[root@zutuanxue ~]# useradd -s /sbin/nologin -r mysql[root@zutuanxue ~]# mkdir -pv /usr/local/mysql/data[root@zutuanxue ~]# tar xf mysql...tar.xx[root@zutuanxue mysql]# cmake . -DCMAKE\\_INSTALL\\_PREFIX=/usr/local/mysql -DMYSQL\\_DATADIR=/usr/local/mysql/data/ -DMYSQL\\_UNIX\\_ADDR=/usr/local/mysql/mysql.sock -DWITH\\_INNOBASE\\_STORAGE\\_ENGINE=1 -DWITH\\_MYISAM\\_STORAGE\\_ENGINE=1 -DENABLED\\_LOCAL\\_INFILE=1 -DEXTRA\\_CHARSETS=all -DDEFAULT\\_CHARSET=utf8 -DDEFAULT\\_COLLATION=utf8\\_general\\_ci -DMYSQL\\_USER=mysql -DWITH\\_DEBUG=0 -DWITH\\_EMBEDDED\\_SERVER=1 -DDOWNLOAD\\_BOOST=1 -DENABLE\\_DOWNLOADS=1 -DWITH\\_BOOST=/usr/local/boost[root@zutuanxue mysql]# cmake . \\-DCMAKE_INSTALL_PREFIX=/usr/local/mysql 指定安装路径-DMYSQL_DATADIR=/usr/local/mysql/data/ 指定数据目录-DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock 指定sock文件路径-DWITH_INNOBASE_STORAGE_ENGINE=1 安装Innodb存储引擎-DWITH_MYISAM_STORAGE_ENGINE=1 安装myisam存储引擎-DENABLED_LOCAL_INFILE=1 允许使用Load data命令从本地导入数据-DEXTRA_CHARSETS=all -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci 安装所有字符集、默认字符集utf-8 、校验字符-DMYSQL_USER=mysql mysql用户名-DWITH_DEBUG=0 关闭debug-DWITH_EMBEDDED_SERVER=1 生成一个libmysqld.a(.so)的库，这个库同时集成了mysql服务与客户端API-DDOWNLOAD_BOOST=1 -DENABLE_DOWNLOADS=1 -DWITH_BOOST=/usr/local/boost 允许boost 允许下载boost库文件。[root@zutuanxue mysql]# make[root@zutuanxue mysql]# make install 4)安装后操作 12345678[root@zutuanxue ~]# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql[root@zutuanxue ~]# chmod 755 /etc/init.d/mysql[root@zutuanxue ~]# chown mysql.mysql /usr/local/mysql/ -R[root@zutuanxue ~]# ln -sf /usr/local/mysql/bin/\\* /usr/bin/[root@zutuanxue ~]# ln -sf /usr/local/mysql/lib/\\* /usr/lib/[root@zutuanxue ~]# ln -sf /usr/local/mysql/libexec/\\* /usr/local/libexec[root@zutuanxue ~]# ln -sf /usr/local/mysql/share/man/man1/\\* /usr/share/man/man1[root@zutuanxue ~]# ln -sf /usr/local/mysql/share/man/man8/\\* /usr/share/man/man8 修改配置文件 确保路径正确 1234567891011121314151617egrep -v &quot;^#|^$&quot; /etc/my.cnf[mysqld]datadir=/usr/local/mysql/datasocket=/usr/local/mysql/mysql.socksymbolic-links=0[mysqld\\_safe]log-error=/var/log/mysql.logpid-file=/var/run/mysql.pid!includedir /etc/my.cnf.d 5)初始化数据库 1[root@zutuanxue ~]# /usr/local/mysql/bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql/ --datadir=/usr/local/mysql/data/ 临时密码 root@localhost: T6upu&gt;pr+8,Z 三、启动mysql1[root@zutuanxue ~]# /etc/init.d/mysql start 密码修改 1[root@zutuanxue ~]# mysql_secure_installation 四、MySQL测试mysql -u root -p’password’ mysql&gt;"},{"path":"/2023/07/11/Web服务器-Apache/部署Apache服务器/","content":"安装步骤 安装apr 安装apr-util 安装apr-iconv 安装apache 启动apache 测试apache MPM 一、安装依赖安装依赖 [root@zutuanxue ~]# yum install -y pcre-devel libxml2 expat-devel 二、 apr介绍及安装APR(Apache portable Run-time libraries，Apache可移植运行库)的目的如其名称一样，主要为上层的应用程序提供一个可以跨越多操作系统平台使用的底层支持接口库。在早期 的Apache版本中，应用程序本身必须能够处理各种具体操作系统平台的细节，并针对不同的平台调用不同的处理函数。 [root@zutuanxue ~]# wget https://www.apache.org/dist/apr/apr-1.7.0.tar.bz2 [root@zutuanxue ~]# tar xf apr-1.7.0.tar.bz2 [root@zutuanxue ~]# cd apr-1.7.0 [root@zutuanxue apr-1.7.0]# .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr [root@zutuanxue apr-1.7.0]# make [root@zutuanxue apr-1.7.0]# make install 三、APR-util介绍及安装apr-util该目录中也是包含了一些常用的开发组件。这些组件与apr目录下的相比，它们与apache的关系更加密切一些。比如存储段和存储段组，加密等等。 [root@zutuanxue ~]# wget https://www.apache.org/dist/apr/apr-util-1.6.1.tar.bz2 [root@zutuanxue ~]# tar xf apr-util-1.6.1.tar.bz2 [root@zutuanxue ~]# cd apr-util-1.6.1 [root@zutuanxue apr-util-1.6.1]# yum install -y expat-devel [root@zutuanxue apr-util-1.6.1]# .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F; [root@zutuanxue apr-util-1.6.1]# make [root@zutuanxue apr-util-1.6.1]# make install 四、apr-iconv介绍及安装apr-iconv包中的文件主要用于实现iconv编码。目前的大部分编码转换过程都是与本地编码相关的。在进行转换之前必须能够正确地设置本地编码。因此假如两个非本地编码A和B需要转换，则转换过程大致为A-&gt;Local以及Local-&gt;B或者B-&gt;Local以及Local-&gt;A。 [root@zutuanxue ~]# wget https://www.apache.org/dist/apr/apr-iconv-1.2.2.tar.bz2 [root@zutuanxue ~]# tar xf apr-iconv-1.2.2.tar.bz2 [root@zutuanxue ~]# cd apr-iconv-1.2.2 [root@zutuanxue apr-iconv-1.2.2]# .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-iconv –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr [root@zutuanxue apr-iconv-1.2.2]# make [root@zutuanxue apr-iconv-1.2.2]# make install 五、apache安装[root@zutuanxue ~]# wget https://www.apache.org/dist/httpd/httpd-2.4.39.tar.gz [root@zutuanxue ~]# tar xf httpd-2.4.39.tar.gz [root@zutuanxue ~]# cd httpd-2.4.39 [root@zutuanxue httpd-2.4.39]# .&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apache –enable-mpms-shared&#x3D;all –with-mpm&#x3D;event –with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr –with-apr-util&#x3D;&#x2F;usr&#x2F;local&#x2F;apr-util –enable-so –enable-remoteip –enable-proxy –enable-proxy-fcgi –enable-proxy-uwsgi –enable-deflate&#x3D;shared –enable-expires&#x3D;shared –enable-rewrite&#x3D;shared –enable-cache –enable-file-cache –enable-mem-cache –enable-disk-cache –enable-static-support –enable-static-ab –disable-userdir –enable-nonportable-atomics –disable-ipv6 –with-sendfile 12345678910111213141516--prefix=/usr/local/apache 指定安装目录--enable-mpms-shared=all --with-mpm=event 开启动态MPM切换 --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util 指定依赖包apr apr-util安装路径--enable-so 打开 so 模块，so 模块是用来提 dso 支持的 apache 核心模块--enable-remoteip 支持基于客户端IP做访问控制 --enable-proxy --enable-proxy-fcgi --enable-proxy-uwsgi 启用代理支持PHP Python网站--enable-deflate=shared 开启压缩--enable-expires=shared 开启客户端缓存--enable-rewrite=shared 开启URL重写--enable-cache --enable-file-cache --enable-mem-cache --enable-disk-cache 开启服务器缓存 --enable-static-support 支持静态连接--enable-static-ab 使用静态连接编译 ab - apache http 服务器性能测试工具--disable-userdir 禁用用户主目录提供页面访问--enable-nonportable-atomics 对新式CPU支持，支持原子的比较交换(compare-and -swap, CAS)操作指令--disable-ipv6 禁用IPV6--with-sendfile 开启sendfile 0复制机制 [root@zutuanxue httpd-2.4.39]# make [root@zutuanxue httpd-2.4.39]# make install ##相关目录 [root@zutuanxue apache]# tree -L 1 . ├── bin 二进制命令 ├── build ├── cgi-bin cgi脚本目录 ├── conf 配置文件目录 ├── error 错误记录 ├── htdocs 默认网站根目录 ├── icons 小图标 ├── include 一些C语言文件 ├── logs 日志目录 ├── man 帮助手册 ├── manual 在线手册 └── modules 存放apache运行需要的模块 六、apache启动[root@zutuanxue ~]# &#x2F;usr&#x2F;local&#x2F;apache&#x2F;bin&#x2F;httpd 七、apache状态测试[root@zutuanxue ~]# elinks http://192.168.11.251 -dump 1It works! 八、MPM多处理模块Apache HTTP 服务器被设计为一个功能强大，并且灵活的 web 服务器， 可以在很多平台与环境中工作。不同平台和不同的环境往往需要不同 的特性，或可能以不同的方式实现相同的特性最有效率。Apache httpd 通过模块化的设计来适应各种环境。这种设计允许网站管理员通过在 编译时或运行时，选择哪些模块将会加载在服务器中，来选择服务器特性。 Apache HTTP 服务器 2.0 扩展此模块化设计到最基本的 web 服务器功能。 它提供了可以选择的多处理模块(MPM)，用来绑定到网络端口上，接受请求， 以及调度子进程处理请求。 扩展到这一级别的服务器模块化设计，带来两个重要的好处: Apache httpd 能更优雅，更高效率的支持不同的平台。尤其是 Apache httpd 的 Windows 版本现在更有效率了，因为 mpm_winnt 能使用原生网络特性取代在 Apache httpd 1.3 中使用的 POSIX 层。它也可以扩展到其它平台 来使用专用的 MPM。 Apache httpd 能更好的为有特殊要求的站点定制。例如，要求 更高伸缩性的站点可以选择使用线程的 MPM，即 worker 或 event； 需要可靠性或者与旧软件兼容的站点可以使用 prefork。 在用户看来，MPM 很像其它 Apache httpd 模块。主要是区别是，在任何时间， 必须有一个，而且只有一个 MPM 加载到服务器中。可用的 MPM 列表位于 模块索引页面。 默认MPM 下表列出了不同系统的默认 MPM。如果你不在编译时选择，那么它就是你将要使用的 MPM。 Netware mpm_netware OS&#x2F;2 mpmt_os2 Unix prefork，worker 或 event，取决于平台特性 Windows mpm_winnt 构建 MPM 为静态模块 在全部平台中，MPM 都可以构建为静态模块。在构建时选择一种 MPM，链接到服务器中。如果要改变 MPM，必须重新构建。 为了使用指定的 MPM，请在执行 configure 脚本 时，使用参数 –with-mpm&#x3D;NAME。NAME 是指定的 MPM 名称。 编译完成后，可以使用 .&#x2F;httpd -l 来确定选择的 MPM。 此命令会列出编译到服务器程序中的所有模块，包括 MPM。 构建 MPM 为动态模块 在 Unix 或类似平台中，MPM 可以构建为动态模块，与其它动态模块一样在运行时加载。 构建 MPM 为动态模块允许通过修改 LoadModule 指令内容来改变 MPM，而不用重新构建服务器程序。 在执行 configure 脚本时，使用 –enable-mpms-shared 选项可以启用此特性。 当给出的参数为 all 时，所有此平台支持的 MPM 模块都会被安装。还可以在参数中给出模块列表。 默认 MPM，可以自动选择或者在执行 configure 脚本时通过 –with-mpm 选项来指定，然后出现在生成的服务器配置文件中。 编辑 LoadModule 指令内容可以选择不同的 MPM。 –enable-mpms-shared&#x3D;all –with-mpm&#x3D;event Apache三种MPM介绍 **Prefork MPM **: 这个多路处理模块(MPM)实现了一个非线程型的、预派生的web服务器，它的工作方式类似于Apache 1.3。它适合于没有线程安全库，需要避免线程兼容性问题的系统。它是要求将每个请求相互独立的情况下最好的MPM，这样若一个请求出现问题就不会影响到其他请求。 这个MPM具有很强的自我调节能力，只需要很少的配置指令调整。最重要的是将MaxClients设置为一个足够大的数值以处理潜在的请求高峰，同时又不能太大，以致需要使用的内存超出物理内存的大小。 Worker MPM : 此多路处理模块(MPM)使网络服务器支持混合的多线程多进程。由于使用线程来处理请求，所以可以处理海量请求，而系统资源的开销小于基于进程的MPM。但是，它也使用了多进程，每个进程又有多个线程，以获得基于进程的MPM的稳定性。 每个进程可以拥有的线程数量是固定的。服务器会根据负载情况增加或减少进程数量。一个单独的控制进程(父进程)负责子进程的建立。每个子进程可以建立ThreadsPerChild数量的服务线程和一个监听线程，该监听线程监听接入请求并将其传递给服务线程处理和应答。 不管是Worker模式或是Prefork 模式，Apache总是试图保持一些备用的(spare)或者是空闲的子进程（空闲的服务线程池）用于迎接即将到来的请求。这样客户端就不需要在得到服务前等候子进程的产生。 Event MPM：以上两种稳定的MPM方式在非常繁忙的服务器应用下都有些不足。尽管HTTP的Keepalive方式能减少TCP连接数量和网络负载，但是 Keepalive需要和服务进程或者线程绑定，这就导致一个繁忙的服务器会耗光所有的线程。 Event MPM是解决这个问题的一种新模型，它把服务进程从连接中分离出来。在服务器处理速度很快，同时具有非常高的点击率时，可用的线程数量就是关键的资源限制，此时Event MPM方式是最有效的。一个以Worker MPM方式工作的繁忙服务器能够承受每秒好几万次的访问量（例如在大型新闻服务站点的高峰时），而Event MPM可以用来处理更高负载。在event工作模式中，会有一些专门的线程用来管理这些keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务器的线程，执行完毕后，又允许它释放。这增强了在高并发场景下的请求处理 apachempm.png"},{"path":"/2023/07/11/Web服务器-Apache/lamp部署-WordPress站点上线/","content":"一、配置虚拟主机1）获得网站代码[root@zutuanxue ~]# wget https://wordpress.org/latest.tar.gz 2）将源文件拷贝到APACHE的htdocs目录[root@zutuanxue ~]# mkdir &#x2F;usr&#x2F;local&#x2F;apache&#x2F;htdocs&#x2F;wordpress&#x2F; [root@zutuanxue ~]# tar xf latest.tar.gz -C &#x2F;opt [root@zutuanxue ~]# mv &#x2F;opt&#x2F;wordpress&#x2F;* &#x2F;usr&#x2F;local&#x2F;apache&#x2F;htdocs&#x2F;wordpress&#x2F; [root@zutuanxue ~]# chown www.www &#x2F;usr&#x2F;local&#x2F;apache&#x2F;htdocs&#x2F;wordpress -R 3）配置虚拟主机[root@zutuanxue htdocs]# cat &#x2F;usr&#x2F;local&#x2F;apache&#x2F;conf&#x2F;extra&#x2F;httpd-vhosts.conf 123456789101112131415161718192021&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/wordpress&quot;&lt;/VirtualHost&gt;&lt;Directory &quot;/usr/local/apache/htdocs/wordpress&quot;&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted&lt;/Directory&gt;&lt;IfModule dir_module&gt; DirectoryIndex phpinfo.php index.php index.html&lt;/IfModule&gt;&lt;FilesMatch &quot;\\.php$&quot;&gt; # Unix sockets require 2.4.7 or later SetHandler &quot;proxy:unix:/usr/local/php/etc/php-fpm.socket|fcgi://localhost/&quot;&lt;/FilesMatch&gt; 4）重启生效[root@zutuanxue ~]# killall httpd [root@zutuanxue ~]# &#x2F;usr&#x2F;local&#x2F;apache&#x2F;bin&#x2F;apachectl 二、安装wordpress1）登陆数据库[root@zutuanxue ~]# mysql -u root -p123 2）新建数据库 wordpressmysql&gt; create database wordpress; Query OK, 1 row affected (0.01 sec) 3）wordpress安装打开浏览器输入[http://IP。我的IP地址是192.168.11.251 ，所以在地址栏中输入的是http://192.168.11.251选择网站语言，我选择的简体中文，然后点继续](http://IP，我的IP地址是192.168.11.251，所以在地址栏中输入的是http://192.168.11.251! 选择网站语言，我选择的简体中文，然后点继续 wordpress_install_01.png wordpress_install_02.png 欢迎信息，同时告诉你准备连接数据库的相关信息和它的安装操作，直接点现在就开始，继续吧。 wordpress_install_03.png 输入数据库的相关信息，点提交。如果这个过不去，说明你数据库连接有问题。请检查你使用上述信息是否手动能连接到数据库 12检查方法mysql -u root -p123 -h 127.0.0.1 wordpress_install_05.png 数据库信息验证正确后，就要开始安装了。 wordpress_install_06.png 安装前要求你设置wordpress的后台管理账户和密码，注意，这可是网站后台管理员啊，密码一定不能像我这么随意。输入完毕后点安装就开始安装了。 wordpress_install_07.png 看到这个图片，恭喜你安装成功了。点登陆，去登陆后台设置网站吧。 wordpress_install_08.png 登陆窗口，输入你的网站后台的管理员账号密码。 wordpress_install_09.png 登陆成功，我们写一篇文章纪念一下吧。 根据步骤发布一篇文章吧！ wordpress_install_11.png 再一次在浏览器中输入HTTP:&#x2F;&#x2F;IP 你就能看到我们的文章了。"},{"path":"/2023/07/11/Web服务器-Apache/Apache站点优化-模块优化/","content":"一、模块介绍apache是一个补丁服务器，在安装apache的时候就为用户提供了很多常用模块供用户使用。但是，在生产环境中，很多模块是没有用的，如果apache开启的时候加载了这些模块，就会造成资源的浪费，所以我要告诉大家的是：找到你业务中需要的模块，将不需要的模块全部注释掉，不要让apache在加载这些模块，节省运行apache服务器资源。 那么如何找到你哪些是你需要的模块呢？请参考apache在线手册，对服务器中你使用的功能做分解，然后在对模块进行区分，筛选后做出模块使用列表，不用的就注释掉。 二、部分模块介绍core Apache HTTP服务器核心提供的功能，始终有效。 mpm_common 收集了被多个多路处理模块(MPM)实现的公共指令。 beos 专门针对BeOS优化过的多路处理模块(MPM) event 一个标准workerMPM的实验性变种。 mpm_netware Novell NetWare优化过的线程化的多路处理模块(MPM) mpmt_os2 专门针对OS&#x2F;2优化过的混合多进程多线程多路处理模块(MPM) prefork 一个非线程型的、预派生的MPM mpm_winnt 用于Windows NT&#x2F;2000&#x2F;XP&#x2F;2003 系列的MPM worker 线程型的MPM，实现了一个混合的多线程多处理MPM，允许一个子进程中包含多个线程。 mod_actions 基于媒体类型或请求方法，为执行CGI脚本而提供 mod_alias 提供从文件系统的不同部分到文档树的映射和URL重定向 mod_asis 发送自己包含HTTP头内容的文件 mod_auth_basic 使用基本认证 mod_auth_digest 使用MD5摘要认证(更安全，但是只有最新的浏览器才支持) mod_authn_alias 基于实际认证支持者创建扩展的认证支持者，并为它起一个别名以便于引用 mod_authn_anon 提供匿名用户认证支持 mod_authn_dbd 使用SQL数据库为认证提供支持 mod_authn_dbm 使用DBM数据库为认证提供支持 mod_authn_default 在未正确配置认证模块的情况下简单拒绝一切认证信息 mod_authn_file 使用纯文本文件为认证提供支持 mod_authnz_ldap 允许使用一个LDAP目录存储用户名和密码数据库来执行基本认证和授权 mod_authz_dbm 使用DBM数据库文件为组提供授权支持 mod_authz_default 在未正确配置授权支持模块的情况下简单拒绝一切授权请求 mod_authz_groupfile 使用纯文本文件为组提供授权支持 mod_authz_host 供基于主机名、IP地址、请求特征的访问控制 mod_authz_owner 基于文件的所有者进行授权 mod_authz_user 基于每个用户提供授权支持 mod_autoindex 自动对目录中的内容生成列表，类似于”ls”或”dir”命令 mod_cache 基于URI键的内容动态缓冲(内存或磁盘) mod_cern_meta 允许Apache使用CERN httpd元文件，从而可以在发送文件时对头进行修改 mod_cgi 在非线程型MPM(prefork)上提供对CGI脚本执行的支持 mod_cgid 在线程型MPM(worker)上用一个外部CGI守护进程执行CGI脚本 mod_charset_lite 允许对页面进行字符集转换 mod_dav 允许Apache提供DAV协议支持 mod_dav_fs 为mod_dav访问服务器上的文件系统提供支持 mod_dav_lock 为mod_dav锁定服务器上的文件提供支持 mod_dbd 管理SQL数据库连接，为需要数据库功能的模块提供支持 mod_deflate 压缩发送给客户端的内容 mod_dir 指定目录索引文件以及为目录提供”尾斜杠”重定向 mod_disk_cache 基于磁盘的缓冲管理器 mod_dumpio 将所有I&#x2F;O操作转储到错误日志中 mod_echo 一个很简单的协议演示模块 mod_env 允许Apache修改或清除传送到CGI脚本和SSI页面的环境变量 mod_example 一个很简单的Apache模块API演示模块 mod_expires 允许通过配置文件控制HTTP的”Expires:”和”Cache-Control:”头内容 mod_ext_filter 使用外部程序作为过滤器 mod_file_cache 提供文件描述符缓存支持，从而提高Apache性能 mod_filter 根据上下文实际情况对输出过滤器进行动态配置 mod_headers 允许通过配置文件控制任意的HTTP请求和应答头信息 mod_ident 实现RFC1413规定的ident查找 mod_imagemap 处理服务器端图像映射 mod_include 实现服务端包含文档(SSI)处理 mod_info 生成Apache配置情况的Web页面 mod_isapi 仅限于在Windows平台上实现ISAPI扩展 mod_ldap 为其它LDAP模块提供LDAP连接池和结果缓冲服务 mod_log_config 允许记录日志和定制日志文件格式 mod_log_forensic 实现”对比日志”，即在请求被处理之前和处理完成之后进行两次记录 mod_logio 对每个请求的输入&#x2F;输出字节数以及HTTP头进行日志记录 mod_mem_cache 基于内存的缓冲管理器 mod_mime 根据文件扩展名决定应答的行为(处理器&#x2F;过滤器)和内容(MIME类型&#x2F;语言&#x2F;字符集&#x2F;编码) mod_mime_magic 通过读取部分文件内容自动猜测文件的MIME类型 mod_negotiation 提供内容协商支持 mod_nw_ssl 仅限于在NetWare平台上实现SSL加密支持 mod_proxy 提供HTTP&#x2F;1.1的代理&#x2F;网关功能支持 mod_proxy_ajp mod_proxy的扩展，提供Apache JServ Protocol支持 mod_proxy_balancer mod_proxy的扩展，提供负载平衡支持 mod_proxy_connect mod_proxy的扩展，提供对处理HTTP CONNECT方法的支持 mod_proxy_ftp mod_proxy的FTP支持模块 mod_proxy_http mod_proxy的HTTP支持模块 mod_rewrite 一个基于一定规则的实时重写URL请求的引擎 mod_setenvif 根据客户端请求头字段设置环境变量 mod_so 允许运行时加载DSO模块 mod_speling 自动纠正URL中的拼写错误 mod_ssl 使用安全套接字层(SSL)和传输层安全(TLS)协议实现高强度加密传输 mod_status 生成描述服务器状态的Web页面 mod_suexec 使用与调用web服务器的用户不同的用户身份来运行CGI和SSI程序 mod_unique_id 为每个请求生成唯一的标识以便跟踪 mod_userdir 允许用户从自己的主目录中提供页面(使用”&#x2F;~username”) mod_usertrack 使用Session跟踪用户(会发送很多Cookie)，以记录用户的点击流 mod_version 提供基于版本的配置段支持 mod_vhost_alias 提供大批量虚拟主机的动态配置支持"},{"path":"/2023/07/11/Web服务器-Apache/Apache站点优化-数据压缩/","content":"一、数据压缩介绍数据从服务器传输到客户端，需要传输时间，文件越大传输时间就越长，为了减少传输时间，我们一般把数据压缩后在传给客户端。 apache支持两种压缩:deflate、gzip mod_gzip 和mod_deflate比较首先一个区别是安装它们的Apache Web服务器版本的差异。Apache 1.x系列没有内建网页压缩技术，所以才去用额外的第三方mod_gzip 模块来执行压缩。而Apache 2.x官方在开发的时候，就把网页压缩考虑进去，内建了mod_deflate 这个模块，用以取代mod_gzip。虽然两者都是使用的Gzip压缩算法，它们的运作原理是类似的。 第二个区别是压缩质量。mod_deflate 压缩速度略快而mod_gzip 的压缩比略高。一般默认情况下，mod_gzip 会比mod_deflate 多出4%~6％的压缩量。 那么，为什么使用mod_deflate？第三个区别是对服务器资源的占用。 一般来说mod_gzip 对服务器CPU的占用要高一些。mod_deflate 是专门为确保服务器的性能而使用的一个压缩模块，mod_deflate 需要较少的资源来压缩文件。这意味着在高流量的服务器，使用mod_deflate 可能会比mod_gzip 加载速度更快。 应用场景：数据压缩传输优化目的：提升用户访问页面加载速度，节约带宽二、数据压缩实现1）开启模块 LoadModule deflate_module modules&#x2F;mod_deflate.so 2）调用模块 DeflateCompressionLevel 4 AddOutputFilterByType DEFLATE text&#x2F;html text&#x2F;plain text&#x2F;xml application&#x2F;x-javascript application&#x2F;x-httpd-php AddOutputFilter DEFLATE js css BrowserMatch \\bMSIE\\s[1-6] dont-vary SetEnvIfNoCase Request_URI .(?:gif|jpe?g|png)$ no-gzip dont-vary SetEnvIfNoCase Request_URI .(?:exe|t?gz|zip|bz2|sit|rar)$ no-gzip dont-vary SetEnvIfNoCase Request_URI .(?:pdf|doc)$ no-gzip dont-vary 12345678910111213&lt;IfModule deflate_module&gt;# 压缩等级 4 1-9，数字越大压缩的越好，也越占用CPU时间DeflateCompressionLevel 4# 压缩类型 html、xml、php、css、jsAddOutputFilterByType DEFLATE text/html text/plain text/xml application/x-javascript application/x-httpd-phpAddOutputFilter DEFLATE js css#浏览器匹配 IE1-6的不压缩BrowserMatch \\bMSIE\\s[1-6] dont-vary#设置不压缩的文件，注意图片本身就是压缩过的，所以不需要再压缩SetEnvIfNoCase Request_URI .(?:gif|jpe?g|png)$ no-gzip dont-varySetEnvIfNoCase Request_URI .(?:exe|t?gz|zip|bz2|sit|rar)$ no-gzip dont-varySetEnvIfNoCase Request_URI .(?:pdf|doc)$ no-gzip dont-vary&lt;/IfModule&gt; 三、测试1）生成HTML数据页面 123for i in `seq 1 20`;do cat /etc/passwd &gt;&gt; /usr/local/apache/htdocs/test_deflate.htmldone 2）未启用压缩前通过浏览器访问该页面，通过开发者工具查看页面大小 deflate_01.png 3）启用压缩再次通过浏览器访问该页面，通过开发者工具查看页面大小，如果明显变小了则说明压缩成功。也可以从响应头中看出多了压缩字段。 deflate_02.png deflate_response_headers03.png"},{"path":"/2023/07/11/Web服务器-Apache/Apache站点优化-下载限速/","content":"一、限速介绍网站除了能共享页面给用户外，还能作为下载服务器存在。但是作为下载服务器时，我们应该考虑服务器的带宽和IO的性能，防止部分邪恶分子会通过大量下载的方式来攻击你的带宽和服务器IO性能。 假如你的服务器被邪恶分子通过下载的方式把带宽占满了，那么你或其他用户在访问的时候就会造成访问慢或者根本无法访问。 假如你的服务器被邪恶分子通过下载的方式把服务器IO占满了，那么你的服务器将会无法处理用户请求或宕机。 以上的两个问题在我们生产环境下是很可能也是很容易被攻击的，为了保护我们的带宽资源，我们可以通过限制下载速度来解决，防止某个用户下载占用大量带宽。同时，也可以通过限制连接数的上限来控制一个用户同一时间内同时发起的连接数做限制。 使用场景：资源下载服务器优化目的：保护带宽及服务器IO资源合理使用二、限速方法apache自带了基于带宽限速的模块 ratelimit_module 该模块只能对连接下载速度做限制，且是单线程的下载，迅雷等下载工具使用的是多线程下载。 mod_limitipconn ：限制每 IP 的连接数 。需要额外安装该模块 三、限速实现1）mod_limitipconn模块下载 wget https://dominia.org/djao/limit/mod_limitipconn-0.24.tar.bz2 2）模块安装 tar -zxvf mod_limitipconn-0.24.tar.gz cd mod_limitipconn-0.24 vim Makefile 修改如下行 12修改：apxs = “/usr/local/apache/bin/apxs” 指定apache命令apxs的路径 make make install 3）查看apache主配置文件,是否有了该模块 LoadModule limitipconn_module modules&#x2F;mod_limitipconn.so 有说明模块安装成功 4）实现限速 限速针对目录或者数据类型 针对目录 &lt;Location &#x2F;baism&gt;…… ; 针对数据类型&lt;Location &#x2F;baism&#x2F;*.mp4&gt;…… 123456789LoadModule ratelimit_module modules/mod_ratelimit.soLoadModule limitipconn_module modules/mod_limitipconn.so&lt;Location /baism&gt; SetOutputFilter RATE_LIMIT SetEnv rate-limit 100 #限速100kMaxConnPerIP 3 #限制的线程数NoIPLimit index.htm #对此文件不做限制&lt;/Location&gt; 四、测试1）生成下载数据 dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;usr&#x2F;local&#x2F;apache&#x2F;htdocs&#x2F;web1&#x2F;baism&#x2F;bigfile bs&#x3D;1M count&#x3D;300 2）使用wget下载数据 wget http://192.168.11.251/baism/bigfile 测试方法：并发下载3个以上看是否有限制查看下载速率是否在100K左右 测试图片 未限制限速前下载速度展示 下载限速1.png 开启下载速度限速，限制下载速度100KB 限速2.png 基于IP的并发下载限制，同一客户端下载并发为3 限速3.png"},{"path":"/2023/07/11/Web服务器-Apache/Apache安装-用户访问控制/","content":"一、访问控制介绍生产环境中，我们的网站分为公站和私站，公站我们巴不得所有人都能来访问，所以不会做任何访问限制。但是私站只是内部人访问，越安全越好，比如网站后台、比如公司数据站等等。所以我们需要通过设置访问控制来允许自己公司电脑或者IP登陆访问，其他人不能访问。 其实这个功能类似于防火墙，可以但是使用起来更加灵活。只针对本站做限制，不影响其他业务。 二、访问控制实现指令介绍Require 指令 #Require all denied 拒绝所有 #Require all granted 允许所有 #Require host address 允许主机域名 多个空格空开 #Require ip ip.address 允许ip或网段 多个空格空开 容器 只要一个成功即可就通过 和用于包含一组授权指令，其中一个指令必须成功才能使指令成功。 所有指令都生效才通过 和用于包含一组授权指令，其中无一个指令必须失败，并且至少有一个指令必须成功才能使指令成功。 所有指令都不生效才通过 和用于包含一组授权指令，其中无一个指令必须成功才能使指令不失败。 实现代码1234567891011121314&lt;Directory &quot;/usr/local/apache/htdocs/web1/b&quot;&gt; AllowOverride None #apache2.4新方法 Require all denied Require ip 192.168.11.24 192.168.11.251 Require host www.ayitula.com #apache2.2老方法 ##The Allow, Deny, and Order directives, provided by mod_access_compat #Order deny,allow #Deny from all #Allow from 192.168.11.23&lt;/Directory&gt;"},{"path":"/2023/07/11/Web服务器-Apache/Apache安全-用户登录验证/","content":"一、登录验证当用户访问网站或者网站某个目录时，如果希望用户提供授权才能登录，那么就需要针对该站或者该目录设置登录验证了。apache提供了该功能，可以让我们针对站点或目录设置登录验证。这样用户访问网站时需要提交账号密码才能登录。 二、登录验证实现1）修改apache配置文件1234567891011121314151617181920212223242526272829303132333435363738&lt;Directory &quot;/usr/local/apache/htdocs/web1/a&quot;&gt;AuthName &quot;Private&quot;AuthType BasicAuthUserFile &quot;/usr/local/apache/user.dbm&quot;#访问控制&lt;RequireAll&gt;Require valid-userRequire not ip 192.168.11.251&lt;/RequireAll&gt;#访问控制#Order deny,allow#Deny from all#Allow from 192.168.11.23&lt;/Directory&gt;# 1) AuthName：定义提示信息，用户访问时提示信息会出现在认证的对话框中# 2) AuthType：定义认证类型，在HTTP1.0中，只有一种认证类型：basic。在HTTP1.1中有几种认证类型，如：MD5# 3) AuthUserFile：定义包含用户名和密码的文本文件，每行一对# 4) AuthGroupFile：定义包含用户组和组成员的文本文件。组成员之间用空格分开，如：group1:user1 user2# 5) require命令：定义哪些用户或组才能被授权访问。如：# require user user1 user2 (只有用户user1和user2可以访问)# requires groups group1 (只有group1中的成员可以访问)# require valid-user (在AuthUserFile指定的文件中的所有用户都可以访问) 2）生成用户验证文件[root@apache_251 extra]# &#x2F;usr&#x2F;local&#x2F;apache&#x2F;bin&#x2F;htpasswd -cm &#x2F;usr&#x2F;local&#x2F;apache&#x2F;user.dbm baism New password: Re-type new password: Adding password for user baism 3）查看文件内容 用户名：秘钥[root@apache_251 extra]# cat &#x2F;usr&#x2F;local&#x2F;apache&#x2F;user.dbm baism:apr1apr1.XawVas2$8Bn7rJFJjGLDZ.63fSiYV1 4）设置站点验证目录[root@apache_251 extra]# mkdir &#x2F;usr&#x2F;local&#x2F;apache&#x2F;htdocs&#x2F;web1&#x2F;a [root@apache_251 extra]# touch &#x2F;usr&#x2F;local&#x2F;apache&#x2F;htdocs&#x2F;web1&#x2F;a&#x2F;file{a…z} 5）重启apache并测试"},{"path":"/2023/07/11/Web服务器-Apache/Apache 默认网站/","content":"一、默认网站每一个web服务器软件一般默认都会提供一个用于测试的网站，apache也为用户提供了一个默认网站。默认网站的配置写在默认配置文件中。 二、配置文件[root@zutuanxue conf]# cat httpd.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034103510361037## This is the main Apache HTTP server configuration file. It contains the# configuration directives that give the server its instructions.# See (URL:http://httpd.apache.org/docs/2.4/); for detailed information.# In particular, see# URL:http://httpd.apache.org/docs/2.4/mod/directives.html;# for a discussion of each configuration directive.## Do NOT simply read the instructions in here without understanding# what they do. They&#x27;re here only as hints or reminders. If you are unsure# consult the online docs. You have been warned.## Configuration and logfile names: If the filenames you specify for many# of the server&#x27;s control files begin with &quot;/&quot; (or &quot;drive:/&quot; for Win32), the# server will use that explicit path. If the filenames do *not* begin# with &quot;/&quot;, the value of ServerRoot is prepended -- so &quot;logs/access_log&quot;# with ServerRoot set to &quot;/usr/local/apache2&quot; will be interpreted by the# server as &quot;/usr/local/apache2/logs/access_log&quot;, whereas &quot;/logs/access_log&quot;# will be interpreted as &#x27;/logs/access_log&#x27;.## ServerRoot: The top of the directory tree under which the server&#x27;s# configuration, error, and log files are kept.## Do not add a slash at the end of the directory path. If you point# ServerRoot at a non-local disk, be sure to specify a local disk on the# Mutex directive, if file-based mutexes are used. If you wish to share the# same ServerRoot for multiple httpd daemons, you will need to change at# least PidFile.##apache软件根目录，apache安装路径。ServerRoot &quot;/usr/local/apache&quot;## Mutex: Allows you to set the mutex mechanism and mutex file directory# for individual mutexes, or change the global defaults## Uncomment and change the directory if mutexes are file-based and the default# mutex file directory is not on a local disk or is not appropriate for some# other reason.## Mutex default:logs## Listen: Allows you to bind Apache to specific IP addresses and/or# ports, instead of the default. See also the &amp;lt;VirtualHost&amp;gt;# directive.## Change this to Listen on specific IP addresses as shown below to# prevent Apache from glomming onto all bound IP addresses.##设置apache监听端口及监听IP地址#Listen 12.34.56.78:80Listen 80## Dynamic Shared Object (DSO) Support## To be able to use the functionality of a module which was built as a DSO you# have to place corresponding `LoadModule&#x27; lines at this location so the# directives contained in it are actually available _before_ they are used.# Statically compiled modules (those listed by `httpd -l&#x27;) do not need# to be loaded here.## 动态共享对象支持,使用LoadModule指令为apaceh添加功能模块 --enable-so# Example:# LoadModule foo_module modules/mod_foo.so## 可载入模块，参考(http://httpd.apache.org/docs/2.4/mod/)LoadModule mpm_event_module modules/mod_mpm_event.so#LoadModule mpm_prefork_module modules/mod_mpm_prefork.so#LoadModule mpm_worker_module modules/mod_mpm_worker.soLoadModule authn_file_module modules/mod_authn_file.so#LoadModule authn_dbm_module modules/mod_authn_dbm.so#LoadModule authn_anon_module modules/mod_authn_anon.so#LoadModule authn_dbd_module modules/mod_authn_dbd.so#LoadModule authn_socache_module modules/mod_authn_socache.soLoadModule authn_core_module modules/mod_authn_core.soLoadModule authz_host_module modules/mod_authz_host.soLoadModule authz_groupfile_module modules/mod_authz_groupfile.soLoadModule authz_user_module modules/mod_authz_user.so#LoadModule authz_dbm_module modules/mod_authz_dbm.so#LoadModule authz_owner_module modules/mod_authz_owner.so#LoadModule authz_dbd_module modules/mod_authz_dbd.soLoadModule authz_core_module modules/mod_authz_core.soLoadModule access_compat_module modules/mod_access_compat.soLoadModule auth_basic_module modules/mod_auth_basic.so#LoadModule auth_form_module modules/mod_auth_form.so#LoadModule auth_digest_module modules/mod_auth_digest.so#LoadModule allowmethods_module modules/mod_allowmethods.so#LoadModule file_cache_module modules/mod_file_cache.so#LoadModule cache_module modules/mod_cache.so#LoadModule cache_disk_module modules/mod_cache_disk.so#LoadModule cache_socache_module modules/mod_cache_socache.so#LoadModule socache_shmcb_module modules/mod_socache_shmcb.so#LoadModule socache_dbm_module modules/mod_socache_dbm.so#LoadModule socache_memcache_module modules/mod_socache_memcache.so#LoadModule socache_redis_module modules/mod_socache_redis.so#LoadModule watchdog_module modules/mod_watchdog.so#LoadModule macro_module modules/mod_macro.so#LoadModule dbd_module modules/mod_dbd.so#LoadModule dumpio_module modules/mod_dumpio.so#LoadModule buffer_module modules/mod_buffer.so#LoadModule ratelimit_module modules/mod_ratelimit.soLoadModule reqtimeout_module modules/mod_reqtimeout.so#LoadModule ext_filter_module modules/mod_ext_filter.so#LoadModule request_module modules/mod_request.so#LoadModule include_module modules/mod_include.soLoadModule filter_module modules/mod_filter.so#LoadModule substitute_module modules/mod_substitute.so#LoadModule sed_module modules/mod_sed.so#LoadModule deflate_module modules/mod_deflate.soLoadModule mime_module modules/mod_mime.soLoadModule log_config_module modules/mod_log_config.so#LoadModule log_debug_module modules/mod_log_debug.so#LoadModule logio_module modules/mod_logio.soLoadModule env_module modules/mod_env.so#LoadModule expires_module modules/mod_expires.soLoadModule headers_module modules/mod_headers.so#LoadModule unique_id_module modules/mod_unique_id.soLoadModule setenvif_module modules/mod_setenvif.soLoadModule version_module modules/mod_version.so#LoadModule remoteip_module modules/mod_remoteip.so#LoadModule proxy_module modules/mod_proxy.so#LoadModule proxy_connect_module modules/mod_proxy_connect.so#LoadModule proxy_ftp_module modules/mod_proxy_ftp.so#LoadModule proxy\\_http_module modules/mod_proxy_http.so#LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so#LoadModule proxy_scgi_module modules/mod_proxy_scgi.so#LoadModule proxy_uwsgi_module modules/mod_proxy_uwsgi.so#LoadModule proxy_fdpass_module modules/mod_proxy_fdpass.so#LoadModule proxy_wstunnel_module modules/mod_proxy_wstunnel.so#LoadModule proxy_ajp_module modules/mod_proxy_ajp.so#LoadModule proxy_balancer_module modules/mod_proxy_balancer.so#LoadModule proxy_express_module modules/mod_proxy_express.so#LoadModule proxy_hcheck_module modules/mod_proxy_hcheck.so#LoadModule session_module modules/mod_session.so#LoadModule session_cookie_module modules/mod_session_cookie.so#LoadModule session_dbd_module modules/mod_session_dbd.so#LoadModule slotmem_shm_module modules/mod_slotmem_shm.so#LoadModule lbmethod_byrequests_module modules/mod_lbmethod_byrequests.so#LoadModule lbmethod_bytraffic_module modules/mod_lbmethod_bytraffic.so#LoadModule lbmethod_bybusyness_module modules/mod_lbmethod_bybusyness.so#LoadModule lbmethod_heartbeat_module modules/mod_lbmethod_heartbeat.soLoadModule unixd_module modules/mod_unixd.so#LoadModule dav_module modules/mod_dav.soLoadModule status_module modules/mod_status.soLoadModule autoindex_module modules/mod_autoindex.so#LoadModule info_module modules/mod_info.so#LoadModule cgid_module modules/mod_cgid.so#LoadModule dav_fs_module modules/mod_dav_fs.so#LoadModule vhost_alias_module modules/mod_vhost_alias.so#LoadModule negotiation_module modules/mod_negotiation.soLoadModule dir_module modules/mod_dir.so#LoadModule actions_module modules/mod_actions.so#LoadModule speling_module modules/mod_speling.soLoadModule alias_module modules/mod_alias.so#LoadModule rewrite_module modules/mod_rewrite.so#启用模块 unixd_module 设置apache守护进程httpd的管理用户和组#启用模块注意格式 &lt;IfModule 模块名称_module&gt;#结束&lt;/IfModule&gt;#启用的前提是已经使用LoadModule指令载入了该模块&lt;IfModule unixd\\_module&gt;## If you wish httpd to run as a different user or group, you must run# httpd as root initially and it will switch.## User/Group: The name (or #number) of the user/group to run httpd as.# It is usually good practice to create a dedicated user and group for# running httpd, as with most system services.##指定守护进程httpd的管理用户User daemon#指定守护进程httpd的管理组Group daemon&lt;/IfModule&gt;# &#x27;Main&#x27; server configuration## The directives in this section set up the values used by the &#x27;main&#x27;# server, which responds to any requests that aren&#x27;t handled by a# &amp;lt;VirtualHost&amp;gt; definition. These values also provide defaults for# any &amp;lt;VirtualHost&amp;gt; containers you may define later in the file.## All of these directives may appear inside &amp;lt;VirtualHost&amp;gt; containers,# in which case these default settings will be overridden for the# virtual host being defined.### ServerAdmin: Your address, where problems with the server should be# e-mailed. This address appears on some server-generated pages, such# as error documents. e.g. admin@your-domain.com##指定管理员email地址ServerAdmin you@example.com## ServerName gives the name and port that the server uses to identify itself.# This can often be determined automatically, but we recommend you specify# it explicitly to prevent problems during startup.## If your host doesn&#x27;t have a registered DNS name, enter its IP address here.##指定服务器在DNS上注册的名称 FQDN#ServerName www.example.com:80ServerName 127.0.0.1## Deny access to the entirety of your server&#x27;s filesystem. You must# explicitly permit access to web content directories in other# &amp;lt;Directory&amp;gt; blocks below.##apache 目录访问权限#使用&lt;Directory /path&gt; 指定目录路径#拒绝用户通过apache访问你的文件系统/及以下的所有内容&lt;Directory &gt;#是否允许.htaccess实现权限复写AllowOverride none#设置所有人的访问权限 denied 拒绝 granted允许Require all denied#设置结束用&lt;/Directory&gt;指令结束&lt;/Directory&gt;## Note that from this point forward you must specifically allow# particular features to be enabled - so if something&#x27;s not working as# you might expect, make sure that you have specifically enabled it# below.### DocumentRoot: The directory out of which you will serve your# documents. By default, all requests are taken from this directory, but# symbolic links and aliases may be used to point to other locations.##使用DocumentRoot指定WEB站点的根目录DocumentRoot &quot;/usr/local/apache/htdocs&quot;#对默认网站根目录设置访问权限&lt;Directory &quot;/usr/local/apache/htdocs&quot;&gt;## Possible values for the Options directive are &quot;None&quot;, &quot;All&quot;,# or any combination of:# Indexes Includes FollowSymLinks SymLinksifOwnerMatch ExecCGI MultiViews## Note that &quot;MultiViews&quot; must be named *explicitly* --- &quot;Options All&quot;# doesn&#x27;t give it to you.## The Options directive is both complicated and important. Please see# (http://httpd.apache.org/docs/2.4/mod/core.html#options)# for more information.#Options Indexes FollowSymLinks#Indexes 站点中有index页面优先加载#FollowSymLinks 在WEB站点根目录允许使用链接文件## AllowOverride controls what directives may be placed in .htaccess files.# It can be &quot;All&quot;, &quot;None&quot;, or any combination of the keywords:# AllowOverride FileInfo AuthConfig Limit##不许使用权限复写AllowOverride None## Controls who can get stuff from this server.##允许所有人访问网站根目录Require all granted&lt;/Directory&gt;## DirectoryIndex: sets the file that Apache will serve if a directory# is requested.#指定站点的默认索引文件&lt;IfModule dir\\_module&gt;DirectoryIndex index.html&lt;/IfModule&gt;## The following lines prevent .htaccess and .htpasswd files from being# viewed by Web clients.##是否允许在目录下使用.htaccess 和 .htpassswd文件设置客户端对网站目录访问权限#.htaccess 访问控制#.htpasswd 用户登陆验证#拒绝在目录下使用.ht开头的文件&lt;Files &quot;.ht\\*&quot;&gt;Require all denied&lt;/Files&gt;## ErrorLog: The location of the error log file.# If you do not specify an ErrorLog directive within a &lt;VirtualHost&gt;# container, error messages relating to that virtual host will be# logged here. If you *do* define an error logfile for a &lt;VirtualHost&gt;# container, that host&#x27;s errors will be logged there and not here.##错误日志ErrorLog &quot;logs/error_log&quot;## LogLevel: Control the number of messages logged to the error\\_log.# Possible values include: debug, info, notice, warn, error, crit,# alert, emerg.##错误日志记录级别:debug, info, notice, warn, error, crit,alert, emerg.LogLevel warn#启用日志模块&lt;IfModule log\\_config\\_module&gt;## The following directives define some format nicknames for use with# a CustomLog directive (see below).##定义日志格式 LogFormat &quot;日志格式&quot; 日志格式名称LogFormat &quot;%h %l %u %t \\&quot;%r\\&quot; %&amp;gt;s %b \\&quot;%&#123;Referer&#125;i\\&quot; \\&quot;%&#123;User-Agent&#125;i\\&quot;&quot; combinedLogFormat &quot;%h %l %u %t \\&quot;%r\\&quot; %&amp;gt;s %b&quot; common&lt;IfModule logio\\_module&gt;# 在访问日志中记录每个请求的输入输出字节 %I input %O output# You need to enable mod\\_logio.c to use %I and %OLogFormat &quot;%h %l %u %t \\&quot;%r\\&quot; %&amp;gt;s %b \\&quot;%&#123;Referer&#125;i\\&quot; \\&quot;%&#123;User-Agent&#125;i\\&quot; %I %O&quot; combinedio&lt;/IfModule&gt;## The location and format of the access logfile (Common Logfile Format).# If you do not define any access logfiles within a &amp;lt;VirtualHost&amp;gt;# container, they will be logged here. Contrariwise, if you *do*# define per-&lt;VirtualHost&gt; access logfiles, transactions will be# logged therein and \\*not\\* in this file.##定义访问日志路径及日志格式CustomLog &quot;logs/access_log&quot; common## If you prefer a logfile with access, agent, and referer information# (Combined Logfile Format) you can use the following directive.##CustomLog &quot;logs/access_log&quot; combined&lt;/IfModule&gt;#使用目录映射&lt;IfModule alias\\_module&gt;## URL重定向# Redirect: Allows you to tell clients about documents that used to# exist in your server&#x27;s namespace, but do not anymore. The client# will make a new request for the document at its new location.# Example:# Redirect permanent /foo http://www.example.com/bar#URL重定向 Redirect 方法 选项#不同机器重定向将访问http://IP/abc 的用户 重定向访问 http:/www.baidu.comRedirect permanent /abc http://www.baidu.com#本机内部URL重定向 http://IP/123 http://IP/7878 ==注意==：被重定向的目录必须存在 比如7878必须有Redirect permanent /123 /7878#seeother 表示改资源被替换过Redirect seeother /123 /7878#gone 表示改资源被移除了Redirect gone /123#permanent 永久重定向 301#temp 临时重定向#seeother 返回一个seeother状态码(303)提示这个资源被替代#gone 返回一个gone状态码(410)提示这个资源被永久删除了## Alias: Maps web paths into filesystem paths and is used to# access content that does not live under the DocumentRoot.# Example:# Alias /webpath /full/filesystem/path## If you include a trailing / on /webpath then the server will# require it to be present in the URL. You will also likely# need to provide a &lt;Directory&gt; section to allow access to# the filesystem path.#Alias 将URI中的没用了映射到文件系统目录(绝对路径)#比如将网站URL http://ip/abc 访问的/abc目录映射到文件系统/usr/local/apache/htdocs/7878Alias /abc /usr/local/apache/htdocs/7878#需要注意是文件系统路径## ScriptAlias: This controls which directories contain server scripts.# ScriptAliases are essentially the same as Aliases, except that# documents in the target directory are treated as applications and# run by the server when requested rather than as documents sent to the# client. The same rules about trailing &quot;/&quot; apply to ScriptAlias# directives as to Alias.#ScriptAlias /cgi-bin/ &quot;/usr/local/apache/cgi-bin/&quot;#脚本目录别名&lt;/IfModule&gt;#使用外部CGI守护进程执行CGI脚本&lt;IfModule cgid_module&gt;## ScriptSock: On threaded servers, designate the path to the UNIX# socket used to communicate with the CGI daemon of mod\\_cgid.##Scriptsock cgisock&lt;/IfModule&gt;## &quot;/usr/local/apache/cgi-bin&quot; should be changed to whatever your ScriptAliased# CGI directory exists, if you have that configured.##CGI目录的访问权限&lt;Directory &quot;/usr/local/apache/cgi-bin&quot;&gt;AllowOverride NoneOptions NoneRequire all granted&lt;/Directory&gt;#自定义http的请求头和响应头#RequestHeader 设置请求头 http://httpd.apache.org/docs/2.4/mod/mod_headers.html#Header 设置响应头 http://httpd.apache.org/docs/2.4/mod/mod_headers.html&lt;IfModule headers\\_module&gt;## Avoid passing HTTP\\_PROXY environment to CGI&#x27;s on this or any proxied# backend servers which have lingering &quot;httpoxy&quot; defects.# &#x27;Proxy&#x27; request header is undefined by the IETF, not listed by IANA#RequestHeader unset Proxy early&lt;/IfModule&gt;#将请求的文件扩展名与文件的行为（处理程序和筛选器）和内容（mime类型、语言、字符集和编码）相关联。#明确告诉apache 可以接受什么类型的文件&lt;IfModule mime_module&gt;## TypesConfig points to the file containing the list of mappings from# filename extension to MIME-type.#TypesConfig conf/mime.types## AddType allows you to add to or override the MIME configuration# file specified in TypesConfig for specific file types.##AddType application/x-gzip .tgz## AddEncoding allows you to have certain browsers uncompress# information on the fly. Note: Not all browsers support this.##AddEncoding x-compress .Z#AddEncoding x-gzip .gz .tgz## If the AddEncoding directives above are commented-out, then you# probably should define those extensions to indicate media types:#AddType application/x-compress .ZAddType application/x-gzip .gz .tgz## AddHandler allows you to map certain file extensions to &quot;handlers&quot;:# actions unrelated to filetype. These can be either built into the server# or added with the Action directive (see below)## To use CGI scripts outside of ScriptAliased directories:# (You will also need to add &quot;ExecCGI&quot; to the &quot;Options&quot; directive.)##AddHandler cgi-script .cgi# For type maps \\(negotiated resources\\):#AddHandler type-map var## Filters allow you to process content before it is sent to the client.## To parse .shtml files for server-side includes (SSI):# (You will also need to add &quot;Includes&quot; to the &quot;Options&quot; directive.)##AddType text/html .shtml#AddOutputFilter INCLUDES .shtml&lt;/IfModule&gt;## The mod_mime_magic module allows the server to use various hints from the# contents of the file itself to determine its type. The MIMEMagicFile# directive tells the module where the hint definitions are located.##MIMEMagicFile conf/magic## Customizable error responses come in three flavors:# 1) plain text 2) local redirects 3) external redirects## Some examples:#ErrorDocument 500 &quot;The server made a boo boo.&quot;#ErrorDocument 404 /missing.html#ErrorDocument 404 &quot;/cgi-bin/missing\\_handler.pl&quot;#ErrorDocument 402 [http://www.example.com/subscription\\_info.html](http://www.example.com/subscription_info.html)### MaxRanges: Maximum number of Ranges in a request before# returning the entire resource, or one of the special# values &#x27;default&#x27;, &#x27;none&#x27; or &#x27;unlimited&#x27;.# Default setting is to accept 200 Ranges.#MaxRanges unlimited## EnableMMAP and EnableSendfile: On systems that support it,# memory-mapping or the sendfile syscall may be used to deliver# files. This usually improves server performance, but must# be turned off when serving from networked-mounted# filesystems or if support for these functions is otherwise# broken on your system.# Defaults: EnableMMAP On, EnableSendfile Off##EnableMMAP off#EnableSendfile on# Supplemental configuration## The configuration files in the conf/extra/ directory can be# included to add extra features or to modify the default configuration of# the server, or you may simply copy their contents here and change as# necessary.#Include 包含子配置文件# Server-pool management \\(MPM specific\\)#Include conf/extra/httpd-mpm.conf# Multi-language error messages#Include conf/extra/httpd-multilang-errordoc.conf# Fancy directory listings#Include conf/extra/httpd-autoindex.conf# Language settings#Include conf/extra/httpd-languages.conf# User home directories#Include conf/extra/httpd-userdir.conf# Real-time info on requests and configuration#Include conf/extra/httpd-info.conf# Virtual hosts#Include conf/extra/httpd-vhosts.conf# Local access to the Apache HTTP Server Manual#Include conf/extra/httpd-manual.conf# Distributed authoring and versioning (WebDAV)#Include conf/extra/httpd-dav.conf# Various default settings#Include conf/extra/httpd-default.conf# Configure mod_proxy_html to understand HTML4/XHTML1#启动代理模块&lt;IfModule proxy\\_html_module&gt;Include conf/extra/proxy-html.conf&lt;/IfModule&gt;;# Secure (SSL/TLS) connections#Include conf/extra/httpd-ssl.conf## Note: The following must must be present to support# starting without SSL on platforms with no /dev/random equivalent# but a statically compiled-in mod\\_ssl.##启用ssl模块&lt;IfModule ssl_module&gt;SSLRandomSeed startup builtinSSLRandomSeed connect builtin&lt;/IfModule&gt;;"},{"path":"/2023/07/11/Web服务器-Apache/Apache 虚拟主机/","content":"一、虚拟主机介绍默认情况下,一个web服务器软件只能定义一个默认网站，也就是说只能发布一个WEB站点，对于大网站还可以，有海量用户来消耗服务器的资源，但是小网站呢？一个服务器上只跑一个小网站，服务器资源使用约等于0，那就尴尬了。为了充分利用服务器资源，现实生产环境中一般都是采用一个WEB服务器软件发布多个站点。如何解决这个问题呢？那就是配置虚拟主机！ 虚拟主机和默认网站在apache中不能同时存在，只能存在一种，当虚拟主机出现后，apache默认网站就失效了，如果你还需要默认网站，就拿虚拟主机在发布一次默认网站对应的站点即可解决。 虚拟主机应用场景：一个WEB服务器同时发布多个WEB站点一个站点出现在网络中需要三个条件：监听IP、监听port、域名。 so 虚拟主机有三种实现方式 基于IP地址 基于监听端口 基于域名(host) 接下来我们就可以使用虚拟主机发布多个网站吧，大家在学习的同时要总结每种实现方式的特点及应用场景 二、基于IP的虚拟主机step 1 修改主配置文件，打开虚拟主机子配置文件 1234567891011121314151617[root@zutuanxue apache]# egrep &quot;Include&quot; conf/httpd.conf#Include conf/extra/httpd-mpm.conf#Include conf/extra/httpd-multilang-errordoc.conf#Include conf/extra/httpd-autoindex.conf#Include conf/extra/httpd-languages.conf#Include conf/extra/httpd-userdir.conf#Include conf/extra/httpd-info.conf##把本行的#去掉Include conf/extra/httpd-vhosts.conf###Include conf/extra/httpd-manual.conf#Include conf/extra/httpd-dav.conf#Include conf/extra/httpd-default.confInclude conf/extra/proxy-html.conf#Include conf/extra/httpd-ssl.conf step 2 设置基于IP的虚拟主机 1）给服务器配置多个IP，有几个虚拟主机及配置几个IP地址，我们实验用了两个虚拟主机，所以我有两个IP即可 192.168.11.251 192.168.11.252 [root@zutuanxue ~]# ifconfig ens33:1 192.168.11.252 2)创建两个WEB站点 WEB1 WEB2 [root@zutuanxue extra]# mkdir &#x2F;usr&#x2F;local&#x2F;apache&#x2F;htdocs&#x2F;web{1…2} #生成两个测试页面 [root@zutuanxue extra]# echo web1 &gt; &#x2F;usr&#x2F;local&#x2F;apache&#x2F;htdocs&#x2F;web1&#x2F;index.html [root@zutuanxue extra]# echo web2 &gt; &#x2F;usr&#x2F;local&#x2F;apache&#x2F;htdocs&#x2F;web2&#x2F;index.html 3)设置子配置文件 1234567891011121314[root@zutuanxue extra]# cat httpd-vhosts.conf&lt;VirtualHost 192.168.11.251:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web1&quot; #ServerName dummy-host.example.com #ErrorLog &quot;logs/dummy-host.example.com-error_log&quot; #CustomLog &quot;logs/dummy-host.example.com-access_log&quot; common&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.11.252:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web2&quot; #ServerName dummy-host2.example.com #ErrorLog &quot;logs/dummy-host2.example.com-error_log&quot; #CustomLog &quot;logs/dummy-host2.example.com-access_log&quot; common&lt;/VirtualHost&gt; 4)重启apache [root@zutuanxue extra]# &#x2F;usr&#x2F;local&#x2F;apache&#x2F;bin&#x2F;apachectl -t Syntax OK [root@zutuanxue extra]# killall httpd [root@zutuanxue extra]# &#x2F;usr&#x2F;local&#x2F;apache&#x2F;bin&#x2F;apachectl 5)测试 [root@zutuanxue ~]# elinks http://192.168.11.251 -dump web1 [root@zutuanxue ~]# elinks http://192.168.11.252 -dump web2 基于IP的虚拟主机特点不同IP对应不同网站 访问方便，用户直接使用默认端口即可访问 服务器需要有多个IP地址（一个公网IP大概一年的费用是600左右） 适合IP充足环境 三、基于prot的虚拟主机环境还原,清除上个实验中的252IP [root@zutuanxue ~]# ifconfig ens33:1 down 1）修改子配置文件 12345678910111213141516[root@zutuanxue extra]# cat httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web1&quot; #ServerName dummy-host.example.com #ErrorLog &quot;logs/dummy-host.example.com-error_log&quot; #CustomLog &quot;logs/dummy-host.example.com-access_log&quot; common&lt;/VirtualHost&gt;#切莫忘了开端口Listen 81&lt;VirtualHost *:81&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web2&quot; #ServerName dummy-host2.example.com #ErrorLog &quot;logs/dummy-host2.example.com-error_log&quot; #CustomLog &quot;logs/dummy-host2.example.com-access_log&quot; common&lt;/VirtualHost&gt; 2）重启服务 [root@zutuanxue extra]# &#x2F;usr&#x2F;local&#x2F;apache&#x2F;bin&#x2F;apachectl -t Syntax OK [root@zutuanxue extra]# killall httpd [root@zutuanxue extra]# &#x2F;usr&#x2F;local&#x2F;apache&#x2F;bin&#x2F;apachectl 3）测试 [root@zutuanxue extra]# elinks http://192.168.11.251:80 -dump web1 [root@zutuanxue extra]# elinks http://192.168.11.251:81 -dump web2 基于端口的虚拟主机特点不同端口对应不同网站 访问需要加端口 节省IP地址 适合私网运行 四、基于域名的虚拟主机1)设置多个域名，生产环境中如果我们可以直接在dns解析域名到主机IP，但是实验中我们没有域名和DNS，我就自己使用hosts文件做了个解析。 修改客户端hosts文件,解析域名 web1.zutuanxue.com 192.168.11.251 web2.zutuanxue.com 192.168.11.252 我就用本机做服务端和客户端，所以我修改本机251的hosts文件 [root@zutuanxue extra]# cat &#x2F;etc&#x2F;hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.11.251 web1.zutuanxue.com 192.168.11.251 web2.zutuanxue.com 2)修改虚拟主机配置文件 1234567891011121314[root@zutuanxue extra]# cat httpd-vhosts.conf&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web1&quot; ServerName web1.ayitula.com #ErrorLog &quot;logs/dummy-host.example.com-error_log&quot; #CustomLog &quot;logs/dummy-host.example.com-access_log&quot; common&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; DocumentRoot &quot;/usr/local/apache/htdocs/web2&quot; ServerName web2.ayitula.com #ErrorLog &quot;logs/dummy-host2.example.com-error_log&quot; #CustomLog &quot;logs/dummy-host2.example.com-access_log&quot; common&lt;/VirtualHost&gt; \\3) 重启服务 [root@zutuanxue extra]# &#x2F;usr&#x2F;local&#x2F;apache&#x2F;bin&#x2F;apachectl -t Syntax OK [root@zutuanxue extra]# killall httpd [root@zutuanxue extra]# &#x2F;usr&#x2F;local&#x2F;apache&#x2F;bin&#x2F;apachectl 4）测试 [root@zutuanxue extra]# elinks http://web1.zutuanxue.com -dump web1 [root@zutuanxue extra]# elinks http://web2.zutuanxue.com -dump web2 基于域名的虚拟主机特点不同域名对应不同网站 需要多个域名 可以是二级或三级域名 每个站点使用默认端口，方便用户访问 只需要一个IP地址，节约成本 适合公网环境"},{"path":"/2023/07/11/Web服务器-Apache/Apache 站点优化-长连接/","content":"一、长连接介绍面临问题：http是一个面向连接的协议，用户完成一次请求需要以下步骤 三次握手 发起请求 响应请求 四次断开 N个请求就重复N次，如果希望用户能够更快的拿到数据，服务器的压力降到最低，让你去优化这个请求过程。 解决方案：答案很明确，那就是建设每次执行的三次握手和四次断开，最好是一次三次握手建立成功后，在这个数据通道完成所有的请求后，然后在四次断开，这就是优化思路–理想中应该是这样。 三次握手 发起请求 响应请求 发起请求 响应请求 。。。。。 请求全部完成后，四次断开 优化目的：减少了三次握手和四次断开的次数。 注意事项：长连接需要服务器和客户端浏览器都支持 长连接特点：提升用户访问速度 降低服务器压力 大量空闲长连接可能造成服务器压力过大 二、长连接实现apache2.4默认开启了长连接，长连接时间为5s，修改子配置文件httpd-default.conf可以定义该选项 #开启长连接功能 On为开启 Off为关闭 KeepAlive On #当keepalive打开时，maxkeepaliverequests指令限制每个连接允许的请求数。如果设置为0，则允许无限请求。我们建议将此设置保持为高值以获得最大服务器性能。不建议大家将这个数值设置为0，防止内存溢出。 MaxKeepAliveRequests 100 长连接时间，默认单位是秒，也可以使用ms 只需在数值后面添加单位就行了。这个值如果你服务器速度快，网络稳定，建议设置小一点，比如3s，因为目前单个请求都是毫秒级的。避免大量空闲长连接消耗你的系统资源。 KeepAliveTimeout 5 实验总结：一次用户访问的长连接数根据用户浏览器的不同建立的数量不同，比如chrome,每次会同时建立5个长连接，也就是五个数据通道，然后完成数据请求，所以大家都反应chrome浏览器好用，其他浏览器要看情况，不同浏览器的连接数不同。"},{"path":"/2023/07/11/Web服务器-Apache/Apache 站点优化-客户端缓存/","content":"一、静态缓存介绍用户每次访问网站都会将页面中的所有元素都请求一遍，全部下载后通过浏览器渲染，展示到浏览器中。但是，网站中的某些元素我们一般都是固定不变的，比如logo，框架文件等元。，用户每次访问都需要加载这些元素。这样做好处是保证了数据的新鲜，可是这些数据不是常变化的，很久才变化一次。每次都请求、下载浪费了用户时间和公司带宽。 所以我们通过静态缓存的方式，将这些不常变化的数据缓存到用户本地磁盘，用户以后再访问这些请求，直接从本地磁盘打开加载，这样的好处是加载速度快，且节约公司带宽及成本。 应用场景：数据缓存优化目的：提升用户访问页面加载速度，节约带宽二、静态缓存实现1）修改apache主配置文件，加载缓存模块 LoadModule expires_module modules&#x2F;mod_expires.so 2）针对虚拟主机或者目录设置缓存策略 1234567891011121314151617181920212223242526272829&lt;IfModule expires_module&gt; #开启缓存 ExpiresActive on #针对不同类型元素设置缓存时间 ExpiresByType image/gif &quot;access plus 1 days&quot; ExpiresByType image/jpeg &quot;access plus 24 hours&quot; ExpiresByType image/png &quot;access plus 24 hours&quot; ExpiresByType text/css &quot;now plus 2 hour&quot; ExpiresByType application/x-javascript &quot;now plus 2 hours&quot; ExpiresByType application/x-shockwave-flash &quot;now plus 2 hours” #其他数据不缓存 ExpiresDefault &quot;now plus 0 min&quot;&lt;/IfModule&gt;缓存起始点access 从当前访问时间开始now (equivalent to &#x27;access&#x27;) 相当于accessmodification 从修改时间算起缓存时间单位yearsmonthsweeksdayshoursminutesseconds 三、验证测试*缓存没有生效前 no_expires.png 缓存生效后测试 apache_expires.png 响应头中加载了缓存字段 Cache-control 和 Expires，并且缓存的时间和我们预设的一致，成功啦。"},{"path":"/2023/07/11/Web服务器-Apache/Apache 介绍/","content":"一、Apache介绍Apache HTTP Server（简称Apache）是Apache软件基金会的一个开放源码的网页服务器，是世界使用排名第一的Web服务器软件。它可以运行在几乎所有广泛使用的计算机平台上，由于其跨平台和安全性被广泛使用，是最流行的Web服务器端软件之一。它快速、可靠并且可通过简单的API扩充，将Perl&#x2F;Python等解释器编译到服务器中。 Apache HTTP服务器是一个模块化的服务器，源于NCSAhttpd服务器，经过多次修改，成为世界使用排名第一的Web服务器软件。 apache当前版本:2.4.X 官方网站:www.apache.org 学习手册:http://httpd.apache.org/docs/2.4/ 二、Apache特点Apacheweb服务器软件拥有以下特性： 1.支持最新的HTTP&#x2F;2通信协议（2.4.17及以后版本） 2.拥有简单而强有力的基于文件的配置过程 3.支持通用网关接口 4.支持基于IP和基于域名的虚拟主机 5.支持多种方式的HTTP认证 6.集成Perl处理模块 7.集成代理服务器模块 8.支持实时监视服务器状态和定制服务器日志 9.支持服务器端包含指令(SSI) 10.支持安全Socket层(SSL) 11.提供用户会话过程的跟踪 12.支持FastCGI 13.通过第三方模块可以支持JavaServlets 14.跨平台 平行软件 IIS Nginx tengine Lighttpd Tomcat Resin 三、部分Apache2.4新特性新增模块 Mod_proxy_fcgi：提供fcgi代理 Mod_ratelimit：限制用户带宽 Mod_request：过滤客户机请求 Mod_remoteip：匹配客户端的IP 新特性 Mpm（工作模式）：支持工作模式在apache运行时更改 但是要开启这种特性，在编译安装要启用这三种功能：–enable-mpms-shared&#x3D;all –with-mpm&#x3D;event 完善了event模式 支持使用自定义变量 基于FQDN的虚拟主机不再需要NameVirtualHost指令 增强版的表达式分析器 支持异步读写 毫秒级别的keepalivetimeout"},{"path":"/2023/07/11/Web服务器-Apache/Apache URL重定向/","content":"一、URL重写介绍Apached的重写功能，即是mod_rewrite模块功能，它是apache的一个模块。它的功能非常强大，可以操作URL中的所有部分。通过改写url，给用户提供一个简介大方的url，当用户访问时可以通过mod_rewrite模块功能转换为真正的资源路径。通过mod_rewrite能实现的功能还有很多，例如隐藏真实地址、实现URL跳转、域名跳转、防盗链、限制访问资源类型等等。 URL重写在生产环境中被广大运维大牛们运用的淋漓尽致，那么什么是URL重写呢？URL重写其实就是改写用户浏览器中的URL地址。 比如说京东,google、亚马逊都在使用: 域名 重写后域名 www.z.cn www.amazon.cn www.g.cn www.google.com.cn www.360buy.com www.jd.com 当用户在浏览器中输入：www.360buy.com域名回车以后，你会发现浏览器中的域名变成了:www.jd.com。这是怎么回事呢？ 那是因为运维在web服务器上设置了URL重写，在你访问服务器的一瞬间改写了你地址栏中的域名。 URL重写应用场景域名变更：比如京东 伪静态：便于CDN缓存页面 域名伪装：隐藏URI真实路径 二、URL重写1）重写指令介绍RewriteEngine on #开启mod_rewrite模块功能 RewriteBase 路径 #基准URL（使用alias设置别名则需使用这个） RewriteCond TestString CondPattern [flags] #重写条件（可以多个） RewriteRule Pattern Substitution [flags] #重写规则 12RewriteCond及RewriteRule行可以可以多个按顺序一个一个执行RewriteRule（[flags不终止情况下]） 2）指令标志位RewriteRule [flags] [flags]，标志符，多个则用逗号隔开。 标志符(摘抄于网上)： redirect|R [&#x3D;code] (强制重定向 redirect) 以 [http://thishost[:thisport]/(使新的URL成为一个URI](http://thishost[:thisport]/%28使新的URL成为一个URI%29%29 为前缀的Substitution可以强制性执行一个外部重定向。 如果code没有指定，则产生一个HTTP响应代码302%28临时性移动%29。如果需要使用在300-400范围内的其他响应代码，只需在此指定这个数值即可， 另外，还可以使用下列符号名称之一: temp %28默认的), permanent, seeother. 用它可以把规范化的URL反馈给客户端，如, 重写“&#x2F;~”为 “&#x2F;u&#x2F;”，或对&#x2F;u&#x2F;user加上斜杠，等等。 注意: 在使用这个标记时，必须确保该替换字段是一个有效的URL! 否则，它会指向一个无效的位置! 并且要记住，此标记本身只是对URL加上 http://thishost[:thisport]/的前缀，重写操作仍然会继续。通常，你会希望停止重写操作而立即重定向，则还需要使用’L’标记. forbidden|F (强制URL为被禁止的 forbidden) 强制当前URL为被禁止的，即，立即反馈一个HTTP响应代码403(被禁止的)。使用这个标记，可以链接若干RewriteConds以有条件地阻塞某些URL。 gone|G(强制URL为已废弃的 gone) 强制当前URL为已废弃的，即，立即反馈一个HTTP响应代码410(已废弃的)。使用这个标记，可以标明页面已经被废弃而不存在了. proxy|P (强制为代理 proxy) 此标记使替换成分被内部地强制为代理请求，并立即(即， 重写规则处理立即中断)把处理移交给代理模块。你必须确保此替换串是一个有效的(比如常见的以 http://hostname开头的)能够为Apache代理模块所处理的URI。使用这个标记，可以把某些远程成分映射到本地服务器名称空间，能够为apache代理模块所处理的uri。使用这个标记，可以把某些远程成分映射到本地服务器名称空间，&#x2F;) 从而增强了ProxyPass指令的功能。 注意: 要使用这个功能，代理模块必须编译在Apache服务器中。 如果你不能确定，可以检查“httpd -l”的输出中是否有mod_proxy.c。 如果有，则mod_rewrite可以使用这个功能；如果没有，则必须启用mod_proxy并重新编译“httpd”程序。 last|L (最后一个规则 last) 立即停止重写操作，并不再应用其他重写规则。 它对应于Perl中的last命令或C语言中的break命令。这个标记可以阻止当前已被重写的URL为其后继的规则所重写。 举例，使用它可以重写根路径的URL(’&#x2F;’)为实际存在的URL, 比如, ‘&#x2F;e&#x2F;www&#x2F;’. next|N (重新执行 next round) 重新执行重写操作(从第一个规则重新开始). 这时再次进行处理的URL已经不是原始的URL了，而是经最后一个重写规则处理的URL。它对应于Perl中的next命令或C语言中的continue命令。 此标记可以重新开始重写操作，即, 立即回到循环的头部。 但是要小心，不要制造死循环! chain|C (与下一个规则相链接 chained) 此标记使当前规则与下一个(其本身又可以与其后继规则相链接的， 并可以如此反复的)规则相链接。 它产生这样一个效果: 如果一个规则被匹配，通常会继续处理其后继规则， 即，这个标记不起作用；如果规则不能被匹配，则其后继的链接的规则会被忽略。比如，在执行一个外部重定向时， 对一个目录级规则集，你可能需要删除“.www” (此处不应该出现“.www”的)。 type|T&#x3D;MIME-type(强制MIME类型 type) 强制目标文件的MIME类型为MIME-type。 比如，它可以用于模拟mod_alias中的ScriptAlias指令，以内部地强制被映射目录中的所有文件的MIME类型为“application&#x2F;x-httpd-cgi”。 nosubreq|NS (仅用于不对内部子请求进行处理 no internal sub-request) 在当前请求是一个内部子请求时，此标记强制重写引擎跳过该重写规则。比如，在mod_include试图搜索可能的目录默认文件(index.xxx)时， Apache会内部地产生子请求。对子请求，它不一定有用的，而且如果整个规则集都起作用，它甚至可能会引发错误。所以，可以用这个标记来排除某些规则。 根据你的需要遵循以下原则: 如果你使用了有CGI脚本的URL前缀，以强制它们由CGI脚本处理，而对子请求处理的出错率(或者开销)很高，在这种情况下，可以使用这个标记。 nocase|NC (忽略大小写 no case) 它使Pattern忽略大小写，即, 在Pattern与当前URL匹配时，’A-Z’ 和’a-z’没有区别。 qsappend|QSA (追加请求串 query string append) 此标记强制重写引擎在已有的替换串中追加一个请求串，而不是简单的替换。如果需要通过重写规则在请求串中增加信息，就可以使用这个标记。 noescape|NE (在输出中不对URI作转义 no URI escaping) 此标记阻止mod_rewrite对重写结果应用常规的URI转义规则。 一般情况下，特殊字符(如’%’, ‘$’, ‘;’等)会被转义为等值的十六进制编码。 此标记可以阻止这样的转义，以允许百分号等符号出现在输出中，如： RewriteRule &#x2F;foo&#x2F;(.*) &#x2F;bar?arg&#x3D;P1&#x3D;$1 [R,NE] 可以使’&#x2F;foo&#x2F;zed’转向到一个安全的请求’&#x2F;bar?arg&#x3D;P1&#x3D;zed’. passthrough|PT (移交给下一个处理器 pass through) 此标记强制重写引擎将内部结构request_rec中的uri字段设置为 filename字段的值，它只是一个小修改，使之能对来自其他URI到文件名翻译器的 Alias，ScriptAlias, Redirect 等指令的输出进行后续处理。举一个能说明其含义的例子：如果要通过mod_rewrite的重写引擎重写&#x2F;abc为&#x2F;def，然后通过mod_alias使&#x2F;def转变为&#x2F;ghi，可以这样: RewriteRule ^&#x2F;abc(.*) &#x2F;def$1 [PT] Alias &#x2F;def &#x2F;ghi 如果省略了PT标记，虽然mod_rewrite运作正常， 即, 作为一个使用API的URI到文件名翻译器，它可以重写uri&#x3D;&#x2F;abc&#x2F;…为filename&#x3D;&#x2F;def&#x2F;…，但是，后续的mod_alias在试图作URI到文件名的翻译时，则会失效。 注意: 如果需要混合使用不同的包含URI到文件名翻译器的模块时， 就必须使用这个标记。。混合使用mod_alias和mod_rewrite就是个典型的例子。 For Apache hackers 如果当前Apache API除了URI到文件名hook之外，还有一个文件名到文件名的hook， 就不需要这个标记了! 但是，如果没有这样一个hook，则此标记是唯一的解决方案。 Apache Group讨论过这个问题，并在Apache 2.0 版本中会增加这样一个hook。 skip|S&#x3D;num (跳过后继的规则 skip) 此标记强制重写引擎跳过当前匹配规则后继的num个规则。 它可以实现一个伪if-then-else的构造: 最后一个规则是then从句，而被跳过的skip&#x3D;N个规则是else从句. (它和’chain|C’标记是不同的!) env|E&#x3D;VAR:VAL (设置环境变量 environment variable) 此标记使环境变量VAR的值为VAL, VAL可以包含可扩展的反向引用的正则表达式$N和%N。 此标记可以多次使用以设置多个变量。这些变量可以在其后许多情况下被间接引用，但通常是在XSSI (via ) or CGI (如 $ENV{’VAR’})中， 也可以在后继的RewriteCond指令的pattern中通过%{ENV:VAR}作引用。使用它可以从URL中剥离并记住一些信息。 cookie|CO&#x3D;NAME:VAL:domain[:lifetime[:path]] (设置cookie) 它在客户端浏览器上设置一个cookie。 cookie的名称是NAME，其值是VAL。 domain字段是该cookie的域，比如’.apache.org’, 可选的lifetime是cookie生命期的分钟数，可选的path是cookie的路径。 RewriteCond [flags] ’nocase|NC’ (不区分大小写) 在扩展后的TestString和CondPattern中，比较时不区分文本的大小写。注意，这个标志对文件系统和subrequest检查没有影响. ’ornext|OR’ (建立与下一个条件的或的关系) 默认的情况下，二个条件之间是AND的关系，用这个标志将关系改为OR。 二、URL重写案例LoadModule rewrite_module modules&#x2F;mod_rewrite.so RewriteEngine on 1)将域名重写为http://www.baidu.com** R 强制重定向 L匹配到此截止** #RewriteRule “^&#x2F;$” “http://www.baidu.com” [R] 2)浏览器匹配，chrome 和 elinks浏览器 #RewriteCond “%{HTTP_USER_AGENT}” “chrome” [NC,OR] #RewriteCond %{HTTP_USER_AGENT} “^elinks” [NC] #强制重写为403禁止 -不重写 F 403标记 #RewriteRule “^&#x2F;$” - [F] 3)PC端 移动端分流 RewriteCond “%{HTTP_USER_AGENT}” “(iPhone|Blackberry|Android|ipad)” [NC] RewriteRule “^&#x2F;$” “http://m.ayitula.com” [L] RewriteRule “^&#x2F;$” “http://book.ayitula.com” [L]"},{"path":"/2023/07/11/Web服务器-Apache/Apacha压力测试/","content":"一、ab命令ab工具 Apache服务器的性能测试工具,它可以测试安装Web服务器每秒处理的HTTP请求. 语法 ab {选项} {参数} 选项 -A：指定连接服务器的基本的认证凭据； -c：指定一次向服务器发出请求数； -C：添加cookie； -g：将测试结果输出为“gnuolot”文件； -h：显示帮助信息； -H：为请求追加一个额外的头； -i：使用“head”请求方式； -k：激活HTTP中的“keepAlive”特性； -n：指定测试会话使用的请求数； -p：指定包含数据的文件； -q：不显示进度百分比； -T：使用POST数据时，设置内容类型头； -v：设置详细模式等级； -w：以HTML表格方式打印结果； -x：以表格方式输出时，设置表格的属性； -X：使用指定的代理服务器发送请求； -y：以表格方式输出时，设置表格属性。 参数 主机：被测试主机。 二、ab压力测试[root@zutuanxue apache]# .&#x2F;bin&#x2F;ab -n 10000 -c 200 http://192.168.11.251/index.php 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@apache_251 apache]# ./bin/ab -n 10000 -c 200 http://192.168.11.251/index.php This is ApacheBench, Version 2.3 &lt;$Revision: 1843412 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 192.168.11.251 (be patient)Completed 1000 requestsCompleted 2000 requestsCompleted 3000 requestsCompleted 4000 requestsCompleted 5000 requestsCompleted 6000 requestsCompleted 7000 requestsCompleted 8000 requestsCompleted 9000 requestsCompleted 10000 requestsFinished 10000 requestsServer Software: Apache/2.4.39 web服务器软件版本Server Hostname: 192.168.11.251 web服务器地址Server Port: 80 web服务器端口Document Path: /index.php URIDocument Length: 0 bytesConcurrency Level: 200Time taken for tests: 238.891 seconds 完成请求总共用的时间Complete requests: 10000 完成10000个请求Failed requests: 0 失败0个请求Non-2xx responses: 10000 非2xx返回码请求Total transferred: 3300000 bytes 总共传输字节数HTML transferred: 0 bytesRequests per second: 41.86 [#/sec] (mean) 并发数,反应服务器的性能，并发数=Complete requests/Time taken for testsTime per request: 4777.821 [ms] (mean) 用户平均请求等待时间Time per request: 23.889 [ms] (mean, across all concurrent requests) 服务器平均请求等待时间Transfer rate: 13.49 [Kbytes/sec] received 传输速率Connection Times (ms) min mean[+/-sd] median maxConnect: 0 0 0.3 0 3Processing: 91 4729 1932.0 4717 21860Waiting: 89 4729 1932.0 4717 21860Total: 92 4729 1931.9 4717 21860Percentage of the requests served within a certain time (ms) 50% 4717 66% 4784 75% 4977 80% 6294 90% 7809 95% 8018 98% 9788 99% 11148 100% 21860 (longest request)"},{"path":"/2023/07/11/MySQL数据库实战/表与表之间关系/","content":"可以在数据库图表中的表之间创建关系，以显示一个表中的列与另一个表中的列是如何相链接的。 在一个关系型数据库中，利用关系可以避免多余的数据。 一、表与表之间关系概述1.1、什么是表与表之间关系在关系型数据库中，为了避免数据冗余，我们的一些表与表之间肯定是有一定的关系。 如：学生表与老师表，部门表与员工表，用户表与权限表等。 在表设计的时候，就应该体现出来表与表之间的这种关系。 1.2、表与表之间关系分类1.2.1、一对多关系一对多关系是最普通的一种关系。在这种关系中，A 表中的一行可以匹配 B 表中的多行，但是 B 表中的一行只能匹配 A 表中的一行。 只有当一个相关列是一个主键或具有唯一约束时，才能创建一对多关系。 image20200215112949021.png 注意： 一对多的创建原则： 主外键关连 1.2.2、一对一关系在一对一关系中，A 表中的一行最多只能匹配于 B 表中的一行，反之亦然。如果相关列都是主键或都具有唯一约束，则可以创建一对一关系。 image20200215122050731.png 注意： 一对一的创建原则： 外键唯一：主表的主键和从表的外键（唯一），形成主外键关系，外键唯一 UNIQUE 外键是主键：主表的主键和从表的主键，形成主外键关系 1.2.3、多对多关系在多对多关系中，A 表中的一行可以匹配 B 表中的多行，反之亦然。要创建这种关系，需要定义第三个表，称为结合表，它的主键由 A 表和 B 表的外部键组成。 image20200215121200999.png 注意： 多对多的创建原则： 二个表与中间表创建1对多的关系。 2、一对多应用创建一对多关系：主外键关连 image20200215123556759.png 新华出版社（Python爬虫、Linux） 海燕出版社（操作系统、数学） 摆渡出版社（英语、网页设计） 大众出版社（） 案例： 这是一个书和出版社的一个例子，书要关联出版社（多个书可以是一个出版社，一个出版社也可以有好多书）。 表的创建 12345678910111213141516#出版社表（被关联表）create table press(id int primary key auto_increment, name char(20)-- 出版社名字);#书表（关联表）create table book(book_id int primary key auto_increment,book_name varchar(20),book_price int,press_id int,constraint fk_pressid_id foreign key(press_id) references press(id)on delete cascadeon update cascade); 插入数据 12345mysql&gt; insert into press(name) values(&#x27;新华出版社&#x27;), (&#x27;海燕出版社&#x27;), (&#x27;摆渡出版社&#x27;), (&#x27;大众出版社&#x27;);Query OK, 4 rows affected (0.09 秒)mysql&gt; insert into book(book_name,book_price,press_id) values(&#x27;Python爬虫&#x27;,100,1), (&#x27;Linux&#x27;,80,1), (&#x27;操作系统&#x27;,70,2), (&#x27;数学&#x27;,50,2), (&#x27;英语&#x27;,103,3), (&#x27;网页设计&#x27;,22,3);Query OK, 6 rows affected (0.07 秒) 查看数据 1234567891011121314151617181920212223mysql&gt; select * from press;+----+-----------------+| id | name |+----+-----------------+| 1 | 新华出版社 || 2 | 海燕出版社 || 3 | 摆渡出版社 || 4 | 大众出版社 |+----+-----------------+4 行于数据集 (0.01 秒)mysql&gt; select * from book;+---------+--------------+------------+----------+| book_id | book_name | book_price | press_id |+---------+--------------+------------+----------+| 1 | Python爬虫 | 100 | 1 || 2 | Linux | 80 | 1 || 3 | 操作系统 | 70 | 2 || 4 | 数学 | 50 | 2 || 5 | 英语 | 103 | 3 || 6 | 网页设计 | 22 | 3 |+---------+--------------+------------+----------+6 行于数据集 (0.01 秒) 三、一对一应用创建一对一：外键唯一，user_id唯一对应一个uid，user_id必须在uid里出现 image20200215164955805.png 案例： 用户和管理员（只有管理员才可以登录，一个管理员对应一个用户） 表创建 123456789101112131415#用户表（被关联表）create table user(id int primary key auto_increment, #主键自增name char(10));#管理员表（关联表）create table manager(id int primary key auto_increment,user_id int unique,password varchar(16),foreign key(user_id) references user(id)on delete cascadeon update cascade); 插入数据 12345mysql&gt; insert into user(name)values(&#x27;susan1&#x27;),(&#x27;susan2&#x27;),(&#x27;susan3&#x27;),(&#x27;susan4&#x27;),(&#x27;susan5&#x27;),(&#x27;susan6&#x27;);Query OK, 6 rows affected (0.02 秒)mysql&gt; insert into manager(user_id,password) values(4,&#x27;sds156&#x27;),(2,&#x27;531561&#x27;),(6,&#x27;f3swe&#x27;);Query OK, 3 rows affected (0.03 秒) 查看数据 12345678910111213141516171819202122mysql&gt; select * from user;+----+--------+| id | name |+----+--------+| 1 | susan1 || 2 | susan2 || 3 | susan3 || 4 | susan4 || 5 | susan5 || 6 | susan6 |+----+--------+6 行于数据集 (0.01 秒)mysql&gt; select * from manager;+----+---------+----------+| id | user_id | password |+----+---------+----------+| 1 | 4 | sds156 || 2 | 2 | 531561 || 3 | 6 | f3swe |+----+---------+----------+3 行于数据集 (0.01 秒) 4、多对多应用创建多对多：要把book_id和author_id设置成联合唯一 image20200215161523092.png 九阳神功（egon、e3） 葵花宝典（egon、e4） 辟邪剑谱（e1、e2、e3） 降龙十巴掌（e4） 或者 egon（九阳神功、葵花宝典） e1（辟邪剑谱） e2（辟邪剑谱） e3（九阳神功、辟邪剑谱） e4（葵花宝典、降龙十巴掌） 案例： 这是一个书和作者的一个例子，书要关联作者（一个作者可以写多个书，一本书也可以有多个作者，双向的一对多，即多对多）。 表创建 1234567891011121314151617181920212223242526#书表（被关联表）create table book1(id int primary key auto_increment,name varchar(10),price float(3,2));#作者表（被关联表）create table author(id int primary key auto_increment,name char(5));#作者和书表（关联表）create table author2book(id int primary key auto_increment,book_id int not null,author_id int not null,unique(book_id,author_id),foreign key(book_id) references book1(id)on delete cascadeon update cascade,foreign key(author_id) references author(id)on delete cascadeon update cascade); 插入数据 12345678mysql&gt; insert into book1(name,price) values(&#x27;九阳神功&#x27;,9.9), (&#x27;葵花宝典&#x27;,9.5), (&#x27;辟邪剑谱&#x27;,5), (&#x27;降龙十巴掌&#x27;,7.3);Query OK, 4 rows affected (0.09 秒)mysql&gt; insert into author(name) values(&#x27;egon&#x27;),(&#x27;e1&#x27;),(&#x27;e2&#x27;),(&#x27;e3&#x27;),(&#x27;e4&#x27;);Query OK, 5 rows affected (0.07 秒)mysql&gt; insert into author2book(book_id,author_id) values(1,1),(1,4),(2,1),(2,5),(3,2),(3,3),(3,4),(4,5);Query OK, 8 rows affected (0.03 秒) 查看数据 12345678910111213141516171819202122232425262728293031323334353637mysql&gt; select * from book1;+----+-----------------+-------+| id | name | price |+----+-----------------+-------+| 1 | 九阳神功 | 9.90 || 2 | 葵花宝典 | 9.50 || 3 | 辟邪剑谱 | 5.00 || 4 | 降龙十巴掌 | 7.30 |+----+-----------------+-------+4 行于数据集 (0.02 秒)mysql&gt; select * from author;+----+------+| id | name |+----+------+| 1 | egon || 2 | e1 || 3 | e2 || 4 | e3 || 5 | e4 |+----+------+5 行于数据集 (0.01 秒)mysql&gt; select * from author2book;+----+---------+-----------+| id | book_id | author_id |+----+---------+-----------+| 1 | 1 | 1 || 2 | 1 | 4 || 3 | 2 | 1 || 4 | 2 | 5 || 5 | 3 | 2 || 6 | 3 | 3 || 7 | 3 | 4 || 8 | 4 | 5 |+----+---------+-----------+8 行于数据集 (0.01 秒)"},{"path":"/2023/07/11/MySQL数据库实战/数据库设计/","content":"数据库设计(Database Design)是指对于一个给定的应用环境，构造最优的数据库模式，建立数据库及其应用系统，使之能够有效地存储数据，满足各种用户的应用需求（信息要求和处理要求）。在数据库领域内，常常把使用数据库的各类系统统称为数据库应用系统。数据库设计的设计内容包括：需求分析、概念结构设计、逻辑结构设计、物理结构设计、数据库的实施和数据库的运行和维护。 一、范式概述1.1、什么是范式好的数据库设计对数据的存储性能和后期的程序开发，都会产生重要的影响。建立科学的，规范的数据库就需要满足一些规则来优化数据的设计和存储，这些规则就称为范式。 1.2、范式分类目前关系数据库有六种范式： 第一范式（1NF） 第二范式（2NF） 第三范式（3NF） 巴斯-科德范式（BCNF）、 第四范式(4NF） 第五范式（5NF，又称完美范式） 一般说来，数据库只需满足第三范式(3NF）就行了。 二、第一范式确保每个字段不可再分。确保每列原子性。 案例： 班级表中的字段 12345+---------+----------+------------------------+| 班级id | 班级名称 | 上课时间 |+---------+----------+------------------------+| 1 | 一班 | 1999-09-01~2000-01-04 |+---------+----------+-------------------------+ 不合理。不满足第一范式，上课时间可以再分 12345+---------+----------+------------------------+| 班级id | 班级名称 | 开课时间 | 结课时间 |+---------+----------+------------------------+| 1 | 一班 | 1999-09-01 | 2000-01-04|+---------+----------+-------------------------+ 地址包含省、市、县、地区是否需要拆分？如果仅仅起地址的作用，不需要统计，可以不拆分；如果有按地区统计的功能需要拆分。一般情况下拆分 三、第二范式一个表只能描述一件事。 订单表中的字段 12345+---------+----------+------------------------+| 订单编号 | 产品编号 | 订购日期 | 价格 |+---------+----------+------------------------+| 00001 | A00001 | 1999-09-01 | 35687.0 |+---------+----------+------------------------+ 不合理。不满足第二范式，一个表中出现了二种描述，一个是订单，一个是产品 123456789101112订单表+---------+------------+| 订单编号 | 订购日期 |+---------+------------+| 00001 | 1999-09-01 | +---------+------------+产品表+----------+------------+| 产品编号 | 价格 |+----------+------------+| A00001 | 35687.0 |+----------+------------+ 如下表设计是否合理？ 123+------+--------+--------+---------+----------+| 学号 | 姓名 | 年龄 | 最高气温 | 青菜价格 | +------+--------+--------+---------+----------+ 四、第三范式在所有的非键字段中，不能有传递依赖。消除传递依赖 订单表中的字段 12345+---------+----------+------------------------+| 订单编号 | 订购日期 | 顾客编号 | 顾客姓名 |+---------+----------+------------------------+| 00001 |1999-09-01| A000001 | Luc |+---------+----------+------------------------+ 不合理。不满足第三范式，因为我们已经可以通过顾客编号知道顾客姓名，所以我们不需要定义顾客姓名 12345+---------+----------+------------+| 订单编号 | 订购日期 | 顾客编号 | +---------+----------+------------+| 00001 |1999-09-01| A000001 | +---------+----------+------------+ 下列设计是否满足第三范式？ 123+------+--------+--------+---------+----------+| 学号 | 姓名 | 语文 | 数学 | 总分 | +------+--------+--------+---------+----------+ 不满足，因为语文和数学确定了，总分就确定了。上面的设计不满足第三范式，但是高考分数表就是这样设计的，为什么？高考分数峰值访问量非常大，这时候就是性能更重要。当性能和规范化冲突的时候，我们首选性能。这就是“反三范式”。"},{"path":"/2023/07/11/MySQL数据库实战/数据库介绍/","content":"数据库(Database)是按照数据结构来组织、存储和管理数据的仓库，它产生于距今六十多年前，随着信息技术和市场的发展，特别是二十世纪九十年代以后，数据管理不再仅仅是存储和管理数据，而转变成用户所需要的各种数据管理的方式。数据库有很多种类型，从最简单的存储有各种数据的表格到能够进行海量数据存储的大型数据库系统都在各个方面得到了广泛的应用。 在信息化社会，充分有效地管理和利用各类信息资源，是进行科学研究和决策管理的前提条件。数据库技术是管理信息系统、办公自动化系统、决策支持系统等各类信息系统的核心部分，是进行科学研究和决策管理的重要技术手段。 一、数据库管理系统1.1、数据存储方式计算机数据（Data）的存储一般以硬盘为数据存储空间资源，从而保证计算机内的数据能够持续保存。对于数据的处理，一般会采用数据库相关的技术进行处理，从而保证数据处理的高效性。 采用数据库的管理模式不仅提高了数据的存储效率，而且在存储的层面上提高了数据的安全性。通过分类的存储模式让数据管理更加安全便捷，更能实现对数据的调用和对比，并且方便查询等操作的使用。 1.2、数据库管理系统常见的数据库管理系统： MySQL:开源免费的数据库，小型的数据库。已经被Oracle收购了，MySQL6.x版本也开始收费。 Oracle:收费的大型数据库，Oracle公司的产品。Oracle收购SUN公司，收购MYSQL。 DB2:IBM公司的数据库产品,收费的。常应用在银行系统中. SQLServer:MicroSoft 公司收费的中型的数据库。C#、.net等语言常使用。 SyBase:已经淡出历史舞台。提供了一个非常专业数据建模的工具PowerDesigner。 SQLite:嵌入式的小型数据库，应用在手机端。 Java常用的数据库:MySQL，Oracle。 Python常用的数据库:MySQL。 1.3、数据库与数据库管理系统关系image20200128210246764.png 2、数据库数据库就是存储数据的仓库，由数据库表组成，其本质是一个文件系统，数据库按照特定的格式将数据存储起来，用户可以对数据库中的数据进行增加，修改，删除及查询操作。 2.1、数据库表数据库中以表为组织单位存储数据。 数据库表由：表名、表字段、表记录构成 如： 在学生档案中，学生信息（数据库表）是由学号、姓名、性别、年龄、籍贯、院系、联系电话（表中字段）等特征组成的，那么这些具体的特征值所构成的一条记录就是一个学生的信息数据，例如“2016010102，张三，男，26，山西，计算机学院，18513232232”（记录）。 2.2、数据库表记录根据表字段所规定的数据类型，我们可以向其中填入一条条的数据，而表中的每条数据类似类的实例对象。表中的一行一行的信息我们称之为记录。 2.2.1、数据库image20200128212446704.png 2.2.2、数据库表结构image20200128212610860.png 2.2.3、记录image20200128212711794.png"},{"path":"/2023/07/11/MySQL数据库实战/多表连接查询/","content":"连接查询是关系数据库中最主要的查询，主要包括内连接、外连接和交叉连接等。通过连接运算符可以实现多个表查询。连接是关系数据库模型的主要特点，也是它区别于其它类型数据库管理系统的一个标志。 在关系数据库管理系统中，表建立时各数据之间的关系不必确定，常把一个实体的所有信息存放在一个表中。当检索数据时，通过连接操作查询出存放在多个表中的不同实体的信息。连接操作给用户带来很大的灵活性，他们可以在任何时候增加新的数据类型。为不同实体创建新的表，然后通过连接进行查询。 一、多表连接查询概述1.1、什么是多表查询连接是在多个表之间通过一定的连接条件，使表之间发生关联，进而能从多个表之间获取数据。 比如： 有一个部门表，有一个员工表，我想查询某部门中的所有员工的信息。这时我们要先找出部门ID，通过部门ID查询出对应的员工信息。 这样我们在查询我们需要的信息的时候就应用了多表。所以这就是我们的多表查询。 1.2、多表查询的作用比如： 我们想查询员工A的名字和他所在的部门的名字，则需要使用多表查询。 那么我们使用一条 SQL 语句查询多张表，因为查询结果在多张不同的表中。而我们的结果要从每张表取 1 列或多列。这就是多表查询的作用。 1.3、多表查询分类多表查询可以分为二类查询： 内连接：隐匿内连接、显示内连接 (INNER JOIN) 外连接：左外连接、右外连接 (LEFT JOIN) (RIGHT JOIN) 1.4、笛卡尔积现象1.4.1、数据准备创建表和数据 12345678910111213141516171819202122#部门表create table dept(id int primary key auto_increment,name varchar(20));insert into dept (name) values (&#x27;研发部&#x27;),(&#x27;渠道部&#x27;),(&#x27;教务部&#x27;);# 创建员工表create table emp (id int primary key auto_increment,name varchar(10),gender char(1), -- 性别salary double, -- 工资join_date date, -- 入职日期dept_id int,foreign key (dept_id) references dept(id) -- 外键，关联部门表(部门表的主键) );insert into emp(name,gender,salary,join_date,dept_id) values(&#x27;张三&#x27;,&#x27;男&#x27;,7200,&#x27;2013-02-24&#x27;,1);insert into emp(name,gender,salary,join_date,dept_id) values(&#x27;李四&#x27;,&#x27;男&#x27;,3600,&#x27;2010-12-02&#x27;,2);insert into emp(name,gender,salary,join_date,dept_id) values(&#x27;王五&#x27;,&#x27;男&#x27;,9000,&#x27;2008-08-08&#x27;,2);insert into emp(name,gender,salary,join_date,dept_id) values(&#x27;赵六&#x27;,&#x27;女&#x27;,5000,&#x27;2015-10-07&#x27;,3);insert into emp(name,gender,salary,join_date,dept_id) values(&#x27;吴七&#x27;,&#x27;女&#x27;,4500,&#x27;2011-03-14&#x27;,1); 显示表中数据 123456789101112131415161718192021mysql&gt; select * from dept;+----+-----------+| id | name |+----+-----------+| 1 | 研发部 || 2 | 渠道部 || 3 | 教务部 |+----+-----------+3 行于数据集 (0.01 秒)mysql&gt; select * from emp;+----+--------+--------+--------+------------+---------+| id | name | gender | salary | join_date | dept_id |+----+--------+--------+--------+------------+---------+| 1 | 张三 | 男 | 7200 | 2013-02-24 | 1 || 2 | 李四 | 男 | 3600 | 2010-12-02 | 2 || 3 | 王五 | 男 | 9000 | 2008-08-08 | 2 || 4 | 赵六 | 女 | 5000 | 2015-10-07 | 3 || 5 | 吴七 | 女 | 4500 | 2011-03-14 | 1 |+----+--------+--------+--------+------------+---------+5 行于数据集 (0.01 秒) 1.4.2、什么是笛卡尔积案例： 查询所有员工和所有部门 1mysql&gt; select * from emp,dept; image20200215173505470.png 左表的每条数据和右表的每条数据组合，这种效果就是笛卡尔积 1.4.3、清除笛卡尔积我们发现笛卡尔积所产生的数据并不是都是有用的，只有员工.dept_id&#x3D;部门.id的值才是我们想要的。 所以我们需要过滤掉没有用的数据。那么如何设置过滤条件呢？ 123456789101112131415161718192021mysql&gt; select * from emp,dept where emp.dept_id=dept.id;+----+--------+--------+--------+------------+---------+-------+-----------+| id | name | gender | salary | join_date | dept_id | id(2) | name(2) |+----+--------+--------+--------+------------+---------+-------+-----------+| 1 | 张三 | 男 | 7200 | 2013-02-24 | 1 | 1 | 研发部 || 5 | 吴七 | 女 | 4500 | 2011-03-14 | 1 | 1 | 研发部 || 2 | 李四 | 男 | 3600 | 2010-12-02 | 2 | 2 | 渠道部 || 3 | 王五 | 男 | 9000 | 2008-08-08 | 2 | 2 | 渠道部 || 4 | 赵六 | 女 | 5000 | 2015-10-07 | 3 | 3 | 教务部 |+----+--------+--------+--------+------------+---------+-------+-----------+mysql&gt; select emp.name,dept.name from emp,dept where emp.dept_id=dept.id;+--------+-----------+| name | name(2) |+--------+-----------+| 张三 | 研发部 || 吴七 | 研发部 || 李四 | 渠道部 || 王五 | 渠道部 || 赵六 | 教务部 |+--------+-----------+5 行于数据集 (0.01 秒) 二、内连接用左边表的记录去匹配右边表的记录，如果符合条件的则显示。如：从表.外键&#x3D;主表.主键 2.1、隐式内连接看不到 join 关键字，条件使用 where 指定 12格式：select */字段列表 from 左表，右表 where 条件表达式; 案例： 查询员工表中所有员工及所在部门 12345678910mysql&gt; select * from emp,dept where emp.dept_id=dept.id;+----+--------+--------+--------+------------+---------+-------+-----------+| id | name | gender | salary | join_date | dept_id | id(2) | name(2) |+----+--------+--------+--------+------------+---------+-------+-----------+| 1 | 张三 | 男 | 7200 | 2013-02-24 | 1 | 1 | 研发部 || 5 | 吴七 | 女 | 4500 | 2011-03-14 | 1 | 1 | 研发部 || 2 | 李四 | 男 | 3600 | 2010-12-02 | 2 | 2 | 渠道部 || 3 | 王五 | 男 | 9000 | 2008-08-08 | 2 | 2 | 渠道部 || 4 | 赵六 | 女 | 5000 | 2015-10-07 | 3 | 3 | 教务部 |+----+--------+--------+--------+------------+---------+-------+-----------+ 2.2、显式内连接使用inner join…on语句，可以省略inner 12格式：select */字段列表 from 左表 [inner] join 右表 on 条件表达式; 案例： 查询王五的信息，显示员工 id，姓名，性别，工资和所在的部门名称。 1234567mysql&gt; select emp.id,emp.name,emp.gender,emp.salary,dept.name from emp join dept on emp.dept_id=dept.id where emp.name=&#x27;王五&#x27;;+----+--------+--------+--------+-----------+| id | name | gender | salary | name(2) |+----+--------+--------+--------+-----------+| 3 | 王五 | 男 | 9000 | 渠道部 |+----+--------+--------+--------+-----------+1 行于数据集 (0.02 秒) SQL优化 12345select emp.id,emp.name,emp.gender,emp.salary,dept.name from emp join dept on emp.dept_id=dept.id where emp.name=&#x27;王五&#x27;;或select e.id,e.name,e.gender,e.salary,d.name from emp e join dept d on e.dept_id=d.id where e.name=&#x27;王五&#x27;;或select e.id,e.name,gender,salary,d.name from emp e join dept d on dept_id=d.id where e.name=&#x27;王五&#x27;; 2.3、内连接使用步骤 确认查询的数据库表 确认数据库表连接条件 确认数据库表查询条件 确认数据库表显示字段 三、左&#x2F;右连接3.1、左连接使用 left outer join…on，outer 可以省略 12格式：select */字段列表 from 左表 left [outer] join 右表 on 条件表达式; 用左边表的记录去匹配右边表的记录，如果符合条件的则显示；否则，显示 NULL 案例： 在部门表中增加一个部门 12mysql&gt; insert into dept(name) values(&#x27;执行部&#x27;);Query OK, 1 rows affected (0.08 秒) 用内连接查询信息 1mysql&gt; select * from dept d inner join emp e on d.id=e.dept_id; image20200215182047845.png 用左连接查询信息 1mysql&gt; select * from dept d left join emp e on d.id=e.dept_id; image20200215182100590.png 注意： 左连接表示的是在内连接的基础上保证左表的信息全部显示 3.2、右连接使用 right outer join…on，outer 可以省略 12格式：select */字段列表 from 左表 right [outer] join 右表 on 条件表达式; 用右边表的记录去匹配左边表的记录，如果符合条件的则显示；否则，显示 NULL 案例： 在员工表中加入一个新员工 12mysql&gt; insert into emp values (null, &#x27;王一&#x27;,&#x27;男&#x27;,6666,&#x27;2013-12-05&#x27;,null);Query OK, 1 rows affected (0.02 秒) 用内连接查询信息 1mysql&gt; select * from dept d inner join emp e on d.id=e.dept_id; image20200215182047845.png 用右连接查询信息 1mysql&gt; select * from dept d right join emp e on d.id=e.dept_id; image20200215183504384.png 注意： 右连接表示的是在内连接的基础上保证右表的信息全部显示 CREATE TABLE temp(select * from table);"},{"path":"/2023/07/11/MySQL数据库实战/SQL介绍/","content":"结构化查询语言是高级的非过程化编程语言，允许用户在高层数据结构上工作。它不要求用户指定对数据的存放方法，也不需要用户了解具体的数据存放方式，所以具有完全不同底层结构的不同数据库系统, 可以使用相同的结构化查询语言作为数据输入与管理的接口。结构化查询语言语句可以嵌套，这使它具有极大的灵活性和强大的功能。 一、SQL概述1.1、什么是SQL结构化查询语言(Structured Query Language)简称SQL，是一种特殊目的的编程语言，是一种数据库查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统；同时也是数据库脚本文件的扩展名。 1.2、SQL作用是一种所有关系型数据库的查询规范，不同的数据库都支持。 通用的数据库操作语言，可以用在不同的数据库中。 不同的数据库 SQL 语句有一些区别 二、SQL分类数据查询语言（DQL:Data Query Language）： 其语句，也称为“数据检索语句”，用以从表中获得数据，确定数据怎样在应用程序给出。保留字SELECT是DQL（也是所有SQL）用得最多的动词，其他DQL常用的保留字有WHERE，ORDER BY，GROUP BY和HAVING。这些DQL保留字常与其他类型的SQL语句一起使用。 数据操作语言（DML：Data Manipulation Language）： 其语句包括动词INSERT，UPDATE和DELETE。它们分别用于添加，修改和删除表中的行。也称为动作查询语言。 事务处理语言（TPL）： 它的语句能确保被DML语句影响的表的所有行及时得以更新。TPL语句包括BEGIN TRANSACTION，COMMIT和ROLLBACK。 **数据定义语言（*DDL*）： 其语句包括动词CREATE和DROP。在数据库中创建新表或删除表（CREAT TABLE 或 DROP TABLE）；为表加入索引等。DDL包括许多与人数据库目录中获得数据有关的保留字。它也是动作查询的一部分。 指针控制语言（CCL）： 它的语句，像DECLARE CURSOR，FETCH INTO和UPDATE WHERE CURRENT用于对一个或多个表单独立的操作。 数据控制语言（DCL）： 它的语句通过GRANT或REVOKE获得许可，确定单个用户和用户组对数据库对象的访问。某些RDBMS可用GRANT或REVOKE控制对表单个列的访问。 三、MySql语法每条语句以分号（;）结尾。 SQL 中不区分大小写，关键字中认为大写和小写是一样的 3种注释方法： image20200128220353753.png"},{"path":"/2023/07/11/MySQL数据库实战/MySQL视图/","content":"视图是指计算机数据库中的视图，是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。 一、视图概述1.1、什么是视图在 SQL 中，视图是基于 SQL 语句的结果集的可视化的表。 视图包含行和列，就像一个真实的表。视图中的字段就是来自一个或多个数据库中的真实的表中的字段。我们可以向视图添加 SQL 函数、WHERE 以及 JOIN 语句，我们也可以提交数据，就像这些来自于某个单一的表。 注意： 数据库的设计和结构不会受到视图中的函数、where 或 join 语句的影响。 1.2、视图的作用重复利用SQL语句 简化SQL查询，快速取数据 只用知道表的部分结构 保护数据，根据特定授权 更改数据格式和表示，视图可返回与底层表的表示和格式不同的数据 注意：在视图创建后，可以用与表基本相同的方式使用（查询、过滤、排序数据、与其他视图或连结、（添加、更新））。 视图只是用来查看存储在别处的数据的设施，本身不包含数据，返回的数据也是从其他表检索出来的。 因为视图本身不包含数据，索引多个表连结或嵌套可能存在性能问题，需测试。 1.3、视图规则和限制与表一样，命名必须是唯一的(不能出现同名视图或表名)。 创建视图数目无限制，但是要考虑复杂查询创建为视图之后的性能影响。 视图不能添加索引，也不能有关联的触发器或者默认值。 视图可以提高安全性，必须具有足够的访问权限。 order by可用在视图中，但是如果从该视图检索数据select中含有order by ，那么该视图中的order by将被覆盖。 视图可以和表一起使用。 1.4、视图的应用权限控制时使用 如某几个列，允许用户查询，其他列不允许查询 可以通过视图，开放其中几列查询，起到权限控制作用 简化复杂查询时使用 查询每个栏目下商品的平均价格，并按平均价格排序，查询出平均价格前3的栏目 视图能不能更新，删除，添加 如果视图的每一行，是与物理表一一对应的则可以 视图的行是由物理表多行经过计算得到的结果，视图不可以更新的 二、视图创建2.1、创建格式12格式：create view 视图名 as select 字段名 from 表名; 案例： 创建一个视图 12345678910111213141516mysql&gt; create view s_view as (select sname,sex,age from students);Query OK, 0 rows affected (0.02 sec)mysql&gt; select * from s_view;+--------+------+------+| sname | sex | age |+--------+------+------+| 张三 | 男 | 19 || 李四 | 男 | 20 || 张红 | 女 | 19 || 张八 | 男 | 18 || 三李 | 男 | 19 || 王六 | 女 | 20 || 刘红 | 女 | 18 |+--------+------+------+8 rows in set (0.00 sec) 2.2、视图的运算规则12格式：create [algorithm = &#123;undefined | merge | temptable&#125;] view 视图名 as select 字段名 from 表名; 注意： ALGORITHM ： 视图算法 undefined 系统自动选择算法 merge 当使用视图时，会把查询视图的语句和创建视图的语句合并起来，形成一条件一句，最后再从基表中查询 temptable 当使用视图时，会把创建视图的语句的查询结果当成一张临时表，再从临时表中进行筛选 案例： 用temptable创建视图 12345678910111213141516171819202122232425mysql&gt; create algorithm=temptable view view_t as select sname,sex,english,math from students order by math,english desc;Query OK, 0 rows affected (0.03 秒)mysql&gt; select * from view_t;+--------+------+---------+------+| sname | sex | english | math |+--------+------+---------+------+| 王六 | 女 | 50.0 | 70.0 || 张红 | 女 | 86.0 | 80.0 || 张八 | 男 | 80.0 | 85.0 || 张三 | 男 | 98.5 | 88.0 || 李四 | 男 | 80.0 | 88.0 || 三李 | 男 | 60.0 | 88.0 || 刘红 | 女 | 90.0 | 98.0 |+--------+------+---------+------+8 行于数据集 (0.01 秒)mysql&gt; select * from view_t group by sex;+--------+------+---------+------+| sname | sex | english | math |+--------+------+---------+------+| 王六 | 女 | 50.0 | 70.0 || 张八 | 男 | 80.0 | 85.0 |+--------+------+---------+------+2 行于数据集 (0.01 秒) 用merge创建视图 12345678910111213141516171819202122232425262728293031323334mysql&gt; create algorithm=merge view view_m as select sname,sex,english,math from students order by math,english desc;Query OK, 0 rows affected (0.04 秒)mysql&gt; select * from view_m;+--------+------+---------+------+| sname | sex | english | math |+--------+------+---------+------+| 王六 | 女 | 50.0 | 70.0 || 张红 | 女 | 86.0 | 80.0 || 张八 | 男 | 80.0 | 85.0 || 张三 | 男 | 98.5 | 88.0 || 李四 | 男 | 80.0 | 88.0 || 三李 | 男 | 60.0 | 88.0 || 刘红 | 女 | 90.0 | 98.0 |+--------+------+---------+------+8 行于数据集 (0.02 秒)mysql&gt; select * from view_m group by sex;+--------+------+---------+------+| sname | sex | english | math |+--------+------+---------+------+| 张三 | 男 | 98.5 | 88.0 || 张红 | 女 | 86.0 | 80.0 |+--------+------+---------+------+2 行于数据集 (0.01 秒)#查询视图的语句和创建视图的语句合并起来，形成一条件一句，最后再从基表中查询mysql&gt; select sname,sex,english,math from students group by sex order by math,english desc;+--------+------+---------+------+| sname | sex | english | math |+--------+------+---------+------+| 张红 | 女 | 86.0 | 80.0 || 张三 | 男 | 98.5 | 88.0 |+--------+------+---------+------+2 行于数据集 (0.02 秒) 2.3、视图的权限范围12格式：[with [cascaded | local ] check option] WITH CHECK OPTION 表示对UPDATE、INSERT和DELETE操作时保持更新，插入或删除的行满足视图定义的条件（即子查询中的条件表达式） 注意： cascaded 默认值 更新视图时要满足所有相关视图和表的条件。 local 表示更新视图时满足该视图本身定义的条件即可。 案例： 1234567891011121314mysql&gt; create view view_1 as select sid,sname,sex,age from students where sid&lt;6;Query OK, 0 rows affected (0.02 秒)mysql&gt; create view view_1_1 as select * from view_1 where sid&gt;2 with cascaded check option;Query OK, 0 rows affected (0.02 秒)mysql&gt; create view view_1_2 as select * from view_1 where sid&gt;2 with local check option;Query OK, 0 rows affected (0.02 秒)mysql&gt; insert into view_1_1 values(6,&#x27;lisi&#x27;,&#x27;男&#x27;,20);CHECK OPTION failed &#x27;zutuanxue.view_1_1&#x27;mysql&gt; insert into view_1_2 values(6,&#x27;lisi&#x27;,&#x27;男&#x27;,20);Query OK, 1 rows affected (0.01 秒) 2.4、视图记录修改12格式：update 数据库表名 set 字段名1=字段值1,字段名2=字段值2,...字段名n=字段值n where 条件表达式; #和表的修改一样 案例： 修改视图中王六的性别为‘男’ 1234567891011121314151617mysql&gt; update s_view set sex=&#x27;男&#x27; where sname=&#x27;王六&#x27;;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select * from s_view;+--------+------+------+| sname | sex | age |+--------+------+------+| 张三 | 男 | 19 || 李四 | 男 | 20 || 张红 | 女 | 19 || 张八 | 男 | 18 || 三李 | 男 | 19 || 王六 | 男 | 20 || 刘红 | 女 | 18 |+--------+------+------+8 rows in set (0.00 sec) 注意： 修改了视图，对基表数据也有影响 12345678910111213mysql&gt; select * from students;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 5 | 三李 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 6 | 王六 | 男 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+8 rows in set (0.00 sec) 修改students表中王六的年龄为21 1234567891011121314151617mysql&gt; update students set age=21 where sname=&#x27;王六&#x27;;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select * from s_view;+--------+------+------+| sname | sex | age |+--------+------+------+| 张三 | 男 | 19 || 李四 | 男 | 20 || 张红 | 女 | 19 || 张八 | 男 | 18 || 三李 | 男 | 19 || 王六 | 男 | 21 || 刘红 | 女 | 18 |+--------+------+------+8 rows in set (0.00 sec) 三、视图修改3.1、修改格式123456格式：alter view 视图名称 as select 语句;或alter view 视图名称 as select 视图;或create or replace view 视图名 as select 字段名 from 表名; 3.2、select 语句 修改案例： 修改我们的s_view视图 12345678910111213141516mysql&gt; alter view s_view as select sname,sex,age,remark from students;Query OK, 0 rows affected (0.01 sec)mysql&gt; select * from s_view;+--------+------+------+-----------------+| sname | sex | age | remark |+--------+------+------+-----------------+| 张三 | 男 | 19 | 他来自四川 || 李四 | 男 | 20 | 他来自重庆 || 张红 | 女 | 19 | 他来自北京 || 张八 | 男 | 18 | 他来自天津 || 三李 | 男 | 19 | 他来自湖北 || 王六 | 女 | 20 | 他来自湖南 || 刘红 | 女 | 18 | 他来自甘肃 |+--------+------+------+-----------------+8 rows in set (0.01 sec) 3.3、select 视图 修改案例： 修改我们的s_view视图 12345678910111213141516171819mysql&gt; create view s_view_1 as(select sname,sex,age,remark from students);Query OK, 0 rows affected (0.01 sec)mysql&gt; alter view s_view as select sname,remark from s_view_1;Query OK, 0 rows affected (0.01 sec)mysql&gt; select * from s_view;+--------+-----------------+| sname | remark |+--------+-----------------+| 张三 | 他来自四川 || 李四 | 他来自重庆 || 张红 | 他来自北京 || 张八 | 他来自天津 || 三李 | 他来自湖北 || 王六 | 他来自湖南 || 刘红 | 他来自甘肃 |+--------+-----------------+8 rows in set (0.00 sec) 3.4、create or replace案例： 修改我们的s_view视图 12345678910111213141516mysql&gt; create or replace view s_view as select sname from students;Query OK, 0 rows affected (0.01 sec)mysql&gt; select * from s_view;+--------+| sname |+--------+| 张三 || 李四 || 张红 || 张八 || 三李 || 王六 || 刘红 |+--------+8 rows in set (0.00 sec) 四、视图查看4.1、显示视图创建情况12格式：show create view 视图名; 案例： 1234567mysql&gt; show create view s_view;+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+| View | Create View | character_set_client | collation_connection |+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+| s_view | CREATE ALGORITHM=UNDEFINED DEFINER=`root`@`localhost` SQL SECURITY DEFINER VIEW `s_view` AS select `s_view_1`.`sname` AS `sname`,`s_view_1`.`remark` AS `remark` from `s_view_1` | utf8mb4 | utf8mb4_0900_ai_ci |+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+1 row in set (0.00 sec) 4.2、查看视图4.2.1、查看视图结构12格式：desc 视图名; 案例： 查看视图s_view结构 1234567mysql&gt; desc s_view;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| sname | varchar(20) | YES | | NULL | |+-------+-------------+------+-----+---------+-------+1 row in set (0.02 sec) 4.2.2、查看数据库中的视图12格式：show tables [like %字符串%]; 案例： 查看数据库中所有视图 123456789101112131415161718192021222324252627282930mysql&gt; show tables;+--------------------+| Tables_in_zutuanxue |+--------------------+| classes || new_user || s_view || s_view_1 || stu || student || students || t1 || t2 || t3 || t4 || t5 || t6 || teacher || user |+--------------------+15 rows in set (0.00 sec)mysql&gt; show tables like &#x27;%view%&#x27;;+-----------------------------+| Tables_in_zutuanxue (%view%) |+-----------------------------+| s_view || s_view_1 |+-----------------------------+2 rows in set (0.00 sec) 五、视图删除及重命名5.1、视图删除12格式：drop view 视图列表; 案例： 删除视图s_view_1 12345678910mysql&gt; drop view s_view_1;Query OK, 0 rows affected (0.00 sec)mysql&gt; show tables like &#x27;%view%&#x27;;+-----------------------------+| Tables_in_zutuanxue (%view%) |+-----------------------------+| s_view |+-----------------------------+1 row in set (0.00 sec) 5.2、视图重命名12格式：rename table 视图名 to 新视图名; 案例： 修改视图s_view的名字为view_s 12345678910mysql&gt; rename table s_view to view_s;Query OK, 0 rows affected (0.01 sec)mysql&gt; show tables like &#x27;%view%&#x27;;+-----------------------------+| Tables_in_zutuanxue (%view%) |+-----------------------------+| view_s |+-----------------------------+1 row in set (0.01 sec)"},{"path":"/2023/07/11/MySQL数据库实战/MySQL约束/","content":"约束是按照约定（特定）条件限制，管束等意思。约束的作用是添加、删除。 在数据库中对表中的数据进行限制，保证数据的正确性、有效性和完整性。一个表如果添加了约束，不正确的数据将无法插入到表中。约束在创建表的时候添加比较合适。 一、约束概述1.1、什么是约束约束用于限制加入表的数据的类型。 可以在创建表时规定约束（通过 CREATE TABLE 语句），或者在表创建之后也可以（通过 ALTER TABLE 语句）。 1.2、约束作用对表中的数据进行限制，保证数据的正确性、有效性和完整性。一个表如果添加了约束，不正确的数据将无法插入到表中。约束在创建表的时候添加比较合适。 1.3、约束分类主键 primary key 唯一 unique 非空 not null 默认值 default 外键 foreign key 检查约束 check 二、主键约束2.1、主键约束格式123456格式1：字段名 字段类型 primary key #在create table 语句中设置主键格式2：alter table 数据库表名 add primary key(字段名); #在已经创建好的数据库表中增加主键格式3：alter table 数据库表名 drop primary key; #在已经创建好的数据库表中删除主键 注意： 非空 not null 唯一 2.2、主键约束作用是每一条记录的唯一标识，不会重复。 如： image20200210091102251.png 注意： 通常主键，单独给每张表设计一个 id 的字段，把 id 作为主键。 主键是给数据库和程序使用的，不是给最终的客户使用的。所以主键有没有含义没有关系，只要不重复，非空就行。 2.3、主键约束应用创建一个老师表，里面包含了字段名（tid，tname，sex，age），将tid做为主键 123456789101112131415161718192021222324create table teacher( tid int primary key, -- sid为主键 tname varchar(20), sex varchar(2), age int);mysql&gt; create table teacher( tid int primary key, -- sid为主键 tname varchar(20), sex varchar(2), age int);Query OK, 0 rows affected (0.10 秒)mysql&gt; desc teacher;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| tid | int(11) | NO | PRI | NULL | || tname | varchar(20) | YES | | NULL | || sex | varchar(2) | YES | | NULL | || age | int(11) | YES | | NULL | |+-------+-------------+------+-----+---------+-------+4 行于数据集 (0.01 秒) 往老师表中插入记录 12345678910111213141516#插入记录mysql&gt; insert into teacher values(1,&#x27;李小四&#x27;,&#x27;男&#x27;,45);Query OK, 1 rows affected (0.08 秒)#插入相同记录mysql&gt; insert into teacher values(1,&#x27;李小四&#x27;,&#x27;男&#x27;,45);Duplicate entry &#x27;1&#x27; for key &#x27;PRIMARY&#x27;mysql&gt; select * from teacher;+-----+-----------+------+------+| tid | tname | sex | age |+-----+-----------+------+------+| 1 | 李小四 | 男 | 45 |+-----+-----------+------+------+1 行于数据集 (0.01 秒)#插入一条null记录mysql&gt; insert into teacher values(null,&#x27;李小四&#x27;,&#x27;男&#x27;,45);Column &#x27;tid&#x27; cannot be null 去掉老师表中的主键约束 123456789101112mysql&gt; alter table teacher drop primary key;Query OK, 1 rows affected (0.07 秒)mysql&gt; desc teacher;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| tid | int(11) | NO | | NULL | || tname | varchar(20) | YES | | NULL | || sex | varchar(2) | YES | | NULL | || age | int(11) | YES | | NULL | |+-------+-------------+------+-----+---------+-------+4 行于数据集 (0.01 秒) 为老师表添加主键约束 12345678910111213mysql&gt; alter table teacher add primary key(tid);Query OK, 0 rows affected (0.25 秒)mysql&gt; desc teacher;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| tid | int(11) | NO | PRI | NULL | || tname | varchar(20) | YES | | NULL | || sex | varchar(2) | YES | | NULL | || age | int(11) | YES | | NULL | |+-------+-------------+------+-----+---------+-------+4 行于数据集 (0.02 秒) 三、主键自增3.1、主键自增格式在数据库表中，主键一般情况下，我们是用一个id字段来表示，如果让我们自己添加的话要做到不能重复、不能为空就比较麻烦，所以主键我们都是设置为自动增长。 12格式：字段名 字段类型 primary key auto_increment 案例： 创建一个用户表，表里面有用户名和密码 12345create table user( uid int primary key auto_increment, uname varchar(20), pword varchar(20)); 在用户表中插入二条件数据 1234567891011121314mysql&gt; insert into user(uname,pword)values(&#x27;zutuanxue01&#x27;,&#x27;00001&#x27;);Query OK, 1 rows affected (0.06 秒)mysql&gt; insert into user(uname,pword)values(&#x27;zutuanxue02&#x27;,&#x27;00002&#x27;);Query OK, 1 rows affected (0.01 秒)mysql&gt; select * from user;+-----+------------+-------+| uid | uname | pword |+-----+------------+-------+| 1 | zutuanxue01 | 00001 || 2 | zutuanxue02 | 00002 |+-----+------------+-------+2 行于数据集 (0.01 秒) 注意： 设置表字段的自增长后，他的默认起始值从1开始 123456789101112mysql&gt; insert into user values(null,&#x27;zutuanxue03&#x27;,&#x27;00003&#x27;);Query OK, 1 rows affected (0.03 秒)mysql&gt; select * from user;+-----+------------+-------+| uid | uname | pword |+-----+------------+-------+| 1 | zutuanxue01 | 00001 || 2 | zutuanxue02 | 00002 || 3 | zutuanxue03 | 00003 |+-----+------------+-------+3 行于数据集 (0.01 秒) 3.2、修改主键自增起始值3.2.1、创建表后修改12格式：alter table 数据库表名 auto_increment=起始值; 案例： 修改用户表中主键自增长的起始值为100 12345678910111213141516mysql&gt; alter table user auto_increment=100;Query OK, 0 rows affected (0.05 秒)mysql&gt; insert into user values(null,&#x27;zutuanxue04&#x27;,&#x27;00004&#x27;);Query OK, 1 rows affected (0.10 秒)mysql&gt; select * from user;+-----+------------+-------+| uid | uname | pword |+-----+------------+-------+| 1 | zutuanxue01 | 00001 || 2 | zutuanxue02 | 00002 || 3 | zutuanxue03 | 00003 || 100 | zutuanxue04 | 00004 |+-----+------------+-------+4 行于数据集 (0.01 秒) 3.2.2、创建表时修改1234567格式：create table 数据库表名( 字段名1 字段类型 primary key auto_increment, 字段名2 字段类型, ... 字段名n 字段类型,)auto_increment=超始值; 创建一个新用户表，表里面有用户名和密码，并设置起始值为100 12345create table new_user( uid int primary key auto_increment, uname varchar(20), pword varchar(20))auto_increment=100; 在新用户表中插入一条件数据 12345678910mysql&gt; insert into new_user(uname,pword)values(&#x27;zutuanxue01&#x27;,&#x27;00001&#x27;);Query OK, 1 rows affected (0.10 秒)mysql&gt; select * from new_user;+-----+------------+-------+| uid | uname | pword |+-----+------------+-------+| 100 | zutuanxue01 | 00001 |+-----+------------+-------+1 行于数据集 (0.01 秒) 3.3、记录删除后对自增的影响3.3.1、delete删除记录后，对自增长字段没有影响 案例： 删除用户数据库表中的所有记录，在插入1条记录 12345678910111213mysql&gt; delete from user;Query OK, 4 rows affected (0.11 秒)mysql&gt; insert into user values(null,&#x27;zhangsan&#x27;,&#x27;zhangsan&#x27;);Query OK, 1 rows affected (0.05 秒)mysql&gt; select * from user;+-----+----------+----------+| uid | uname | pword |+-----+----------+----------+| 101 | zhangsan | zhangsan |+-----+----------+----------+1 行于数据集 (0.01 秒) 3.3.2、truncate删除记录后，自增长字段重新从1开始 案例： 删除用户数据库表中的所有记录，在插入1条记录 1234567891011121314151617181920212223242526mysql&gt; truncate user;Query OK, 0 rows affected (0.02 秒)mysql&gt; insert into user values(null,&#x27;zhangsan&#x27;,&#x27;zhangsan&#x27;);Query OK, 1 rows affected (0.05 秒)mysql&gt; select * from user;+-----+----------+----------+| uid | uname | pword |+-----+----------+----------+| 1 | zhangsan | zhangsan |+-----+----------+----------+1 行于数据集 (0.01 秒)mysql&gt; truncate new_user;Query OK, 0 rows affected (0.06 秒)mysql&gt; insert into new_user values(null,&#x27;zhangsan&#x27;,&#x27;zhangsan&#x27;);Query OK, 1 rows affected (0.04 秒)mysql&gt; select * from new_user;+-----+----------+----------+| uid | uname | pword |+-----+----------+----------+| 1 | zhangsan | zhangsan |+-----+----------+----------+1 行于数据集 (0.01 秒) 四、唯一约束唯一约束就是：设计表中的某一个字段不能出现重复的记录 4.1、唯一约束格式1字段名 字段类型 unique #在create table 语句中设置唯一约束 4.2、唯一约束应用4.2.1、插入相同记录案例： 创建一个新的表t1，表里包含字段名（id,name） 1234create table t1( id int, name varchar(20) unique -- 姓名唯一，不能出现重复); 往表中插入一条记录 12mysql&gt; insert into t1 values(1,&#x27;zhangsan&#x27;);Query OK, 1 rows affected (0.08 秒) 继续插入同一条件记录 12mysql&gt; insert into t1 values(1,&#x27;zhangsan&#x27;);Duplicate entry &#x27;zhangsan&#x27; for key &#x27;name&#x27; 4.2.1、插入null记录案例： 12345678910111213mysql&gt; insert into t1 values(1,null);Query OK, 1 rows affected (0.02 秒)mysql&gt; insert into t1 values(1,null);Query OK, 1 rows affected (0.05 秒)mysql&gt; select * from t1;+------+----------+| id | name |+------+----------+| 1 | zhangsan || 1 | NULL || 1 | NULL |+------+----------+3 行于数据集 (0.01 秒) 注意： null表示的是没有数据，所有不存在重复的问题 五、非空约束非空约束就是：数据库表中的字段的值，不能为null 5.1、非空约束格式1字段名 字段类型 not null #在create table 语句中设置字段值不能为null 5.2、非空约束应用案例： 创建一个新的表t2，表里包含字段名（id,name） 1234create table t2( id int, name varchar(20) not null -- 姓名的记录不能为null); 往表中插入一条记录 12mysql&gt; insert into t2 values(1,&#x27;lisi&#x27;);Query OK, 1 rows affected (0.10 秒) 往表中插入一条姓名为null的记录 123456789mysql&gt; insert into t2 values(1, null);Column &#x27;name&#x27; cannot be nullmysql&gt; select * from t2;+------+------+| id | name |+------+------+| 1 | lisi |+------+------+1 行于数据集 (0.01 秒) 注意： 字段设置了非空与唯一约束与主键区别？ 主键数在一个表中，只能有一个。自增长只能用在主键上 非空与唯一约束可以设置在N个字段上 六、默认值默认值就是：当我们在增加记录的时候如果不去设置值，那么自动的会用默认值补齐，字段默认的默认值是null 6.1、默认值格式1字段名 字段类型 default 默认值 #在create table 语句中设置字段的默认值，不设置默认值为null 6.2、默认值应用案例： 创建一个新的表t3，表里包含字段名（id,name） 1234create table t3( id int, name varchar(20) default &#x27;lisi&#x27; -- 增加时如果不加入姓名，姓名为‘lisi’); 往表中插入一条记录 12mysql&gt; insert into t3 values(1,&#x27;zhangsan&#x27;);Query OK, 1 rows affected (0.03 秒) 往表中插入一条id为1的记录，其他信息不用增加 方法一： 1234567891011mysql&gt; insert into t3(id) values(1);Query OK, 1 rows affected (0.06 秒)mysql&gt; select * from t3;+------+----------+| id | name |+------+----------+| 1 | zhangsan || 1 | lisi |+------+----------+2 行于数据集 (0.01 秒) 方法二： 123456789101112mysql&gt; insert into t3 values(1,default);Query OK, 1 rows affected (0.09 秒)mysql&gt; select * from t3;+------+----------+| id | name |+------+----------+| 1 | zhangsan || 1 | lisi || 1 | lisi |+------+----------+3 行于数据集 (0.01 秒) 七、外键约束产生7.1、数据冗余数据冗余是指数据之间的重复，也可以说是同一数据存储在不同数据文件中的现象。 7.2、表的数据冗余员工表 image20200213223102058.png 除了数据冗余的问题外，假如我们的研发部搬到了北京，这这时候，我们就要去修改我们的研发部的地点，这样的修改数据的时候也会很麻烦。 问题解决 数据冗余、数据增、删、改？ image20200213224403897.png 7.3、为什么要使用外键约束新的问题？ 假如我们在员工表中增加一条记录 image20200213225528342.png 员工表中的记录dep_id中的3，在部门表中并没有这个id的记录。我们也将这条记录加入了进去。那么我们的员工王六就没有对应的部门了。这种情况在实际的应用中是不允许的。 实际情况： 我们员工表中的dep_id的值，只能是部门表中存在的id。 解决方法： 使用外键约束 7.4、什么是外键约束一张表的一个字段受限于另外一张表的一个字段对应的值。这里涉及到两张表：被引用的表叫主表（父表），另外一张叫从表（子表）。 子表：定义了外键的表，外键的取值要么取父表中字段对应的值，要么取NULL值，严重受限于父表 父表：被引用的字段要具有唯一性（绝大多数都是用的父表的主键） image20200213230844619.png 八、外键约束8.1、外键约束格式12格式一：[constraint][外键约束名称] foreign key(外键字段名) references 主表名称(主键字段名); #在create table时设置 案例： 创建一个班级表： 12345678910111213141516171819create table classes( -- 班级表cid int primary key auto_increment,-- 班级IDcname varchar(20),-- 班级名称 crenshu int(3),-- 班级人数cmajor varchar(10),-- 专业cmark text -- 备注);mysql&gt; desc classes;+---------+-------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+---------+-------------+------+-----+---------+----------------+| cid | int(11) | NO | PRI | NULL | auto_increment || cname | varchar(20) | YES | | NULL | || crenshu | int(3) | YES | | NULL | || cmajor | varchar(10) | YES | | NULL | || cmark | text | YES | | NULL | |+---------+-------------+------+-----+---------+----------------+5 行于数据集 (0.01 秒) 插入班级信息: 12345678910mysql&gt; insert into classes values(null,&#x27;一班&#x27;,60,&#x27;计算机&#x27;,&#x27;学校的王牌专业&#x27;),(null,&#x27;二班&#x27;,50,&#x27;财务会计&#x27;,&#x27;学校最好就业专业&#x27;);Query OK, 2 rows affected (0.06 秒)mysql&gt; select * from classes;+-----+--------+---------+--------------+--------------------------+| cid | cname | crenshu | cmajor | cmark |+-----+--------+---------+--------------+--------------------------+| 3 | 一班 | 60 | 计算机 | 学校的王牌专业 || 4 | 二班 | 50 | 财务会计 | 学校最好就业专业 |+-----+--------+---------+--------------+--------------------------+2 行于数据集 (0.01 秒) 创建一个学生表（与班级表建立主外键关联）： 1234567891011121314151617181920212223242526create table stu -- 学生表(sid int primary key auto_increment, -- 学生IDsname varchar(20),-- 学生姓名ssex varchar(2),-- 性别stell varchar(11),-- 电话号码sdate date ,-- 入学日期srmark varchar(30),-- 备注sclassid int,-- 外键对应主表中的主建 -- 创建外键约束constraint stu_sclassid_fk foreign key (sclassid) references classes(cid));mysql&gt; desc stu;+----------+-------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+----------------+| sid | int(11) | NO | PRI | NULL | auto_increment || sname | varchar(20) | YES | | NULL | || ssex | varchar(2) | YES | | NULL | || stell | varchar(11) | YES | | NULL | || sdate | date | YES | | NULL | || srmark | varchar(30) | YES | | NULL | || sclassid | int(11) | YES | MUL | NULL | |+----------+-------------+------+-----+---------+----------------+7 行于数据集 (0.01 秒) 注意： PRI主键约束； UNI唯一约束； MUL可以重复。 插入学生信息： 123456789101112131415mysql&gt; insert into stu values(null,&#x27;张三&#x27;,&#x27;男&#x27;,&#x27;13111111111&#x27;,&#x27;2019-09-01&#x27;,&#x27;学习成绩不错&#x27;,3);Query OK, 1 rows affected (0.03 秒)mysql&gt; insert into stu values(null,&#x27;李四&#x27;,&#x27;男&#x27;,&#x27;13112211112&#x27;,&#x27;2019-09-01&#x27;,&#x27;学习成绩一般&#x27;,1);Cannot add or update a child row: a foreign key constraint fails (`zutuanxue`.`stu`, CONSTRAINT `stu_sclassid_fk` FOREIGN KEY (`sclassid`) REFERENCES `classes` (`cid`))mysql&gt; select * from stu;+-----+--------+------+-------------+------------+--------------------+----------+| sid | sname | ssex | stell | sdate | srmark | sclassid |+-----+--------+------+-------------+------------+--------------------+----------+| 1 | 张三 | 男 | 13111111111 | 2019-09-01 | 学习成绩不错 | 3 |+-----+--------+------+-------------+------------+--------------------+----------+1 行于数据集 (0.02 秒)格式二：alter table 从表名称 add [constraint][外键约束名称] foreign key(外键字段名) references 主表名称(主键字段名); #建好表后修改 案例： 创建一个学生表： 123456789101112131415161718192021222324create table stu1 -- 学生表(sid int primary key auto_increment, -- 学生IDsname varchar(20),-- 学生姓名ssex varchar(2),-- 性别stell varchar(11),-- 电话号码sdate date ,-- 入学日期srmark varchar(30),-- 备注sclassid int -- 外键对应主表中的主建 );mysql&gt; desc stu1;+----------+-------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+----------------+| sid | int(11) | NO | PRI | NULL | auto_increment || sname | varchar(20) | YES | | NULL | || ssex | varchar(2) | YES | | NULL | || stell | varchar(11) | YES | | NULL | || sdate | date | YES | | NULL | || srmark | varchar(30) | YES | | NULL | || sclassid | int(11) | YES | | NULL | |+----------+-------------+------+-----+---------+----------------+7 行于数据集 (0.02 秒) 为我们的学生表stu1加入我们的外键约束 1234567891011121314151617mysql&gt; alter table stu1 add constraint stu_sclassid_fk1foreign key (sclassid) references classes(cid);Query OK, 0 rows affected (0.05 秒)mysql&gt; desc stu1;+----------+-------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+----------------+| sid | int(11) | NO | PRI | NULL | auto_increment || sname | varchar(20) | YES | | NULL | || ssex | varchar(2) | YES | | NULL | || stell | varchar(11) | YES | | NULL | || sdate | date | YES | | NULL | || srmark | varchar(30) | YES | | NULL | || sclassid | int(11) | YES | MUL | NULL | |+----------+-------------+------+-----+---------+----------------+7 行于数据集 (0.02 秒) 插入学生信息： 12345678910111213mysql&gt; insert into stu1 values(null,&#x27;张三&#x27;,&#x27;男&#x27;,&#x27;13111111111&#x27;,&#x27;2019-09-01&#x27;,&#x27;学习成绩不错&#x27;,3);Query OK, 1 rows affected (0.07 秒)mysql&gt; insert into stu1 values(null,&#x27;李四&#x27;,&#x27;男&#x27;,&#x27;13112211112&#x27;,&#x27;2019-09-01&#x27;,&#x27;学习成绩一般&#x27;,1);Cannot add or update a child row: a foreign key constraint fails (`zutuanxue`.`stu1`, CONSTRAINT `stu_sclassid_fk1` FOREIGN KEY (`sclassid`) REFERENCES `classes` (`cid`))mysql&gt; select * from stu1;+-----+--------+------+-------------+------------+--------------------+----------+| sid | sname | ssex | stell | sdate | srmark | sclassid |+-----+--------+------+-------------+------------+--------------------+----------+| 1 | 张三 | 男 | 13111111111 | 2019-09-01 | 学习成绩不错 | 3 |+-----+--------+------+-------------+------------+--------------------+----------+1 行于数据集 (0.01 秒) 8.2、删除外键约束12格式：alter table 从表 drop foreign key 外键约束名称; 案例： 删除stu1中的外表关联 12345678910111213141516mysql&gt; alter table stu1 drop foreign key stu_sclassid_fk1;Query OK, 0 rows affected (0.05 秒)mysql&gt; desc stu1;+----------+-------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+----------------+| sid | int(11) | NO | PRI | NULL | auto_increment || sname | varchar(20) | YES | | NULL | || ssex | varchar(2) | YES | | NULL | || stell | varchar(11) | YES | | NULL | || sdate | date | YES | | NULL | || srmark | varchar(30) | YES | | NULL | || sclassid | int(11) | YES | MUL | NULL | |+----------+-------------+------+-----+---------+----------------+7 行于数据集 (0.02 秒) 插入数据 1234567891011mysql&gt; insert into stu1 values(null,&#x27;李四&#x27;,&#x27;男&#x27;,&#x27;13112211112&#x27;,&#x27;2019-09-01&#x27;,&#x27;学习成绩一般&#x27;,1);Query OK, 1 rows affected (0.04 秒)mysql&gt; select * from stu1;+-----+--------+------+-------------+------------+--------------------+----------+| sid | sname | ssex | stell | sdate | srmark | sclassid |+-----+--------+------+-------------+------------+--------------------+----------+| 1 | 张三 | 男 | 13111111111 | 2019-09-01 | 学习成绩不错 | 3 || 3 | 李四 | 男 | 13112211112 | 2019-09-01 | 学习成绩一般 | 1 |+-----+--------+------+-------------+------------+--------------------+----------+2 行于数据集 (0.01 秒) 九、级联操作9.1、为什么要级联当我们的主表班级表中的cid发生变化时，我们应该如何去改变我们的从表学生表中的sclassid？这个时候我们就需要级联。 123456mysql&gt; delete from classes;Cannot delete or update a parent row: a foreign key constraint fails (`zutuanxue`.`stu`, CONSTRAINT `stu_sclassid_fk` FOREIGN KEY (`sclassid`) REFERENCES `classes` (`cid`))mysql&gt; delete from classes where cid=3;Cannot delete or update a parent row: a foreign key constraint fails (`zutuanxue`.`stu`, CONSTRAINT `stu_sclassid_fk` FOREIGN KEY (`sclassid`) REFERENCES `classes` (`cid`))mysql&gt; update classes set cid=1 where cid=3;Cannot delete or update a parent row: a foreign key constraint fails (`zutuanxue`.`stu`, CONSTRAINT `stu_sclassid_fk` FOREIGN KEY (`sclassid`) REFERENCES `classes` (`cid`)) 9.2、级联是什么在修改和删除主表的主键时，同时更新或删除副表的外键值，称为级联操作。 级联操作分为二种：级联更新、级联删除 9.2、级联操作方式123格式：on update cascade #级联更新on delete cascade #级联操作 只能是创建表的时候创建级联关系。更新主表中的主键，从表中的外键列也自动同步更新 案例： 创建一个学生表（与班级表建立主外键关联，并加入级联操作） 123456789101112create table stu -- 学生表(sid int primary key auto_increment, -- 学生IDsname varchar(20),-- 学生姓名ssex varchar(2),-- 性别stell varchar(11),-- 电话号码sdate date ,-- 入学日期srmark varchar(30),-- 备注sclassid int,-- 外键对应主表中的主建 -- 创建外键约束constraint stu_sclassid_fk foreign key (sclassid) references classes(cid) on update cascade on delete cascade); 在学生表中插入数据 1234567891011121314mysql&gt; insert into stu values(null,&#x27;张三&#x27;,&#x27;男&#x27;,&#x27;13111111111&#x27;,&#x27;2019-09-01&#x27;,&#x27;学习成绩不错&#x27;,3);Query OK, 1 rows affected (0.11 秒)mysql&gt; insert into stu values(null,&#x27;李四&#x27;,&#x27;男&#x27;,&#x27;13112211112&#x27;,&#x27;2019-09-01&#x27;,&#x27;学习成绩一般&#x27;,4);Query OK, 1 rows affected (0.08 秒)mysql&gt; select * from stu;+-----+--------+------+-------------+------------+--------------------+----------+| sid | sname | ssex | stell | sdate | srmark | sclassid |+-----+--------+------+-------------+------------+--------------------+----------+| 1 | 张三 | 男 | 13111111111 | 2019-09-01 | 学习成绩不错 | 3 || 2 | 李四 | 男 | 13112211112 | 2019-09-01 | 学习成绩一般 | 4 |+-----+--------+------+-------------+------------+--------------------+----------+2 行于数据集 (0.01 秒) 修改我们班级表中的主键 1234567891011121314151617181920212223242526272829mysql&gt; select * from classes;+-----+--------+---------+--------------+--------------------------+| cid | cname | crenshu | cmajor | cmark |+-----+--------+---------+--------------+--------------------------+| 3 | 一班 | 60 | 计算机 | 学校的王牌专业 || 4 | 二班 | 50 | 财务会计 | 学校最好就业专业 |+-----+--------+---------+--------------+--------------------------+2 行于数据集 (0.01 秒)mysql&gt; update classes set cid=1 where cid=3;Query OK, 1 rows affected (0.06 秒)mysql&gt; select * from classes;+-----+--------+---------+--------------+--------------------------+| cid | cname | crenshu | cmajor | cmark |+-----+--------+---------+--------------+--------------------------+| 1 | 一班 | 60 | 计算机 | 学校的王牌专业 || 4 | 二班 | 50 | 财务会计 | 学校最好就业专业 |+-----+--------+---------+--------------+--------------------------+2 行于数据集 (0.01 秒)mysql&gt; select * from stu;+-----+--------+------+-------------+------------+--------------------+----------+| sid | sname | ssex | stell | sdate | srmark | sclassid |+-----+--------+------+-------------+------------+--------------------+----------+| 1 | 张三 | 男 | 13111111111 | 2019-09-01 | 学习成绩不错 | 1 || 2 | 李四 | 男 | 13112211112 | 2019-09-01 | 学习成绩一般 | 4 |+-----+--------+------+-------------+------------+--------------------+----------+2 行于数据集 (0.01 秒) 删除我们班级表中的主键 123456789101112131415161718mysql&gt; delete from classes where cid=4;Query OK, 1 rows affected (0.01 秒)mysql&gt; select * from classes;+-----+--------+---------+-----------+-----------------------+| cid | cname | crenshu | cmajor | cmark |+-----+--------+---------+-----------+-----------------------+| 1 | 一班 | 60 | 计算机 | 学校的王牌专业 |+-----+--------+---------+-----------+-----------------------+1 行于数据集 (0.01 秒)mysql&gt; select * from stu;+-----+--------+------+-------------+------------+--------------------+----------+| sid | sname | ssex | stell | sdate | srmark | sclassid |+-----+--------+------+-------------+------------+--------------------+----------+| 1 | 张三 | 男 | 13111111111 | 2019-09-01 | 学习成绩不错 | 1 |+-----+--------+------+-------------+------------+--------------------+----------+1 行于数据集 (0.01 秒) 十、检查约束10.1、什么是检查约束检查约束指定某列中的值必须满足布尔表达式，根据用户自己的需求来进行限制。 10.2、检查约束使用10.2.1、行级添加1234567格式：create table 表名( check (字段名1 != 字段名1), 字段名1 字段类型 check (表达式), 字段名2 字段类型 constraint 唯一约束名 check (表达式) [not enforced]); 注意： 表达式中可以包含该字段名: 字段名 &gt; 0表达式注意事项1.允许使用文字，内置函数和运算符2.不允许在使用了auto_increment的列上使用3.不允许存储函数和用户定义的函数4.不允许子查询等如果省略或指定为enforced，则创建并强制执行约束。如果指定为not enforced，则创建约束但不强制执行。 案例： 创建一个表t4 123456create table t4( id int primary key auto_increment, username varchar(32), phone varchar(11) check(length(phone) =11)); 插入数据 12345mysql&gt; insert into t4 values(null,&#x27;zhangsan&#x27;,&#x27;13812221222&#x27;);Query OK, 1 rows affected (0.01 秒)mysql&gt; insert into t4 values(null,&#x27;zhangsan&#x27;,&#x27;1381222125&#x27;);Check constraint &#x27;t4_chk_1&#x27; is violated. 10.2.2、表级添加1234567格式：create table 表名( 字段名1 字段类型, 字段名2 字段类型, [constraint 检查约束名] check(布尔表达式) [ not enforced]); 案例： 创建一个表t5 1234567create table t5( id int primary key auto_increment, username varchar(32), phone varchar(11), constraint t5_check_phone check(length(phone) =11)); 插入数据 12345mysql&gt; insert into t5 values(null,&#x27;zhangsan&#x27;,&#x27;13812222222&#x27;);Query OK, 1 rows affected (0.01 秒)mysql&gt; insert into t5 values(null,&#x27;zhangsan&#x27;,&#x27;1381222222&#x27;);Check constraint &#x27;t4_check_phone&#x27; is violated. 10.2.3、表后添加12格式：alter table 数据库表名 add constraint 检查约束名 check(检查约束); 案例： 创建一个表t6 123456789create table t6( id int primary key auto_increment, username varchar(32), phone varchar(11));mysql&gt; alter table t6 add constraint t6_check_phone check(length(phone)=11);Query OK, 0 rows affected (0.09 秒) 插入数据 12345mysql&gt; insert into t6 values(null,&#x27;zhangsan&#x27;,&#x27;13812221222&#x27;);Query OK, 1 rows affected (0.01 秒)mysql&gt; insert into t6 values(null,&#x27;zhangsan&#x27;,&#x27;1381222125&#x27;);Check constraint &#x27;t6_check_phone&#x27; is violated. 10.2.4、约束删除12格式：alter table 数据库表名 drop check 检查约束名; 案例： 删除t6表中的检查约束t6_check_phone 12mysql&gt; alter table t6 drop check t6_check_phone;Query OK, 0 rows affected (0.02 秒) 插入数据 12mysql&gt; insert into t6 values(null,&#x27;zhangsan&#x27;,&#x27;1381222125&#x27;);Query OK, 1 rows affected (0.01 秒)"},{"path":"/2023/07/11/MySQL数据库实战/MySQL数据备份与还原/","content":"MySQL 数据库管理系统通常会采用有效的措施来维护数据库的可靠性和完整性。但是在数据库的实际使用过程当中，仍存在着一些不可预估的因素，会造成数据库运行事务的异常中断，从而影响数据的正确性，甚至会破坏数据库，导致数据库中的数据部分或全部丢失。 数据库系统提供了备份和恢复策略来保证数据库中数据的可靠性和完整性。 一、mysqldump备份1.1、数据库备份数据库备份是指通过导出数据或者复制表文件的方式来制作数据库的副本。当数据库出现故障或遭到破坏时，将备份的数据库加载到系统，从而使数据库从错误状态恢复到备份时的正确状态。 1.2、备份&#x2F;还原格式1.2.1、备份备份整个数据库 123格式：mysqldump -u用户名 -p密码 数据库名 &gt; sql文件位置[root@localhost mysql]# ./bin/mysqldump -uroot -p zutuanxue &gt; /usr/local/mysql/data/zutuanxue.sql 备份数据库中的某个表 123格式：mysqldump -u用户名 -p密码 数据库名 数据库表名1 数据库表名2&gt; sql文件位置[root@localhost mysql]# ./bin/mysqldump -uroot -p zutuanxue t5 t6 &gt; ./data/1.sql 备份多个数据库 123格式：mysqldump -u用户名 -p密码 --databases 数据库名1 数据库名2&gt; sql文件位置[root@localhost mysql]# ./bin/mysqldump -uroot -p --databases a zutuanxue &gt; ./data/2.sql 备份系统中所有数据库 123格式：mysqldump -u用户名 -p密码 --all-databases &gt; sql文件位置[root@localhost mysql]# ./bin/mysqldump -uroot -p --all-databases &gt; ./data/1.sql 1.2.2、还原登录mysql数据库后 123456格式：source 导入文件的路径;mysql&gt; use zutuanxue;Database changedmysql&gt; source /usr/local/mysql/data/zutuanxue.sql 二、图形化的备份与还原2.1、备份打开数据库-&gt;右击要备份的数据库 image20200216142554960.png 选择“结构和数据”或者“结构”，跳出存储路径，存储一个sql文件 image20200216142651361.png 点击“保存”，跳出进度窗口 image20200216142820725.png 2.2、还原打开要还原的数据库，右击“数据库” image20200216143025810.png 选择“运行SQL文件” image20200216143109143.png 选择sql“文件”所在的位置，点击“开始” image20200216143212105.png 运行完成后点击关闭，查看数据库下是否有表 image20200216143324447.png"},{"path":"/2023/07/11/MySQL数据库实战/MySQL常用函数/","content":"MySQL函数，是一种控制流程函数，属于数据库用语言。 MySQL数据库中提供了很丰富的函数。MySQL函数包括数学函数、字符串函数、日期和时间函数、条件判断函数、系统信息函数、加密函数、格式化函数等。通过这些函数，可以简化用户的操作。 一、数学函数1.1、函数概述MySQL函数是MySQL数据库提供的内部函数。这些内部函数可以帮助用户更加方便的处理表中的数据。 1.2、数学函数概述数学函数是MySQL中常用的一类函数。主要用于处理数字，包括整型、浮点数等。 1.3、常用数学函数1.3.1、abs()abs(X):返回X的绝对值 1234567mysql&gt; select abs(-32);+----------+| abs(-32) |+----------+| 32 |+----------+1 行于数据集 (0.03 秒) 1.3.2、mod()MOD(N,M)或%:返回N被M除的余数。 123456789101112131415mysql&gt; select mod(15,7);+-----------+| mod(15,7) |+-----------+| 1 |+-----------+1 行于数据集 (0.02 秒)mysql&gt; select 15%7;+------+| 15%7 |+------+| 1 |+------+1 行于数据集 (0.02 秒) 1.3.3、ceiling()CEILING(X):返回不小于X的最小整数值。 123456789101112131415mysql&gt; select ceiling(1.23);+---------------+| ceiling(1.23) |+---------------+| 2 |+---------------+1 行于数据集 (0.02 秒)mysql&gt; select ceiling(-1.23);+----------------+| ceiling(-1.23) |+----------------+| -1 |+----------------+1 行于数据集 (0.02 秒) 1.3.4、round()ROUND(X) :返回参数X的四舍五入的一个整数。 123456789101112131415mysql&gt; select round(3.58);+-------------+| round(3.58) |+-------------+| 4 |+-------------+1 行于数据集 (0.02 秒)mysql&gt; select round(-3.58);+--------------+| round(-3.58) |+--------------+| -4 |+--------------+1 行于数据集 (0.01 秒) 1.3.5、pi()PI()：返回圆周率π，默认显示6位小数 1234567mysql&gt; select pi();+----------+| pi() |+----------+| 3.141593 |+----------+1 行于数据集 (0.03 秒) 1.2.6、sqrt()SQRT(x)：返回非负数的x的二次方根 1234567mysql&gt; select sqrt(16);+----------+| sqrt(16) |+----------+| 4 |+----------+1 行于数据集 (0.03 秒) 1.3.7、ceil()CEIL(x)：返回不小于x的最小整数 123456789101112131415mysql&gt; select ceil(1.3);+-----------+| ceil(1.3) |+-----------+| 2 |+-----------+1 行于数据集 (0.01 秒)mysql&gt; select ceil(-1.3);+---------------+| ceiling(-1.3) |+---------------+| -1 |+---------------+1 行于数据集 (0.01 秒) 1.3.8、floor()FLOOR(x)：返回不大于x的最大整数 123456789101112131415mysql&gt; select floor(1.3);+------------+| floor(1.3) |+------------+| 1 |+------------+1 行于数据集 (0.01 秒)mysql&gt; select floor(-1.3);+-------------+| floor(-1.3) |+-------------+| -2 |+-------------+1 行于数据集 (0.01 秒) 1.3.9、round()ROUND(x)、ROUND(x,y) 前者返回最接近于x的整数，即对x进行四舍五入；后者返回最接近x的数，其值保留到小数点后面y位，若y为负值，则将保留到x到小数点左边y位 123456789101112131415mysql&gt; select round(1.3555);+---------------+| round(1.3555) |+---------------+| 1 |+---------------+1 行于数据集 (0.01 秒)mysql&gt; select round(1.3555,2);+-----------------+| round(1.3555,2) |+-----------------+| 1.36 |+-----------------+1 行于数据集 (0.02 秒) 1.3.10、sign()SIGN(x):返回参数x的符号，-1表示负数，0表示0，1表示正数 1234567891011121314151617181920212223mysql&gt; select sign(5);+---------+| sign(5) |+---------+| 1 |+---------+1 行于数据集 (0.02 秒)mysql&gt; select sign(-5);+----------+| sign(-5) |+----------+| -1 |+----------+1 行于数据集 (0.02 秒)mysql&gt; select sign(0);+---------+| sign(0) |+---------+| 0 |+---------+1 行于数据集 (0.02 秒) 1.3.11、pow(x,y)POW(x,y)和、POWER(x,y):返回x的y次乘方的值 123456789101112131415mysql&gt; select pow(2,4);+----------+| pow(2,4) |+----------+| 16 |+----------+1 行于数据集 (0.01 秒)mysql&gt; select power(3,3);+------------+| power(3,3) |+------------+| 27 |+------------+1 行于数据集 (0.02 秒) 1.3.12、rand()RAND()：随机函数，返回0-1内的随机数 123456789101112131415mysql&gt; select rand();+---------------------+| rand() |+---------------------+| 0.30107216378773766 |+---------------------+1 行于数据集 (0.03 秒)mysql&gt; select rand();+---------------------+| rand() |+---------------------+| 0.37762552907469266 |+---------------------+1 行于数据集 (0.01 秒) 1.3.13、truncate()TRUNCATE(x,Y):数值截取，返回数值x截取y位小数的结果（不四舍五入） 123456789101112131415mysql&gt; select truncate(3.1415926,2);+-----------------------+| truncate(3.1415926,2) |+-----------------------+| 3.14 |+-----------------------+1 行于数据集 (0.01 秒)mysql&gt; select truncate(3.1415926,4);+-----------------------+| truncate(3.1415926,4) |+-----------------------+| 3.1415 |+-----------------------+1 行于数据集 (0.01 秒) 二、字符串函数2.1、字符串函数概述字符串函数是MySQL中常用的一类函数。主要用于处理字符串。 2.2、常用字符串函数2.2.1、ascii()ASCII(str):返回字符串str的最左面字符的ASCII代码值。如果str是空字符串，返回0。如果str是NULL，返回NULL。 12345678910111213141516171819202122232425262728293031mysql&gt; select ascii(&#x27;2&#x27;);+------------+| ascii(&#x27;2&#x27;) |+------------+| 50 |+------------+1 行于数据集 (0.01 秒)mysql&gt; select ascii(2);+----------+| ascii(2) |+----------+| 50 |+----------+1 行于数据集 (0.01 秒)mysql&gt; select ascii(&#x27;Ax&#x27;);+-------------+| ascii(&#x27;Ax&#x27;) |+-------------+| 65 |+-------------+1 行于数据集 (0.02 秒)mysql&gt; select ascii(&#x27;ax&#x27;);+-------------+| ascii(&#x27;ax&#x27;) |+-------------+| 97 |+-------------+1 行于数据集 (0.02 秒) 2.2.2、concat()CONCAT(str1,str2,…):返回来自于参数连结的字符串。如果任何参数是NULL，返回NULL。可以有超过2个的参数。一个数字参数被变换为等价的字符串形式。 1234567891011121314151617181920212223mysql&gt; select concat(&#x27;hello&#x27;,&#x27;world&#x27;,&#x27;!&#x27;);+-----------------------------+| concat(&#x27;hello&#x27;,&#x27;world&#x27;,&#x27;!&#x27;) |+-----------------------------+| helloworld! |+-----------------------------+1 行于数据集 (0.02 秒)mysql&gt; select concat(&#x27;hello&#x27;,null,&#x27;world&#x27;);+------------------------------+| concat(&#x27;hello&#x27;,null,&#x27;world&#x27;) |+------------------------------+| NULL |+------------------------------+1 行于数据集 (0.04 秒)mysql&gt; select concat(12,21);+---------------+| concat(12,21) |+---------------+| 1221 |+---------------+1 行于数据集 (0.02 秒) 2.2.3、length()LENGTH(str):获取字符串字节长度（返回字节数，要注意字符集） 123456789101112131415mysql&gt; select length(&#x27;hello world&#x27;);+-----------------------+| length(&#x27;hello world&#x27;) |+-----------------------+| 11 |+-----------------------+1 行于数据集 (0.02 秒)mysql&gt; select length(&#x27;你好&#x27;);+--------------+| length(&#x27;你好&#x27;) |+--------------+| 6 |+--------------+1 行于数据集 (0.02 秒) 注意： 一个汉字是算三个字节，一个数字或字母算一个字节 2.2.4、locate()LOCATE(substr,str):返回子串substr在字符串str第一个出现的位置，如果substr不是在str里面，返回0. 123456789101112131415mysql&gt; select locate(&#x27;wo&#x27;,&#x27;hello world&#x27;);+----------------------------+| locate(&#x27;wo&#x27;,&#x27;hello world&#x27;) |+----------------------------+| 7 |+----------------------------+1 行于数据集 (0.04 秒)mysql&gt; select locate(&#x27;wob&#x27;,&#x27;hello world&#x27;);+-----------------------------+| locate(&#x27;wob&#x27;,&#x27;hello world&#x27;) |+-----------------------------+| 0 |+-----------------------------+1 行于数据集 (0.02 秒) 2.2.5、instr()INSTR(str,substr):返回子串substr在字符串str中的第一个出现的位置。 123456789101112131415mysql&gt; select instr(&#x27;hello world&#x27;,&#x27;o&#x27;);+--------------------------+| instr(&#x27;hello world&#x27;,&#x27;o&#x27;) |+--------------------------+| 5 |+--------------------------+1 行于数据集 (0.01 秒)mysql&gt; select instr(&#x27;hello world&#x27;,&#x27;ob&#x27;);+---------------------------+| instr(&#x27;hello world&#x27;,&#x27;ob&#x27;) |+---------------------------+| 0 |+---------------------------+1 行于数据集 (0.01 秒) 2.2.6、left()LEFT(str,len):返回字符串str的最左面len个字符。 1234567mysql&gt; select left(&#x27;hello world&#x27;,5);+-----------------------+| left(&#x27;hello world&#x27;,5) |+-----------------------+| hello |+-----------------------+1 行于数据集 (0.01 秒) 2.2.7、right()RIGHT(str,len):返回字符串str的最右面len个字符。 1234567mysql&gt; select right(&#x27;hello world&#x27;,5);+------------------------+| right(&#x27;hello world&#x27;,5) |+------------------------+| world |+------------------------+1 行于数据集 (0.01 秒) 2.2.8、substring()SUBSTRING(str,pos):从字符串str的起始位置pos返回一个子串。 12345678910111213141516171819202122232425262728293031323334353637mysql&gt; select substring(&#x27;hello world&#x27;,5);+----------------------------+| substring(&#x27;hello world&#x27;,5) |+----------------------------+| o world |+----------------------------+1 行于数据集 (0.01 秒)mysql&gt; select substring(&#x27;hello world&#x27;,2,6);+------------------------------+| substring(&#x27;hello world&#x27;,2,6) |+------------------------------+| ello w |+------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select substring(&#x27;hello world&#x27; from 7);+---------------------------------+| substring(&#x27;hello world&#x27; from 7) |+---------------------------------+| world |+---------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select substring(&#x27;hello world&#x27; from 7 for 2);+---------------------------------------+| substring(&#x27;hello world&#x27; from 7 for 2) |+---------------------------------------+| wo |+---------------------------------------+mysql&gt; select substring(&#x27;hello world&#x27; from -3 for 2);+----------------------------------------+| substring(&#x27;hello world&#x27; from -3 for 2) |+----------------------------------------+| rl |+----------------------------------------+1 行于数据集 (0.01 秒) 2.2.9、trim()TRIM(str):返回字符串str，所有前缀或后缀被删除了。 1234567mysql&gt; select trim(&#x27; hello world &#x27;);+-------------------------+| trim(&#x27; hello world &#x27;) |+-------------------------+| hello world |+-------------------------+1 行于数据集 (0.01 秒) 2.2.10、ltrim()&#x2F;rtrim()LTRIM(str):返回删除了其前置空格字符的字符串str。 RTRIM(str):返回删除了其拖后空格字符的字符串str。 123456789101112131415mysql&gt; select ltrim(&#x27; hello world &#x27;);+--------------------------+| ltrim(&#x27; hello world &#x27;) |+--------------------------+| hello world |+--------------------------+1 行于数据集 (0.01 秒)mysql&gt; select rtrim(&#x27; hello world &#x27;);+--------------------------+| rtrim(&#x27; hello world &#x27;) |+--------------------------+| hello world |+--------------------------+1 行于数据集 (0.01 秒) 2.2.11、replace()REPLACE(str,from_str,to_str):返回字符串str，其字符串from_str的所有出现由字符串to_str代替。 1234567mysql&gt; select replace(&#x27;hello world&#x27;,&#x27;o&#x27;,&#x27;O&#x27;);+--------------------------------+| replace(&#x27;hello world&#x27;,&#x27;o&#x27;,&#x27;O&#x27;) |+--------------------------------+| hellO wOrld |+--------------------------------+1 行于数据集 (0.01 秒) 2.3、常用字符串函数2.3.1、repeat()REPEAT(str,count):返回由重复count次的字符串str组成的一个字符串。如果count &lt;&#x3D; 0，返回一个空字符串。如果str或count是NULL，返回NULL。 123456789101112131415mysql&gt; select repeat(&#x27;hello&#x27;,3);+-------------------+| repeat(&#x27;hello&#x27;,3) |+-------------------+| hellohellohello |+-------------------+1 行于数据集 (0.01 秒)mysql&gt; select repeat(&#x27;hello&#x27;,0);+-------------------+| repeat(&#x27;hello&#x27;,0) |+-------------------+| |+-------------------+1 行于数据集 (0.01 秒) 2.3.2、reverse()REVERSE(str):返回颠倒字符顺序的字符串str。 1234567mysql&gt; select reverse(&#x27;hello world!&#x27;);+-------------------------+| reverse(&#x27;hello world!&#x27;) |+-------------------------+| !dlrow olleh |+-------------------------+1 行于数据集 (0.02 秒) 2.3.3、insert()INSERT(str,pos,len,newstr):返回字符串str，在位置pos起始的子串且len个字符长的子串由字符串newstr代替。 1234567mysql&gt; select insert(&#x27;hello world!&#x27;,5,3,&#x27;is&#x27;);+---------------------------------+| insert(&#x27;hello world!&#x27;,5,3,&#x27;is&#x27;) |+---------------------------------+| hellisorld! |+---------------------------------+1 行于数据集 (0.02 秒) 2.3.4、elt()ETL(index,str1,str2,str3…):返回指定index位置的字符串 123456789101112131415mysql&gt; select elt(2,&#x27;hello&#x27;,&#x27;world&#x27;,&#x27;!&#x27;);+----------------------------+| elt(2,&#x27;hello&#x27;,&#x27;world&#x27;,&#x27;!&#x27;) |+----------------------------+| world |+----------------------------+1 行于数据集 (0.01 秒)mysql&gt; select elt(4,&#x27;hello&#x27;,&#x27;world&#x27;,&#x27;!&#x27;);+----------------------------+| elt(4,&#x27;hello&#x27;,&#x27;world&#x27;,&#x27;!&#x27;) |+----------------------------+| NULL |+----------------------------+1 行于数据集 (0.01 秒) 2.3.5、upper()UPPER(x)或UCASE(x):用于将字母转成大写，x可以是单个字母也可以是字符串； 123456789101112131415mysql&gt; select upper(&#x27;abcdfe&#x27;);+-----------------+| upper(&#x27;abcdfe&#x27;) |+-----------------+| ABCDFE |+-----------------+1 行于数据集 (0.01 秒)mysql&gt; select ucase(&#x27;abcdfe&#x27;);+-----------------+| ucase(&#x27;abcdfe&#x27;) |+-----------------+| ABCDFE |+-----------------+1 行于数据集 (0.01 秒) 2.3.6、lower()LOWER(x)或LCASE(x):用于将字母转成小写，x可以是单个字母也可以是字符串； 123456789101112131415mysql&gt; select lower(&#x27;ABCDEF&#x27;);+-----------------+| lower(&#x27;ABCDEF&#x27;) |+-----------------+| abcdef |+-----------------+1 行于数据集 (0.01 秒)mysql&gt; select lcase(&#x27;ABCDEF&#x27;);+-----------------+| lcase(&#x27;ABCDEF&#x27;) |+-----------------+| abcdef |+-----------------+1 行于数据集 (0.01 秒) 2.3.7、char_length()CHAR_LENGTH():获取字符串字符数，获取字符串长度 123456789101112131415mysql&gt; select char_length(&#x27;hello world&#x27;);+----------------------------+| char_length(&#x27;hello world&#x27;) |+----------------------------+| 11 |+----------------------------+1 行于数据集 (0.01 秒)mysql&gt; select char_length(&#x27;你好&#x27;);+-------------------+| char_length(&#x27;你好&#x27;) |+-------------------+| 2 |+-------------------+1 行于数据集 (0.01 秒) 注意： 不管汉字还是数字或者是字母都算是一个字符 2.3.8、strcmp()STRCMP(str1,str2):比较两个字符串的大小。左边大于右边时返回1，左边等于右边时返回0，，左小于于右时返回-1。 1234567891011121314151617181920212223mysql&gt; select strcmp(&#x27;a&#x27;,&#x27;b&#x27;);+-----------------+| strcmp(&#x27;a&#x27;,&#x27;b&#x27;) |+-----------------+| -1 |+-----------------+1 行于数据集 (0.01 秒)mysql&gt; select strcmp(&#x27;d&#x27;,&#x27;b&#x27;);+-----------------+| strcmp(&#x27;d&#x27;,&#x27;b&#x27;) |+-----------------+| 1 |+-----------------+1 行于数据集 (0.01 秒)mysql&gt; select strcmp(&#x27;b&#x27;,&#x27;b&#x27;);+-----------------+| strcmp(&#x27;b&#x27;,&#x27;b&#x27;) |+-----------------+| 0 |+-----------------+1 行于数据集 (0.01 秒) 2.3.9、field()FIELD(str,str1,str2,str3…):与find_in_set类似，返回str在str1,str2,str3…中的位置。 123456789101112131415mysql&gt; select field(&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;a&#x27;,&#x27;e&#x27;);+--------------------------------+| field(&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;a&#x27;,&#x27;e&#x27;) |+--------------------------------+| 4 |+--------------------------------+1 行于数据集 (0.02 秒)mysql&gt; select find_in_set(&#x27;a&#x27;,&#x27;b,c,d,a,e&#x27;);+------------------------------+| find_in_set(&#x27;a&#x27;,&#x27;b,c,d,a,e&#x27;) |+------------------------------+| 4 |+------------------------------+1 行于数据集 (0.02 秒) 2.3.10、position()POSITION(str1 IN str2):返回子串str1在字符串str2中的位置 1234567mysql&gt; select position(&#x27;ld&#x27; in &#x27;helloworld&#x27;);+--------------------------------+| position(&#x27;ld&#x27; in &#x27;helloworld&#x27;) |+--------------------------------+| 9 |+--------------------------------+1 行于数据集 (0.01 秒) 2.3.11、locate()LOCATE(str1,str,pos):函数返回字符串str1在str中的第pos位置后第一次出现的位置。如果str1在str中不存在，返回0。 123456789101112131415mysql&gt; select locate(&#x27;hel&#x27;,&#x27;hello world&#x27;,1);+-------------------------------+| locate(&#x27;hel&#x27;,&#x27;hello world&#x27;,1) |+-------------------------------+| 1 |+-------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select locate(&#x27;hel&#x27;,&#x27;hello world&#x27;,2);+-------------------------------+| locate(&#x27;hel&#x27;,&#x27;hello world&#x27;,2) |+-------------------------------+| 0 |+-------------------------------+1 行于数据集 (0.01 秒) 2.3.12、substring_index()SUBSTRING_INDEX(str,delim,count):在定界符delim及count出现前，从字符串str返回自字符串。若count为正值,则返回最终定界符(从左边开始) ，若为-1则是从后往前截取； 123456789101112131415mysql&gt; select substring_index(&#x27;hello/world/!&#x27;,&#x27;/&#x27;,-1);+-----------------------------------------+| substring_index(&#x27;hello/world/!&#x27;,&#x27;/&#x27;,-1) |+-----------------------------------------+| ! |+-----------------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select substring_index(&#x27;hello/world/!&#x27;,&#x27;/&#x27;,1);+----------------------------------------+| substring_index(&#x27;hello/world/!&#x27;,&#x27;/&#x27;,1) |+----------------------------------------+| hello |+----------------------------------------+1 行于数据集 (0.01 秒) 三、日期和时间函数3.1、日期和时间函数概述日期和时间函数是MySQL中常用的一类函数。主要用于处理日期时间。 3.2、常用日期和时间函数3.2.1、curdate()CURDATE()或CURRENT_DATE():返回当前日期 123456789101112131415mysql&gt; select curdate();+------------+| curdate() |+------------+| 2020-02-17 |+------------+1 行于数据集 (0.01 秒)mysql&gt; select current_date();+----------------+| current_date() |+----------------+| 2020-02-17 |+----------------+1 行于数据集 (0.01 秒) 3.2.2、curtime()CURTIME()或CURRENT_TIME()：返回当前时间 123456789101112131415mysql&gt; select curtime();+-----------+| curtime() |+-----------+| 03:01:16 |+-----------+1 行于数据集 (0.01 秒)mysql&gt; select current_time();+----------------+| current_time() |+----------------+| 03:01:26 |+----------------+1 行于数据集 (0.01 秒) 3.2.3、now()NOW():返回当前日期时间 1234567mysql&gt; select now();+---------------------+| now() |+---------------------+| 2020-02-17 03:02:09 |+---------------------+1 行于数据集 (0.01 秒) 3.2.4、month()MONTH(date)或MONTHNAME(date):返回date的月份，范围1到12 123456789101112131415mysql&gt; select month(now());+--------------+| month(now()) |+--------------+| 2 |+--------------+1 行于数据集 (0.01 秒)mysql&gt; select monthname(now());+------------------+| monthname(now()) |+------------------+| February |+------------------+1 行于数据集 (0.01 秒) 3.2.5、week()WEEK(date):从日期中选择出周数 1234567mysql&gt; select week(now());+-------------+| week(now()) |+-------------+| 7 |+-------------+1 行于数据集 (0.01 秒) 3.2.6、year()YEAR(date):从日期中选择出年份 1234567mysql&gt; select year(now());+-------------+| year(now()) |+-------------+| 2020 |+-------------+1 行于数据集 (0.01 秒) 3.2.7、hour()HOUR(date):从日期中选择出小时数,返回time的小时，范围是0到23。 1234567mysql&gt; select hour(now());+-------------+| hour(now()) |+-------------+| 3 |+-------------+1 行于数据集 (0.02 秒) 3.2.8、minute()MINUTE():从日期中选择出分钟数,范围是0到59。 1234567mysql&gt; select minute(now());+---------------+| minute(now()) |+---------------+| 12 |+---------------+1 行于数据集 (0.01 秒) 3.2.9、second()SECOND(time):回来time的秒数，范围是0到59。 1234567mysql&gt; select second(now());+---------------+| second(now()) |+---------------+| 41 |+---------------+1 行于数据集 (0.01 秒) 3.3、常用日期和时间函数3.3.1、weekday()WEEKDAY(date)或DAYNAME(date):返回date的星期索引(0&#x3D;星期一，1&#x3D;星期二, ……6&#x3D; 星期天)。 123456789101112131415mysql&gt; select weekday(now());+----------------+| weekday(now()) |+----------------+| 0 |+----------------+1 行于数据集 (0.01 秒)mysql&gt; select dayname(now());+----------------+| dayname(now()) |+----------------+| Monday |+----------------+1 行于数据集 (0.01 秒) 3.3.2、dayofweek()DAYOFWEEK(date):返回日期date的星期索引(1&#x3D;星期天，2&#x3D;星期一, …7&#x3D;星期六)。 1234567mysql&gt; select dayofweek(now());+------------------+| dayofweek(now()) |+------------------+| 2 |+------------------+1 行于数据集 (0.01 秒) 3.3.3、dayofmonth()DAYOFMONTH(date):返回date的月份中的日期，在1到31范围内。 1234567mysql&gt; select dayofmonth(now());+-------------------+| dayofmonth(now()) |+-------------------+| 17 |+-------------------+1 行于数据集 (0.01 秒) 3.3.4、dayofyear()DAYOFYEAR(date):返回date在一年中的日数, 在1到366范围内。 1234567mysql&gt; select dayofyear(now());+------------------+| dayofyear(now()) |+------------------+| 48 |+------------------+1 行于数据集 (0.01 秒) 3.3.5、quarter()QUARTER(date):返回date一年中的季度，范围1到4。 1234567mysql&gt; select quarter(now());+----------------+| quarter(now()) |+----------------+| 1 |+----------------+1 行于数据集 (0.02 秒) 3.3.6、date_add()DATE_ADD(date,INTERVAL expr type) ,进行日期增加的操作，可以精确到秒 123456789101112131415161718192021222324252627282930mysql&gt; select &#x27;1997-12-31 23:59:59&#x27;+interval 1 second;+-----------------------------------------+| &#x27;1997-12-31 23:59:59&#x27;+interval 1 second |+-----------------------------------------+| 1998-01-01 00:00:00 |+-----------------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select &#x27;1997-12-31&#x27;+interval 1 second;+--------------------------------+| &#x27;1997-12-31&#x27;+interval 1 second |+--------------------------------+| 1997-12-31 00:00:01 |+--------------------------------+1 行于数据集 (0.02 秒)mysql&gt; select date_add(&#x27;1997-12-31 23:59:59&#x27;,interval 1 second);+---------------------------------------------------+| date_add(&#x27;1997-12-31 23:59:59&#x27;,interval 1 second) |+---------------------------------------------------+| 1998-01-01 00:00:00 |+---------------------------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select date_add(&#x27;1997-12-31 23:59:59&#x27;,interval &#x27;1:1&#x27; minute_second);+--------------------------------------------------------------+| date_add(&#x27;1997-12-31 23:59:59&#x27;,interval &#x27;1:1&#x27; minute_second) |+--------------------------------------------------------------+| 1998-01-01 00:01:00 |+--------------------------------------------------------------+1 行于数据集 (0.01 秒) 3.3.7、date_sub()DATE_SUB(date,INTERVAL expr type) ，进行日期减少的操作，可以精确到秒 12345678910111213141516171819202122mysql&gt; select &#x27;1997-12-31&#x27;-interval 1 second;+--------------------------------+| &#x27;1997-12-31&#x27;-interval 1 second |+--------------------------------+| 1997-12-30 23:59:59 |+--------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select date_sub(&#x27;1997-12-31 23:59:59&#x27;,interval &#x27;1:1&#x27; minute_second);+--------------------------------------------------------------+| date_sub(&#x27;1997-12-31 23:59:59&#x27;,interval &#x27;1:1&#x27; minute_second) |+--------------------------------------------------------------+| 1997-12-31 23:58:58 |+--------------------------------------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select date_sub(&#x27;1997-12-31 23:59:59&#x27;,interval 30 day);+-------------------------------------------------+| date_sub(&#x27;1997-12-31 23:59:59&#x27;,interval 30 day) |+-------------------------------------------------+| 1997-12-01 23:59:59 |+-------------------------------------------------+1 行于数据集 (0.01 秒) 四、系统信息函数4.1、系统函数概述系统信息函数用来查询MySQL数据库的系统信息。 4.2、常用系统函数4.2.1、version()VERSION()函数返回数据库的版本号； 1234567mysql&gt; select version();+-----------+| version() |+-----------+| 8.0.17 |+-----------+1 行于数据集 (0.01 秒) 4.2.2、connection_id()CONNECTION_ID()函数返回服务器的连接数，也就是到现在为止MySQL服务的连接次数； 1234567mysql&gt; select connection_id();+-----------------+| connection_id() |+-----------------+| 78 |+-----------------+1 行于数据集 (0.01 秒) 4.2.3、database()DATABASE()和SCHEMA()返回当前数据库名。 123456789101112131415mysql&gt; select database();+------------+| database() |+------------+| zutuanxue |+------------+1 行于数据集 (0.01 秒)mysql&gt; select schema();+----------+| schema() |+----------+| zutuanxue |+----------+1 行于数据集 (0.01 秒) 4.2.4、用户函数USER()、SYSTEM_USER()、SESSION_USER()、CURRENT_USER()和CURRENT_USER这几个函数可以返回当前用户的名称。 123456789101112131415161718192021222324252627282930313233343536373839mysql&gt; select user();+--------------------+| user() |+--------------------+| root@192.168.1.104 |+--------------------+1 行于数据集 (0.01 秒)mysql&gt; select system_user();+--------------------+| system_user() |+--------------------+| root@192.168.1.104 |+--------------------+1 行于数据集 (0.01 秒)mysql&gt; select session_user();+--------------------+| session_user() |+--------------------+| root@192.168.1.104 |+--------------------+1 行于数据集 (0.02 秒)mysql&gt; select current_user();+----------------+| current_user() |+----------------+| root@% |+----------------+1 行于数据集 (0.01 秒)mysql&gt; select current_user;+--------------+| current_user |+--------------+| root@% |+--------------+1 行于数据集 (0.01 秒) 4.2.5、字符集函数charset() CHARSET(str)函数返回字符串str的字符集，一般情况这个字符集就是系统的默认字符集； 1234567mysql&gt; select charset(&#x27;ad&#x27;);+---------------+| charset(&#x27;ad&#x27;) |+---------------+| utf8 |+---------------+1 行于数据集 (0.01 秒) collation() COLLATION(str)函数返回字符串str的字符排列方式。 1234567mysql&gt; select collation(&#x27;ad&#x27;);+-----------------+| collation(&#x27;ad&#x27;) |+-----------------+| utf8_general_ci |+-----------------+1 行于数据集 (0.01 秒) 五、其他函数5.1、md5()加密函数是MySQL中用来对数据进行加密的函数。 MD5(str)函数可以对字符串str进行加密。MD5(str)函数主要对普通的数据进行加密。下面使用MD5(str)函数为字符串“abcd”加密。 1234567mysql&gt; select md5(&#x27;abcd&#x27;);+----------------------------------+| md5(&#x27;abcd&#x27;) |+----------------------------------+| e2fc714c4727ee9395f324cd2e7f331f |+----------------------------------+1 行于数据集 (0.04 秒) 5.2、format()格式化函数FORMAT(x,n) FORMAT(x,n)函数可以将数字x进行格式化，将x保留到小数点后n位。这个过程需要进行四舍五入。例如FORMAT(2.356,2)返回的结果将会是2.36；FORMAT(2.353,2)返回的结果将会是2.35。下面使用FORMAT(x,n)函数来讲235.3456和235.3454进行格式化，都保留到小数点后3位。 1234567mysql&gt; select format(235.3456,3),format(235.3456,2);+--------------------+--------------------+| format(235.3456,3) | format(235.3456,2) |+--------------------+--------------------+| 235.346 | 235.35 |+--------------------+--------------------+1 行于数据集 (0.01 秒) 5.3、进制转换函数BIN(x)返回x的二进制编码； HEX(x)返回x的十六进制编码； OCT(x)返回x的八进制编码； CONV(x,f1,f2)将x从f1进制数变成f2进制数。 12345678910111213141516171819202122232425262728293031mysql&gt; select bin(10);+---------+| bin(10) |+---------+| 1010 |+---------+1 行于数据集 (0.01 秒)mysql&gt; select hex(10);+---------+| hex(10) |+---------+| A |+---------+1 行于数据集 (0.01 秒)mysql&gt; select oct(10);+---------+| oct(10) |+---------+| 12 |+---------+1 行于数据集 (0.01 秒)mysql&gt; select conv(10,10,2);+---------------+| conv(10,10,2) |+---------------+| 1010 |+---------------+1 行于数据集 (0.01 秒) 5.4、条件判断函数5.4.1、if()IF(expr,v1,v2)如果表达式 expr 成立，返回结果 v1；否则，返回结果 v2 123456789101112131415mysql&gt; select if(1&gt;0,&#x27;yes&#x27;,&#x27;no&#x27;);+--------------------+| if(1&gt;0,&#x27;yes&#x27;,&#x27;no&#x27;) |+--------------------+| yes |+--------------------+1 行于数据集 (0.01 秒)mysql&gt; select if(strcmp(&#x27;test&#x27;,&#x27;test1&#x27;),&#x27;yes&#x27;,&#x27;no&#x27;);+---------------------------------------+| if(strcmp(&#x27;test&#x27;,&#x27;test1&#x27;),&#x27;yes&#x27;,&#x27;no&#x27;) |+---------------------------------------+| yes |+---------------------------------------+1 行于数据集 (0.01 秒) 5.4.2、ifnull()IFNULL(v1,v2):如果v1不为NULL，则返回v1，否则返回v2 123456789101112131415mysql&gt; select ifnull(&#x27;yes&#x27;,&#x27;no&#x27;);+--------------------+| ifnull(&#x27;yes&#x27;,&#x27;no&#x27;) |+--------------------+| yes |+--------------------+1 行于数据集 (0.02 秒)mysql&gt; select ifnull(null,&#x27;no&#x27;);+-------------------+| ifnull(null,&#x27;no&#x27;) |+-------------------+| no |+-------------------+1 行于数据集 (0.01 秒) 5.4.3、caseCASE expr WHEN v1 THEN r1 [WHEN v2 THEN v2] [ELSE rn] END:如果expr等于某个vn，则返回对应位置THEN后面的结果，如果与所有值都不想等，则返回ELSE后面的rn 12345678910111213141516171819202122232425262728293031mysql&gt; select case 11 when 1 then &#x27;one&#x27; when 2 then &#x27;two&#x27; else &#x27;more&#x27; end;+-------------------------------------------------------------+| case 11 when 1 then &#x27;one&#x27; when 2 then &#x27;two&#x27; else &#x27;more&#x27; end |+-------------------------------------------------------------+| more |+-------------------------------------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select case when 1&gt;0 then &#x27;true&#x27; else &#x27;false&#x27; end;+--------------------------------------------+| case when 1&gt;0 then &#x27;true&#x27; else &#x27;false&#x27; end |+--------------------------------------------+| true |+--------------------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select case binary &#x27;B&#x27; when &#x27;a&#x27; then 1 when &#x27;b&#x27; then 2 end;+-----------------------------------------------------+| case binary &#x27;B&#x27; when &#x27;a&#x27; then 1 when &#x27;b&#x27; then 2 end |+-----------------------------------------------------+| NULL |+-----------------------------------------------------+1 行于数据集 (0.01 秒)mysql&gt; select case binary &#x27;B&#x27; when &#x27;a&#x27; then 1 when &#x27;B&#x27; then 2 end;+-----------------------------------------------------+| case binary &#x27;B&#x27; when &#x27;a&#x27; then 1 when &#x27;B&#x27; then 2 end |+-----------------------------------------------------+| 2 |+-----------------------------------------------------+1 行于数据集 (0.01 秒) 常用函数–时间日期函数 DEFAUILT 日期类型 NOW():获取到当前日期和时间SELECT NOW();返回2023-3-21 14:50:22CURDAE() 获取当前的日期"},{"path":"/2023/07/11/MySQL数据库实战/MySql客户端/","content":"Navicat for MySQL是一套管理和开发MySQL或MariaDB的理想解决方案，支持单一程序，可同时连接到MySQL和MariaDB。这个功能齐备的前端软件为数据库管理、开发和维护提供了直观而强大的图形界面，给MySQL或MariaDB新手以及专业人士提供了一组全面的工具。 1、Navicat for MySQL下载与安装1.1、下载1http://www.navicat.com.cn/download/navicat-for-mysql image20200222233257400.png image20200222233338007.png 1.2、下载完成image20200222233455188.png 1.3、安装右击“navicat150_mysql_cs_x64.exe”，以管理员身份运行，选择“是” image20200222233702941.png 跳出安装程序对话框，选择“下一步” image20200222233952780.png 选择“我同意”，继续“下一步” image20200222234125462.png 选择“安装路径”，继承“下一步” image20200222234450664.png 选择“快捷方式路径”，继续“下一步” image20200222234354406.png 选择在“桌面创建快捷方式”，继续“下一步” image20200222234708924.png 进入“装备安装”界面，点击“安装” image20200222234904299.png 进入“安装”界面，直到跳出“完成”界面 image20200222235023235.png 点击“完成”，安装成功 image20200222235103254.png 1.4、Navicat for MySQL连接MySQL数据库1.4.1、打开Navicat for MySQLimage20200222235353143.png 1.4.2、创建新连接连接-&gt;MySQL image20200222235549717.png 文件-&gt;新建连接-&gt;MySQL image20200222235719188.png 新建连接对话框，输入对应信息，点击“测试连接” image20200223000045104.png 连接成功 image20200223000156896.png 确认连接后如下： image20200223000512002.png 2、Navicat for MySQL操作-上2.1、数据库操作2.2.1、创建数据库右击“MySQL连接”，选择“新建数据库” image20200223001205072.png 2.2.2、删除数据库右击想要删除的数据库，选择“删除数据库” image20200223001414043.png 2.2、数据库表操作2.2.1、新建表右击“表”，选择“新建表” image20200223001746104.png image20200223002004707.png 3、Navicat for MySQL操作-下3.1、数据库表操作3.1.1、操作表中结构与记录表结构（表的修改） image20200223002415540.png 表记录（记录的增加、删除、修改、查看） image20200223002826369.png 3.1.2、删除表右击想删除的表，选择“删除表” image20200223003000136.png 3.2、命令列窗口的打开右击连接&#x2F;数据库，选择“命令列窗口” image20200223003312998.png image20200223003438588.png 相当于 image20200223003552091.png"},{"path":"/2023/07/11/MySQL数据库实战/MySql安装与使用/","content":"mysql是目前最流行的关系型数据库管理系统,在WEB应用方面MySQL是最好的RDBMS(Relational Database Management System：关系数据库管理系统)应用软件之一。 MySQL是非常灵活的一款数据库，虽然它不是绝对完美，但它的灵活足够适应很多高要求的环境。为了发挥MySQL的性能并很好的使用它，我们就得先了解其设计。MySQL的灵活主要体现在我们可以通过不同的配置使他在不同的硬件上都能运行的很好。但是MySQL最重要，与众不同的特性是它的存储引擎架构，这种架构将查询处理及其他系统任务和数据的存储&#x2F;提取相分离。 一、mysql概述1.1、关系型数据库关系型数据库天然就是二维表格，因此存储在数据表的行和列中。数据表可以彼此关联协作存储，也很容易提取数据。 1.2、MySQL数据库MySQL是一个关系型数据库管理系统，由瑞典MySQL AB公司开发，目前属于Oracle公司。 MySQL可将数据保存在不同的表中，而不是将所有数据放在一个大的仓库内，从而加快了访问速度并提高了灵活性。 MySQL 使用了标准的 SQL 语言形式。支持大型的数据库，可以处理拥有上千万条记录的大型数据库。MySQL 还可用于多种系统中，且支持多种语言。 1.3、RDBMS术语数据库：数据库是一些关联表的集合。 数据表：表是数据的矩阵。在一个数据库中的表看起来像一个简单的电子表格。 列：一列（数据元素）包含了相同的数据，例如邮政编码的数据。 行：一行（&#x3D;元组，或者记录）是一组相关的数据，例如一条用户订阅的数据。 亢余：存储两倍数据，亢余降低了性能，但是提高了数据的安全性。 主键：主键是唯一的，一个数据表中只能够包含一个主键，你可以使用主键来查询数据。 外键：外键用于关联两个表。 复合键：复合键（组合键）将多个列作为一个索引键，一般用于复合索引。 索引：使用索引可快速访问数据库表中的特定信息。索引是对数据库表中一列或者多列的值进行排序的一种结构。类似于书籍的目录。 1.4、mysql下载https://dev.mysql.com/downloads/mysql/ image20200223135527926.png 点击“Download”后，我们要先登录Oracle，才能进行下载。 2、mysql安装2.1、指定安装文件位置将mysql安装包放到&#x2F;usr&#x2F;local&#x2F;下面 image20200223011252870.png 2.2、解压12[root@zutuanxue local]# xz -d mysql-8.0.17-linux-glibc2.12-x86_64.tar.xz [root@zutuanxue local]# tar -xvf mysql-8.0.17-linux-glibc2.12-x86_64.tar 2.3、改名1[root@zutuanxue local]# mv mysql-8.0.17-linux-glibc2.12-x86_64 mysql 2.4、创建用户组mysql用户组、mysql用户 1234[root@zutuanxue local]# groupadd mysql[root@zutuanxue local]# useradd -r -g mysql mysql[root@zutuanxue local]# passwd mysql#更改密码：Ww1985929wW 2.5、修改MySQL配置文件&#x2F;etc&#x2F;my.cnf 1234567891011121314151617181920212223242526272829303132333435# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.6/en/server-configuration-defaults.html# *** DO NOT EDIT THIS FILE. It&#x27;s a template which will be copied to the# *** default location during install, and will be replaced if you# *** upgrade to a newer version of MySQL.[mysqld]# Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M# Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin# These are commonly set, remove the # and set as required.basedir = /usr/local/mysqldatadir = /usr/local/mysql/dataport = 3306# server_id = .....socket = /tmp/mysql.sockcharacter-set-server = utf8skip-name-resolvelog-error = /usr/local/mysql/data/error.logpid-file = /usr/local/mysql/data/mysql.pid# Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2M sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES 2.6、创建data文件夹data文件夹是用于存储数据库文件，他的位置是在mysql目录下 1[root@zutuanxue mysql]# mkdir data 2.7、更改mysql目录权限12[root@zutuanxue mysql]# chown -R mysql .[root@zutuanxue mysql]# chgrp -R mysql . image20200223012815486.png 2.8、初始化数据库1[root@zutuanxue mysql]# ./bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data 执行完后查看初始密码： 1[root@zutuanxue mysql]# vim /usr/local/mysql/data/error.log image20200223013228179.png image20200223182708100.png 2.9、启动mysql服务12[root@zutuanxue mysql]# ./support-files/mysql.server startStarting MySQL... SUCCESS! 2.10、修改root密码1[root@zutuanxue mysql]# ./bin/mysql -uroot -prj%-:yqHb98g image20200223014851493.png 修改密码： 12mysql&gt; alter user &#x27;root&#x27;@&#x27;localhost&#x27; identified by &#x27;Root123456&#x27;;Query OK, 0 rows affected (0.05 sec) 3、mysql操作3.1、服务器操作启动、停止、重启 1234567[root@zutuanxue mysql]# ./support-files/mysql.server restartShutting down MySQL. SUCCESS! Starting MySQL.. SUCCESS! [root@zutuanxue mysql]# ./support-files/mysql.server stopShutting down MySQL.. SUCCESS! [root@zutuanxue mysql]# ./support-files/mysql.server startStarting MySQL.. SUCCESS! 3.2、设置远程连接12345678mysql&gt; create user &#x27;root&#x27;@&#x27;%&#x27; identified with mysql_native_password by &#x27;Root123456&#x27;;Query OK, 0 rows affected (0.01 sec)mysql&gt; grant all on *.* to &#x27;root&#x27;@&#x27;%&#x27;;Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 遇到问题： Can’t connect to MySQL server on ‘192.168.1.121’ (61) 12[root@zutuanxue mysql]# systemctl stop firewalld.service [root@zutuanxue mysql]# firewall-cmd --state 4、mysql卸载4.1、停止mysql服务12[root@zutuanxue mysql]# ./support-files/mysql.server stopShutting down MySQL.... SUCCESS! 4.2、查找所有mysql相关文件夹查找 1[root@zutuanxue mysql]# find / -name mysql image20200223024128126.png 删除所有查出来的文件夹 12[root@zutuanxue mysql]# rm -rf /var/lib/selinux/targeted/active/modules/100/mysql...... 4.3、删除配置文件配置文件一般有&#x2F;etc&#x2F;my.cnf 或&#x2F;etc&#x2F;init.d&#x2F;mysql.server， 12[root@zutuanxue mysql]# rm -f /etc/my.cnf[root@zutuanxue mysql]# rm -rf /etc/init.d/mysql.server 4.4、删除用户组123[root@zutuanxue mysql]# userdel mysql[root@zutuanxue mysql]# id mysqlid: “mysql”：无此用户"},{"path":"/2023/07/11/MySQL数据库实战/MySQL子查询/","content":"在SQL语言中，一个SELECT-FROM-WHERE语句称为一个查询块。当获得一个查询的答案需要多个步骤的操作，首先必须创建一个查询来确定用户不知道但包含在数据库中的值，将一个查询块嵌套在另一个查询块的WHERE字句或HAVING短语的条件中查询块称为子查询或内层查询。上层的查询块曾为父查询或外层查询。子查询的结果作为输入传递回“父查询”或“外部查询”。父查询将这个值结合到计算中，以便确定最后的输出。 一、子查询概述1.1、什么是子查询子查询是一种常用计算机语言sql中select语言中嵌套查询下层的程序模块。当一个查询是另一个查询的条件时，称之为子查询。 如： 查询渠道部有那些员工 1234567891011121314151617#第一步，查询出&#x27;渠道部&#x27;的idmysql&gt; select id from dept where name=&#x27;渠道部&#x27;;+----+| id |+----+| 2 |+----+1 行于数据集 (0.02 秒)#第二步，通过查询出的‘渠道部’的id，在查询渠道部的员工信息mysql&gt; select * from emp where dept_id=2;+----+--------+--------+--------+------------+---------+| id | name | gender | salary | join_date | dept_id |+----+--------+--------+--------+------------+---------+| 2 | 李四 | 男 | 3600 | 2010-12-02 | 2 || 3 | 王五 | 男 | 9000 | 2008-08-08 | 2 |+----+--------+--------+--------+------------+---------+2 行于数据集 (0.01 秒) 子查询方式 12345678mysql&gt; select * from emp where dept_id=(select id from dept where name=&#x27;渠道部&#x27;);+----+--------+--------+--------+------------+---------+| id | name | gender | salary | join_date | dept_id |+----+--------+--------+--------+------------+---------+| 2 | 李四 | 男 | 3600 | 2010-12-02 | 2 || 3 | 王五 | 男 | 9000 | 2008-08-08 | 2 |+----+--------+--------+--------+------------+---------+2 行于数据集 (0.03 秒) 1.2、子查询特点一个查询的结果做为另一个查询的条件 有查询的嵌套，内部的查询称为子查询 子查询要使用括号 1.3、子查询结果的三种情况单行单列 image20200215215222589.png 多行单列 image20200215215408848.png 多行多列 image20200215215431152.png 二、单行单列查询子查询结果只要是单行单列，肯定在 WHERE 后面作为条件，父查询使用：比较运算符，如：&gt; 、&lt;、&lt;&gt;、&#x3D;、&gt;&#x3D;、&lt;&#x3D;等 12格式：select */字段列表 from 数据库表名 where 字段名=(子查询); 案例： 查询工资最高的员工信息 分析： 先找出最高工资，在查找员工信息 123456789101112131415mysql&gt; select max(salary) from emp;+-------------+| max(salary) |+-------------+| 9000 |+-------------+1 行于数据集 (0.01 秒)mysql&gt; select * from emp where salary=(select max(salary) from emp);+----+--------+--------+--------+------------+---------+| id | name | gender | salary | join_date | dept_id |+----+--------+--------+--------+------------+---------+| 3 | 王五 | 男 | 9000 | 2008-08-08 | 2 |+----+--------+--------+--------+------------+---------+1 行于数据集 (0.01 秒) 查询工资小于平均工资的员工信息 分析： 先算出员工的平均工资，在查看小于平均工资的员工信息 1234567891011121314151617mysql&gt; select avg(salary) from emp;+-------------------+| avg(salary) |+-------------------+| 5994.333333333333 |+-------------------+1 行于数据集 (0.02 秒)mysql&gt; select * from emp where salary&lt;(select avg(salary) from emp);+----+--------+--------+--------+------------+---------+| id | name | gender | salary | join_date | dept_id |+----+--------+--------+--------+------------+---------+| 2 | 李四 | 男 | 3600 | 2010-12-02 | 2 || 4 | 赵六 | 女 | 5000 | 2015-10-07 | 3 || 5 | 吴七 | 女 | 4500 | 2011-03-14 | 1 |+----+--------+--------+--------+------------+---------+3 行于数据集 (0.03 秒) 三、单行多列查询子查询结果只要是单行多列，结果集类似于一个数组，父查询使用in、not in运算符 12格式：select */字段列表 from 数据库表名 where 字段名 in (子查询); 案例： 查询工资大于 5000 的员工，来自于哪些部门的名字 分析： 先找出工资大于5000的员工的部门ID，通过部门ID查找对应的部门名字 1234567891011121314151617mysql&gt; select dept_id from emp where salary&gt;5000;+---------+| dept_id |+---------+| 1 || 2 |+---------+2 行于数据集 (0.01 秒)mysql&gt; select * from dept where id in(select dept_id from emp where salary&gt;5000); +----+-----------+| id | name |+----+-----------+| 1 | 研发部 || 2 | 渠道部 |+----+-----------+2 行于数据集 (0.01 秒) 查询研发部与渠道部所有的员工信息 分析： 先查找研发部与渠道部的id，通过id查找到研发部与渠道部的员工信息 123456789101112131415161718mysql&gt; select id from dept where name=&#x27;研发部&#x27; or name=&#x27;渠道部&#x27;;+----+| id |+----+| 1 || 2 |+----+mysql&gt; select * from emp where dept_id in(select id from dept where name in(&#x27;研发部&#x27;,&#x27;渠道部&#x27;));+----+--------+--------+--------+------------+---------+| id | name | gender | salary | join_date | dept_id |+----+--------+--------+--------+------------+---------+| 1 | 张三 | 男 | 7200 | 2013-02-24 | 1 || 2 | 李四 | 男 | 3600 | 2010-12-02 | 2 || 3 | 王五 | 男 | 9000 | 2008-08-08 | 2 || 5 | 吴七 | 女 | 4500 | 2011-03-14 | 1 |+----+--------+--------+--------+------------+---------+4 行于数据集 (0.02 秒) 四、多行多列子查询结果只要是多行多列，肯定在 FROM 后面作为表，子查询作为表需要取别名，否则这张表没有名称则无法访问表中的字段。 12格式：select */字段列表 from (子查询) [as] 表别名 where 条件表达式; 案例： 查询出 2011 年以后入职的员工信息，包括部门名称 分析：先找出2011年入职的员工信息组成一个新表，在查询所在的部门信息 12345678910111213141516171819mysql&gt; select * from emp where join_date&gt;=&#x27;2011-01-01&#x27;;+----+--------+--------+--------+------------+---------+| id | name | gender | salary | join_date | dept_id |+----+--------+--------+--------+------------+---------+| 1 | 张三 | 男 | 7200 | 2013-02-24 | 1 || 4 | 赵六 | 女 | 5000 | 2015-10-07 | 3 || 5 | 吴七 | 女 | 4500 | 2011-03-14 | 1 |+----+--------+--------+--------+------------+---------+3 行于数据集 (0.01 秒)mysql&gt; select * from dept d,(select * from emp where join_date&gt;=&#x27;2011-01-01&#x27;) e where d.id=e.dept_id;+----+-----------+-------+---------+--------+--------+------------+---------+| id | name | id(2) | name(2) | gender | salary | join_date | dept_id |+----+-----------+-------+---------+--------+--------+------------+---------+| 1 | 研发部 | 1 | 张三 | 男 | 7200 | 2013-02-24 | 1 || 3 | 教务部 | 4 | 赵六 | 女 | 5000 | 2015-10-07 | 3 || 1 | 研发部 | 5 | 吴七 | 女 | 4500 | 2011-03-14 | 1 |+----+-----------+-------+---------+--------+--------+------------+---------+3 行于数据集 (0.02 秒) 还可以使用表连接查询 12345678mysql&gt; select * from emp inner join dept on emp.dept_id = dept.id where join_date &gt;=&#x27;2011-1-1&#x27;;+----+--------+--------+--------+------------+---------+-------+-----------+| id | name | gender | salary | join_date | dept_id | id(2) | name(2) |+----+--------+--------+--------+------------+---------+-------+-----------+| 1 | 张三 | 男 | 7200 | 2013-02-24 | 1 | 1 | 研发部 || 4 | 赵六 | 女 | 5000 | 2015-10-07 | 3 | 3 | 教务部 || 5 | 吴七 | 女 | 4500 | 2011-03-14 | 1 | 1 | 研发部 |+----+--------+--------+--------+------------+---------+-------+-----------+"},{"path":"/2023/07/11/MySQL数据库实战/MySQL多主模型实战/","content":"MySQL AB解决了数据备份的问题，但是当A由于某些原因宕机后，WEB服务器就没有办法在往数据库写或者读写了。线上业务中断了，完了，出事故了。这该怎么办呢？ 本节课主要给大家讲解如果处理因为MySQL主服务器宕机造成的业务中断问题，保障MySQL业务高可用。 一、实验拓扑图mysql_aa拓扑图.png 二、架构原理1、MySQL互为主备，保障多台MySQL的数据强一致性。 2、VIP漂移，任何一台宕机都不影响数据读写 3、宕机服务器修复，自动同步故障间的缺失数据 三、实验准备 机器三台并设置好IP地址 关闭防火墙、selinux 时间同步 node1、node2安装mysql manage01部署lamp 上线业务并进行容灾测试 知识储备点：MySQL AB复制 四、node1、node2互为主备123456789101112131415161718192021222324252627282930311、确认binlog开启2、设置server-id3、创建同步mysql用户4、设置同步#以node2为例#创建用户mysql&gt; create user sko2 identified by &quot;123456&quot;;Query OK, 0 rows affected (0.00 sec)mysql&gt; grant replication slave on *.* to sko2;Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)#开始同步#同步前 主服务器生成一个新binlog开始同步，防止之前的binlog中语句无法执行mysql&gt; stop slave;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; change master to -&gt; master_host=&#x27;192.168.98.202&#x27;,-&gt; master_user=&#x27;sko&#x27;,-&gt; master_password=&#x27;98989&#x27;,-&gt; master_log_file=&#x27;binlog.000002&#x27;,-&gt; master_log_pos=xxx;Query OK, 0 rows affected, 3 warnings (0.01 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec) 五、manage01-lamp12345678# 部署lamp业务环境[root@manage01 ~]# yum -y install httpd php php-mysql[root@manage01 ~]# systemctl start httpd[root@manage01 ~]# systemctl start php-fpm[root@manage01 ~]# vim /var/www/html/phpinfo.php#测试&lt;?php phpinfo(); ?&gt; 六、配置MySQL高可用1、模拟故障，将配有VIP的mysql宕机，手动回收VIP并配给另外一个运行的mysql服务器，查看业务是否正常。 2、恢复宕机mysql，查看宕机过程中的产生的数据是否能够从另外一个运行的mysql中恢复回来。 12参考nginx高可用部署https://www.zutuanxue.com/home/4/58_388 七、上线业务测试a、拷贝站点 1[root@manage01 ~]# cp -r 测试站点html/* /var/www/html/ b、安装站点打开浏览器输入 http://IP/install.php c、根据站点提示输入数据并查询，查询数据库数据同步情况 d、停止主mysql继续测试业务，确保正常工作 e、启动宕机mysql，确保停机期间的数据同步"},{"path":"/2023/07/11/MySQL数据库实战/MySQL事务/","content":"事务（Transaction），一般是指要做的或所做的事情。在计算机术语中是指访问并可能更新数据库中各种数据项的一个程序执行单元(unit)。事务通常由高级数据库操纵语言或编程语言（如SQL，C++或Java）书写的用户程序的执行所引起，并用形如begin transaction和end transaction语句（或函数调用）来界定。事务由事务开始(begin transaction)和事务结束(end transaction)之间执行的全体操作组成。 一、事务概述1.1、什么是事务MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你既需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ 事务是一个事件处理的完整的过程。比如：存款、取款、转帐等操作都可以称之为一个事务。 1.2、事务的应用场景我们想完成一次转帐业务，那么他会多次去访问我们的数据库。转帐实上就是从一个帐户上扣钱，在往一个帐户上加钱。这样我们执行了二次sql，如果其中一个sql失败，那么整个业务就没有执行成功。所有的sql都需要回滚，整个业务失败。 数据准备 123456789#创建数据表create table yh(id int primary key auto_increment,name varchar(20),money double);-- 添加数据insert into yh(name,money)values(&#x27;张三&#x27;, 1000),(&#x27;李四&#x27;, 1000); 案例： 模拟张三给李四转500元钱 分析： 先从张三的帐户减出500，在往李四的帐户加入500元 1234567891011121314mysql&gt; update yh set money=money-500 where name=&#x27;张三&#x27;;Query OK, 1 rows affected (0.02 秒)mysql&gt; update yh set money=money+500 where name=&#x27;李四&#x27;;Query OK, 1 rows affected (0.04 秒)mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 500 || 2 | 李四 | 1500 |+----+--------+-------+2 行于数据集 (0.04 秒) 如果转帐时出现问题： 当张三账号上-500 元,服务器崩溃了。李四的账号并没有+500 元，数据就出现问题了。 因为他们是一个整体的业务，所以我们需要保证其中一条 SQL 语句出现问题，整个转账就算失败。只有两条 SQL 都成功了转账才算成功。这个时候就需要用到事务。 1.3、事务提交方式mysql中有两种事务提交方式： 手动提交 自动提交 二、事务手动提交2.1、手动提交的过程image20200215230939254.png 事务执行成功的过程：开启事务-&gt;执行多条件SQL语句-&gt;成功-&gt;事务提交 事务执行失败的过程：开启事务-&gt;执行多条件SQL语句-&gt;失败-&gt;事务回滚 2.2、语法格式1234格式：start transaction; #开启事务 commit; #提交事务 rollback; #回滚事务 案例： 事务的成功提交：模拟张三给李四转 500 元钱（成功） 目前数据库数据如下： image20200215232438482.png 123456789101112131415161718192021#开启事务mysql&gt; start transaction;Query OK, 0 rows affected (0.01 秒)#执行从张三帐户扣出500元mysql&gt; update yh set money=money-500 where name=&#x27;张三&#x27;;Query OK, 1 rows affected (0.01 秒)#执行往李四帐户加入500元mysql&gt; update yh set money=money+500 where name=&#x27;李四&#x27;;Query OK, 1 rows affected (0.01 秒)#提交事务mysql&gt; commit;Query OK, 0 rows affected (0.08 秒)#查看帐户mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 0 || 2 | 李四 | 2000 |+----+--------+-------+2 行于数据集 (0.01 秒) 事务回滚：模拟李四给张三转 500 元钱（失败） 目前数据库数据如下： image20200215232946263.png 123456789101112131415161718192021#开启事务mysql&gt; start transaction;Query OK, 0 rows affected (0.02 秒)#执行从李四帐户扣出500元mysql&gt; update yh set money=money-500 where name=&#x27;李四&#x27;;Query OK, 1 rows affected (0.01 秒)#执行往张三帐户加入500元，但是加了600mysql&gt; update yh set money=money+600 where name=&#x27;张三&#x27;;Query OK, 1 rows affected (0.01 秒)#事务回滚mysql&gt; rollback;Query OK, 0 rows affected (0.02 秒)#查看帐户mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 0 || 2 | 李四 | 2000 |+----+--------+-------+2 行于数据集 (0.01 秒) 三、事务自动提交MySQL 默认每一条 DML(增删改)语句都是一个单独的事务，每条语句都会自动开启一个事务，语句执行完毕自动提交事务，MySQL 默认开始自动提交事务。 如： 事务开始-&gt;update&#x2F;delete&#x2F;insert into-&gt;事务提交 3.1、自动提交事务案例： 自动事务提交：往张三的帐户里存入1000元，目前数据库数据如下： image20200215233931488.png 1234567891011mysql&gt; update yh set money=money+1000 where name=&#x27;张三&#x27;;Query OK, 1 rows affected (0.05 秒)mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1000 || 2 | 李四 | 2000 |+----+--------+-------+2 行于数据集 (0.01 秒) 3.2、取消自动提交查看 MySQL 是否开启自动提交事务 12格式：select @@autocommit; 注意： @@表示全局变量，1 表示开启，0 表示关闭 取消自动提交事务 12格式：set autocommit=0; 案例： 123456789101112131415161718mysql&gt; select @@autocommit;+--------------+| @@autocommit |+--------------+| 1 |+--------------+1 行于数据集 (0.01 秒)mysql&gt; set autocommit=0;Query OK, 0 rows affected (0.01 秒)mysql&gt; select @@autocommit;+--------------+| @@autocommit |+--------------+| 0 |+--------------+1 行于数据集 (0.01 秒) 从李四的帐户取出1000元，目前数据库数据如下： image20200215234548334.png 注意： 要在窗口A、窗口B中验证 1234567891011121314151617181920#窗口Amysql&gt; update yh set money=money-1000 where name=&#x27;李四&#x27;;Query OK, 1 rows affected (0.01 秒)mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1000 || 2 | 李四 | 1000 |+----+--------+-------+2 行于数据集 (0.01 秒)#在窗口B中查询银行帐户(第一次验证)#提交mysql&gt; commit;Query OK, 0 rows affected (0.10 秒)#在窗口B中查询银行帐户(第二次验证) 在打开一个窗口 123456789101112131415161718#窗口Bmysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1000 || 2 | 李四 | 2000 |+----+--------+-------+2 行于数据集 (0.01 秒)mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1000 || 2 | 李四 | 1000 |+----+--------+-------+2 行于数据集 (0.02 秒) 4、事务原理一个事务会涉及到大量的cpu计算和IO操作，这些操作被打包成一个执行单元,要么同时都完成，要么同时都不完成。 4.1、自动提交原理图如果没有显示启动事务,数据库会根据autocommit的值.默认每条sql操作都会自动提交。 image20200218000643813.png 4.2、手动提交原理图如果开启了事务，其中有任何一条语句因为崩溃或者其它原因无法执行，那么该组中所有的sql语句都不会执行。 image20200218001646389.png 4.3、事务提交步骤客户端连接上服务器端，创建连接同时创建当前用户的临时事务日志文件。 开启事务，改变原有的操作机制（所有的操作都会先写入临时日志文件）。 写入SQL，接收并执行SQL，所有的SQL操作都会写入临时文件；返回数据时，从数据库表拿取数据，但要通过临时日志文件加工在返回。 事务的提交或回滚，提交：同步临时日志文件中的SQL操作结果到数据库表；回滚：清除临时日志文件 5、事务回滚我们可以在mysql事务处理过程中定义保存点(SAVEPOINT)，然后回滚到指定的保存点前的状态。 定义保存点，以及回滚到指定保存点前状态的语法如下： 12345格式：savepoint 保存点名; #定义保存点rollback to savepoint 保存点名; #回滚到指定保存点或rollback to 保存点名; 数据表准备 123456789101112#创建一个管理员表create table manager( id int primary key auto_increment, uname varchar(20), pword varchar(20));#插入数据insert into manager(uname,pword) values(&#x27;zhangsan&#x27;,&#x27;zhangsan&#x27;),(&#x27;lisi&#x27;,&#x27;lisi&#x27;);#插入数据insert into manager(uname,pword) values(&#x27;wangwu&#x27;,&#x27;wangwu&#x27;),(&#x27;zhaoliu&#x27;,&#x27;zhaoliu&#x27;); 案例： 开启事务 向表中插入二条件记录 设置保存点，保存点的名字为：insert_point 向表中插入二条件记录 回到保存点：insert_point 12345678910111213141516171819202122232425262728293031323334353637383940414243mysql&gt; start transaction;Query OK, 0 rows affected (0.01 秒)mysql&gt; insert into manager(uname,pword) values(&#x27;zhangsan&#x27;,&#x27;zhangsan&#x27;),(&#x27;lisi&#x27;,&#x27;lisi&#x27;);Query OK, 2 rows affected (0.01 秒)mysql&gt; select * from manager;+----+----------+----------+| id | uname | pword |+----+----------+----------+| 1 | zhangsan | zhangsan || 2 | lisi | lisi |+----+----------+----------+2 行于数据集 (0.01 秒)mysql&gt; savepoint insert_point;Query OK, 0 rows affected (0.01 秒)mysql&gt; insert into manager(uname,pword) values(&#x27;wangwu&#x27;,&#x27;wangwu&#x27;),(&#x27;zhaoliu&#x27;,&#x27;zhaoliu&#x27;);Query OK, 2 rows affected (0.01 秒)mysql&gt; select * from manager;+----+----------+----------+| id | uname | pword |+----+----------+----------+| 1 | zhangsan | zhangsan || 2 | lisi | lisi || 3 | wangwu | wangwu || 4 | zhaoliu | zhaoliu |+----+----------+----------+4 行于数据集 (0.01 秒)mysql&gt; rollback to savepoint insert_point;Query OK, 0 rows affected (0.00 秒)mysql&gt; select * from manager;+----+----------+----------+| id | uname | pword |+----+----------+----------+| 1 | zhangsan | zhangsan || 2 | lisi | lisi |+----+----------+----------+2 行于数据集 (0.01 秒) 注意： 设置保存点可以让我们在失败的时候回到保存点，而不是回到事务开启的时候。 六、事务隔离级别6.1、事务特性原子性（Atomicity）： 事务内的操作要嘛全部完成，要嘛全部回滚。 一致性(Consistency)： 事务执行的前后都是合法的数据状态，不会违反任何的数据完整性。 隔离性（Isolation）: 主要是事务之间的相互的影响，根据隔离有不同的影响效果。 持久性（Durability）： 事务一旦提交，就会体现在数据库上，不能回滚。 6.2、事务的并发问题脏读： 比如事务A执行的过程中，读到了事务B未提交的内容。 不可重复读： 指一个事务在前后两次查询的结果不一致。 幻读： 幻读是指前后两次相同条件下的查询，后一次查询读到了前一次查询没有的行数据。 6.3、事务的隔离级别image20200218012806058.png 注意： 隔离级别越高，性能越差，安全性越高。 6.4、事务隔离命令查看隔离级别 12345678910#格式：select @@transaction_isolation;mysql&gt; select @@transaction_isolation;+-------------------------+| @@transaction_isolation |+-------------------------+| REPEATABLE-READ |+-------------------------+1 行于数据集 (0.01 秒) 设置隔离级别 12345#格式：set global transaction_isolation=级别字符串mysql&gt; set global transaction_isolation=&#x27;read-committed&#x27;;Query OK, 0 rows affected (0.01 秒) 重启客户端，查看 1234567mysql&gt; select @@transaction_isolation;+-------------------------+| @@transaction_isolation |+-------------------------+| READ-COMMITTED |+-------------------------+1 行于数据集 (0.02 秒) 7、脏读7.1、设置隔离级别1234567891011mysql&gt; set global transaction_isolation=&#x27;read-uncommitted&#x27;;Query OK, 0 rows affected (0.00 秒)#重启窗口查看隔离级别mysql&gt; select @@transaction_isolation;+-------------------------+| @@transaction_isolation |+-------------------------+| READ-UNCOMMITTED |+-------------------------+1 行于数据集 (0.02 秒) 7.2、脏读恢复yh表中的数据为： image20200218104028518.png 打开A，B两个窗口，分别开启事务： 12mysql&gt; start transaction;Query OK, 0 rows affected (0.00 秒) 在A窗口里执行，转帐操作 12345mysql&gt; update yh set money=money-500 where id=1;Query OK, 1 rows affected (0.00 秒)mysql&gt; update yh set money=money+500 where id=2;Query OK, 1 rows affected (0.00 秒) 在B窗口里执行，查看帐户，钱已经到帐 12345678mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 500 || 2 | 李四 | 1500 |+----+--------+-------+2 行于数据集 (0.01 秒) 在A窗口里执行回滚 12mysql&gt; rollback;Query OK, 0 rows affected (0.05 秒) 在B窗口里执行，查看帐户，钱不见了 12345678mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1000 || 2 | 李四 | 1000 |+----+--------+-------+2 行于数据集 (0.01 秒) 脏读是比较危险的事情，如果张三在李四那里买了一个汽球花了500元，那么张三转帐给李四后，李四发货给张三，张三收到货物后把事务回滚，这样李四再也没有看到钱。 要解决脏读的问题我们要提高隔离级别？ 1234567891011mysql&gt; set global transaction_isolation=&#x27;read-committed&#x27;;Query OK, 0 rows affected (0.00 秒)#重启窗口查看隔离级别mysql&gt; select @@transaction_isolation;+-------------------------+| @@transaction_isolation |+-------------------------+| READ-COMMITTED |+-------------------------+1 行于数据集 (0.02 秒) 案例： 恢复yh表中的数据为： image20200218104028518.png 打开A，B两个窗口，分别开启事务： 12mysql&gt; start transaction;Query OK, 0 rows affected (0.00 秒) 在A窗口里执行，转帐操作 12345mysql&gt; update yh set money=money-500 where id=1;Query OK, 1 rows affected (0.00 秒)mysql&gt; update yh set money=money+500 where id=2;Query OK, 1 rows affected (0.00 秒) 在B窗口里执行，查看帐户，帐户没有变化 12345678mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1000 || 2 | 李四 | 1000 |+----+--------+-------+2 行于数据集 (0.01 秒) 在A窗口里执行，事务提交 12mysql&gt; commit;Query OK, 0 rows affected (0.05 秒) 在B窗口里执行，查看帐户，钱到帐了 12345678mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 500 || 2 | 李四 | 1500 |+----+--------+-------+2 行于数据集 (0.01 秒) 这样我们就解决了脏读的问题，提高我们的隔离级别。 八、不可重复读8.1、设置隔离级别1234567891011mysql&gt; set global transaction_isolation=&#x27;read-committed&#x27;;Query OK, 0 rows affected (0.00 秒)#重启窗口查看隔离级别mysql&gt; select @@transaction_isolation;+-------------------------+| @@transaction_isolation |+-------------------------+| READ-COMMITTED |+-------------------------+1 行于数据集 (0.02 秒) 8.2、不可重复读恢复yh表中的数据为： image20200218104028518.png 打开A，B两个窗口，分别开启事务： 12mysql&gt; start transaction;Query OK, 0 rows affected (0.00 秒) 在B窗口里执行，查看帐户 12345678mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1000 || 2 | 李四 | 1000 |+----+--------+-------+2 行于数据集 (0.01 秒) 在A窗口里更新数据，并提交事务 12345mysql&gt; update yh set money=money+500 where id=1;Query OK, 1 rows affected (0.00 秒)mysql&gt; commit;Query OK, 0 rows affected (0.01 秒) 在B窗口里在次执行，查看帐户 12345678mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1500 || 2 | 李四 | 1000 |+----+--------+-------+2 行于数据集 (0.02 秒) 看着这二个数据本身觉得没有什么问题，如果这二次的数据分别是显示在银行职员的显示器上和发送给客户，那么银行的工作人员都不知道以什么为准了。 要解决不可重复读的问题我们要提高隔离级别？ 1234567891011mysql&gt; set global transaction_isolation=&#x27;repeatable-read&#x27;;Query OK, 0 rows affected (0.00 秒)#重启窗口查看隔离级别mysql&gt; select @@transaction_isolation;+-------------------------+| @@transaction_isolation |+-------------------------+| REPEATABLE-READ |+-------------------------+1 行于数据集 (0.01 秒) 案例： 恢复yh表中的数据为： image20200218104028518.png 打开A，B两个窗口，分别开启事务： 12mysql&gt; start transaction;Query OK, 0 rows affected (0.00 秒) 在B窗口里执行，查看帐户 12345678mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1000 || 2 | 李四 | 1000 |+----+--------+-------+2 行于数据集 (0.01 秒) 在A窗口里更新数据，并提交事务 12345mysql&gt; update yh set money=money+500 where id=1;Query OK, 1 rows affected (0.00 秒)mysql&gt; commit;Query OK, 0 rows affected (0.01 秒) 在B窗口里在次执行，查看帐户 12345678mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1000 || 2 | 李四 | 1000 |+----+--------+-------+2 行于数据集 (0.02 秒) 这样我们就解决了不可重复读的问题，提高我们的隔离级别。 九、幻读9.1、设置隔离级别1234567891011mysql&gt; set global transaction_isolation=&#x27;repeatable-read&#x27;;Query OK, 0 rows affected (0.00 秒)#重启窗口查看隔离级别mysql&gt; select @@transaction_isolation;+-------------------------+| @@transaction_isolation |+-------------------------+| REPEATABLE-READ |+-------------------------+1 行于数据集 (0.01 秒) 9.2、幻读恢复yh表中的数据为： image20200218104028518.png 打开A，B两个窗口，分别开启事务： 12mysql&gt; start transaction;Query OK, 0 rows affected (0.00 秒) 在A窗口里执行，查询ID为3的帐户 12mysql&gt; select * from yh where id=3;空的数据集 (0.00 秒) 在B窗口里执行，查询ID为3的帐户，没有就添加记录，并提交事务 123456789101112131415161718mysql&gt; select * from yh where id=3;空的数据集 (0.00 秒)mysql&gt; insert into yh values(3,&#x27;王五&#x27;,1000);Query OK, 1 rows affected (0.01 秒)mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1500 || 2 | 李四 | 1000 || 3 | 王五 | 1000 |+----+--------+-------+3 行于数据集 (0.01 秒)mysql&gt; commit;Query OK, 0 rows affected (0.09 秒) 在A窗口里执行，添加id为3的帐户 1234567891011mysql&gt; insert into yh values(3,&#x27;王五&#x27;,1000);Duplicate entry &#x27;3&#x27; for key &#x27;PRIMARY&#x27;mysql&gt; select * from yh;+----+--------+-------+| id | name | money |+----+--------+-------+| 1 | 张三 | 1500 || 2 | 李四 | 1000 |+----+--------+-------+2 行于数据集 (0.01 秒) 我们在A窗口中看不到新加人员的王五信息，但是我们想自己增加王五的信息也无加入的我们的数据库，这就是幻读。 要解决幻读的问题我们要提高隔离级别？ 1234567891011mysql&gt; set global transaction_isolation=&#x27;serializable&#x27;;Query OK, 0 rows affected (0.00 秒)#重启窗口查看隔离级别mysql&gt; select @@transaction_isolation;+-------------------------+| @@transaction_isolation |+-------------------------+| SERIALIZABLE |+-------------------------+1 行于数据集 (0.01 秒) 案例： 恢复yh表中的数据为： image20200218104028518.png 打开A，B两个窗口，分别开启事务： 12mysql&gt; start transaction;Query OK, 0 rows affected (0.00 秒) 在A窗口里执行，查询ID为3的帐户 12mysql&gt; select * from yh where id=3;空的数据集 (0.00 秒) 在B窗口里执行，查询ID为3的帐户，没有就添加记录，并提交事务 12345mysql&gt; select * from yh where id=3;空的数据集 (0.00 秒)mysql&gt; insert into yh values(3,&#x27;王五&#x27;，1000);| #光标闪烁，不能执行下去 这样我们就解决了幻读的问题，提高我们了融离级别。"},{"path":"/2023/07/11/MySQL数据库实战/MySQL 索引/","content":"在关系数据库中，索引是一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构，它是某个表中一列或若干列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单。索引的作用相当于图书的目录，可以根据目录中的页码快速找到所需的内容。 一、索引概述1.1、什么是索引索引是用于快速找出在某个列中拥有特定值的行。 如果没有索引，MySQL必须从第一条记录开始读完整个表，直到找出相关的行，表越大，查询数据所花费的时间就越多。 如果拥有索引，MySQL能够快速到达一个位置去搜索数据文件，而不必查看所有数据，那么将会节省很大一部分时间。 1.2、为什么建立索引如果有一张产品表，记录着4W产品的信息。有一个品牌的字段记录产品的品牌，现在想要查询出这个品牌的产品。 如果没有索引，那么将从表中第一条记录一条条往下遍历，直到找到该条信息为止。 如果拥有索引，那么会将该品牌字段，通过一定的方法进行存储，好让查询该字段上的信息时，能够快速找到对应的数据，而不必在遍历4W条产品数据。 1.3、索引存储分类其中MySQL中的索引的存储类型有两种：BTREE、HASH。要想知道在这二种存储类型中是如何查找的，那么就必须学会算法的知识，对于现在的我们只需要了解索引的作用及功能就好了。 1.4、索引优缺点优点： 所有的字段都可以被索引，也就是可以给任意字段设置索引 加快数据的查询速度 缺点： 创建索引和维护索引要耗费时间 数据量的增加，所耗费的时间也会增加 索引也需要占空间，如果我们的索引量越来越大的话，那么索引文件可能达到我们数据的最大线值 表中数据发生变化时，索引也需要动态维护，降低数据维护效率 1.5、索引的使用原则通过上面说的优点和缺点，我们可以看出，索引并不是越多越好，而是需要自己合理的使用。那么那些表应该去使用索引呢？ 避免使用过多索引： 经常更新的表、数据量小的表、相同值少的字段上等 使用索引： 经常查询的表、不同值较多的字段上等 一个表中很够创建多个索引，这些索引会被存放到一个索引文件中(专门存放索引的地方) 二、索引类型索引是在存储引擎中实现的，也就是说不同的存储引擎，会使用不同的索引。 MyISAM和InnoDB存储引擎：只支持BTREE索引， 也就是说默认使用BTREE MEMORY&#x2F;HEAP存储引擎：支持HASH和BTREE索引 MySQL目前主要有以下几种索引类型： 单列索引（普通索引、唯一索引、主键索引） 组合索引 全文索引 空间索引 2.1、单列索引-普通索引MySQL中普通索引并没有什么限制，纯粹为了查询数据更快一点。 可以在定义索引的字段中插入重复值和空值 创建表时创建索引 12345678格式：create table 表名( 字段名1 字段类型1, 字段名2 字段类型2, ... 字段名n 字段类型n, index/key 索引名(字段名(长度))); 案例： 1234567891011121314151617181920212223242526272829303132333435363738394041create table book( bid int primary key auto_increment, bname varchar(200), bcbs varchar(200), index(bname));create table book1( bid int primary key auto_increment, bname varchar(200), bcbs varchar(200), key(bname));mysql&gt; show create table book;+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| book | CREATE TABLE `book` ( `bid` int(11) NOT NULL AUTO_INCREMENT, `bname` varchar(200) DEFAULT NULL, `bcbs` varchar(200) DEFAULT NULL, PRIMARY KEY (`bid`), KEY `bname` (`bname`)) ENGINE=InnoDB DEFAULT CHARSET=gbk |+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 行于数据集 (0.01 秒)mysql&gt; show create table book1;+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| book1 | CREATE TABLE `book1` ( `bid` int(11) NOT NULL AUTO_INCREMENT, `bname` varchar(200) DEFAULT NULL, `bcbs` varchar(200) DEFAULT NULL, PRIMARY KEY (`bid`), KEY `bname` (`bname`)) ENGINE=InnoDB DEFAULT CHARSET=gbk |+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 行于数据集 (0.01 秒) 测试查询： 1mysql&gt; explain select * from book where bname=&#x27;计算机&#x27;; image20200217091133154.png id： select识别符。这是select的查询序列号，也就是一条语句中，该select是第几次出现。比如：在这条语句中select只出现了1次。 select_type： select查询类型。 simple：表示为简单的select，没有使用union或子查询，就是简单的select。 primary：表示最外面的select ，拥有子查询时，就会出现2次select。 union：表示第二层。在select 之后使用了 union subquery：在子查询中，第二SELECT。 table： 数据库表的名字。他们按被读取的先后顺序排列 type： 指定本数据表和其他数据表之间的关联关系。 ref： 就是连接程序无法根据键值只取得一条记录的情况。 system： 表只有一行记录（等于系统表）。 可能的取值有 const、eq_ref、index和all等 possible_keys： MySQL在搜索数据记录时可以选用的各个索引，该表中就只有一个索引，bname key： 实际选用的索引 key_len： 显示了mysql使用索引的长度(也就是使用的索引个数)，当 key 字段的值为 null时，索引的长度就是 null。注意，key_len的值可以告诉你在联合索引中mysql会真正使用了哪些索引。 ref： 给出关联关系中另一个数据表中数据列的名字。常量（const） rows： MySQL在执行这个查询时预计会从这个数据表里读出的记录条数。 extra： 提供了与关联操作有关的信息，没有则什么都不写。 2.2、单列索引-唯一索引唯一索引是索引列中的值必须是唯一的，允许为空值。在使用唯一索引时要加入记录。 创建表时创建索引 12345678格式：create table 表名( 字段名1 字段类型1, 字段名2 字段类型2, ... 字段名n 字段类型n, unique index 索引名(字段名(长度))); 案例： 12345678910111213141516171819create table book2( bid int, bname varchar(200), bcbs varchar(200), unique index unique_bid(bid));mysql&gt; show create table book2;+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| book2 | CREATE TABLE `book2` ( `bid` int(11) DEFAULT NULL, `bname` varchar(200) DEFAULT NULL, `bcbs` varchar(200) DEFAULT NULL, UNIQUE KEY `unique_bid` (`bid`)) ENGINE=InnoDB DEFAULT CHARSET=gbk |+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 行于数据集 (0.02 秒) 测试查询 1mysql&gt; explain select * from book2 where bid=1; image20200217092552395.png 注意： 要查看其中查询使用的索引，必须先往表中插入数据，然后在查询数据，不然查找一个没有的bid值，是不会使用索引的。 123mysql&gt; insert into book2 values(1,&#x27;计算机基础&#x27;,&#x27;清华出版社&#x27;);Query OK, 1 rows affected (0.06 秒)mysql&gt; explain select * from book2 where bid=1; image20200217092825869.png 可以看到，通过id查询时，会使用唯一索引。并且还实验了查询一个没有的id值，则不会使用索引。 2.3、单列索引-主键索引是一种特殊的唯一索引，不允许有空值。 创建表时创建索引 12345678格式：create table 表名( 字段名1 字段类型1, 字段名2 字段类型2, ... 字段名n 字段类型n, primary key 索引名(字段名(长度))); 案例： 12345678910111213141516171819create table book3( bid int, bname varchar(200), bcbs varchar(200), primary key(bid));mysql&gt; show create table book3;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| book3 | CREATE TABLE `book3` ( `bid` int(11) NOT NULL, `bname` varchar(200) DEFAULT NULL, `bcbs` varchar(200) DEFAULT NULL, PRIMARY KEY (`bid`)) ENGINE=InnoDB DEFAULT CHARSET=gbk |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 行于数据集 (0.02 秒) 测试查询 1234mysql&gt; insert into book3 values(1,&#x27;计算机基础&#x27;,&#x27;清华出版社&#x27;);Query OK, 1 rows affected (0.12 秒)mysql&gt; explain select * from book3 where bid=1; image20200217093610423.png 主键索引就是：我们以前声明的主键约束，就是一个主键索引。 2.4、组合索引在表中的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用，使用组合索引时遵循最左前缀集合。 创建表时创建索引 12345678格式：create table 表名( 字段名1 字段类型1, 字段名2 字段类型2, ... 字段名n 字段类型n, index 索引名(字段名1(长度),字段名2(长度),...字段名n(长度))); 案例： 123456789101112131415161718192021create table stu1( sid int, sname varchar(20), age int, sex varchar(2), index index_sid_sname_age(sid,sname,age));mysql&gt; show create table stu1;+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| stu1 | CREATE TABLE `stu1` ( `sid` int(11) DEFAULT NULL, `sname` varchar(20) DEFAULT NULL, `age` int(11) DEFAULT NULL, `sex` varchar(2) DEFAULT NULL, KEY `index_sid_sname_age` (`sid`,`sname`,`age`)) ENGINE=InnoDB DEFAULT CHARSET=gbk |+-------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 行于数据集 (0.01 秒) 注意： 最左前缀 组合索引就是遵从了最左前缀，利用索引中最左边的列集来匹配行，这样的列集称为最左前缀。 例如，这里由sid、sname和age 3个字段构成的索引，索引行中就按sid&#x2F;sname&#x2F;age的顺序存放，索引可以索引下面字段组合(sid，sname，age)、（sid,age）、(sid，sname)或者(sid)。如果要查询的字段不构成索引最左面的前缀，那么就不会是用索引，比如，age或者（sname，age）组合就不会使用索引查询 测试查询 1mysql&gt; explain select * from stu1 where sid=1 and sname=&quot;job&quot;; image20200217095020128.png 1mysql&gt; explain select * from stu1 where age=17 and sname=&quot;job&quot;; image20200217095150193.png 2.5、全文索引全文索引，只有在MyISAM引擎上才能使用，只能在CHAR,VARCHAR,TEXT类型字段上使用全文索引。 全文索引，就是在一堆文字中，通过其中的某个关键字等，就能找到该字段所属的记录行。 比如：有学员的备注信息里有”成绩很好，是一个好学生” 通过“好学生”，可能就可以找到该条记录。这里说的是可能，因为全文索引的使用涉及了很多细节。 创建表时创建索引 12345678格式：create table 表名( 字段名1 字段类型1, 字段名2 字段类型2, ... 字段名n 字段类型n, fulltext index 索引名(字段名(长度)))ENGINE=MyISAM; 案例： 1234567891011121314151617181920212223create table stu2( sid int, sname varchar(20), age int, sex varchar(2), info text, fulltext index full_info(info))ENGINE=MyISAM;mysql&gt; show create table stu2;+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| stu2 | CREATE TABLE `stu2` ( `sid` int(11) DEFAULT NULL, `sname` varchar(20) DEFAULT NULL, `age` int(11) DEFAULT NULL, `sex` varchar(2) DEFAULT NULL, `info` text, FULLTEXT KEY `full_info` (`info`)) ENGINE=MyISAM DEFAULT CHARSET=gbk |+-------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 行于数据集 (0.02 秒) 测试全文索引 1mysql&gt; explain select * from stu2 where match(info) against(&#x27;好学生&#x27;); image20200217100917184.png 注意： 在使用全文搜索时，限制较多： 需要使用MATCH函数 只能通过MyISAM引擎 只能在CHAR,VARCHAR,TEXT上设置全文索引 搜索的关键字默认至少要4个字符，搜索的关键字太短就会被忽略掉 2.6、空间索引空间索引是对空间数据类型的字段建立的索引。 MySQL中的空间数据类型有四种，GEOMETRY（几何类型）、POINT（点）、LINESTRING（线）、POLYGON（面）。在创建空间索引时，也要使用MyISAM引擎，创建空间索引的列也不能为null。 创建表时创建索引 12345678格式：create table 表名( 字段名1 字段类型1, 字段名2 字段类型2, ... 字段名n 字段类型n, spatial index 索引名(字段名(长度)))ENGINE = MyISAM; 案例： 123456789101112131415create table t( g geometry not null, spatial index s_g(g))ENGINE = MyISAM;mysql&gt; show create table t;+-------+------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------------------------------------------+| t | CREATE TABLE `t` ( `g` geometry NOT NULL, SPATIAL KEY `s_g` (`g`)) ENGINE=MyISAM DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------------------------------------------+1 行于数据集 (0.01 秒) 三、索引操作3.1、创建索引12格式：alter table 数据表名 add [unique|fulltext|spatial] [index|key] [索引名][字段名][asc|desc] 查看表中索引 12格式：show index from 数据库表名; 案例： 1mysql&gt; show index from book2; image20200217104030561.png Table:创建索引的表 Non_unique：表示索引非唯一，1代表 非唯一索引， 0代表 唯一索引，意思就是该索引是不是唯一索引 Key_name：索引名称 Seq_in_index 表示该字段在索引中的位置，单列索引的话该值为1，组合索引为每个字段在索引定义中的顺序(这个只需要知道单列索引该值就为1，组合索引为别的) Column_name：表示定义索引的列字段 Sub_part：表示索引的长度 Null：表示该字段是否能为空值 Index_type：表示索引类型 我们继续为book2加一个索引 1234mysql&gt; alter table book2 add index i_bname(bname);Query OK, 0 rows affected (0.07 秒)mysql&gt; show index from book2; image20200217104438329.png 3.2、删除索引12格式一：alter table 数据库表名 drop index 索引名; 案例： 删除book2中的i_bname索引 1234mysql&gt; alter table book2 drop index i_bname;Query OK, 0 rows affected (0.02 秒)mysql&gt; show index from book2; image20200217112753060.png 12格式二：drop index 索引名 on 数据库表名; 案例： 删除book2中的unique_bid索引 12345mysql&gt; drop index unique_bid on book2;Query OK, 0 rows affected (0.12 秒)mysql&gt; show index from book2;空的数据集 (0.01 秒)"},{"path":"/2023/07/11/MySQL数据库实战/MySQL 存储过程/","content":"存储过程（Stored Procedure）是在大型数据库系统中，一组为了完成特定功能的SQL 语句集，它存储在数据库中，一次编译后永久有效，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。存储过程是数据库中的一个重要对象。在数据量特别庞大的情况下利用存储过程能达到倍速的效率提升 一、存储过程概述1.1、什么是存储过程存储过程是数据库中的一个重要对象。 存储过程是在数据库系统中，一组为了完成特定功能的SQL 语句集。存储过程是存储在数据库中，一次编译后，到处运行。不需要再次编译，用户通过指定存储过程的名字并传递参数（如果该存储过程带有参数）来执行。 1.2、存储过程特点用来完成较复杂业务比较灵活，易修改，好编写，可编程性强编写好的存储过程可重复使用 1.3、存储过程优缺点优点 存储过程在创建的时候直接编译，sql语句每次使用都要编译，效率高。 存储过程可以被重复使用。 存储过程只连接一次数据库，sql语句在访问多张表时，连接多次数据库。 存储的程序是安全的。存储过程的应用程序授予适当的权限。缺点在那里创建的存储过程，就只能在那里使用，可移植性差。 开发存储过程时，标准不定好的话，后期维护麻烦。 没有具体的编辑器，开发和调试都不方便。 太复杂的业务逻辑，存储过程也解决不了。 二、存储过程创建2.1、创建格式12345格式：create procedure 过程名()begin......end; 案例： 查看员工与部门表中的全信息 12345678910111213141516171819202122232425262728293031create procedure dept_emp()begin\tselect * from dept;\tselect * from emp;end;mysql&gt; call dept_emp();+----+-----------+| id | name |+----+-----------+| 1 | 研发部 || 2 | 渠道部 || 3 | 教务部 || 4 | 执行部 |+----+-----------+4 行于数据集 (0.02 秒)+----+--------+--------+--------+------------+---------+| id | name | gender | salary | join_date | dept_id |+----+--------+--------+--------+------------+---------+| 1 | 张三 | 男 | 7200 | 2013-02-24 | 1 || 2 | 李四 | 男 | 3600 | 2010-12-02 | 2 || 3 | 王五 | 男 | 9000 | 2008-08-08 | 2 || 4 | 赵六 | 女 | 5000 | 2015-10-07 | 3 || 5 | 吴七 | 女 | 4500 | 2011-03-14 | 1 || 6 | 王一 | 男 | 8768 | 2013-12-05 | NULL || 7 | 王二 | 女 | NULL | NULL | NULL |+----+--------+--------+--------+------------+---------+7 行于数据集 (0.05 秒)Query OK, 0 rows affected (0.05 秒) 2.2、变量12345格式：declare 变量名 变量类型 default 默认值; #声明变量set 变量名=值; #变量赋值select 字段名 into 变量名 from 数据库表; #查询表中字段，完成变量赋值select 变量名; #显示变量 案例： 查看员工表中id&#x3D;1的员工的姓名 12345678910111213141516create procedure emp_name()begin\tdeclare ename varchar(20) default &#x27;&#x27;;\tselect name into ename from emp where id=1;\tselect ename;end;mysql&gt; call emp_name();+--------+| ename |+--------+| 张三 |+--------+1 行于数据集 (0.01 秒)Query OK, 0 rows affected (0.01 秒) 2.3、变量作用域存储过程中变量是有作用域的，作用范围在begin和end块之间，end结束变量的作用范围即结束。 变量可分为： 局部变量： begin和end块之间 全局变量： 放在所有代码块之前；传参变量是全局的，可以在多个块之间起作用 案例： 查看员工的人数与部门表中的部门数，并找出最高和最低工资（局部变量） 12345678910111213141516171819202122232425262728293031323334create procedure dept_or_emp()begin\tbegin declare e_n int default 0; declare d_n int default 0; select count(*) into e_n from emp; select count(*) into d_n from dept; select e_n,d_n;\tend;\tbegin declare max_s double default 0; declare min_s double default 0; select max(salary) into max_s from emp; select min(salary) into min_s from emp; select max_s,min_s;\tend;end;mysql&gt; call dept_or_emp();+------+------+| e_n | d_n |+------+------+| 7 | 4 |+------+------+1 行于数据集 (0.26 秒)+-------+-------+| max_s | min_s |+-------+-------+| 9000 | 3600 |+-------+-------+1 行于数据集 (0.26 秒)Query OK, 0 rows affected (0.26 秒) 查看员工的人数与部门表中的部门数，并找出最高和最低工资（全局变量） 12345678910111213141516171819202122232425262728293031323334create procedure dept_or_emp1()begin\tdeclare e_n int default 0;\tdeclare d_n int default 0;\tdeclare max_s double default 0;\tdeclare min_s double default 0;\tbegin select count(*) into e_n from emp; select count(*) into d_n from dept;\tend;\tbegin select max(salary) into max_s from emp; select min(salary) into min_s from emp;\tend;\tselect e_n,d_n,max_s,min_s;end;mysql&gt; call dept_or_emp1();+------+------+| e_n | d_n |+------+------+| 7 | 4 |+------+------+1 行于数据集 (0.22 秒)+-------+-------+| max_s | min_s |+-------+-------+| 9000 | 3600 |+-------+-------+1 行于数据集 (0.23 秒)Query OK, 0 rows affected (0.23 秒) 三、存储过程参数12345格式：create procedure 过程名([IN|OUT|INOUT] 参数名 参数数据类型 )begin......end; 注意： in：传入参数 out：传出参数 inout：可以传入也可以传出 3.1、in表示该参数的值必须在调用存储过程事指定，如果不显示指定为in,那么默认就是in类型。 案例： 根据传入的id查看员工的姓名。 123456789101112131415161718192021222324252627282930313233343536create procedure emp_id(eid int)begin\tdeclare ename varchar(20) default &#x27;&#x27;;\tselect name into ename from emp where id=eid;\tselect ename;end;mysql&gt; call emp_id(1);+--------+| ename |+--------+| 张三 |+--------+1 行于数据集 (0.01 秒)Query OK, 0 rows affected (0.01 秒)mysql&gt; call emp_id(2);+--------+| ename |+--------+| 李四 |+--------+1 行于数据集 (0.01 秒)Query OK, 0 rows affected (0.02 秒)mysql&gt; call emp_id(9);+-------+| ename |+-------+| |+-------+1 行于数据集 (0.01 秒)Query OK, 0 rows affected (0.01 秒) 3.2、outout参数也需要指定，但必须是变量，不能是常量。 案例： 根据传入的id，返回员工的姓名。 123456789101112131415161718create procedure emp_id1(eid int,out ename varchar(20))begin\tselect name into ename from emp where id=eid;end;mysql&gt; set @ename=&#x27;&#x27;;Query OK, 0 rows affected (0.02 秒)mysql&gt; call emp_id1(3,@ename);Query OK, 1 rows affected, 1 warnings (0.02 秒)mysql&gt; select @ename;+--------+| @ename |+--------+| 王五 |+--------+1 行于数据集 (0.02 秒) 3.3、inout如果既需要传入，同时又需要传出，则可以使用INOUT类型参数 案例： 根据传入的id，返回员工的id和姓名。 123456789101112131415161718192021create procedure emp_id2(inout eid int,out ename varchar(20))begin\tselect id,name into eid,ename from emp where id=eid;end;mysql&gt; set @eid=3;Query OK, 0 rows affected (0.01 秒)mysql&gt; set @ename=&#x27;&#x27;;Query OK, 0 rows affected (0.01 秒)mysql&gt; call emp_id2(@eid,@ename);Query OK, 1 rows affected (0.01 秒)mysql&gt; select @eid,@ename;+------+--------+| @eid | @ename |+------+--------+| 3 | 王五 |+------+--------+1 行于数据集 (0.01 秒) 四、存储过程条件4.1、if…else…end if1234567格式：if()then...else...end if; 案例： 输入一个id，判断他是否是偶数，偶数打印对应的姓名，奇数打印id 12345678910111213141516171819202122232425262728293031create procedure emp_if_id(eid int)begin\tdeclare ename varchar(20) default &#x27;&#x27;;\tif(eid%2=0)\tthen select name into ename from emp where id=eid; select ename; else select eid; end if;end;mysql&gt; call emp_if_id(2);+--------+| ename |+--------+| 李四 |+--------+1 行于数据集 (0.02 秒)Query OK, 0 rows affected (0.02 秒)mysql&gt; call emp_if_id(1);+------+| eid |+------+| 1 |+------+1 行于数据集 (0.01 秒)Query OK, 0 rows affected (0.01 秒) 4.2、if…elseif…else…endif12345678910格式：if()then...elseif()then...else...end if; 案例： 给id为1，2，3的员工加薪1000元，其他员工不变 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748create procedure emp_if_salary(eid int)begin\tdeclare esalary double default 0;\tif(eid=1)\tthen update emp set salary=salary+1000 where id=eid; elseif(eid=2) then update emp set salary=salary+1000 where id=eid; elseif(eid=3) then update emp set salary=salary+1000 where id=eid; else update emp set salary=salary where id=eid; end if; select salary into esalary from emp where id=eid; select esalary;end;mysql&gt; call emp_if_salary(1);+---------+| esalary |+---------+| 8200 |+---------+1 行于数据集 (0.03 秒)Query OK, 0 rows affected (0.05 秒)mysql&gt; call emp_if_salary(3);+---------+| esalary |+---------+| 10000 |+---------+1 行于数据集 (0.02 秒)Query OK, 0 rows affected (0.02 秒)mysql&gt; call emp_if_salary(9);+---------+| esalary |+---------+| 0 |+---------+1 行于数据集 (0.02 秒)Query OK, 0 rows affected (0.02 秒) 4.3、case123456格式：case()when... then...when... then...else...end case; 案例： 给id为1，2，3的员工加薪1000元，其他员工不变 1234567891011121314151617181920212223create procedure emp_case_salary(eid int)begin\tdeclare esalary double default 0;\tcase (eid)\twhen 1 then update emp set salary=salary+1000 where id=eid; when 2 then update emp set salary=salary+1000 where id=eid; when 3 then update emp set salary=salary+1000 where id=eid; else update emp set salary=salary where id=eid; end case; select salary into esalary from emp where id=eid; select esalary;end;mysql&gt; call emp_case_salary(3);+---------+| esalary |+---------+| 12000 |+---------+1 行于数据集 (0.02 秒)Query OK, 0 rows affected (0.02 秒) 五、存储过程循环5.1、while1234格式：while(表达式) do ...... end while; 案例： 通过id查询出员工表中的前5个员工的姓名 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748create procedure emp_view()begin\tdeclare eid int default 1;\tdeclare ename varchar(20) default &#x27;&#x27;;\twhile(eid&lt;=5) do select name into ename from emp where id=eid; select ename; set eid=eid+1;\tend while;\tend;mysql&gt; call emp_view();+--------+| ename |+--------+| 张三 |+--------+1 行于数据集 (0.01 秒)+--------+| ename |+--------+| 李四 |+--------+1 行于数据集 (0.01 秒)+--------+| ename |+--------+| 王五 |+--------+1 行于数据集 (0.02 秒)+--------+| ename |+--------+| 赵六 |+--------+1 行于数据集 (0.02 秒)+--------+| ename |+--------+| 吴七 |+--------+1 行于数据集 (0.03 秒)Query OK, 0 rows affected (0.03 秒) 5.2、repeat123456格式：repeat...until 条件 -- 条件成立，跳出循环....end repeat; 案例： 通过id查询出员工表中的前5个员工的姓名 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849create procedure emp_view1()begin\tdeclare eid int default 1;\tdeclare ename varchar(20) default &#x27;&#x27;;\trepeat select name into ename from emp where id=eid; select ename; set eid=eid+1;\tuntil eid&gt;5\tend repeat;\tend;mysql&gt; call emp_view1();+--------+| ename |+--------+| 张三 |+--------+1 行于数据集 (0.02 秒)+--------+| ename |+--------+| 李四 |+--------+1 行于数据集 (0.03 秒)+--------+| ename |+--------+| 王五 |+--------+1 行于数据集 (0.05 秒)+--------+| ename |+--------+| 赵六 |+--------+1 行于数据集 (0.06 秒)+--------+| ename |+--------+| 吴七 |+--------+1 行于数据集 (0.06 秒)Query OK, 0 rows affected (0.06 秒) 六、存储过程游标游标是保存查询结果的临时区域 12345格式：declare 游标名 cursor for SQL语句; #声明游标open 游标名; #打开游标fetch 游标名 into 变量名; #取出游标的值close 游标名; #关闭游标 案例： 输出员工表中的id和姓名 1234567891011121314151617181920create procedure emp_all_view()begin\tdeclare eid int default 1;\tdeclare ename varchar(20) default &#x27;&#x27;;\tdeclare c_emp cursor for select id,name from emp;\topen c_emp;\tfetch c_emp into eid,ename;\tselect eid,ename;\tclose c_emp;end;mysql&gt; call emp_all_view();+------+--------+| eid | ename |+------+--------+| 1 | 张三 |+------+--------+1 行于数据集 (0.03 秒)Query OK, 0 rows affected (0.03 秒) 这样我们只取出了一条信息，这个时候我们需要循环？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465create procedure emp_all_view1()begin\tdeclare eid int default 1;\tdeclare ename varchar(20) default &#x27;&#x27;;\tdeclare c_emp cursor for select id,name from emp; open c_emp;\tloop fetch c_emp into eid,ename; select eid,ename;\tend loop;\tclose c_emp;end;mysql&gt; call emp_all_view1();+------+--------+| eid | ename |+------+--------+| 1 | 张三 |+------+--------+1 行于数据集 (0.01 秒)+------+--------+| eid | ename |+------+--------+| 2 | 李四 |+------+--------+1 行于数据集 (0.02 秒)+------+--------+| eid | ename |+------+--------+| 3 | 王五 |+------+--------+1 行于数据集 (0.03 秒)+------+--------+| eid | ename |+------+--------+| 4 | 赵六 |+------+--------+1 行于数据集 (0.03 秒)+------+--------+| eid | ename |+------+--------+| 5 | 吴七 |+------+--------+1 行于数据集 (0.03 秒)+------+--------+| eid | ename |+------+--------+| 6 | 王一 |+------+--------+1 行于数据集 (0.04 秒)+------+--------+| eid | ename |+------+--------+| 7 | 王二 |+------+--------+1 行于数据集 (0.05 秒)No data - zero rows fetched, selected, or processed 七、存储过程操作7.1、存储过程查看12格式：show procedure status [like &#x27;%字符串%&#x27;]; 案例： 12mysql&gt; show procedure status;mysql&gt;show procedure status like &#x27;%emp%&#x27;; image20200221144121604.png 7.2、存储过程删除12格式：drop procedure 存储过程名; 案例： 12mysql&gt; drop procedure emp_id;Query OK, 0 rows affected (0.02 秒) 八、自定义函数8.1、自定义函数创建函数与存储过程最大的区别是函数必须有返回值，否则会报错 123456格式：create function 函数名(参数) returns 返回类型begin.....return 返回值;end; 案例： 通过输入的id获取员工的姓名 123456create function getName(eid int) returns varchar(20)begin\tdeclare ename varchar(20) default &#x27;&#x27;;\tselect name into ename from emp where id=eid;\treturn ename;end; image20200221152753864.png 注意： 这是我们开启了bin-log, 我们就必须指定我们的函数指定一个参数deterministic 不确定的no sql 没有SQL语句，当然也不会修改数据reads sql data 只是读取数据，当然也不会修改数据modifies sql data 要修改数据contains sql 包含了SQL语句 1234567891011121314create function getName(eid int) returns varchar(20) reads sql databegin\tdeclare ename varchar(20) default &#x27;&#x27;;\tselect name into ename from emp where id=eid;\treturn ename;end;mysql&gt; select getName(1);+------------+| getName(1) |+------------+| 张三 |+------------+1 行于数据集 (0.02 秒) 8.2、自定义函数操作8.2.1、自定义函数查询12格式：show function status [like &#x27;%字符串%&#x27;]; 案例： 12mysql&gt; show function status；mysql&gt; show function status like &#x27;%getName%&#x27;; image20200221154839122.png 8.2.2、自定义函数删除12格式：drop function 函数名; 案例： 12mysql&gt; drop function getName;Query OK, 0 rows affected (0.03 秒) 九、触发器触发器与函数、存储过程一样，触发器是一种对象，它能根据对表的操作时间，触发一些动作，这些动作可以是insert,update,delete等操作。 9.1、触发器创建1234create trigger 触发器名字 触发时间 触发事件 on 表 for each rowbegin -- 触发器内容主体，每行用分号结尾end 注意： 触发时间： 当 SQL 指令发生时，会令行中数据发生变化，而每张表中对应的行有两种状态：数据操作前和操作后 before：表中数据发生改变前的状态 after：表中数据发生改变后的状态 触发事件： 触发器是针对数据发送改变才会被触发，对应的操作只有insert、update、delete 案例： 向员工表中插入数据时，记录插入的id，动作，时间 123456789101112131415161718192021222324252627#创建一个操作表create table emp_log(\tid int primary key auto_increment, eid int, eaction varchar(20), etime datetime);mysql&gt; select * from emp_log;空的数据集 (0.01 秒)#创建触发器create trigger emp_insert after insert on emp for each rowbegin\tinsert into emp_log values(null,NEW.id,&#x27;insert&#x27;,now());end;mysql&gt; insert into emp(id,name,gender)values(8,&#x27;王三&#x27;,&#x27;男&#x27;);Query OK, 1 rows affected (0.01 秒)mysql&gt; select * from emp_log;+----+------+---------+---------------------+| id | eid | eaction | etime |+----+------+---------+---------------------+| 1 | 8 | insert | 2020-02-21 03:12:44 |+----+------+---------+---------------------+1 行于数据集 (0.02 秒) 9.2、触发器操作9.2.1、触发器查看12格式：show triggers [like &#x27;%字符串%&#x27;]; 案例： 12mysql&gt; show triggers;mysql&gt; show triggers like &#x27;%emp%&#x27;; image20200221161653246.png 9.2.2、触发器删除12格式：drop trigger 触发器名; 案例： 12mysql&gt; drop trigger emp_insert;Query OK, 0 rows affected (0.02 秒) 十、事件事件取代了原先只能由操作系统的计划任务来执行的工作，而且MySQL的事件调度器可以精确到每秒钟执行一个任务，而操作系统的计划任务只能精确到每分钟执行一次。 10.1、事件创建1234567格式：create event[IF NOT EXISTS] event_name -- 创建事件on schedule 时间和频率 -- on schedule 什么时候来执行[on completion [NOT] preserve] -- 调度计划执行完成后是否还保留[enable | disable] -- 是否开启事件，默认开启[comment &#x27;事件描述&#x27;] -- 事件的注释do event_body;-- 需要执行的SQL 注意： 单次计划任务示例在2019年2月1日4点执行一次 on schedule at ‘2019-02-01 04:00:00’ 重复计划执行on schedule every 1 second 每秒执行一次on schedule every 1 minute 每分钟执行一次on schedule every 1 day 没天执行一次 指定时间范围的重复计划任务每天在20:00:00执行一次 on schedule every 1 day starts ‘2019-02-01 20:00:00’ 案例： 每5秒向emp_log,插入当前日期时间记录 1mysql&gt; desc emp_log; image20200221171724196.png 123456789create event e_insert on schedule every 5 second on completion preserveenablecomment &#x27;每5秒插入一次&#x27;dobegin\tinsert into emp_log values(null,1,&#x27;insert1&#x27;,now());end;#do call 存储过程 #do select 函数名 10.2、事件操作10.2.1、查看事件12格式：show events; 案例： 1mysql&gt; show events; image20200221174040539.png 10.2.2、启用和禁用事件12格式：alter event 事件名 disable/enable; 禁用事件 1234mysql&gt; alter event e_insert disable;Query OK, 0 rows affected (0.01 秒)mysql&gt; select * from emp_log; image20200221174401961.png 启用事件 1234mysql&gt; alter event e_insert enable;Query OK, 0 rows affected (0.02 秒)mysql&gt; select * from emp_log; image20200221174452171.png 10.2.3、删除事件12格式：drop event 事件名; 案例： 12345mysql&gt; drop event e_insert;Query OK, 0 rows affected (0.02 秒)mysql&gt; show events;空的数据集 (0.01 秒)"},{"path":"/2023/07/11/MySQL数据库实战/MySQL DCL语句/","content":"数据控制语言 (Data Control Language) 在SQL语言中，是一种可对数据访问权进行控制的指令，它可以控制特定用户账户对数据表、查看表、存储程序、用户自定义函数等数据库对象的控制权。由 GRANT 和 REVOKE 两个指令组成。 一、DCL概述1.1、什么是DCLDCL 语句主要是DBA 用来管理系统中的对象权限时所使用，一般的开发人员很少使用。 DCL中主要包括创建用户、给用户授权、对用户撤销授权、查询用户授权和删除用户等操作。 1.2、为什么学习DCL在一个企业里面的数据库服务器上面可能同时运行着很多个项目的数据库。所以，我们应该可以根据不同的项目建立不同的用户，分配不同的权限来管理和维护数据库。 二、用户管理mysql数据库的用户都在mysql数据库下面的user表中 2.1、查看用户12格式：select * from user; 案例： 123mysql&gt; select * from user;mysql&gt; select user,host,plugin,authentication_string from user; image20200218234525100.png 2.2、创建用户12格式：create user &#x27;用户名&#x27;@&#x27;主机名&#x27; identified by &#x27;密码&#x27;; 注意： 用户名： 新用户的名字 主机名： 指定该用户在哪个主机上可以登陆，如果是本地用户可用localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符% 密码： 密码可以为空，如果为空则该用户可以不需要密码登陆服务器 案例： 创建一个用户root1，只能在本机登录（localhost） 1234mysql&gt; create user &#x27;root1&#x27;@&#x27;localhost&#x27; identified by &#x27;123&#x27;;Query OK, 0 rows affected (0.02 秒)mysql&gt; select user,host,plugin,authentication_string from user; image20200219000040373.png 创建一个用户root2，可以在任何主机（%）登录 1234mysql&gt; create user &#x27;root2&#x27;@&#x27;%&#x27; identified by &#x27;123&#x27;;Query OK, 0 rows affected (0.01 秒)mysql&gt; select user,host,plugin,authentication_string from user; image20200219000412028.png 注意： 指定加密方式，增加用户 1234mysql&gt; create user &#x27;root3&#x27;@&#x27;%&#x27; identified with mysql_native_password by &#x27;123&#x27;;Query OK, 0 rows affected (0.01 秒)mysql&gt; select user,host,plugin,authentication_string from user; image20200219001939522.png 2.3、删除用户1drop user &#x27;用户名&#x27;@&#x27;主机名&#x27;; 案例： 删除root1 1234mysql&gt; drop user root1@localhost;Query OK, 0 rows affected (0.01 秒)mysql&gt; select user,host,plugin,authentication_string from user; 三、密码管理3.1、修改用户密码12格式：alter user &#x27;用户名&#x27;@&#x27;主机名&#x27; identified by &#x27;密码&#x27;; 案例： 修改root2的密码 12mysql&gt; alter user &#x27;root2&#x27;@&#x27;%&#x27; identified by &#x27;456&#x27;;Query OK, 0 rows affected (0.02 秒) 注意： 如果想用该root2用户连接上mysql服务端的话，我们的密码修改时应该是： 12mysql&gt; alter user &#x27;root2&#x27;@&#x27;%&#x27; identified with mysql_native_password by &#x27;456&#x27;;Query OK, 0 rows affected (0.02 秒) 3.2、设置管理员（root）密码清空密码 123use mysql; update user set authentication_string=&#x27;&#x27; where user=&#x27;root&#x27;;#设置提root用户的密码为‘’，本地，远程 设置密码 12alter user &#x27;root&#x27;@&#x27;%&#x27; identified by &#x27;Root12345&#x27;;alter user &#x27;root&#x27;@&#x27;localhost&#x27; identified by &#x27;Root12345&#x27;; 四、权限管理4.1、查看用户权限12格式：show grants for &#x27;用户名&#x27;@&#x27;主机名&#x27;; 案例： 查看’root2’，’root3’及’root’权限 1234567891011121314151617mysql&gt; show grants for &#x27;root2&#x27;@&#x27;%&#x27;;+-----------------------------------+| Grants for root2@% |+-----------------------------------+| GRANT USAGE ON *.* TO `root2`@`%` |+-----------------------------------+1 行于数据集 (0.01 秒)mysql&gt; show grants for &#x27;root3&#x27;@&#x27;%&#x27;;+-----------------------------------+| Grants for root3@% |+-----------------------------------+| GRANT USAGE ON *.* TO `root3`@`%` |+-----------------------------------+1 行于数据集 (0.02 秒)mysql&gt; show grants for &#x27;root&#x27;@&#x27;%&#x27; image20200219002900607.png 4.2、授权12格式：grant 权限 1, 权限 2... on 数据库名.表名 to &#x27;用户名&#x27;@&#x27;主机名&#x27;; 注意： grant… on …to ：授权关键字 权限： 如select\\insert\\update\\delete等，如果是所有用all 数据库名.表名： 该用户可以操作哪个数据库的哪些表。如果要授予该用户对所有数据库和表的相应操作权限则可用表示，如.* ’用户名’@‘主机名’ ： 注意单引号不能省略 案例： 给’root2’分配，增加、删除、修改、查询表的权限 1mysql&gt; grant insert,delete,update,select on zutuanxue.* to &#x27;root2&#x27;@&#x27;%&#x27;; 给’root3’分配所有权限 1mysql&gt; grant all on *.* to &#x27;root3&#x27;@&#x27;%&#x27;; 4.3、撤销授权12格式：revoke 权限 1, 权限 2... on 数据库名.表名 from &#x27;用户名&#x27;@&#x27;主机名&#x27;; 注意： revoke… on …from ： 撤消授权关键字 权限： 如select\\insert\\update\\delete等，如果是所有用all 数据库名.表名： 该用户可以操作哪个数据库的哪些表。如果要撤消授予该用户对所有数据库和表的相应操作权限则可用表示，如.* ’用户名’@‘主机名’ ： 注意单引号不能省略 案例： 撤消’root2’的权限 12mysql&gt; revoke all on zutuanxue.* from &#x27;root2&#x27;@&#x27;%&#x27;;Query OK, 0 rows affected (0.01 sec)"},{"path":"/2023/07/11/MySQL数据库实战/MySQL AB复制/","content":"mysql AB复制实战mysqldump解决了mysql数据库的备份，它只是基于某个时间点做备份，无法解决实时备份的问题，为了解决mysql实时备份的问题，mysql官方推出了mysql主从备份机制，可以让用户通过设置mysql主从来实现数据库实时备份。 1、MySQL服务器宕机怎么 单点故障 2、数据的安全 一、mysql AB复制通过多台机器实现一主多从的方式来实现数据备份，主服务器负责让用户读写数据，从服务器负责同步主服务器数据，也可以承担用户读的任务。 至少两台机器 二、AB复制原理mysql_ab_原理.jpg 1、用户or web 对主服务器的所有修改操作都会记录在binary log日志 成功的修改操作【增加 修改 删除】 记录的是SQL语句 主上的一个线程 2、从 有两个线程 IO线程：负责连接主mysql【AB通信 A授权账号】提取binlog中的SQL语句到relay log SQL线程：在本地执行relay log中新增的SQL语句 注意：AB是异步 三、master服务器设置实验拓扑 mysql_ab拓扑图.png 安装mysql并启动 关闭防火墙,selinux 设置时间服务器 修改配置文件 设置server-id&#x3D;N 创建slave连接master的账号，用于取SQL语句 3.1、安装mysql并启动a、安装mysql 12官网下载mysql yum源，安装安装方法：yum -y install mysql-server mysql b、启动mysql 1systemctl enable mysqld;systemctl start mysqld c、修改root密码 12mysql&gt; alter user &#x27;root&#x27;@&#x27;localhost&#x27; identified by &#x27;98989&#x27;;Query OK, 0 rows affected (0.01 sec) 3.2、关闭防火墙,selinux12345678[root@node1 ~]# systemctl disable firewalld[root@node1 ~]# iptables -F[root@node1 ~]# iptables -t nat -F[root@node1 ~]# sed -i -r &#x27;/SELINUX=/c\\SELINUX=disabled&#x27; /etc/selinux/config[root@node1 ~]# reboot其他机器同理 3.3、设置时间服务器123456789101112131415禁止向centos默认时间服务器同步时间[root@node1 ~]# sed -i.bak &#x27;/^pool 2.centos.pool.ntp.org iburst$/s//#/&#x27; /etc/chrony.conf 设置时间服务器为阿里云的[root@node1 ~]# cat &gt;&gt; /etc/chrony.conf &lt;&lt;EOF&gt; server ntp1.aliyun.com&gt; server ntp2.aliyun.com&gt; server ntp3.aliyun.com&gt; server ntp4.aliyun.com&gt; EOF重启服务生效[root@node1 ~]# systemctl restart chronyd查看命令，看一下时间服务器IP地址[root@node1 ~]# chronyc sources -v 3.4、修改配置文件 设置server-id&#x3D;Nserver-id的数字越小，优先级越高。 1[root@node1 ~]# echo &quot;server-id=1&quot; &gt;&gt; /etc/my.cnf.d/mysql-server.cnf 确认binlog是开启的 1如果没有开启 log-bin=binlog 3.5、创建slave连接master的账号，用于取SQL语句登陆进入mysql: mysql -u root -p password: 12345678mysql&gt; create user sko identified by &quot;98989&quot;;Query OK, 0 rows affected (0.00 sec)mysql&gt; grant replication slave on *.* to sko;Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 查看主的状态 12345678910111213141516171819mysql&gt; show master status \\G;*************************** 1. row *************************** File: binlog.000002 Position: 155 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)ERROR: No query specifiedmysql&gt; mysql&gt; create database db1;Query OK, 1 row affected (0.00 sec)File: binlog.000002 当前主的binlog日志Position: 155 当前binlog日志的SQL语句记录点 四、slave设置实验步骤 安装mysql并启动 关闭防火墙、selinux 设置时间服务器 修改配置文件 设置server-id&#x3D;N+x 设置master主信息 测试同步 12345- [4.1] 安装mysql并启动- [4.2] 关闭防火墙、selinux- [4.3] 设置时间服务器省略...... 4.3、修改配置文件 设置server-id&#x3D;N+x从服务器的server-id要比主的数字大。 1[root@node2 ~]# echo &quot;server-id=2&quot; &gt;&gt; /etc/my.cnf.d/mysql-server.cnf 4.4、设置slave同步12345678mysql&gt; stop slave;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; change master to master_host=&#x27;192.168.98.201&#x27;,master_user=&#x27;sko&#x27;,master_password=&#x27;98989&#x27;,master_log_file=&#x27;binlog.000002&#x27;;Query OK, 0 rows affected, 3 warnings (0.01 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec) 4.5、验证slave123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566mysql&gt; show slave status \\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.98.201 Master_User: sko Master_Port: 3306 Connect_Retry: 60 Master_Log_File: binlog.000002 Read_Master_Log_Pos: 337 Relay_Log_File: node2-relay-bin.000002 Relay_Log_Pos: 545 Relay_Master_Log_File: binlog.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 337 Relay_Log_Space: 753 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: ae106b21-59c3-11ea-aa77-000c29b8d045 Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: Master_public_key_path: Get_master_public_key: 0 Network_Namespace: 1 row in set (0.00 sec)ERROR: No query specified 4.6、干货分享，如何解决AB不同步的问题123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131Slave_IO_Running: Yes#该线程负责从master上拿binlog日志到relaylog，复制线程#该线程如果是NO，如何排除#1、查主从网络是否能通信，iptables selinux#2、查你的repl账号在slave上是否能连接masterSlave_SQL_Running: Yes#该线程负责将本机relaylog中的SQL语句执行一次#该线程为NO,如何排除#该线程为NO说明relaylog中的SQL语句在本地无法执行#1、查看mysql&gt; show slave status \\G; 找到不能执行的语句mysql&gt; show slave status \\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.98.201 Master_User: sko Master_Port: 3306 Connect_Retry: 60 Master_Log_File: binlog.000002 Read_Master_Log_Pos: 515 Relay_Log_File: node2-relay-bin.000002 Relay_Log_Pos: 545 Relay_Master_Log_File: binlog.000002 Slave_IO_Running: Yes Slave_SQL_Running: No Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 1008 Last_Error: Error &#x27;Can&#x27;t drop database &#x27;db1&#x27;; database doesn&#x27;t exist&#x27; on query. Default database: &#x27;db1&#x27;. Query: &#x27;drop database db1&#x27; Skip_Counter: 0 Exec_Master_Log_Pos: 337 Relay_Log_Space: 931 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: NULLMaster_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 1008 Last_SQL_Error: Error &#x27;Can&#x27;t drop database &#x27;db1&#x27;; database doesn&#x27;t exist&#x27; on query. Default database: &#x27;db1&#x27;. Query: &#x27;drop database db1&#x27; Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: ae106b21-59c3-11ea-aa77-000c29b8d045 Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: 200227 20:36:57 Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: Master_public_key_path: Get_master_public_key: 0 Network_Namespace: 1 row in set (0.00 sec)ERROR: No query specified#这段就能看到为何不能执行，原因是slave上没有db1数据库，所以不能删除。 Last_SQL_Error: Error &#x27;Can&#x27;t drop database &#x27;db1&#x27;; database doesn&#x27;t exist&#x27; on query. Default database: &#x27;db1&#x27;. Query: &#x27;drop database db1&#x27; #2、最关键的一步，如何定位错误点 #Read_Master_Log_Pos: 515 找到目前复制的master Binlog日志的pos位置，从这个位置开始,后续在slave上做差异还原同步。 #拓展：如何找下一个POS位置，去看你master的当前binlog日志 #定位错误点SQL语句的位置号[root@node1 ~]# mysqlbinlog /var/lib/mysql/binlog.000002|egrep -B 30 &quot;drop database db1&quot;.........# at 414 错误点SQL语句的位置号#200227 20:36:57 server id 1 end_log_pos 515 CRC32 0x683207a9 Query\tthread_id=8\texec_time=0\terror_code=0\tXid = 17SET TIMESTAMP=1582853817/*!*/;drop database db1..........#定位错误点SQL语句之后一条的位置号[root@node1 ~]# mysqlbinlog /var/lib/mysql/binlog.000002|egrep -A 30 &quot;drop database db1&quot;drop database db1/*!*/;# at 515 发现下一条SQL语句是515#200227 20:42:37 server id 1 end_log_pos 592 CRC32 0x2677edde Anonymous_GTID\tlast_committed=2\tsequence_number=3\trbr_only=no\toriginal_committed_timestamp=1582854157245396\timmediate_commit_timestamp=1582854157245396\ttransaction_length=182# original_commit_timestamp=1582854157245396 (2020-02-27 20:42:37.245396 EST)# immediate_commit_timestamp=1582854157245396 (2020-02-27 20:42:37.245396 EST)/*!80001 SET @@session.original_commit_timestamp=1582854157245396*//*!*/;/*!80014 SET @@session.original_server_version=80017*//*!*/;/*!80014 SET @@session.immediate_server_version=80017*//*!*/;SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27;/*!*/;# at 592#200227 20:42:37 server id 1 end_log_pos 697 CRC32 0x3624f753 Query\tthread_id=11\texec_time=0\terror_code=0\tXid = 24SET TIMESTAMP=1582854157/*!*/;/*!80016 SET @@session.default_table_encryption=0*//*!*/;create database db2/*!*/;....................#发现下一条SQL语句是515#通过上述命令可以查看pos 515之后的语句，-A 30 是指往后30行 -B 30是看往前30行，根据自己的需求设置 #3、重新设置同步指令mysql&gt; stop slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; change master to master_host=&#x27;192.168.98.201&#x27;,master_user=&#x27;sko&#x27;,master_password=&#x27;98989&#x27;,master_log_file=&#x27;binlog.000002&#x27;,master_log_pos=515;Query OK, 0 rows affected, 2 warnings (0.01 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec)"},{"path":"/2023/07/11/MySQL数据库实战/DQL语句排序与分组/","content":"一、DQL-排序排序是计算机内经常进行的一种操作，其目的是将一组“无序”的记录序列调整为“有序”的记录序列。分内部排序和外部排序，若整个排序过程不需要访问外存便能完成，则称此类排序问题为内部排序。反之，若参加排序的记录数量很大，整个序列的排序过程不可能在内存中完成，则称此类排序问题为外部排序。内部排序的过程是一个逐步扩大记录的有序序列长度的过程。 1.1、排序概述将数据库表中杂乱无章的数据记录，通过字段的升序或降序的顺序排列的过程叫做排序。 1.2、排序语法通过order by子句 123456格式：select */字段列表 from 数据库表名 [where 条件表达式] [order by 字段名 [asc/desc]]LIMIT 值1，值2; 说明： asc：升序，默认值 desc：降序 1.3、单列排序按照一个字段进行排序 案例： 查看学生信息表中按照英语成绩升序排列，去掉成绩为null的学生。 12345678910111213mysql&gt; select * from students where english is not null order by english;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 || 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 |+------+--------+------+------+---------+------+------------+-----------------+7 行于数据集 (0.01 秒) 1.4、组合排序按照多个字段进行排序，先按1字段排序，在按2字段排序，在按n字段排序 12格式：select */字段列表 from 数据库表名 [where 条件表达式] [order by 字段名1 [asc/desc],字段名2 [asc/desc],...,字段名n [asc/desc]]; 案例： 查看学生信息表中先按照数学成绩升序排列，在按照英语成绩降序排列，最后去掉成绩为null的学生。 12345678910111213mysql&gt; select * from students where english is not null order by math,english desc;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+7 行于数据集 (0.02 秒) 二、DQL 分组数据分组是根据统计研究的需要，将原始数据按照某种标准划分成不同的组别，分组后的的数据称为分组数据。 数据分组应遵循两个基本原则： 穷尽性原则 这一原则就是要求调查的每一单位都能无一例外地划归到某一组去，不会产生“遗漏”现象。 互斥性原则 这一原则就是要求将调查单位分组后，各个组的范围应该互不相容、互为排斥。即每个调查单位在特定的分组标志下只能归属某一组，而不能同时或可能同时归属到几个组。 2.1、分组概述 什么是分组 分组就是将一组行记录按列或表达式的值分组成摘要行记录。通过GROUP BY子句返回每个分组的一个行记录。换句话说，它减少了在结果集中的行数。 分组语法 – 语法 12格式：select */字段列表 from 数据库表名 [group by 分组字段名 [having 条件表达式]]; – 分组方式 将学生信息表中男、女同学进行分组 image20200209001000938.png 原始数据 image20200209001300283.png 分组为：男一组，女一组 image20200209001300283.png 返回每组第一条数据 image20200209002544753.png 2.2、分组应用 实际分组方式 12345678mysql&gt; select sex from students group by sex;+------+| sex |+------+| 男 || 女 |+------+2 行于数据集 (0.01 秒) 注意： 当我们使用某个字段分组,在查询的时候也需要将这个字段查询出来,否则看不到数据属于哪组的。 单独分组没什么用处，分组的目的就是为了统计，一般分组会跟聚合函数一起使用。 案例： 查询学生信息表中男、女同学的人数 12345678mysql&gt; select sex,count(*) from students group by sex;+------+----------+| sex | count(*) |+------+----------+| 男 | 6 || 女 | 3 |+------+----------+2 行于数据集 (0.01 秒) where与having – where** 查询学生信息表中数学成绩在80分以上的，男、女同学的人数 123456789#where后面不能用聚合函数mysql&gt; select sex,count(*) from students where math&gt;80 group by sex;+------+----------+| sex | count(*) |+------+----------+| 男 | 4 || 女 | 1 |+------+----------+2 行于数据集 (0.01 秒) 注意： where是将不符合条件的先去掉，在分组。 – having 查询学生信息表中男、女同学的人数，人数超过3人显示 12345678#having n&gt;3 可以写成 having count(*)&gt;3mysql&gt; select sex,count(*) as n from students group by sex having n&gt;3;+------+---+| sex | n |+------+---+| 男 | 6 |+------+---+1 行于数据集 (0.03 秒) 注意： having是先分组，在将分组后不符合条件的去掉。 – where与having区别 where 子句 在分组之前过滤数据，即先过滤再分组。 where 后面不可以使用聚合函数。 having 子句 在分组之后过滤数据，即先分组再过滤。 having 后面可以使用聚合函数。"},{"path":"/2023/07/11/MySQL数据库实战/DQL语句/","content":"DQL（Data QueryLanguage ）数据查询语言，基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块。 一、DQL概述1.1、什么是DQLDQL：数据查询语言，用于从数据库表中查询数据，并不会修改数据，只是一种显示数据的方式。由select语句构成。 1.2、记录查询格式12格式：select */字段列表 from 数据库表名 [where 条件表达式]; 格式说明： select *&#x2F;字段列表： 查询完后需要展示的字段 from 数据库表名： 指定要查询的数据库表 [where 条件表达式]： 查询满足条件的记录 二、记录查询2.1、简单查询查询表中的记录和列 1234格式：select * from 数据库表名; #查询表中所有记录,显示所有列或select 字段名1,字段名2,...,字段名n from 数据库表名; #查询表中所有记录，显示指定列 案例： 查询student表中的所有记录，显示所有列 12345678910#显示所有记录mysql&gt; select * from student;+------+-----------+------------+------+| id | sname | birthday | sex |+------+-----------+------------+------+| 1 | 郭德纲 | 1973-01-18 | 男 || 2 | 林志颖 | 1974-10-18 | 男 || 3 | 柳岩 | 1980-11-08 | 女 |+------+-----------+------------+------+3 行于数据集 (0.01 秒) 查询student表中的所有记录，显示所有姓名、性别列 12345678910#显示所有记录,显示列为姓名、性别mysql&gt; select sname,sex from student;+-----------+------+| sname | sex |+-----------+------+| 郭德纲 | 男 || 林志颖 | 男 || 柳岩 | 女 |+-----------+------+3 行于数据集 (0.01 秒) 2.2、别名查询别名有二种：字段别名、表别名 作用： 字段别名查询出记录显示新的名字，并不影响表的结构。 表别名取了一个新的名字，可以代替表名使用。 字段别名 12格式：select 字段名1 as 别名1,字段名2 as 别名2,...,字段名n as 别名n from 数据库表名; 案例： 查询student表中的sname和sex，以别名’姓名’和’性别’显示 12345678910#使用字段别名显示姓名、性别mysql&gt; select sname as 姓名,sex as 性别 from student;+-----------+------+| 姓名 | 性别 |+-----------+------+| 郭德纲 | 男 || 林志颖 | 男 || 柳岩 | 女 |+-----------+------+3 行于数据集 (0.01 秒) 表别名 12格式：select 字段名1 as 别名1,字段名2 as 别名2,...,字段名n as 别名n from 数据库表名 as 别名; 案例： 查询student表中的sname和sex，以别名’姓名’和’性别’显示，并为student表取了一个别名 s 12345678910#使用字段别名显示姓名、性别，表别名没有具体表现mysql&gt; select sname as 姓名,sex as 性别 from student as s;+-----------+------+| 姓名 | 性别 |+-----------+------+| 郭德纲 | 男 || 林志颖 | 男 || 柳岩 | 女 |+-----------+------+3 行于数据集 (0.01 秒) 注意： 表别名一般用于多表查询，单表查询中没有具体体现。 2.3、清除重复记录查询12格式：select distinct 字段名 from 数据库表名; 案例： 去掉性别重复的记录 去掉性别和姓名同时重复的记录 1234567891011121314151617181920212223242526272829#查看所有记录mysql&gt; select * from student;+------+-----------+------------+------+| id | sname | birthday | sex |+------+-----------+------------+------+| 1 | 郭德纲 | 1973-01-18 | 男 || 2 | 林志颖 | 1974-10-18 | 男 || 3 | 柳岩 | 1980-11-08 | 女 |+------+-----------+------------+------+3 行于数据集 (0.01 秒)#查看sex不重复的记录mysql&gt; select distinct sex from student;+------+| sex |+------+| 男 || 女 |+------+2 行于数据集 (0.01 秒)#查看sex,sname都不重复的记录mysql&gt; select distinct sex,sname from student;+------+-----------+| sex | sname |+------+-----------+| 男 | 郭德纲 || 男 | 林志颖 || 女 | 柳岩 |+------+-----------+3 行于数据集 (0.01 秒) 2.4、运算查询字段与固定值运算 12格式：select 字段名+固定值 from 数据库表名; 注意： 运算的字段必须是数值型 案例： 查询student表中年龄减10岁，并显示sname和age 123456789mysql&gt; select age-10 as age ,sname from student;+-----+--------+| age | sname |+-----+--------+| 37 | 郭德纲 || 36 | 林志颖 || 30 | 柳岩 |+-----+--------+3 rows in set 字段与字段运算 12格式：select 字段名+字段名 from 数据库表名; 注意： 运算的字段必须是数值型 案例： 查询student表中age与id的和，并显示出来age和id 12345678910mysql&gt; select age+id,age,id from student;+--------+-----+----+| age+id | age | id |+--------+-----+----+| 48 | 47 | 1 || 48 | 46 | 2 || 43 | 40 | 3 |+--------+-----+----+3 rows in set 三、条件查询3.1、条件查询前准备新建学生信息表（students） 字段：学生ID（sid）、学生姓名(sname)、学生性别(sex)、学生年龄(age)、英语成绩(english)、数学成绩(math)、入学时间(entertime)、备注(remark) 12345678910create table students( sid int, sname varchar(20), sex varchar(2), age int, english double(4,1), math double(4,1), entertime date, remark text); image20200207010430241.png 记录： 12345678insert into students values(1,&#x27;张三&#x27;,&#x27;男&#x27;,19,98.5,88,&#x27;2017-09-01&#x27;,&#x27;他来自四川&#x27;),(2,&#x27;李四&#x27;,&#x27;男&#x27;,20,80,88,&#x27;2017-09-01&#x27;,&#x27;他来自重庆&#x27;),(3,&#x27;张红&#x27;,&#x27;女&#x27;,19,86,80,&#x27;2017-09-01&#x27;,&#x27;他来自北京&#x27;),(4,&#x27;张八&#x27;,&#x27;男&#x27;,18,80,85,&#x27;2017-09-01&#x27;,&#x27;他来自天津&#x27;),(5,&#x27;李三&#x27;,&#x27;男&#x27;,19,60,88,&#x27;2017-09-01&#x27;,&#x27;他来自湖北&#x27;),(6,&#x27;王六&#x27;,&#x27;女&#x27;,20,50,70,&#x27;2017-09-01&#x27;,&#x27;他来自湖南&#x27;),(7,&#x27;刘红&#x27;,&#x27;女&#x27;,18,90,98,&#x27;2017-09-01&#x27;,&#x27;他来自甘肃&#x27;); image20200207011044328.png 3.2、基础比较运算符12格式：&gt;、&lt;、&lt;=、&gt;=、=、&lt;&gt; 注意： 在SQL中“&lt;&gt;”，表示不等于，mysql中也可以用“!&#x3D;”表示 在SQL中没有“&#x3D;&#x3D;” 案例： 查询学生信息表中英语成绩大于80的学生信息 123456789mysql&gt; select * from students where english&gt;80;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+3 行于数据集 (0.02 秒) 查询学生信息表中英语成绩小于80的学生信息 12345678mysql&gt; select * from students where english&lt;80;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 |+------+--------+------+------+---------+------+------------+-----------------+2 行于数据集 (0.01 秒) 查询学生信息表中年龄大于等于19岁的学生信息 1234567891011mysql&gt; select * from students where age&gt;=19;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 |+------+--------+------+------+---------+------+------------+-----------------+5 行于数据集 (0.01 秒) 查询学生信息表中年龄小于等于19岁的学生信息 1234567891011mysql&gt; select * from students where age&lt;=19;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+5 行于数据集 (0.01 秒) 查询学生信息表中数学成绩等于88的学生信息 123456789mysql&gt; select * from students where math=88;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 |+------+--------+------+------+---------+------+------------+-----------------+3 行于数据集 (0.02 秒) 查询学生信息表中年龄不等于18岁的学生信息 1234567891011mysql&gt; select * from students where age&lt;&gt;18;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 |+------+--------+------+------+---------+------+------------+-----------------+5 行于数据集 (0.02 秒) 查询学生信息表中年龄大于等于20岁的学生的姓名和性别 12345678mysql&gt; select sname,sex from students where age&gt;=20;+--------+------+| sname | sex |+--------+------+| 李四 | 男 || 王六 | 女 |+--------+------+2 行于数据集 (0.01 秒) 3.3、提高比较运算符12格式：between...and... #在一定的范围内 注意： 包含头尾 案例： 查询学生信息表中英语成绩80到90岁之间的学生信息 12345678910111213mysql&gt; select * from students where english between 80 and 90;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+4 行于数据集 (0.01 秒)格式：in(值1,值2...,值n) #表示用n个值相等not in(值1,值2...,值n) #表示用n个值不相等 案例： 查询学生信息表中sid为1，3，5的信息 123456789mysql&gt; select * from students where sid in(1,3,5);+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 |+------+--------+------+------+---------+------+------------+-----------------+3 行于数据集 (0.01 秒) 查询学生信息表中sid除了1，3，5的信息 123456789101112mysql&gt; select * from students where sid not in(1,3,5);+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+4 行于数据集 (0.01 秒)格式：like &#x27;%值%&#x27; #模糊查询 注意： 12345mysql通配符% :匹配任意多个字符_ ：匹配一个字符 案例： 查询学生信息表中姓’张’的学生信息 123456789101112mysql&gt; select * from students where sname like &#x27;张%&#x27;;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 |+------+--------+------+------+---------+------+------------+-----------------+3 行于数据集 (0.01 秒)mysql&gt; select * from students where sname like &#x27;张&#x27;;空的数据集 (0.01 秒) 查询学生信息表中包含’红’字的学生信息 12345678mysql&gt; select * from students where sname like &#x27;%红%&#x27;;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+2 行于数据集 (0.01 秒) 查询学生信息表中姓’王’的二个字的学生信息 12345678910mysql&gt; select * from students where sname like &#x27;王_&#x27;;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 |+------+--------+------+------+---------+------+------------+-----------------+1 行于数据集 (0.01 秒)格式：is null #表示某字段值为nullis not null #表示某字段值不为null 注意： 不能写成：字段名&#x3D;null 案例： 查询学生信息表中age为null学生信息 查询学生信息表中english为null学生信息 12345678910111213141516mysql&gt; select * from students where age is null;+------+--------+------+------+---------+------+-----------+--------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+-----------+--------+| 8 | 王五 | 男 | NULL | NULL | NULL | NULL | NULL |+------+--------+------+------+---------+------+-----------+--------+1 行于数据集 (0.01 秒)mysql&gt; select * from students where english is null;+------+-----------+------+------+---------+------+-----------+--------+| sid | sname | sex | age | english | math | entertime | remark |+------+-----------+------+------+---------+------+-----------+--------+| 8 | 王五 | 男 | NULL | NULL | NULL | NULL | NULL || 9 | 李老六 | 男 | 19 | NULL | NULL | NULL | NULL |+------+-----------+------+------+---------+------+-----------+--------+2 行于数据集 (0.01 秒) 查询学生信息表中english不为null学生信息 12345678910111213mysql&gt; select * from students where english is not null;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+7 行于数据集 (0.02 秒) 3.4、逻辑运算符1234格式：and #与，二边条件同时成立，成立 &amp;&amp;or #或，二边条件有一边成立，成立 ||not #非，一边条件成立，取反；一边条件不成立，取反 ！ 案例： 查询学生信息表中english大于85的男生的学生信息 1234567mysql&gt; select * from students where english&gt;85 and sex=&#x27;男&#x27;;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 |+------+--------+------+------+---------+------+------------+-----------------+1 行于数据集 (0.01 秒) 查询学生信息表中年龄大于等于20岁或数学成绩大于85的学生信息 1234567891011mysql&gt; select * from students where age&gt;=20 or math&gt;85;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+5 行于数据集 (0.01 秒) 查询学生信息表中除了年龄大于等于20岁或数学成绩大于85的学生信息 12345678mysql&gt; select * from students where not (age&gt;=20 or math&gt;85);+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 |+------+--------+------+------+---------+------+------------+-----------------+2 行于数据集 (0.01 秒)"},{"path":"/2023/07/11/MySQL数据库实战/DQL-聚合函数/","content":"SQL基本函数，聚合函数对一组值执行计算，并返回单个值，也被称为组函数。 聚合函数对一组值执行计算并返回单一的值。除 COUNT 以外，聚合函数忽略空值，如果COUNT函数的应用对象是一个确定列名，并且该列存在空值，此时COUNT仍会忽略空值。 所有聚合函数都具有确定性。任何时候用一组给定的输入值调用它们时，都返回相同的值。聚合函数可以应用于查询语句的SELECT中，或者HAVING子句中，但不可用于WHERE语句中，因为WHERE是对逐条的行记录进行筛选。 一、聚合函数概述1.1、什么是聚合函数SQL基本函数，聚合函数对一组值执行计算，并返回单个值，也被称为组函数。 聚合函数经常与 SELECT 语句的 GROUP BY 子句的HAVING一同使用。 1.2、聚合函数的特点除了 COUNT 以外，聚合函数忽略空值。聚合函数经常与 SELECT 语句的 GROUP BY 子句一同使用。所有聚合函数都具有确定性。任何时候用一组给定的输入值调用它们时，都返回相同的值。 1.3、常用聚合函数123456count(字段名)：统计总行数sum(字段名)：计算列总和avg(字段名)：求某一列平均值min(字段名)：求某一列的最小值max(字段名)：求某一列的最大值SUBSTRING(str,num,len)：字符串截取 举例：SELECT SUBSTRING(&#x27;javaMySQLOracle&#x27;,5,5); 1.4、聚合函数语法12格式：select 聚合函数(字段名) from 数据库表名; 二、聚合函数应用2.1、聚合函数基础应用案例： 查看学生信息表中通过英语成绩统计所有的学生数 1234567mysql&gt; select count(english) as 学生人数 from students;+-----+| 总人数 |+-----+| 7 |+-----+1 行于数据集 (0.01 秒) 注意： null的记录是不会统计，如果要想统计null，可以用ifnull(字段名,默认值) 默认值里设置：null用0表示 1234567mysql&gt; select count(ifnull(english,0)) as 总人数 from students;+-----+| 总人数 |+-----+| 9 |+-----+1 行于数据集 (0.02 秒) 除了前面这个方法可以统计学生人数外，我们还可以： 12345678#比较常用的方法mysql&gt; select count(*) from students;+----------+| count(*) |+----------+| 9 |+----------+1 行于数据集 (0.01 秒) 查看学生信息表中年龄大于19的总人数 1234567mysql&gt; select count(*) from students where age&gt;19;+----------+| count(*) |+----------+| 2 |+----------+1 行于数据集 (0.02 秒) 查看学生信息表中英语成绩的总分 1234567mysql&gt; select sum(english) as 英语总分 from students;+-------+| 英语总分 |+-------+| 544.5 |+-------+1 行于数据集 (0.01 秒) 查看学生信息表中英语成绩的平均分 1234567mysql&gt; select avg(english) as 英语平均分 from students;+----------+| 英语平均分 |+----------+| 77.78571 |+----------+1 行于数据集 (0.01 秒) 查看学生信息表中英语成绩的最高分 1234567mysql&gt; select max(english) as 英语最高分 from students;+-------+| 英语最高分 |+-------+| 98.5 |+-------+1 行于数据集 (0.01 秒) 查看学生信息表中英语成绩的最低分 1234567mysql&gt; select min(english) as 英语最低分 from students;+-------+| 英语最低分 |+-------+| 50.0 |+-------+1 行于数据集 (0.01 秒) 2.2、聚合函数分组应用案例： 统计学生信息表中男生的人数与女生的人数 12345678mysql&gt; select count(*),sex from students group by sex;+----------+------+| count(*) | sex |+----------+------+| 6 | 男 || 3 | 女 |+----------+------+2 行于数据集 (0.01 秒) 统计学生信息表中男生和女生的人数、英语总成绩、数学平均成绩 12345678mysql&gt; select count(*),sex,sum(english),avg(math) from students group by sex;+----------+------+--------------+-----------+| count(*) | sex | sum(english) | avg(math) |+----------+------+--------------+-----------+| 6 | 男 | 318.5 | 87.25000 || 3 | 女 | 226.0 | 82.66667 |+----------+------+--------------+-----------+2 行于数据集 (0.01 秒) 统计学生信息表中男生和女生的人数、英语总成绩、数学平均成绩，总人数超过3人显示 1234567mysql&gt; select count(*) as n,sex,sum(english),avg(math) from students group by sex having n&gt;3;+---+------+--------------+-----------+| n | sex | sum(english) | avg(math) |+---+------+--------------+-----------+| 6 | 男 | 318.5 | 87.25000 |+---+------+--------------+-----------+1 行于数据集 (0.02 秒) 三、聚合函数应用扩展3.1、group_concatgroup_concat(字段名)可以作为一个输出字段来使用，表示分组之后，根据分组结果，使用group_concat()来放置每一组的某字段的值的集合。 案例： 统计学生信息表中男生和女生的人数、英语总成绩、数学平均成绩及数学成绩的集合 12345678mysql&gt; select count(*),sex,sum(english),avg(math),group_concat(math) from students group by sex;+----------+------+--------------+-----------+---------------------+| count(*) | sex | sum(english) | avg(math) | group_concat(math) |+----------+------+--------------+-----------+---------------------+| 3 | 女 | 226.0 | 82.66667 | 80.0,70.0,98.0 || 6 | 男 | 318.5 | 87.25000 | 88.0,88.0,85.0,88.0 |+----------+------+--------------+-----------+---------------------+2 行于数据集 (0.02 秒) 3.2、with rollup在最后新增一行，来记录当前列里所有记录的总和 案例： 统计学生信息表中男生和女生的人数、英语总成绩、数学平均成绩及增加显示列的记录总和 123456789mysql&gt; select count(*),sex,sum(english),avg(math) from students group by sex with rollup;+----------+------+--------------+-----------+| count(*) | sex | sum(english) | avg(math) |+----------+------+--------------+-----------+| 3 | 女 | 226.0 | 82.66667 || 6 | 男 | 318.5 | 87.25000 || 9 | NULL | 544.5 | 85.28571 |+----------+------+--------------+-----------+3 行于数据集 (0.02 秒)"},{"path":"/2023/07/11/MySQL数据库实战/DQL-模糊查询/","content":"模糊查询即模糊检索，是指搜索系统自动按照用户输入关键词的同义词进行模糊检索，从而得出较多的检索结果。与之相反的是“精准搜索”。模糊检索也可以说是同义词检索，这里的同义词是用户通过“检索管理”中的“同义词典”来配置的。 用户在检索页面中输入同义词中任何一个词检索时，只要选中“模糊检索”复选框，则该关键词的所有同义词信息也都被检索出来。 举例：例如配置了“电脑”与“computer”为同义词后，检索“电脑”，则包含“computer”的网页也会出现在检索结果中。 一、模糊查询概述1.1、什么是模糊查询模糊查询是针对字符串操作的，类似正则表达式，没有正则表达式强大。 1.2、通配符1234%：表示任意0个或多个字符。_： 表示任意单个字符。[ ]：表示括号内所列字符中的一个（类似正则表达式）。[^ ] ：表示不在括号所列之内的单个字符。 1.3、回顾%和_1.3.1、%应用可匹配任意类型和长度的字符，有些情况下若是中文，请使用两个百分号（%%）表示。 12格式：select */字段列表 from 数据库表名 where 字段名 like %字符串%; 案例： 查询出学生信息表中姓名里有‘三’的学生信息 12345678mysql&gt; select * from students where sname like &#x27;%三%&#x27;;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 |+------+--------+------+------+---------+------+------------+-----------------+2 行于数据集 (0.02 秒) 1.3.2、_应用匹配单个任意字符，它常用来限制表达式的字符长度语句。 12格式：select */字段列表 from 数据库表名 where 字段名 like _字符串_; 案例： 查询学生信息表中姓名里含有‘红’字，二个字的学生信息 12345678mysql&gt; select * from students where sname like &#x27;_红&#x27; or sname like &#x27;红_&#x27;;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+2 行于数据集 (0.01 秒) 二、模糊查询应用2.1、[ ]应用指定一个字符、字符串或范围，要求所匹配对象为它们中的任一个。 12格式：select */字段列表 from 数据库表名 where 字段名 regexp [字符串]字符串; 案例： 查询学生信息表中姓名里有张和李的人的信息 123456789101112mysql&gt; select * from students where sname regexp &#x27;[张李]&#x27;;+------+-----------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+-----------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 5 | 三李 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 9 | 李老六 | 男 | 19 | NULL | NULL | NULL | NULL |+------+-----------+------+------+---------+------+------------+-----------------+6 行于数据集 (0.02 秒) 查询学生信息表中姓名为张红和李红的人的信息 12345678#[张李]红 张红 李红mysql&gt; select * from students where sname regexp &#x27;[张李]红&#x27;;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 |+------+--------+------+------+---------+------+------------+-----------------+1 行于数据集 (0.01 秒) 查询学生信息表中年龄包含789这几个数字的人的信息 123456789101112mysql&gt; select * from students where age regexp &#x27;[789]&#x27;;+------+-----------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+-----------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 5 | 三李 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 || 9 | 李老六 | 男 | 19 | NULL | NULL | NULL | NULL |+------+-----------+------+------+---------+------+------------+-----------------+6 行于数据集 (0.01 秒) 注意： 如 [ ] 内有一系列字符（01234、abcde之类的）则可略写为“0-4”、“a-e” 2.2、[^]应用其取值和 [] 相同，但它要求所匹配对象为指定字符以外的任一个字符。 12格式：select */字段列表 from 数据库表名 where 字段名 regexp [^字符串]字符串; 案例： 查询学生信息表中姓名不是张红、李红，而是其他红的人的信息。 1234567mysql&gt; select * from students where sname regexp &#x27;[^张李]红&#x27;;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+1 行于数据集 (0.01 秒) 查询学生信息表中年龄不包含7891这几个数字的人的信息 12345678mysql&gt; select * from students where age regexp &#x27;[^7891]&#x27;;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 |+------+--------+------+------+---------+------+------------+-----------------+2 行于数据集 (0.01 秒) 查询学生信息表中姓张和姓李的人的信息 1234567891011mysql&gt; select * from students where sname regexp &#x27;^[张李]&#x27;;+------+-----------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+-----------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 9 | 李老六 | 男 | 19 | NULL | NULL | NULL | NULL |+------+-----------+------+------+---------+------+------------+-----------------+5 行于数据集 (0.01 秒) 注意： 1^[]表示的是：字符串开始的第一个字符 SELECT字段名或表达式或函数或常量值FROM 表名 WHERE 主键字段&#x3D;值 或者 写 非主键字段&#x3D;值 表达式 ORDER BY 字段 ASC或DESC SELECTE * FROM STUDENT WHERE INSELECTE * FROM STUDENT WHERE 内连接外连接"},{"path":"/2023/07/11/MySQL数据库实战/DQL-limit分页/","content":"在我们使用查询语句的时候，经常要返回前几条或者中间某几行数据，这个时候怎么办呢？不用担心，mysql已经为我们提供了这样一个功能-limit。 一、limit概述Limit是限制的意思，所以limit的作用就是限制查询记录的条数。 二、limit语法12格式：select */字段列表 from 数据库表名 [limit offset,length]; 说明： offset：起始行数，从 0 开始计数，如果省略，默认就是 0 length： 返回的行数 三、limit应用案例： 查询学生信息表中前5条记录 123456789101112#offset可以省略，省略时，从0开始mysql&gt; select * from students limit 5;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 |+------+--------+------+------+---------+------+------------+-----------------+5 行于数据集 (0.02 秒) 查询学生信息表中从第3条记录开始，查询出5条记录 1234567891011mysql&gt; select * from students limit 2,5;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 || 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 |+------+--------+------+------+---------+------+------------+-----------------+5 行于数据集 (0.01 秒) 四、limit分页4.1、什么是分页打开百度，输入我们想要查看的信息，查出来的数据会有成千上万条数据，那么这些数据在页面不能一次性展示，这个时候我们就需要用到分页。 image20200209012451326.png 4.2、MySql中的分页案例： 查询学生信息表中的信息，按5条记录为一页展示 第一页 1234567891011mysql&gt; select * from students limit 0,5;+------+--------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+--------+------+------+---------+------+------------+-----------------+| 1 | 张三 | 男 | 19 | 98.5 | 88.0 | 2017-09-01 | 他来自四川 || 2 | 李四 | 男 | 20 | 80.0 | 88.0 | 2017-09-01 | 他来自重庆 || 3 | 张红 | 女 | 19 | 86.0 | 80.0 | 2017-09-01 | 他来自北京 || 4 | 张八 | 男 | 18 | 80.0 | 85.0 | 2017-09-01 | 他来自天津 || 5 | 李三 | 男 | 19 | 60.0 | 88.0 | 2017-09-01 | 他来自湖北 |+------+--------+------+------+---------+------+------------+-----------------+5 行于数据集 (0.01 秒) 第二页 12345678910mysql&gt; select * from students limit 5,5;+------+-----------+------+------+---------+------+------------+-----------------+| sid | sname | sex | age | english | math | entertime | remark |+------+-----------+------+------+---------+------+------------+-----------------+| 6 | 王六 | 女 | 20 | 50.0 | 70.0 | 2017-09-01 | 他来自湖南 || 7 | 刘红 | 女 | 18 | 90.0 | 98.0 | 2017-09-01 | 他来自甘肃 || 8 | 王五 | 男 | NULL | NULL | NULL | NULL | NULL || 9 | 李老六 | 男 | 19 | NULL | NULL | NULL | NULL |+------+-----------+------+------+---------+------+------------+-----------------+4 行于数据集 (0.01 秒) 注意： limit中offset在发生着变化，第一页是0，第二页是(前一页的offset+length)，而length并没有发生变化。 如果最后一页的记录数没有指定的length条，是有多少显示多少 LIMIT函数 LIMIT 4 显示前几行 分页处理 每页显示5条总记录数20条 123456SELECT * FROM student limit 0,10;显示第一页的数据，有10条显示第二页的数据，有20条SELECT * FROM student limit 20,10;limit(当前页码-1)*每页显示的条数，每页显示的条数； limit 0,4;"},{"path":"/2023/07/11/MySQL数据库实战/DML语句/","content":"数据操纵语言DML（Data Manipulation Language），用户通过它可以实现对数据库的基本操作。就是我们最经常用到的UPDATE、INSERT、DELETE。 主要用来对数据库的数据进行一些操作。 一、表记录操作-上1.1、DML概述DML 操作是指对数据库中表记录的操作，主要包括表记录的插入（insert）、更新（update）和删除（delete），是开发人员日常使用最频繁的操作。 1.2、插入记录12格式：insert into 数据库表名 [字段名列表] values(字段值列表) 说明： insert into 数据库表名：指定增加记录的表 [字段名列表]：表示要给那些字段加入字段值，没有，就为所有字段 values（字段值列表）：表示为对应的字段加入对应的字段值 为所有字段插入值 1234格式：insert into 数据库表名(字段名1,字段名2...,字段名n)values(字段值1,字段值2...,字段值n);或insert into 数据库表名 values(字段值1,字段值2...,字段值n); 案例： 123456789101112131415#指定所有字段插入记录mysql&gt; insert into student(id,sname,birthday)values(1,&quot;林志颖&quot;,&quot;1974-10-18&quot;);Query OK, 1 rows affected (0.03 秒)#不指定字段，默认所有字段插入记录mysql&gt; insert into student values(2,&quot;郭德纲&quot;,&quot;1973-01-18&quot;);Query OK, 1 rows affected (0.01 秒)#查看数据库表中所有记录mysql&gt; select * from student;+------+-----------+------------+| id | sname | birthday |+------+-----------+------------+| 1 | 林志颖 | 1974-10-18 || 2 | 郭德纲 | 1973-01-18 |+------+-----------+------------+2 行于数据集 (0.01 秒) 插入部分字段值 123格式：insert into 数据库表名(字段名1,字段名2...)values(字段值1,字段值2...);#注意：没有给定字段的值，为null; 案例： 12345678910111213#插入部分字段值mysql&gt; insert into student(id,sname)values(3,&quot;柳岩&quot;);Query OK, 1 rows affected (0.01 秒)#查看数据库表中所有记录mysql&gt; select * from student;+------+-----------+------------+| id | sname | birthday |+------+-----------+------------+| 1 | 林志颖 | 1974-10-18 || 2 | 郭德纲 | 1973-01-18 || 3 | 柳岩 | NULL |+------+-----------+------------+3 行于数据集 (0.01 秒) 注意： 只插入部份字段值时，前面必须带字段名字。 12mysql&gt; insert into student values(4,&quot;王宝强&quot;);Column count doesn&#x27;t match value count at row 1#列计数与第1行的值计数不匹配 二、表记录操作-下2.1、更新记录123格式：update 数据库表名 set 字段名1=字段值1,字段名2=字段值2...,字段名n=字段值n [where 条件表达式];#注意：更新的数据可以是0-N条记录 说明： update 数据库表名：指定需要更新的数据库表 set 字段名&#x3D;字段值：修改指定的数据库表中字段的值 [where 条件表达式]：修改满足条件的记录的字段值，可省略 不带条件记录更新 12格式：update 数据库表名 set 字段名1=字段值1,字段名2=字段值2...,字段名n=字段值n; #表示修改表中所有记录 案例： 加入一个性别（sex varchar(2)）字段，将sex的值都改为“男” 123456789101112131415161718192021222324252627#在student表中增加字段sexmysql&gt; alter table student add sex varchar(2);Query OK, 0 rows affected (0.24 秒)#查看表结构mysql&gt; desc student;+----------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || sname | varchar(20) | YES | | NULL | || birthday | date | YES | | NULL | || sex | varchar(2) | YES | | NULL | |+----------+-------------+------+-----+---------+-------+4 行于数据集 (0.01 秒)#修改student表中sex字段的值为&#x27;男&#x27;mysql&gt; update student set sex=&#x27;男&#x27;;Query OK, 3 rows affected (0.09 秒)#查看表中所有记录mysql&gt; select * from student;+------+-----------+------------+------+| id | sname | birthday | sex |+------+-----------+------------+------+| 1 | 林志颖 | 1974-10-18 | 男 || 2 | 郭德纲 | 1973-01-18 | 男 || 3 | 柳岩 | NULL | 男 |+------+-----------+------------+------+3 行于数据集 (0.01 秒) 带条件记录更新 12格式：update 数据库表名 set 字段名1=字段值1,字段名2=字段值2...,字段名n=字段值n [where 条件表达式]; #表示修改表中满足条件的记录 案例： 修改id&#x3D;3的记录，将sex改为’女’ 12345678910111213#修改id为3记录中的sex改为&#x27;女&#x27;mysql&gt; update student set sex=&#x27;女&#x27; where id=3;Query OK, 1 rows affected (0.01 秒)#查看表中所有记录mysql&gt; select * from student;+------+-----------+------------+------+| id | sname | birthday | sex |+------+-----------+------------+------+| 1 | 林志颖 | 1974-10-18 | 男 || 2 | 郭德纲 | 1973-01-18 | 男 || 3 | 柳岩 | NULL | 女 |+------+-----------+------------+------+3 行于数据集 (0.01 秒) 修改id&#x3D;3的记录，将sex改为’女’，birthday改为1980-11-08 12345678910111213#修改id为3记录中的sex改为&#x27;女&#x27;,birthday改为1980-11-08mysql&gt; update student set sex=&#x27;女&#x27;,birthday=&#x27;1980-11-08&#x27; where id=3;Query OK, 1 rows affected (0.11 秒)#查看表中所有记录mysql&gt; select * from student;+------+-----------+------------+------+| id | sname | birthday | sex |+------+-----------+------------+------+| 1 | 林志颖 | 1974-10-18 | 男 || 2 | 郭德纲 | 1973-01-18 | 男 || 3 | 柳岩 | 1980-11-08 | 女 |+------+-----------+------------+------+3 行于数据集 (0.01 秒) 2.2、删除记录12格式：delete from 数据库表名 [where 条件表达式]; 说明： delete from 数据库表名：指定删除记录的表 [where 条件表达式]：删除满足条件的记录的字段值，可省略 带条件删除记录 12格式：delete from 数据库表名 [where 条件表达式]; #删除满足条件的记录 案例： 删除id为1的记录 123456789101112#删除id=1的记录mysql&gt; delete from student where id=1;Query OK, 1 rows affected (0.08 秒)#查看所有记录mysql&gt; select * from student;+------+-----------+------------+------+| id | sname | birthday | sex |+------+-----------+------------+------+| 2 | 郭德纲 | 1973-01-18 | 男 || 3 | 柳岩 | 1980-11-08 | 女 |+------+-----------+------------+------+2 行于数据集 (0.02 秒) 不带条件删除记录 1234格式：delete from 数据库表名; #删除表中所有的记录或truncate table 数据库表名; #删除表中所有的记录 truncate语句删除后将重置自增列，表结构及其字段、约束、索引保持不变，执行速度比DELETE语句快 案例： 删除表中所有记录 123456789101112#删除所有记录mysql&gt; delete from student;Query OK, 2 rows affected (0.08 秒)#查看所有记录mysql&gt; select * from student;空的数据集 (0.01 秒)#删除所有记录mysql&gt; truncate table student;Query OK, 0 rows affected (0.08 秒)#查看所有记录mysql&gt; select * from student;空的数据集 (0.01 秒) 注意： truncate删除的是表的结构，再创建一张表；delete删除的是表的记录；"},{"path":"/2023/07/11/MySQL数据库实战/DDL语句/","content":"数据库模式定义语言DDL(Data Definition Language)，是用于描述数据库中要存储的现实世界实体的语言。 数据库模式定义语言并非程序设计语言，DDL数据库模式定义语言是SQL语言（结构化查询语言）的组成部分。DDL描述的模式，必须由计算机软件进行编译，转换为便于计算机存储、查询和操纵的格式，完成这个转换工作的程序称为模式编译器。 模式编译器处理模式定义主要产生两种类型的数据：数据字典以及数据类型和结构定义。 一、数据库操作-上1.1、DDL概述DDL（data definition language）数据库定义语言：其实就是我们在创建表的时候用到的一些sql，比如说：CREATE、ALTER、DROP等。DDL主要是用在操作数据库，定义或改变数据库表的结构，数据类型等初始化工作。 1.2、创建数据库直接创建数据库 12格式：create database 数据库名; 判断数据库是否已经存在，不存在则创建 12格式：create database if not exists 数据库名; 创建数据库并指定字符集 12格式：create database 数据库名 character set 字符集; 案例： 123456789101112#创建数据库mysql&gt; create database zutuanxue;Query OK, 1 rows affected (0.08 秒)#创建成功#在次创建同名数据库mysql&gt; create database zutuanxue;Can&#x27;t create database &#x27;zutuanxue&#x27;; database exists #无法创建数据库“zutuanxue”；数据库存在#判断是否存在，如果不存在则创建数据库zutuanxuemysql&gt; create database if not exists zutuanxue;Query OK, 1 rows affected, 1 warnings (0.01 秒)#创建数据库并指定字符集为 gbkmysql&gt; create database zutuanxue01 default character set gbk;Query OK, 1 rows affected (0.03 秒) 注意： default 可以不要 补充：了解字符集查看 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#查看字符集mysql&gt; show character set;+----------+---------------------------------+---------------------+--------+| Charset | Description | Default collation | Maxlen |+----------+---------------------------------+---------------------+--------+| armscii8 | ARMSCII-8 Armenian | armscii8_general_ci | 1 || ascii | US ASCII | ascii_general_ci | 1 || big5 | Big5 Traditional Chinese | big5_chinese_ci | 2 || binary | Binary pseudo charset | binary | 1 || cp1250 | Windows Central European | cp1250_general_ci | 1 || cp1251 | Windows Cyrillic | cp1251_general_ci | 1 || cp1256 | Windows Arabic | cp1256_general_ci | 1 || cp1257 | Windows Baltic | cp1257_general_ci | 1 || cp850 | DOS West European | cp850_general_ci | 1 || cp852 | DOS Central European | cp852_general_ci | 1 || cp866 | DOS Russian | cp866_general_ci | 1 || cp932 | SJIS for Windows Japanese | cp932_japanese_ci | 2 || dec8 | DEC West European | dec8_swedish_ci | 1 || eucjpms | UJIS for Windows Japanese | eucjpms_japanese_ci | 3 || euckr | EUC-KR Korean | euckr_korean_ci | 2 || gb18030 | China National Standard GB18030 | gb18030_chinese_ci | 4 || gb2312 | GB2312 Simplified Chinese | gb2312_chinese_ci | 2 || gbk | GBK Simplified Chinese | gbk_chinese_ci | 2 || geostd8 | GEOSTD8 Georgian | geostd8_general_ci | 1 || greek | ISO 8859-7 Greek | greek_general_ci | 1 || hebrew | ISO 8859-8 Hebrew | hebrew_general_ci | 1 || hp8 | HP West European | hp8_english_ci | 1 || keybcs2 | DOS Kamenicky Czech-Slovak | keybcs2_general_ci | 1 || koi8r | KOI8-R Relcom Russian | koi8r_general_ci | 1 || koi8u | KOI8-U Ukrainian | koi8u_general_ci | 1 || latin1 | cp1252 West European | latin1_swedish_ci | 1 || latin2 | ISO 8859-2 Central European | latin2_general_ci | 1 || latin5 | ISO 8859-9 Turkish | latin5_turkish_ci | 1 || latin7 | ISO 8859-13 Baltic | latin7_general_ci | 1 || macce | Mac Central European | macce_general_ci | 1 || macroman | Mac West European | macroman_general_ci | 1 || sjis | Shift-JIS Japanese | sjis_japanese_ci | 2 || swe7 | 7bit Swedish | swe7_swedish_ci | 1 || tis620 | TIS620 Thai | tis620_thai_ci | 1 || ucs2 | UCS-2 Unicode | ucs2_general_ci | 2 || ujis | EUC-JP Japanese | ujis_japanese_ci | 3 || utf16 | UTF-16 Unicode | utf16_general_ci | 4 || utf16le | UTF-16LE Unicode | utf16le_general_ci | 4 || utf32 | UTF-32 Unicode | utf32_general_ci | 4 || utf8 | UTF-8 Unicode | utf8_general_ci | 3 || utf8mb4 | UTF-8 Unicode | utf8mb4_0900_ai_ci | 4 |+----------+---------------------------------+---------------------+--------+41 行于数据集 (0.02 秒) 1.3、查看数据库查看所有数据库 12格式：show databases; 查看某个数据库 12格式：show create database 数据库名; 案例： 12345678910111213141516171819202122#查看所有数据库mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mb || mysql || performance_schema || sys || zutuanxue || zutuanxue01 |+--------------------+7 行于数据集 (0.01 秒)#查看数据库zutuanxue的信息mysql&gt; show create database zutuanxue;+----------+-------------------------------------------------------------------------------------------------+| Database | Create Database |+----------+-------------------------------------------------------------------------------------------------+| zutuanxue | CREATE DATABASE `zutuanxue` /*!40100 DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci */ |+----------+-------------------------------------------------------------------------------------------------+1 行于数据集 (0.01 秒) 二、数据库操作-下2.1、修改数据库修改字符集 12格式：alter database 数据库名 character set 字符集; 案例： 123#需求：将zutuanxue01数据库的字符集改成 utf8mysql&gt; alter database zutuanxue01 character set utf8;Query OK, 1 rows affected, 1 warnings (0.09 秒) 注意： 为什么修改的不是数据库名？ 容易引起数据丢失。 1rename database 旧数据库名 to 新数据库名; 这个是5.1.7到5.1.23版本可以用，但是官方不推荐，会有丢失数据的危险 2.2、删除数据库删除数据库 12格式:drop database 数据库名; 案例： 12345678910111213141516#需求：删除zutuanxue01数据库mysql&gt; drop database zutuanxue01;Query OK, 0 rows affected (0.07 秒)#查看所有数据库mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mb || mysql || performance_schema || sys || zutuanxue |+--------------------+6 行于数据集 (0.01 秒) 2.3、使用数据库查看当前数据库 12格式：select database();#mysql中的全局函数 切换数据库 12格式：use 数据库名; 案例： 12345678910111213141516171819#查看当前使用的数据库mysql&gt; select database();+------------+| database() |+------------+| NULL |#当前没有使用的数据库+------------+1 行于数据集 (0.01 秒)#切换或指定当前使用的数据库mysql&gt; use zutuanxue;Query OK, 0 rows affected (0.01 秒)#查看当前使用的数据库mysql&gt; select database();+------------+| database() |+------------+| zutuanxue |#当前使用的数据库为zutuanxue+------------+1 行于数据集 (0.01 秒) 三、数据库表操作-上3.1、创建表创建表结构 1234567格式：create table 数据库表名( 字段名1 字段类型1, 字段名2 字段类型2, ... 字段名n 字段类型n); 关键字说明 create：创建 table：表 3.2、数据类型（mysql）数字类型 image20200206171122469.png 日期类型 image20200206171204522.png 字符串类型 image20200206171241199.png BLOB&#x2F;TEXT image20200206171350662.png BINARY&#x2F;VARBINARY image20200206171423603.png ENUM&#x2F;SET image20200206171501339.png 案例： 创建一个学生表，里面包含了编号、学生名字、出生年月等数据 分析： 表名：students 字段有：编号（id,int类型）、学生名字（sname,varchar()类型）、出生日期（birthday date类型） 12345678910111213141516171819create table students( id int, -- 学生id sname varchar(20), -- 学生名字 birthday date -- 学生出生日期);#想要创建数据库表先进入，数据库mysql&gt; use zutuanxue;Query OK, 0 rows affected (0.01 秒)#创建表mysql&gt; create table students(id int ,sname varchar(20),birthday date);Query OK, 0 rows affected (0.05 秒)#查看所有表mysql&gt; show tables;+--------------------+| Tables_in_zutuanxue |+--------------------+| students |+--------------------+1 行于数据集 (0.01 秒) 3.3、查看表查看所有表 12格式：show tables; 查看表结构 12格式：desc 数据库表名; 查看表SQL信息 12格式：show create table 数据库表名; 案例： 查看zutuanxue数据库下的所有表 1234567891011#进入mysql数据库mysql&gt; use zutuanxue;Query OK, 0 rows affected (0.01 秒)#查看数据库里的所有表mysql&gt; show tables;+--------------------+| Tables_in_zutuanxue |+--------------------+| students |+--------------------+1 行于数据集 (0.01 秒) 查看students数据库表的结构 123456789mysql&gt; desc students;+----------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || sname | varchar(20) | YES | | NULL | || birthday | date | YES | | NULL | |+----------+-------------+------+-----+---------+-------+3 行于数据集 (0.01 秒) 查看students数据库表的信息 123456789101112#查看students数据库表SQL信息mysql&gt; show create table students;+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| students | CREATE TABLE `students` ( `id` int(11) DEFAULT NULL, `sname` varchar(20) DEFAULT NULL, `birthday` date DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci |+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 行于数据集 (0.01 秒) 4、数据库表操作-中4.1、快速建表建新表 12格式：create table 新数据库表名 like 旧数据库表名; 案例： 创建一个students01表，要求表结构与students相同 12345678910111213#创建一个新表与旧表结构相同mysql&gt; create table students01 like students;Query OK, 0 rows affected (0.11 秒)#查看表结构mysql&gt; desc students01;+----------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || sname | varchar(20) | YES | | NULL | || birthday | date | YES | | NULL | |+----------+-------------+------+-----+---------+-------+3 行于数据集 (0.02 秒) 4.2、删除表直接删除表 12格式：drop table 数据库表名; 判断表是否存在，存在则删除 12格式：drop table if exists 数据库表名; 案例： 123456#直接删除students01;mysql&gt; drop table students01;Query OK, 0 rows affected (0.09 秒)#有就删除students01,没有就不删除;mysql&gt; drop table if exists students01;Query OK, 0 rows affected, 1 warnings (0.01 秒) 5、数据库表操作-下5.1、修改表添加表字段 12格式：alter table 数据库表名 add 字段名 字段类型； 案例： 为students表添加一个字段性别（sex char类型) 1234567891011121314#增加字段mysql&gt; alter table students add sex char;Query OK, 0 rows affected (0.05 秒)#查看表结构mysql&gt; desc students;+----------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || sname | varchar(20) | YES | | NULL | || birthday | date | YES | | NULL | || sex | char(1) | YES | | NULL | |+----------+-------------+------+-----+---------+-------+4 行于数据集 (0.01 秒) 修改表字段类型 12格式：alter table 数据库表名 modify 字段名 新字段类型; 案例： 将students表中字段性别（sex）的字段类型改为varchar(2) 1234567891011121314#修改字段类型mysql&gt; alter table students modify sex varchar(2);Query OK, 0 rows affected (0.06 秒)#查看表结构mysql&gt; desc students;+----------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || sname | varchar(20) | YES | | NULL | || birthday | date | YES | | NULL | || sex | varchar(2) | YES | | NULL | |+----------+-------------+------+-----+---------+-------+4 行于数据集 (0.01 秒) 修改表字段名 12格式：alter table 数据库表名 change 旧字段名 新字段名 字段类型; 案例： 将students表中的性别（sex）改成班级（classes）类型为varchar(10) 1234567891011121314#修改字段名mysql&gt; alter table students change sex classes varchar(10);Query OK, 0 rows affected (0.07 秒)#查看表结构mysql&gt; desc students;+----------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || sname | varchar(20) | YES | | NULL | || birthday | date | YES | | NULL | || classes | varchar(10) | YES | | NULL | |+----------+-------------+------+-----+---------+-------+4 行于数据集 (0.02 秒) 删除表中字段 12格式：alter table 数据库表名 drop 字段名; 案例： 删除students表中的班级（classes）字段 12345678910111213#删除字段mysql&gt; alter table students drop classes;Query OK, 0 rows affected (0.05 秒)#查看表结构mysql&gt; desc students;+----------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+----------+-------------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || sname | varchar(20) | YES | | NULL | || birthday | date | YES | | NULL | |+----------+-------------+------+-----+---------+-------+3 行于数据集 (0.01 秒) 修改表名 12格式：rename table 数据库表名 to 新数据库表; 案例： 1234567891011#修改表名mysql&gt; rename table students to student;Query OK, 0 rows affected (0.04 秒)#查看所有表mysql&gt; show tables;+--------------------+| Tables_in_zutuanxue |+--------------------+| student |+--------------------+1 行于数据集 (0.01 秒) 修改字符集 12格式：alter table 数据库表名 character set 字符集; 案例： 修改student表的字符集 123456789101112131415#修改数据库表字符集mysql&gt; alter table student character set gbk;Query OK, 0 rows affected (0.07 秒)#查看数据库表SQL信息mysql&gt; show create table student;+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| student | CREATE TABLE `student` ( `id` int(11) DEFAULT NULL, `sname` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL, `birthday` date DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=gbk |+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 行于数据集 (0.01 秒)"},{"path":"/2023/07/11/Linux常用服务器部署实战/部署linux网络安装服务器/","content":"一、批量部署概述什么是PXE预启动执行环境（PXE）是由Intel公司开发的最新技术，工作于Client&#x2F;Server的网络模式，支持工作站通过网络从远端服务器下载映像，并由此支持通过网络启动操作系统，在启动过程中，终端要求服务器分配IP地址，再用TFTP（trivial file transfer protocol）或MTFTP(multicast trivial file transfer protocol)协议下载一个启动软件包到本机内存中执行，由这个启动软件包完成终端（客户端）基本软件设置，从而引导预先安装在服务器中的终端操作系统。PXE可以引导多种操作系统，如：Windows95&#x2F;98&#x2F;2000&#x2F;windows2003&#x2F;windows2008&#x2F;winXP&#x2F;win7&#x2F;win8,linux系列系统等。 PXE原理PXE是在没有软驱、硬盘、CD-ROM的情况下引导计算机的一种方式，也就是BIOS将使用PXE协议从网络引导。整个安装的过程是这样的： PXE网卡启动 &#x3D;&gt; DHCP获得IP地址 &#x3D;&gt; 从TFTP上下载 pxelinux.0、vmlinuz、initr.img 等 &#x3D;&gt; 引导系统进入安装步骤 &#x3D;&gt; 通过PEX linux 下载ks.cfg文件并跟据ks.cfg自动化安装系统 &#x3D;&gt; 完成。 image20200403143123698.png TFTP服务TFTP是用来下载远程文件的最简单网络协议，它其于UDP协议而实现。 什么是kickstartKickStart是一种无人职守安装方式。KickStart的工作原理是通过记录典型的安装过程中所需人工干预填写的各种参数，并生成一个名为ks.cfg的文件；在其后的安装过程中（不只局限于生成KickStart安装文件的机器）当出现要求填写参数的情况时，安装程序会首先去查找KickStart生成的文件，当找到合适的参数时，就采用找到的参数，当没有找到合适的参数时，才需要安装者手工干预。这样，如果KickStart文件涵盖了安装过程中出现的所有需要填写的参数时，安装者完全可以只告诉安装程序从何处取ks.cfg文件，然后去忙自己的事情。等安装完毕，安装程序会根据ks.cfg中设置的重启选项来重启系统，并结束安装。 二、批量部署原理image20200403144115628.png 1、PXE Client向DHCP发送请求： PXE Client从自己的PXE网卡启动，通过PXE BootROM(自启动芯片)会以UDP(简单用户数据报协议)发送一个广播请求，向本网络中的DHCP服务器索取IP。 2、DHCP服务器提供信息： DHCP服务器收到客户端的请求，验证是否来至合法的PXE Client的请求，验证通过它将给客户端一个“提供”响应，这个“提供”响应中包含了为客户端分配的IP地址、pxelinux启动程序(TFTP)位置，以及配置文件所在位置。 3、PXE客户端请求下载启动文件： 客户端收到服务器的“回应”后，会回应一个帧，以请求传送启动所需文件。这些启动文件包括：pxelinux.0、pxelinux.cfg&#x2F;default、vmlinuz、initrd.img等文件。 4、Boot Server响应客户端请求并传送文件： 当服务器收到客户端的请求后，他们之间之后将有更多的信息在客户端与服务器之间作应答, 用以决定启动参数。BootROM由TFTP通讯协议从Boot Server下载启动安装程序所必须的文件(pxelinux.0、pxelinux.cfg&#x2F;default)。default文件下载完成后，会根据该文件中定义的引导顺序，启动Linux安装程序的引导内核。 5、请求下载自动应答文件： 客户端通过pxelinux.cfg&#x2F;default文件成功的引导Linux安装内核后，安装程序首先必须确定你通过什么安装介质来安装linux，如果是通过网络安装(NFS, FTP, HTTP)，则会在这个时候初始化网络，并定位安装源位置。接着会读取default文件中指定的自动应答文件ks.cfg所在位置，根据该位置请求下载该文件。 这里有个问题，在第2步和第5步初始化2次网络了，这是由于PXE获取的是安装用的内核以及安装程序等，而安装程序要获取的是安装系统所需的二进制包以及配置文件。因此PXE模块和安装程序是相对独立的，PXE的网络配置并不能传递给安装程序，从而进行两次获取IP地址过程，但IP地址在DHCP的租期内是一样的。 6、客户端安装操作系统： 将ks.cfg文件下载回来后，通过该文件找到OS Server，并按照该文件的配置请求下载安装过程需要的软件包。 OS Server和客户端建立连接后，将开始传输软件包，客户端将开始安装操作系统。安装完成后，将提示重新引导计算机。 三、kickstart批量部署实战环境： selinux关闭，防火墙关闭 Server：192.168.2.100 Step 1 配置dnf源 1234567891011[root@zutuanxue ~]# cat server.repo [serverApp]name=appenabled=1gpgcheck=0baseurl=file:///mnt/AppStream[serverOS]name=osenabled=1gpgcheck=0baseurl=file:///mnt/BaseOS Step 2 安装软件包 1[root@zutuanxue ~]# dnf install dhcp-server tftp-server httpd syslinux -y Step 3 搭建并启动DHCP 12345678910111213[root@zutuanxue ~]# vim /etc/dhcp/dhcpd.conf subnet 192.168.2.0 netmask 255.255.255.0 &#123; option routers 192.168.2.100; range 192.168.2.10 192.168.2.20; next-server 192.168.2.100; filename &quot;pxelinux.0&quot;;&#125;[root@zutuanxue ~]# systemctl start dhcpd[root@zutuanxue ~]# systemctl status dhcpd[root@zutuanxue ~]# netstat -antlup | grep :67udp 0 0 0.0.0.0:67 0.0.0.0:* 31465/dhcpd udp 0 0 0.0.0.0:67 0.0.0.0:* 1345/dnsmasq Step 4 生成需要的文件并启动tftp服务 12345678910111213[root@zutuanxue ~]# cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/[root@zutuanxue ~]# cp /mnt/isolinux/&#123;vmlinuz,ldlinux.c32,initrd.img&#125; /var/lib/tftpboot/[root@zutuanxue ~]# mkdir /var/lib/tftpboot/pxelinux.cfg[root@zutuanxue ~]# vim /var/lib/tftpboot/pxelinux.cfg/default #生成default文件default linuxtimeout 3label linux kernel vmlinuz append initrd=initrd.img ip=dhcp method=http://192.168.2.100/RHEL ks=http://192.168.2.100/ks.cfg[root@zutuanxue mnt]# systemctl start tftp #启动tftp服务[root@zutuanxue mnt]# systemctl status tftp[root@zutuanxue mnt]# netstat -antulp | grep :69udp6 0 0 :::69 :::* 1/systemd Step 5 搭建并启动http服务 12[root@zutuanxue ~]# mkdir /var/www/html/RHEL #建立软件包存放目录[root@zutuanxue ~]# mount /dev/cdrom /var/www/html/RHEL #将光盘挂载到对应目录中 Step 6 生成ks.cfg文件 由于CentOS8.0中没有system-config-kickstart包，所以无法通过工具生成ks文件，需要手动生成，例子中root用户和新建的hello用户的密码都为‘&#96;123qwe’ 如果需要自己额外指定密码，请使用其它工具进行转换，例如doveadm命令 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647cp /root/anaconda-ks.cfg /var/www/html/ks.cfg\t#生成ks.cfg文件[root@zutuanxue ~]# vim /var/www/html/ks.cfg#version=RHEL8ignoredisk --only-use=sdaautopart --type=lvm# Partition clearing informationclearpart --all #删除所有分区# Use graphical installgraphicalurl --url=&quot;http://192.168.2.100/RHEL/&quot; #指定安装URL# Keyboard layoutskeyboard --vckeymap=cn --xlayouts=&#x27;cn&#x27;# System languagelang zh_CN.UTF-8# Network informationnetwork --bootproto=dhcp --device=ens33 --ipv6=auto --activatenetwork --hostname=localhost.localdomain##root用户的密码&quot;111111&quot;rootpw --iscrypted $6$kdHt1qIdgNPlHUD1$zibMjh/AQGZQjIJe8Q4HYiin.IKaV7MHWciueiwbLD/03giuSqzU5ynSu/giDAjMLpJFj/CpNgT7TKSm5XyxV1# X Window System configuration informationxconfig --startxonboot# Run the Setup Agent on first boot#firstboot disable #初次启动设置firstboot --disable# System servicesservices --enabled=&quot;chronyd&quot;# System timezonetimezone America/New_York --isUtc#Reboot after installation\t#安装完成后自动重启reboot# License agreement #同意授权协议eula --agreed#添加一个普通用户名字为zutuanxue密码&quot;111111&quot; 属组为 whelluser --groups=wheel --name=zutuanxue --password=$6$kdHt1qIdgNPlHUD1$zibMjh/AQGZQjIJe8Q4HYiin.IKaV7MHWciueiwbLD/03giuSqzU5ynSu/giDAjMLpJFj/CpNgT7TKSm5XyxV1 --iscrypted --gecos=&quot;zutuanxue&quot;%packages@^graphical-server-environment%end%addon com_redhat_kdump --disable --reserve-mb=&#x27;auto&#x27;%end%anacondapwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notemptypwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyokpwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty%end Step 7 修改文件权限，启动http服务 123456[root@zutuanxue ~]# chmod a+r /var/www/html/ks.cfg[root@zutuanxue ~]# systemctl start httpd[root@zutuanxue ~]# systemctl start httpd[root@zutuanxue ~]# systemctl status httpd[root@zutuanxue ~]# netstat -antlp | grep :80tcp6 0 0 :::80 :::* LISTEN 33976/httpd Step 8 测试 选择网络启动 image20191202110450898.png 获取IP和相关文件 image20191202110525859.png 开启安装进程 install6.png 安装完成后自动重启 install7.png 四、kickstart+uefi批量部署环境： selinux关闭，防火墙关闭 Server：192.168.2.100 Step 1 配置dnf源 1234567891011[root@zutuanxue ~]# cat server.repo [serverApp]name=appenabled=1gpgcheck=0baseurl=file:///mnt/AppStream[serverOS]name=osenabled=1gpgcheck=0baseurl=file:///mnt/BaseOS Step 2 安装软件包 1[root@zutuanxue ~]# dnf install dhcp-server tftp-server httpd -y Step 3 搭建并启动DHCP 12345678910111213[root@zutuanxue ~]# vim /etc/dhcp/dhcpd.conf subnet 192.168.2.0 netmask 255.255.255.0 &#123; option routers 192.168.2.100; range 192.168.2.10 192.168.2.20; next-server 192.168.2.100; filename &quot;BOOTX64.EFI&quot;;#注意差异，使用的不是pxelinux.0&#125;[root@zutuanxue ~]# systemctl start dhcpd[root@zutuanxue ~]# systemctl status dhcpd[root@zutuanxue ~]# netstat -antlup | grep :67udp 0 0 0.0.0.0:67 0.0.0.0:* 31465/dhcpd udp 0 0 0.0.0.0:67 0.0.0.0:* 1345/dnsmasq Step 4 生成需要的文件并启动tftp服务 12345678910111213141516[root@zutuanxue ~]# cd /mnt/EFI/BOOT/[root@zutuanxue BOOT]# cp BOOTX64.EFI grub.cfg grubx64.efi /var/lib/tftpboot/[root@zutuanxue ~]# cp /mnt/isolinux/&#123;vmlinuz,initrd.img&#125; /var/lib/tftpboot/[root@zutuanxue ~]# vim /var/lib/tftpboot/grub.cfgset default=&quot;0&quot;set timeout=3menuentry &#x27;Install CentOS Linux 8.0.1905&#x27; &#123; linuxefi /vmlinuz ip=dhcp ks=http://192.168.2.100/ks.cfg initrdefi /initrd.img&#125;[root@zutuanxue mnt]# systemctl start tftp #启动tftp服务[root@zutuanxue mnt]# systemctl status tftp[root@zutuanxue mnt]# netstat -antulp | grep :69udp6 0 0 :::69 :::* 1/systemd Step 5 搭建并启动http服务 12[root@zutuanxue ~]# mkdir /var/www/html/RHEL #建立软件包存放目录[root@zutuanxue ~]# mount /dev/cdrom /var/www/html/RHEL #将光盘挂载到对应目录中 Step 6 生成ks.cfg文件 由于CentOS8.0中没有system-config-kickstart包，所以无法通过工具生成ks文件，需要手动生成，例子中root用户和新建的hello用户的密码都为‘&#96;123qwe’ https://access.redhat.com/labs/kickstartconfig/ 如果需要自己额外指定密码，请使用其它工具进行转换，例如doveadm命令，但是系统没有这个工具，所以推荐使用python来实现 注意： 1[root@zutuanxue ~]# python3 -c &#x27;import crypt,getpass;pw=&quot;zutuanxue&quot;;print(crypt.crypt(pw))&#x27; 生成ks.cfg文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647cp /root/anaconda-ks.cfg /var/www/html/ks.cfg\t#生成ks.cfg文件[root@zutuanxue ~]# vim /var/www/html/ks.cfg#version=RHEL8ignoredisk --only-use=nvme0n1 ###注意这是与BIOS方式差异的位置，注意设备类型，可在BIOS中查看到autopart --type=lvm# Partition clearing informationclearpart --all #删除所有分区# Use graphical installgraphicalurl --url=&quot;http://192.168.2.100/RHEL/&quot; #指定安装URL# Keyboard layoutskeyboard --vckeymap=cn --xlayouts=&#x27;cn&#x27;# System languagelang zh_CN.UTF-8# Network informationnetwork --bootproto=dhcp --device=ens33 --ipv6=auto --activatenetwork --hostname=localhost.localdomain# Root password\t“`123qwe” ##root用户的密码&quot;111111&quot;rootpw --iscrypted $6$kdHt1qIdgNPlHUD1$zibMjh/AQGZQjIJe8Q4HYiin.IKaV7MHWciueiwbLD/03giuSqzU5ynSu/giDAjMLpJFj/CpNgT7TKSm5XyxV1# X Window System configuration informationxconfig --startxonboot# Run the Setup Agent on first boot#firstboot disable #初次启动设置firstboot --disable# System servicesservices --enabled=&quot;chronyd&quot;# System timezonetimezone America/New_York --isUtc#Reboot after installation\t#安装完成后自动重启reboot# License agreement #同意授权协议eula --agreed#添加一个普通用户名字为zutuanxue密码&quot;111111&quot; 属组为 whelluser --groups=wheel --name=zutuanxue --password=$6$kdHt1qIdgNPlHUD1$zibMjh/AQGZQjIJe8Q4HYiin.IKaV7MHWciueiwbLD/03giuSqzU5ynSu/giDAjMLpJFj/CpNgT7TKSm5XyxV1 --iscrypted --gecos=&quot;zutuanxue&quot;%packages@^graphical-server-environment%end%addon com_redhat_kdump --disable --reserve-mb=&#x27;auto&#x27;%end%anacondapwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notemptypwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyokpwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty%end Step 7 修改文件权限，启动http服务 123456[root@zutuanxue ~]# chmod a+r /var/www/html/ks.cfg[root@zutuanxue ~]# systemctl start httpd[root@zutuanxue ~]# systemctl start httpd[root@zutuanxue ~]# systemctl status httpd[root@zutuanxue ~]# netstat -antlp | grep :80tcp6 0 0 :::80 :::* LISTEN 33976/httpd Step 8 测试 新建虚拟机的是要选择自定义使用UEFI"},{"path":"/2023/07/11/Linux常用服务器部署实战/Linux 时间服务器/","content":"概述什么是时间服务器 NTP：Network Time Protocol 网络时间协议，用来同步网络中各主机的时间，在linux系统中早期使用ntp来实现，后来使用chrony来实现，Chrony 应用本身已经有几年了，其是是网络时间协议的 (NTP) 的另一种实现。 Chrony可以同时做为ntp服务的客户端和服务端 一直以来众多发行版里标配的都是ntpd对时服务，自rhel7&#x2F;centos7 起，Chrony做为了发行版里的标配服务，不过老的ntpd服务依旧在rhel7&#x2F;centos7里可以找到 。 核心组件： chronyd：是守护进程，主要用于调整内核中运行的系统时间和时间服务器同步。它确定计算机增减时间的比率，并对此进行调整补偿。 chronyc：提供一个用户界面，用于监控性能并进行多样化的配置。它可以在chronyd实例控制的计算机上工作，也可以在一台不同的远程计算机上工作。 优势 chrony用来同步时间，来代替ntp服务，优点是很精巧的时间同步工具，更快响应时钟变化，在应对延时提供更好的稳定性能，不会出现时间空白，跨越互联网同步时间只需要几毫秒。 它的优势主要包括 12345#更快的同步：能在最大程度的减少时间和频率误差，这对于非全天运行的台式计算机或系统而言非常有用#更快的响应速度：能够更好的响应时间频率的快速变化，这对于具备不稳定时钟的虚拟机或导致时钟频率发生变化的节能技术而言更有帮助#稳定：在初始同步后，它并不会停止时钟，以防对需要系统时间的程序造成影响，以及可以更好的应对延迟 相关文件说明 &#x2F;etc&#x2F;chrony.conf 主配置文件 &#x2F;usr&#x2F;bin&#x2F;chronyc 客户端程序工具 &#x2F;usr&#x2F;sbin&#x2F;chronyd 服务端程序 配置文件说明 123456789101112131415161718192021222324252627282930313233343536373839[root@zutuanxue ~]# vim /etc/chrony.conf# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).pool 2.centos.pool.ntp.org iburst###指定时间服务器的地址，可以使用pool开始也可以使用server开始，iburst可以加速初始同步，perfer表示优先# Record the rate at which the system clock gains/losses time.driftfile /var/lib/chrony/drift#用来记录时间差异，由于chrony是通过BIOS判断时间的，他会用这个时间与上层时间服务器进行对比，将差异记录下来# Allow the system clock to be stepped in the first three updates# if its offset is larger than 1 second.makestep 1.0 3#让chrony可以根据需求逐步进行时间的调整，避免在某些情况下时间差异较大，导致调整时间耗时过长，以上的设置表示在误差时间大于1.0秒的话，前三次使用update更新时间是使用step（分阶段）而不是slew(微调),如果最后一个值是负数的话，如-1则表示随时步进# Enable kernel synchronization of the real-time clock (RTC).rtcsync#启用内核模式，在内核模式中，系统时间每11分钟会同步到实时时钟（RTC）# Enable hardware timestamping on all interfaces that support it.#hwtimestamp *# 通过使用hwtimestamp指令启用硬件时间戳# Increase the minimum number of selectable sources required to adjust# the system clock.#minsources 2# Allow NTP client access from local network.#allow 192.168.0.0/16#允许同步的网段# Serve time even if not synchronized to a time source.#local stratum 10#即时自己未能通过网络时间服务器同步时间，也允许将本地时间作为标准时间同步给其他客户端# Specify file containing keys for NTP authentication.keyfile /etc/chrony.keys#验证的秘钥文件# Get TAI-UTC offset and leap seconds from the system tz database.leapsectz right/UTC#从system tz数据库中获取TAI(国际原子时)和UTC（协调世界时）之间的时间偏移及闰秒# Specify directory for log files.logdir /var/log/chrony#日志文件的位置# Select which information is logged.#log measurements statistics tracking 时间服务器实战环境：两台主机，系统为CentOS8，IP地址为192.168.2.100,192.168.2.200,selinux和防火墙关闭 要求: 192.168.2.100为内网时间服务器，192.168.2.200为客户端，200的客户端的时间要与100的时间同步 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788在192.168.2.100主机上step1\t检查时间服务器上是否有相关软件包[root@zutuanxue ~]# rpm -qa | grep chronychrony-3.3-3.el8.x86_64step2\t检查本机的时区[root@zutuanxue ~]# timedatectl Local time: 五 2020-01-17 17:36:14 CST Universal time: 五 2020-01-17 09:36:14 UTC RTC time: 五 2020-01-17 09:36:56 Time zone: Asia/Shanghai (CST, +0800)System clock synchronized: yes NTP service: active RTC in local TZ: no注：如果不是本地时区请设置时区[root@zutuanxue ~]# timedatectl list-timezones | grep ShanghaiAsia/Shanghai[root@zutuanxue ~]# timedatectl set-timezone Asia/Shanghaistep3\t修改配置文件[root@zutuanxue ~]# vim /etc/chrony.confserver 192.168.2.100 iburst #定义时间服务器的地址driftfile /var/lib/chrony/drift\tmakestep 1.0 3rtcsyncallow 192.168.2.0/24\t#定义允许谁来同步local stratum 10\t#允许将本地时间作为标准leapsectz right/UTC\tlogdir /var/log/chronybindaddress 192.168.2.100\t#监听的网络接口step4\t启动服务&amp;查看端口[root@zutuanxue ~]# systemctl start chronyd[root@zutuanxue ~]# lsof -i :123在192.168.2.200主机上step5\t检查软件包[root@slave ~]# rpm -qa | grep chronychrony-3.3-3.el8.x86_64step6\t检查并设置本机时区[root@slave ~]# timedatectl Local time: 五 2020-01-17 04:19:38 EST Universal time: 五 2020-01-17 09:19:38 UTC RTC time: 五 2020-01-17 16:04:57 Time zone: America/New_York (EST, -0500)System clock synchronized: yes NTP service: active RTC in local TZ: no[root@slave ~]# timedatectl list-timezones |grep ShanghaiAsia/Shanghai[root@slave ~]# timedatectl set-time Asia/Shanghaistep7\t修改配置文件[root@zutuanxue ~]# vim /etc/chrony.confserver 192.168.2.100 iburstdriftfile /var/lib/chrony/driftmakestep 1.0 3rtcsynckeyfile /etc/chrony.keysleapsectz right/UTClogdir /var/log/chronystep8 启动服务&amp;检查能否连接时间服务器[root@slave ~]# systemctl start chronyd[root@slave ~]# chronyc sources -v210 Number of sources = 1 .-- Source mode &#x27;^&#x27; = server, &#x27;=&#x27; = peer, &#x27;#&#x27; = local clock. / .- Source state &#x27;*&#x27; = current synced, &#x27;+&#x27; = combined , &#x27;-&#x27; = not combined,| / &#x27;?&#x27; = unreachable, &#x27;x&#x27; = time may be in error, &#x27;~&#x27; = time too variable.|| .- xxxx [ yyyy ] +/- zzzz|| Reachability register (octal) -. | xxxx = adjusted offset,|| Log2(Polling interval) --. | | yyyy = measured offset,|| \\ | | zzzz = estimated error.|| | | \\MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^* 192.168.2.100 11 6 377 57 +13ms[ +278us] +/- 3718us#可以在2.100上使用date -s命令修改时间，在2.200上重启服务，看到时间同步chronyc命令chronyc sources -v 查看时间同步源chronyc sourcestats -v\t查看时间同步源状态timedatectl set-local-rtc 1\t设置硬件时间硬件时间默认为UTCtimedatectl set-ntp yes\t启用NTP时间同步：chronyc tracking\t校准时间服务器："},{"path":"/2023/07/11/Linux常用服务器部署实战/Linux 双机热备/","content":"一 Rsync概述1.1、什么是Rsyncrsync是一款开源，快速，多功能的可实现增量的本地或远程的数据镜像同步备份的优秀工具。适用于多个平台。从软件名称可以看出来是远程同步的意思（remote sync）可实现全量备份与增量备份，因此非常适合用于架构集中式备份或异地备份等应用。 官网： http://rsync.samba.org/ 端口： 873 运行模式： C&#x2F;S B&#x2F;S 1.2、rsync特性1、支持拷贝特殊文件如链接文件、设备等 2、可以有排除指定文件或目录同步的功能，相当于tar的排除功能 3、可以做到保持原文件或目录的权限、时间、软硬链接、属主、组等所有属性均不改变 4、可以实现增量同步，即只同步发生变化的数据，因此数据传输效率很高 5、可以使用rcp，rsh，ssh等方式来配合传输文件（rsync本身不对数据加密） 6、可以通过socket（进程方式）传输文件和数据（服务端和客户端）。 7、支持匿名的或认证（无须系统用户）的进程模式传输，可实现方便安全的进行数据备份及镜像 1.3、传输方式拉复制(下载)： rsync备份服务器定期去所有主机上拉取数据 image20200116202338681.png 推复制（上传）： 所有主服务器将本地数据推送至从服务器 image20200116202157436.png 在日常使用中，这两种形式都是混合使用的如： 大量数据备份 image20200116202528449.png 异地备份 image20200116202556118.png 二 rsync拉复制实战环境： 两台主机，IP地址为192.168.11.16，192.168.11.100 操作系统为CentOS8 关闭selinux和防火墙 需求： 希望192.168.11.100这台主机&#x2F;cache目录的数据与192.168.11.16这台主机&#x2F;cache目录中的数据保持一致 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172step1\t在192.168.11.16这台主机上制作rsync服务[root@zutuanxue ~]# rpm -qa | grep rsyncrsync-3.1.3-4.el8.x86_64#检查是或否安装的相关软件包[root@zutuanxue ~]# mkdir /etc/rsyncd[root@zutuanxue ~]# vim rsyncd.confuid=root #定义以哪个用户的身份启动进程\tgid=root #定义以哪个组的身份启动进程port=873 #此服务默认端口873max connections=0 #最大连接数（正整数），0代表不限制。log file=/var/log/rsyncd.log\t#定义日志文件位置pid file=/var/run/rsyncd.pid\t#定义pid文件位置lock file=/var/run/rsyncd.lock\t#定义锁定文件位置，避免多开motd file=/etc/rsyncd/rsyncd.motd\t#定义欢迎信息read only=yes #权限为只读hosts allow=192.168.11.0/24 #允许的网段hosts deny=* #拒绝所有，允许个别[www]\t#定义共享名称为wwwpath=/cache #路径list=yes #允许别人看到ignore errors #忽略错误auth users=hello #授权的账号secrets file=/etc/rsyncd/rsyncd.secrets\t#密码文件setp2\t建立欢迎信息文件，内容随意[root@zutuanxue ~]# vim /etc/rsyncd/rsyncd.motdstep3\t建立密码文件[root@zutuanxue ~]# vim /etc/rsyncd/rsyncd.secretshello：123456[root@zutuanxue ~]# chmod 600 rsyncd.secretsstep4\t建立cache目录和文件[root@zutuanxue ~]# mkdir /cache[root@zutuanxue ~]# touch /cache/file&#123;1..10&#125;step5启动服务[root@zutuanxue ~]# rsync\t--daemon --config=/etc/rsyncd/rsyncd.conf[root@zutuanxue ~]# lsof\t-i\t:873step6\t在192.168.11.100上建立密码文件并修改权限[root@slave ~]# vim /etc/rsync.pw123456[root@slave ~]# chmod 600 /etc/rsync.pw[root@slave ~]#\tmkdir /cachestep7\t同步测试[root@slave ~]#\trsync -avzP\t--delete --password-file=/etc/rsync.pw hello@192.168.11.16::www /cache rsync参数-a\t归档模式传输，相当于-rlptgoD一起使用-v\t详细模式输出-z\t传输时进行压缩以提高效率-r\t递归传输目录及子目录，即目录下得所有目录都同样传输-t\t保持文件时间信息-o\t保持文件属主信息-p\t保持文件权限-g\t保持文件属组信息-l 保留软连接-P\t显示同步的过程及传输时的进度等信息-D\t保持设备文件信息-L\t保留软连接指向的目标文件--exclude=PATTERN\t指定排除不需要传输的文件模式--bwlimit=1m\t限速传输--delete\t让目标目录和源目录数据保持一致--password-file\t指定密码文件位置step8\t定义计划任务[root@slave ~]#\tcrontab -e* * * * * rsync -avzP\t--delete --password-file=/etc/rsync.pw hello@192.168.11.16::www /cachestep9\t将11.16主机上文件进行调整，观察是否改变 三 Rsync推复制环境： 两台主机，IP地址为192.168.11.16，192.168.11.100 操作系统为CentOS8 关闭selinux和防火墙 需求： 希望192.168.11.100这台主机&#x2F;cache目录的数据与192.168.11.16这台主机&#x2F;cache目录中的数据保持一致 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566注：停止192.168.11.16主机上的rsync服务step1\t在192.168.11.100这台主机上制作rsync服务[root@slave ~]# rpm -qa | grep rsyncrsync-3.1.3-4.el8.x86_64#检查是或否安装的相关软件包[root@slave ~]# mkdir /etc/rsyncd[root@slave ~]# vim rsyncd.confuid=root #定义以哪个用户的身份启动进程\tgid=root #定义以哪个组的身份启动进程port=873 #此服务默认端口873max connections=0 #最大连接数（正整数），0代表不限制。log file=/var/log/rsyncd.log\t#定义日志文件位置pid file=/var/run/rsyncd.pid\t#定义pid文件位置lock file=/var/run/rsyncd.lock\t#定义锁定文件位置，避免多开motd file=/etc/rsyncd/rsyncd.motd\t#定义欢迎信息read only=no #权限为不只读（可写）hosts allow=192.168.11.0/24 #允许的网段hosts deny=* #拒绝所有，允许个别[www]\t#定义共享名称为wwwpath=/cache #路径list=yes #允许别人看到ignore errors #忽略错误auth users=hello #授权的账号secrets file=/etc/rsyncd/rsyncd.secrets\t#密码文件setp2\t建立欢迎信息文件，内容随意[root@slave ~]# vim /etc/rsyncd/rsyncd.motdstep3\t建立密码文件[root@slave ~]# vim /etc/rsyncd/rsyncd.secretshello：123456[root@slave ~]# chmod 600 rsyncd.secretsstep4\t建立cache目录[root@slave ~]# mkdir /cachestep5启动服务[root@slave ~]# rsync\t--daemon --config=/etc/rsyncd/rsyncd.conf[root@slave ~]# lsof\t-i\t:873step6\t在192.168.11.16上安装监控软件[root@zutuanxue ~]# tar fx sersync2.5_32bit_binary_stable_final.tar.gz -C /usr/src/[root@zutuanxue ~]# cd /usr/src/GNU-Linux-x86/step7\t配置监控软件[root@zutuanxue ~]# vim confxml.xml &lt;sersync&gt; &lt;localpath watch=&quot;/cache&quot;&gt; &lt;remote ip=&quot;192.168.11.100&quot; name=&quot;www&quot;/&gt; . . . &lt;rsync&gt; &lt;commonParams params=&quot;-artuz&quot;/&gt; &lt;auth start=&quot;true&quot; users=&quot;hello&quot; passwordfile=&quot;/etc/rsync.pw&quot;/&gt;[root@zutuanxue ~]# vim /etc/rsync.pw123456[root@zutuanxue ~]# chmod 600 rsync.pw step8\t启动监控软件[root@zutuanxue ~]# ./sersync2\t-r\t#第一次启动加-r 可以查看到工作流程step9\t重新打开一个终端，在192.168.11.16上建立、删除文件，去192.168.11.100上查看是否同步成功"},{"path":"/2023/07/11/Linux常用服务器部署实战/FTP文件服务器/","content":"一、FTP介绍FTP (File transfer protocol) 是TCP&#x2F;IP 协议组中的协议之一。他最主要的功能是在服务器与客户端之间进行文件的传输。FTP就是实现两台计算机之间的拷贝，从远程计算机拷贝文件至自己的计算机上，称之为“下载 （download）”文件。将文件从自己计算机中拷贝至远程计算机上，则称之为“上传（upload）”文件。这个古老的协议使用的是明码传输方式，且过去有相当多的安全危机历史。为了更安全的使用 FTP 协议，我们主要介绍较为安全但功能较少的 vsftpd(very secure File transfer protocol ) 这个软件。FTP是一个C&#x2F;S类型的软件，FTP监听TCP端口号为21，数据端口为20。 二、应用场景下载服务器：提供对外的下载服务 文件服务器：提供上传和下载服务 三、FTP的权限FTP 服务器的功能除了单纯的进行文件的传输与管理之外，依据服务器软件的设定架构，它还可以提供几个主要的功能。：不同等级的用户身份：user, guest, anonymousFTP 服务器在默认的情况下，依据使用者登录的情况而分为三种不同的身份，分别是： (1)本地用户：系统中真实存在的用户 (2)来宾, guest； (3)匿名登录者, anonymous 这三种身份的用户在系统上面的权限差异很大！例如实体用户取得系统的权限比较完整， 所以可以进行比较多的动作；至于匿名登录者，大概我们就仅提供他下载资源的能力而已，并不许匿名者使用太多主机的资源！ 当然，这三种人物因为权限的不同能够使用的【在线命令】自然也就不相同！ 四、FTP的工作模式FTP支持两种模式，一种方式叫做Standard (也就是 PORT方式，主动方式)，一种是 Passive (也就是PASV，被动方式)。 Standard模式 FTP的客户端发送 PORT 命令到FTP服务器。Passive模式FTP的客户端发送 PASV命令到 FTP Server。 下面介绍一个这两种方式的工作原理： Port模式FTP 客户端首先和FTP服务器的TCP 21端口建立连接，通过这个通道发送命令，客户端需要接收数据的时候在这个通道上发送PORT命令。 PORT命令包含了客户端用什么端口接收数据。在传送数据的时候，服务器端通过自己的TCP 20端口连接至客户端的指定端口发送数据。 FTP server必须和客户端建立一个新的连接用来传送数据。 Passive模式在建立控制通道的时候和Standard模式类似，但建立连接后发送的不是Port命令，而是Pasv命令。FTP服务器收到Pasv命令后，随机打开一个高端端口（端口号大于1024）并且通知客户端在这个端口上传送数据的请求，客户端连接FTP服务器此端口，然后FTP服务器将通过这个端口进行数据的传送，这个时候FTP server不再需要建立一个新的和客户端之间的连接。 很多防火墙在设置的时候都是不允许接受外部发起的连接的，所以许多位于防火墙后或内网的FTP服务器不支持PASV模式，因为客户端无法穿过防火墙打开FTP服务器的高端端口；而许多内网的客户端不能用PORT模式登陆FTP服务器，因为从服务器的TCP 20无法和内部网络的客户端建立一个新的连接，造成无法工作。 五、FTP安装部署约定：本实验中使用过的机器为centos8.0_x86_64系统，IP地址192.168.11.16&#x2F;24.请关闭防火墙和SELINUX。 123456789101112131415vsftp安装[root@localhost ~]# dnf -y install vsftpd ftpvsftp开机启动[root@localhost ~]# systemctl enable vsftpdCreated symlink from /etc/systemd/system/multi-user.target.wants/vsftpd.service to /usr/lib/systemd/system/vsftpd.service.启动vsftp服务[root@localhost ~]# systemctl start vsftpd验证启动[root@localhost ~]# lsof -i :21COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEvsftpd 1951 root 4u IPv6 32837 0t0 TCP *:ftp (LISTEN) 六、FTP配置文件6.1）相关文件主配文件:&#x2F;etc&#x2F;vsftpd&#x2F;vsftpd.conf 下载目录:&#x2F;var&#x2F;ftp&#x2F; FTP日志:&#x2F;var&#x2F;log&#x2F;xferlog 6.2）主配文件详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165# Example config file /etc/vsftpd/vsftpd.conf## The default compiled in settings are fairly paranoid. This sample file# loosens things up a bit, to make the ftp daemon more usable.# Please see vsftpd.conf.5 for all compiled in defaults.## READ THIS: This example file is NOT an exhaustive list of vsftpd options.# Please read the vsftpd.conf.5 manual page to get a full idea of vsftpd&#x27;s# capabilities.##匿名用户访问,YES是允许，NO是拒绝# Allow anonymous FTP? (Beware - allowed by default if you comment this out).anonymous_enable=NO## Uncomment this to allow local users to log in.# 本地用户登录,YES是允许，NO是拒绝.默认访问的是本地用户家目录，如果你开启了selinux# 请设置开启布尔值ftp_home_dir为ON# When SELinux is enforcing check for SE bool ftp_home_dirlocal_enable=YES##允许本地用户上传# Uncomment this to enable any form of FTP write command.write_enable=YES## Default umask for local users is 077. You may wish to change this to 022,# 上传的权限是022，使用的是umask权限。对应的目录是755，文件是644# if your users expect that (022 is used by most other ftpd&#x27;s)local_umask=022## Uncomment this to allow the anonymous FTP user to upload files. This only# has an effect if the above global write enable is activated. Also, you will# obviously need to create a directory writable by the FTP user.# When SELinux is enforcing check for SE bool allow_ftpd_anon_write, allow_ftpd_full_access# 开启匿名用户上传功能，默认是拒绝的#anon_upload_enable=YES## Uncomment this if you want the anonymous FTP user to be able to create# new directories.# 开启匿名用户创建文件或文件夹权限#anon_mkdir_write_enable=YES## Activate directory messages - messages given to remote users when they# go into a certain directory.# 开启目录欢迎消息，一般对命令行登陆有效dirmessage_enable=YES## Activate logging of uploads/downloads.# 开启上传和下载日志记录功能xferlog_enable=YES##使用标准模式# Make sure PORT transfer connections originate from port 20 (ftp-data).connect_from_port_20=YES## If you want, you can arrange for uploaded anonymous files to be owned by# a different user. Note! Using &quot;root&quot; for uploaded files is not# recommended!# 声明匿名用户上传文件的所有者# 允许更改匿名用户上传文件的所有者#chown_uploads=YES#所有者为whoever#chown_username=whoever## You may override where the log file goes if you like. The default is shown# below.# 日志文件路径#xferlog_file=/var/log/xferlog## If you want, you can have your log file in standard ftpd xferlog format.# Note that the default log file location is /var/log/xferlog in this case.# 日志文件采用标准格斯xferlog_std_format=YES## You may change the default value for timing out an idle session.# 会话超时时间#idle_session_timeout=600## You may change the default value for timing out a data connection.# 数据传输超时时间#data_connection_timeout=120## It is recommended that you define on your system a unique user which the# ftp server can use as a totally isolated and unprivileged user.# FTP子进程管理用户#nopriv_user=ftpsecure## Enable this and the server will recognise asynchronous ABOR requests. Not# recommended for security (the code is non-trivial). Not enabling it,# however, may confuse older FTP clients.# 是否允许客户端发起“async ABOR”请求，该操作是不安全的默认禁止。#async_abor_enable=YES## By default the server will pretend to allow ASCII mode but in fact ignore# the request. Turn on the below options to have the server actually do ASCII# mangling on files when in ASCII mode. The vsftpd.conf(5) man page explains# the behaviour when these options are disabled.# Beware that on some FTP servers, ASCII support allows a denial of service# attack (DoS) via the command &quot;SIZE /big/file&quot; in ASCII mode. vsftpd# predicted this attack and has always been safe, reporting the size of the# raw file.# ASCII mangling is a horrible feature of the protocol.# 该选项用于指定是否允许上传时以ASCII模式传输数据#ascii_upload_enable=YES#该选项用于指定是否允许下载时以ASCII模式传输数据#ascii_download_enable=YES## You may fully customise the login banner string:# FTP文本界面登陆欢迎词#ftpd_banner=Welcome to blah FTP service.## You may specify a file of disallowed anonymous e-mail addresses. Apparently# useful for combatting certain DoS attacks.# 是否开启拒绝的Email功能#deny_email_enable=YES# (default follows)# 指定保存被拒接的Email地址的文件#banned_email_file=/etc/vsftpd/banned_emails## You may specify an explicit list of local users to chroot() to their home# directory. If chroot_local_user is YES, then this list becomes a list of# users to NOT chroot().# (Warning! chroot&#x27;ing can be very dangerous. If using chroot, make sure that# the user does not have write access to the top level directory within the# chroot)# 是否开启对本地用户chroot的限制，YES为默认所有用户都不能切出家目录，NO代表默认用户都可以切出家目录# 设置方法类似于：YES拒绝所有，允许个别 NO 允许所有拒绝个别#chroot_local_user=YES#开启特例列表#chroot_list_enable=YES# (default follows)# 如果chroot_local_user的值是YES则该文件中的用户是可以切出家目录，如果是NO，该文件中的用户则不能切出家目录# 一行一个用户。#chroot_list_file=/etc/vsftpd/chroot_list## You may activate the &quot;-R&quot; option to the builtin ls. This is disabled by# default to avoid remote users being able to cause excessive I/O on large# sites. However, some broken FTP clients such as &quot;ncftp&quot; and &quot;mirror&quot; assume# the presence of the &quot;-R&quot; option, so there is a strong case for enabling it.# 是否开启ls 递归查询功能 ls -R#ls_recurse_enable=YES## When &quot;listen&quot; directive is enabled, vsftpd runs in standalone mode and# listens on IPv4 sockets. This directive cannot be used in conjunction# with the listen_ipv6 directive.# 是否开启ftp独立模式在IPV4listen=NO## This directive enables listening on IPv6 sockets. By default, listening# on the IPv6 &quot;any&quot; address (::) will accept connections from both IPv6# and IPv4 clients. It is not necessary to listen on *both* IPv4 and IPv6# sockets. If you want that (perhaps because you want to listen on specific# addresses) then you must run two copies of vsftpd with two configuration# files.# Make sure, that one of the listen options is commented !!# 是否开启ftp独立模式在ipv6listen_ipv6=YES#启用pam模块验证pam_service_name=vsftpd#是否开启userlist功能.#是否启用用户列表功能userlist_enable=YES 通过配置文件的分析，VSFTP不允许匿名访问，本地用户可以下载和上传。如果允许匿名用户登录的话需要将anonymous_enable&#x3D;YES，然后重新启动服务 我们可以通过修改配置文件的内容即可配置FTP的相关登陆情况。 七、FTP客户端访问FTP是一个C&#x2F;S类型的软件,连接服务端需要FTP客户端才能完成，常见的FTP客户端有以下几种: 浏览器：可以通过浏览器中输入 ftp://ip或者ftp://域名的方式来访问FTP 自带客户端:命令行下可以使用ftp命令去连接 三方客户端：FileZilla 8uftp 图形软件或者文本界面的lftp等 三种方式中，文本界面是比较麻烦的，无法鼠标流。所以我重点给大家讲解一下 7.1）文本界面登陆123456789101112131415161718192021222324252627282930313233343536373839404142434445464748文本界面匿名登陆[root@localhost ~]# ftp 192.168.11.16Connected to 192.168.11.16 (192.168.11.16).220 (vsFTPd 3.0.3)Name (192.168.11.16:root): ftp\t#用户名可以是ftp也可以是anonymous331 Please specify the password.Password: #密码为空230 Login successful. #显示登陆成功Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; ls227 Entering Passive Mode (192,168,11,16,90,35).150 Here comes the directory listing.drwxr-xr-x 2 0 0 6 May 14 2019 pub226 Directory send OK.通过ls可以列出当前目录下有哪些内容 看到有一个目录叫pubftp&gt; pwd257 &quot;/&quot; 通过pwd命令查看当前路径 注意这里显示的是FTP的根目录ftp&gt; bye221 Goodbye.退出使用bye命令文本界面本地用户登录[root@localhost ~]# ftp 192.168.11.16Connected to 192.168.11.16 (192.168.11.16).220 (vsFTPd 3.0.3)Name (192.168.11.16:root): hello331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; ls227 Entering Passive Mode (192,168,11,16,130,240).150 Here comes the directory listing.drwxr-xr-x 2 1001 1001 6 Jan 15 08:56 下载drwxr-xr-x 2 1001 1001 6 Jan 15 08:56 公共drwxr-xr-x 2 1001 1001 6 Jan 15 08:56 图片drwxr-xr-x 2 1001 1001 6 Jan 15 08:56 文档drwxr-xr-x 2 1001 1001 6 Jan 15 08:56 桌面drwxr-xr-x 2 1001 1001 6 Jan 15 08:56 模板drwxr-xr-x 2 1001 1001 6 Jan 15 08:56 视频drwxr-xr-x 2 1001 1001 6 Jan 15 08:56 音乐226 Directory send OK.ftp&gt; pwd257 &quot;/home/hello&quot; is the current directory 7.2）FTP客户端常用命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129键入help命令可以查看所有可使用的命令ftp&gt; helpCommands may be abbreviated. Commands are:! debug mdir sendport site$ dir mget put sizeaccount disconnect mkdir pwd statusappend exit mls quit structascii form mode quote systembell get modtime recv suniquebinary glob mput reget tenexbye hash newer rstatus tickcase help nmap rhelp tracecd idle nlist rename typecdup image ntrans reset userchmod lcd open restart umaskclose ls prompt rmdir verbosecr macdef passive runique ?delete mdelete proxy send!+linux命令 执行系统命令!ls /opt 显示linux系统中/opt目录下的内容ftp&gt; !ls /optdhcp dns rhlcd linux系统中的当前目录lcd /root 将linux系统中的当前目录切换到/root下ftp&gt; lcd /rootLocal directory now /rootput 上传命令，mput批量上传命令上传initial-setup-ks.cfg文件到hello家目录下ftp&gt; put initial-setup-ks.cfg local: initial-setup-ks.cfg remote: initial-setup-ks.cfg227 Entering Passive Mode (192,168,11,16,96,132).150 Ok to send data.226 Transfer complete.1803 bytes sent in 0.00135 secs (1333.58 Kbytes/sec)可以看到上传成功了验证一下上传结果ftp&gt; ls227 Entering Passive Mode (192,168,11,16,173,142).150 Here comes the directory listing.-rw-r--r-- 1 1000 1000 1803 Feb 26 07:01 initial-setup-ks.cfgdrwxr-xr-x 2 1000 1000 6 Jan 11 01:37 下载drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 公共drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 图片drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 文档drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 桌面drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 模板drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 视频drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 音乐226 Directory send OK.看见了吧切换linux当前目录到/tmpftp&gt; lcd /tmpLocal directory now /tmpget下载命令，mget批量下载下载initial-setup-ks.cfg到linux系统当前目录/tmpftp&gt; get initial-setup-ks.cfglocal: initial-setup-ks.cfg remote: initial-setup-ks.cfg227 Entering Passive Mode (192,168,11,16,229,134).150 Opening BINARY mode data connection for initial-setup-ks.cfg (1803 bytes).226 Transfer complete.1803 bytes received in 2.9e-05 secs (62172.41 Kbytes/sec)列出linux目录/tmp的内容，看到了下载的文件initial-setup-ks.cfgftp&gt; !ls /tmp/dhcp tracker-extract-files.0initial-setup-ks.cfg VMwareDnDsystemd-private-8e7a99ea89c14ab396d66116970fe04d-chronyd.service-sghHHs vmware-rootsystemd-private-8e7a99ea89c14ab396d66116970fe04d-colord.service-wK7h08 yum_save_tx.2019-02-20.16-10.Z6uXqR.yumtxsystemd-private-8e7a99ea89c14ab396d66116970fe04d-cups.service-cokBro yum_save_tx.2019-02-21.09-03.08zIbU.yumtxsystemd-private-8e7a99ea89c14ab396d66116970fe04d-rtkit-daemon.service-6wt1S0 yum_save_tx.2019-02-22.11-10.prawAT.yumtxftp&gt; close221 Goodbye.ftp&gt; lsNot connected.可以使用close断开连接，当连接断开希望再次连接直接使用open命令即可ftp&gt; open 192.168.11.16Connected to 192.168.11.16 (192.168.11.16).220 (vsFTPd 3.0.2)Name (192.168.11.16:root): hello331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; ls227 Entering Passive Mode (192,168,11,16,192,88).150 Here comes the directory listing.-rw-r--r-- 1 1000 1000 1803 Feb 26 07:01 initial-setup-ks.cfgdrwxr-xr-x 2 1000 1000 6 Jan 11 01:37 下载drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 公共drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 图片drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 文档drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 桌面drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 模板drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 视频drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 音乐226 Directory send OK.delete命令可以删除属于自己的文件删除initial-setup-ks.cfg文件ftp&gt; delete initial-setup-ks.cfg250 Delete operation successful.ftp&gt; ls227 Entering Passive Mode (192,168,11,16,168,142).150 Here comes the directory listing.drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 下载drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 公共drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 图片drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 文档drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 桌面drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 模板drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 视频drwxr-xr-x 2 1000 1000 6 Jan 11 01:37 音乐226 Directory send OK. 八、基于虚拟用户配置安全的ftp在ftp中不论是匿名用户还是实名用户都是系统中真实存在的用户，或多或少都会有一些安全方面的风险，为了避免这个风险，开发者在ftp中加入了一个虚拟用户的概念，所有虚拟用户都会被统一映射为一个系统账号，免去了管理过多账户的麻烦，那么这个虚拟用户如何实现呢？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091a、修改配置文件 [root@zutuanxue pam.d]# egrep -v &quot;^#&quot; /etc/vsftpd/vsftpd.conf anonymous_enable=YESlocal_enable=YESwrite_enable=YESlocal_umask=022dirmessage_enable=YESxferlog_enable=YESconnect_from_port_20=YESxferlog_std_format=YESchroot_local_user=YESlisten=NOlisten_ipv6=YES#虚拟用户配置选项#pam登陆验证pam_service_name=vftp#允许虚拟用户功能guest_enable=YES#虚拟用户映射到本地用户helloguest_username=hello#这里我通过指令改变了默认设置，允许虚拟用户写allow_writeable_chroot=YES #本地用户的根目录#这里是定义虚拟用户主目录，用户和组必须指定为宿主用户hellolocal_root=/home/hello#允许虚拟用户和本地用户权限一致virtual_use_local_privs=YES#如果虚拟用户和本地用户权限不同，可以通过以下的指令来设置指令，配置文件和登陆名同步即可。#user_config_dir=/etc/vsftpd/vconf.d/b、生成虚拟用户账号密码文件奇数行数账户，偶数行是密码[root@zutuanxue ~]# cat /etc/vsftpd/vuservuser01123456vuser02123456使用db_load转成db格式[root@zutuanxue ~]# db_load -T -t hash -f /etc/vsftpd/vuser /etc/vsftpd/vuser.db要求权限是600[root@zutuanxue ~]# chmod 600 /etc/vsftpd/vuser.dbc、配置pam认证，注意先后顺序[root@zutuanxue ~]# cat /etc/pam.d/vftp #虚拟用户登录auth sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vuseraccount sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vuser#本地登陆session optional pam_keyinit.so force revokeauth required pam_listfile.so item=user sense=deny file=/etc/vsftpd/ftpusers onerr=succeedauth required pam_shells.soauth include password-authaccount include password-authsession required pam_loginuid.sosession include password-authd、重启服务生效[root@zutuanxue ~]# systemctl restart vsftpd[root@zutuanxue ~]# cat /etc/vsftpd/chroot_list vuser01vuser02e、验证登陆[root@zutuanxue ~]# ftp 192.168.11.16Connected to 192.168.11.16 (192.168.11.16).220 Welcome to ayitula FTP service.Name (192.168.11.16:root): vuser01331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; ls227 Entering Passive Mode (192,168,11,16,82,91).150 Here comes the directory listing.226 Transfer done (but failed to open directory).登陆成功了."},{"path":"/2023/07/11/Linux常用服务器部署实战/DNS服务/","content":"DNS：域名系统（英文：Domain Name System)是一个域名系统，是万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。类似于生活中的114服务，可以通过人名找到电话号码，也可以通过电话号码找到人名(生活中没有那么准确的原因是人名有重名，而域名是全世界唯一的)。 DNS协议运行在UDP协议之上，使用端口号53 12域名:域名是一个网站的逻辑地址，比如www.zutuanxue.com，相比IP地址更加方便人类记忆，所以被广泛使用。 一、DNS介绍计算机的发展起源于上世纪60年代，最初只有美国的几所高校在使用，计算机之间通信需要知道对方的地址(IP地址)，但是人们对IP地址的记忆又是不敏感的(就像生活中你能记住多少个好友的手机号码一样)。为了方便人类记忆，大学的科学家们把计算机的名字和对应的IP地址写入到计算机中的hosts文件，以此文件来做解析。 但是随着计算机和网络的发展出现了局域网，计算机的数量随之增加；后来为了解决方便通信问题，我们使用了wins服务器来进行计算机名和IP的注册服务，通过一个名称服务器来自动管理局域网中的计算机，并提供解析服务。人们在局域网中通过计算机名就能连接到了对应的计算机。该技术中要求计算机名称必须唯一，正是由于这个原因使得局域网中的计算机又不能太多。 微型计算机的出现和局域网的发展推动了广域网的发展，hosts文件只能针对极少的计算机网络，wins可以管理局域网的解析。到了广域网，人们就迫切需要一个新的服务做解析服务器，使解析方便、快速、高效的应对广域网环境。为了解决广域网解析问题，美国人研发出了DNS服务，以及成立了管理DNS相关的机构，并提出了域名命名规则。 1234567域名管理机构Internet 域名与地址管理机构（ICANN）是为承担域名系统管理，IP地址分配，协议参数配置，以及主服务器系统管理等职能而设立的非盈利机构.现由IANA和其他实体与美国政府约定进行管理。域名分国际域名和国内域名两种，对于国际域名而言，其命名规则是：域名可以由（a-z、A-Z大小写等价）26个英文字母、数字（0-9）以及连接符“-”组成，但是域名的首位必须是字母或数字。对于域名的长度也有一定的限制：国际通用顶级域名长度不得超过26个字符，中国国家顶级域名长度不得超过20个字符 二、DNS的解析原理目前，因特网的命名方法是层次树状结构的方法。采用这种命名方法，任何一个连接在因特网上的主机或设备，都有一个某一的层次结构的名字，即域名(domain name)。域是名字空间中一个可被管理的划分。域可以继续按层次划分为子域，如二级域、三级域等等。 image20200114172132398.png 三、DNS查询递归查询:一般客户机和服务器之间属递归查询，即当客户机向DNS服务器发出请求后,若DNS服务器本身不能解析,则会向另外的DNS服务器发出查询请求，得到结果后转交给客户机；如果主机所询问的本地域名服务器不知道被查询的域名的IP地址，那本地 DNS就会扮演DNS客户的角色，去代理原客户去帮忙找根域名服务器发出请求，递归即递给服务器，所有操作都有服务器来完成。 迭代查询:一般DNS服务器之间属迭代查询，如：DNS1问DNS2,DNS2不知道会告诉DNS1一个DNS3的IP地址，让DNS1去问问DNS3知不知道，以此类推，就是迭代查询。 关于递归和迭代举个生活例子帮助大家理解：比如你问张老师一个问题，张老师告诉他答案这之间的叫递归查询。这期间也许张老师也不会，这时张老师问李老师，张老师去问崔老师，这之间的查询叫迭代查询！ image20200114180942259.png 正向查找：将域名解析为IP 1www.zutuanxue.com ---&gt; 118.190.209.153 反向查找：将IP解析为域名 1118.290.209.153 ---&gt; www.zutuanxue.com 四、DNS服务器部署约定：本实验中使用过的机器为centos8.0_x86_64系统，IP地址192.168.11.16&#x2F;24.请关闭防火墙和SELINUX。 4.1）DNS安装DNS服务是由bind程序提供的，所以要实现DNS服务就需要安装bind程序包。 123456[root@zutuanxue ~]# dnf -y install bind bind-chrootbind DNS主程序包bind-chroot DNS安全包，改变默认DNS根目录，将DNS运行在监牢模式说明:chroot监牢模式监牢是一个软件机制，其功能是使得某个程序无法访问规定区域之外的资源，同样也为了增强安全性（LCTT 译注：chroot “监牢”，所谓“监牢”就是指通过chroot机制来更改某个进程所能看到的根目录，即将某进程限制在指定目录中，保证该进程只能对该目录及其子目录的文件进行操作，从而保证整个服务器的安全）。Bind Chroot DNS 服务器的默认“监牢”为 /var/named/chroot。 4.2）DNS启动DNS的守护进程叫做named,DNS是以named用户身份来运行，named用户在安装包的时候会在系统中自动创建。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869CentOS8下安装了bind-chroot之后，若要使用named-chroot.service，则需要关闭named.service。两者只能运行一个方法一: 不使用chroot模式启动DNS开启开机启动[root@zutuanxue ~]# systemctl enable namedCreated symlink from /etc/systemd/system/multi-user.target.wants/named.service to /usr/lib/systemd/system/named.service.启动DNS服务[root@zutuanxue ~]# systemctl start named验证启动[root@zutuanxue ~]# lsof -i :53COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEdnsmasq 1520 nobody 5u IPv4 27001 0t0 UDP bogon:domain dnsmasq 1520 nobody 6u IPv4 27002 0t0 TCP bogon:domain (LISTEN)named 2553 named 21u IPv4 38662 0t0 TCP localhost:domain (LISTEN)named 2553 named 22u IPv6 38664 0t0 TCP localhost:domain (LISTEN)named 2553 named 512u IPv4 38660 0t0 UDP localhost:domain named 2553 named 513u IPv4 38660 0t0 UDP localhost:domain named 2553 named 514u IPv4 38660 0t0 UDP localhost:domain named 2553 named 515u IPv4 38660 0t0 UDP localhost:domain named 2553 named 516u IPv6 38663 0t0 UDP localhost:domain named 2553 named 517u IPv6 38663 0t0 UDP localhost:domain named 2553 named 518u IPv6 38663 0t0 UDP localhost:domain named 2553 named 519u IPv6 38663 0t0 UDP localhost:domain方法二: 使用chroot模式DNS将对应的文件移动到chroot根目录主配文件[root@zutuanxue ~]# cp /etc/named.conf /var/named/chroot/etc/[root@zutuanxue ~]# chgrp named /var/named/chroot/etc/named.conf[root@zutuanxue ~]# named-checkconf /var/named/chroot/etc/named.conf区域数据库文件[root@zutuanxue named]# cd /var/named/[root@zutuanxue named]# cp -r data /var/named/chroot/var/named/[root@zutuanxue named]# cp -r dynamic /var/named/chroot/var/named/[root@zutuanxue named]# cp named.* /var/named/chroot/var/named/[root@zutuanxue named]# cd /var/named/chroot/var/named/[root@zutuanxue named]# chown -R named.named *启动DNS服务开机启动[root@zutuanxue ~]# systemctl enable named-chroot.service Created symlink from /etc/systemd/system/multi-user.target.wants/named-chroot.service to /usr/lib/systemd/system/named-chroot.service.启动服务[root@zutuanxue ~]# mv /etc/named.conf /root/[root@zutuanxue ~]# systemctl start named-chroot验证启动[root@zutuanxue ~]# lsof -i :53COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEdnsmasq 1525 nobody 5u IPv4 27359 0t0 UDP bogon:domain named 2877 named 21u IPv4 44717 0t0 TCP localhost:domain (LISTEN)named 2877 named 22u IPv4 44719 0t0 TCP bogon:domain (LISTEN)named 2877 named 23u IPv4 44721 0t0 TCP bogon:domain (LISTEN)named 2877 named 512u IPv4 44715 0t0 UDP localhost:domain named 2877 named 513u IPv4 44715 0t0 UDP localhost:domain named 2877 named 514u IPv4 44715 0t0 UDP localhost:domain named 2877 named 515u IPv4 44715 0t0 UDP localhost:domain named 2877 named 516u IPv4 44718 0t0 UDP bogon:domain named 2877 named 517u IPv4 44718 0t0 UDP bogon:domain named 2877 named 518u IPv4 44718 0t0 UDP bogon:domain named 2877 named 519u IPv4 44718 0t0 UDP bogon:domain named 2877 named 520u IPv4 44720 0t0 UDP bogon:domain named 2877 named 521u IPv4 44720 0t0 UDP bogon:domain named 2877 named 522u IPv4 44720 0t0 UDP bogon:domain named 2877 named 523u IPv4 44720 0t0 UDP bogon:domain 4.3）DNS配置文件默认情况下，如果不安装bind-chroot这个包，配置文件的路径如下： 配置文件:&#x2F;etc&#x2F;named.conf 区域数据库文件:&#x2F;var&#x2F;named&#x2F; 由于我们安装了bind-chroot这个用于改变默认DNS配置文件的路径的包，所以相对应的配置文件的路径也发生了变化。 变化如下： 配置文件:&#x2F;var&#x2F;named&#x2F;chroot&#x2F;etc&#x2F;named.conf 区域数据库文件:&#x2F;var&#x2F;named&#x2F;chroot&#x2F;var&#x2F;named&#x2F; a、主配文件详解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788//// named.conf//// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS// server as a caching only nameserver (as a localhost DNS resolver only).//// See /usr/share/doc/bind*/sample/ for example named configuration files.//options&#123; #IPv4监听端口为53，只允许本机连接 listen-on port 53 &#123; 127.0.0.1; &#125;; #IPv6监听端口为53，只允许本机连接 listen-on-v6 port 53 &#123; ::1; &#125;; #定义工作目录 directory &quot;/var/named&quot;; #CACHE文件路径,指定服务器在收到rndc dump命令时，转储数据到文件的路径。默认cache_dump.db dump-file &quot;data/cache_dump.db&quot;; #静态文件路径,指定服务器在收到rndc stats命令时，追加统计数据的文件路径。默认named.stats statistics-file &quot;data/named_stats.txt&quot;; #内存静态文件路径,服务器在退出时，将内存统计写到文件的路径。默认named.mem_stats memstatistics-file &quot;data/named_mem_stats.txt&quot;; #在收到rndc secroots指令后，服务器转储安全根的目的文件的路径名。默认named.secroots secroots-file &quot;data/named.secroots&quot;; # 指定服务器在通过rndc recursing命令指定转储当前递归请求到的文件路径。默认named.recursing recursing-file &quot;data/named.recursing&quot;; #指定允许哪些主机可以进行普通的DNS查询,可以是关键字:any/localhost/none,也可以是IPV4,IPV6地址 allow-query &#123; localhost; &#125;; #指定允许哪些主机可以对缓存的访问 allow-query-cache &#123; localhost; &#125;; /* - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion. 假如你建立的是一个权威DNS你不需要开启递归 - If you are building a RECURSIVE (caching) DNS server, you need to enable recursion. 假如你建立的是一个递归DNS,你需要开启递归服务 - If your recursive DNS server has a public IP address, you MUST enable access control to limit queries to your legitimate users. Failing to do so will 如果你的递归DNS是具有公网IP，你必须要设置访问控制来限制对合法用户的查询. cause your server to become part of large scale DNS amplification 否则你的DNS会被大规模的攻击 attacks. Implementing BCP38 within your network would greatly 在您的网络中实现BCP38将非常重要减少此类攻击面 reduce such attack surface */ #开启递归 recursion yes; #开启DNSSEC在权威或者递归服务器之间信任服务 dnssec-enable yes; #开启DNSSEC验证在递归服务器 dnssec-validation yes; #指定目录，其中保存着跟踪被管理DNSSEC密钥文件。默认为工作目录。 managed-keys-directory &quot;/var/named/dynamic&quot;; #PID文件路径 pid-file &quot;/run/named/named.pid&quot;; #session-keyfile文件路径 session-keyfile &quot;/run/named/session.key&quot;;&#125;;logging &#123;#开启DNS日志记录 channel default_debug &#123; file &quot;data/named.run&quot;; severity dynamic; &#125;;&#125;; #定义一个根域zone &quot;.&quot; IN &#123; #域类型为hint,还有master slave forward等类型 type hint; #区域数据库文件路径 file &quot;/var/named/named.ca&quot;; &#125;;&#125;; #包含两个子配置文件 include &quot;/etc/named.rfc1912.zones&quot;; include &quot;/etc/named.root.key&quot;; b、区域数据库文件详解 12345678910111213141516171819202122232425262728293031323334353637正向解析[root@zutuanxue ~]# cat /var/named/named.localhost ;缓存时间$TTL 1D;@表示相应的域名\t@ IN SOA @ rname.invalid. (;解析的域名 类型 授权域 授权域名服务器 管理员邮箱 0 ; serial 序列号,每次更新该文件系列号都应该变大 1D ; refresh 刷新时间,即规定从域名服务器多长时间查询一个主服务器，以保证从服务器的数据是最新的 1H ; retry 重试时间,即当从服务试图在主服务器上查询更时，而连接失败了，则这个值规定了从服务多长时间后再试 1W ; expire 过期时间,从服务器在向主服务更新失败后多长时间后清除对应的记录 3H ) ; minimum 这个数据用来规定缓存服务器不能与主服务联系上后多长时间清除相应的记录 NS @ ;NS 名称服务器，表示这个主机为域名服务器 A 127.0.0.1;主机头 A记录 IP AAAA ::1; AAAA 解析为IPV6地址#反向解析[root@zutuanxue ~]# cat named.loopback $TTL 1D@ IN SOA @ rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS @ PTR localhost;IP 反向指针 主机名;PTR 反向指针 反解 五、部署一个正向解析5.1）教学案例对zutuanxue.com域名做解析，解析要求如下： www 解析为A记录 IP地址为 192.168.11.88 news 做别名解析CNAME 解析为 www 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748491）主配置文件[root@zutuanxue ~]# cat /var/named/chroot/etc/named.conf options &#123; listen-on port 53 &#123; any; &#125;; directory &quot;/var/named&quot;;&#125;;//定义根域//用于DNS向根递归查询zone &quot;.&quot; IN &#123; type hint; //保存了DNS根级服务器的地址 file &quot;named.ca&quot;;&#125;;//定义一个主域//注意每行都要;结尾zone &quot;zutuanxue.com&quot; IN &#123;//类型为master type master;//区域数据库文件名称 file &quot;zutuanxue.com.zone&quot;;&#125;;2）区域数据库文件[root@zutuanxue named]# cat zutuanxue.com.zone $TTL 1Dzutuanxue.com. IN SOA ns1.zutuanxue.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum;zutuanxue.com. 需要做解析的域名;ns1.zutuanxue.com. 为zutuanxue.com.做解析的DNS 这里我们既是DNS也同时为自己域名做了解析 NS ns1.zutuanxue.com.;A 域名机械为IP;PTR IP解析为域名;MX 邮件标记;CNAME 别名ns1 A 192.168.11.16www A 192.168.11.88news CNAME www 5.2）测试方法域名解析linux系统为大家提供了三个命令，看大家喜欢用哪个都可以。 a、host采用非交互式解析， b、nslookup可以采用交互或非交互式解析 c、dig显示详细的解析流程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162测试注意：请将你的测试客户端机器的DNS指向你自己的DNS服务器的IP地址。本例中我使用DNS服务器给自己当测试端，我修改了自己的DNS服务器地址[root@zutuanxue ~]# cat /etc/resolv.conf # Generated by NetworkManagernameserver 192.168.11.16#host命令[root@zutuanxue ~]# host news.zutuanxue.comnews.zutuanxue.com is an alias for www.zutuanxue.com.www.zutuanxue.com has address 192.168.11.88#nslookup 命令---交互式解析[root@zutuanxue ~]# nslookup&gt; news.zutuanxue.comServer: 192.168.11.16Address: 192.168.11.16#53news.zutuanxue.com canonical name = www.zutuanxue.com.Name: www.zutuanxue.comAddress: 192.168.11.88&gt; exit#nslookup 命令---非交互式解析[root@zutuanxue ~]# nslookup news.zutuanxue.comServer: 192.168.11.16Address: 192.168.11.16#53news.zutuanxue.com canonical name = www.zutuanxue.com.Name: www.zutuanxue.comAddress: 192.168.11.88#dig命令[root@zutuanxue ~]# dig news.zutuanxue.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-73.el7_6 &lt;&lt;&gt;&gt; news.zutuanxue.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 28487;; flags: qr aa rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 1, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;news.zutuanxue.com. IN A;; ANSWER SECTION:news.zutuanxue.com. 86400 IN CNAME www.zutuanxue.com.www.zutuanxue.com. 86400 IN A 192.168.11.88;; AUTHORITY SECTION:zutuanxue.com. 86400 IN NS www.zutuanxue.com.;; Query time: 0 msec;; SERVER: 192.168.11.16#53(192.168.11.16);; WHEN: 一 2月 25 10:52:19 CST 2019;; MSG SIZE rcvd: 93技巧：在dig解析中，后面跟上+trace来显示详细解析流程[root@zutuanxue ~]# dig www.zutuanxue.com +trace 六、部署一个反向解析案例:对www.zutuanxue.com做反向解析，其对应的IP地址为192.168.11.88 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051521）主配置文件添加反向解析zone[root@zutuanxue ~]# cat /var/named/chroot/etc/named.conf options &#123; listen-on port 53 &#123; any; &#125;; directory &quot;/var/named&quot;;&#125;;//定义根域//用于DNS向根递归查询zone &quot;.&quot; IN &#123; type hint; //保存了DNS根级服务器的地址 file &quot;named.ca&quot;;&#125;;//定义一个主域//注意每行都要;结尾zone &quot;zutuanxue.com&quot; IN &#123;//类型为master type master;//区域数据库文件名称 file &quot;zutuanxue.com.zone&quot;;&#125;;//定义一个反向解析//此处需要倒写网段zone &quot;11.168.192.in-addr.arpa&quot; IN &#123; type master; file &quot;192.168.11.arpa&quot;;&#125;;2）区域数据库文件设置[root@zutuanxue named]# cat 192.168.11.arpa $TTL 1D11.168.192.in-addr.arpa. IN SOA ns1.zutuanxue.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS ns1.zutuanxue.com.88 PTR www.zutuanxue.com.注意：文件的所有者和所有者组都是named3）使用nslookup测试[root@zutuanxue ~]# nslookup 192.168.11.88Server: 192.168.11.16Address: 192.168.11.16#5388.11.168.192.in-addr.arpa name = www.zutuanxue.com. 七、DNS服务器冗余image20200114172337009.png DNS服务器在网络中为全世界的服务器提供了域名解析服务，扮演着至关重要的角色。网络中的某台DNS一旦宕机，就会造成部分域名无法解析，用户无法顺利访问到对应的服务器。但是我们学习的过程中也发现了，我们的DNS部署在单台服务器上，如果出现单点故障，我们应该如何应对呢？我们可以通过部署多台相同解析的DNS来解决单点故障，就算一台DNS服务器出现问题，也不会影响解析服务。怎么部署呢？如何保障多台之间的解析一致？这就是我们要讨论的问题了。我们来学习辅助DNS吧！ 辅助DNS是从主DNS拉取区域数据库文件的的，当主DNS解析的域名对应的区域数据库文件发生变化，辅助就会去找主DNS拉取新的区域数据库文件，保证和主的解析一致，而且是自动的不需要人为干预的，确保了主从DNS的区域数据库文件的一致性。 教学案例:按照图例,为主DNS(192.168.11.16）部署一台辅助DNS(192.168.11.116)，实现数据同步。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980辅助DNS设置a、软件包安装[root@slave ~]# dnf -y install bind bind-chrootb、设置主配文件[root@slave etc]# cat /var/named/chroot/etc/named.confoptions &#123; listen-on port 53 &#123; any; &#125;; directory &quot;/var/named&quot;;&#125;;//定义根域//用于DNS向根递归查询zone &quot;.&quot; IN &#123; type hint; //保存了DNS根级服务器的地址 file &quot;named.ca&quot;;&#125;;//定义一个主域//注意每行都要;结尾zone &quot;zutuanxue.com&quot; IN &#123;//类型为slave 代表辅助 type slave;//区域数据库文件名称 file &quot;zutuanxue.com.zone&quot;;//设置主DNS IP,向该IP去同步数据 masters &#123; 192.168.11.16; &#125;;&#125;;//定义一个反向解析//此处需要倒写网段zone &quot;11.168.192.in-addr.arpa&quot; IN &#123;//类型写slave 代表辅助 type slave; file &quot;192.168.11.arpa&quot;;//设置主DNS IP,向该IP去同步数据 masters &#123; 192.168.11.16; &#125;;&#125;;修改权限[root@slave etc]# chgrp named named.conf c、启动服务[root@slave chroot]# systemctl enable named-chroot.service Created symlink from /etc/systemd/system/multi-user.target.wants/named-chroot.service to /usr/lib/systemd/system/named-chroot.service.[root@slave chroot]# systemctl start named-chrootd、验证[root@slave ~]# ls /var/named/chroot/var/named/192.168.11.arpa zutuanxue.com.zone chroot data dynamic named.ca named.empty named.localhost named.loopback slaves发现192.168.11.arpa zutuanxue.com.zone 这两个数据库文件已经同步过来了，解析一下看看吧！设置客户端的DNS IP为192.168.11.116，我的测试机就是这台slave机器，所以设置为192.168.11.116即可[root@slave ~]# cat /etc/resolv.conf nameserver 192.168.11.116使用nslookup验证一下[root@slave ~]# nslookup news.zutuanxue.comServer: 192.168.11.116Address: 192.168.11.116#53news.zutuanxue.com canonical name = www.zutuanxue.com.Name: www.zutuanxue.comAddress: 192.168.11.88[root@slave ~]# nslookup 192.168.11.88Server: 192.168.11.116Address: 192.168.11.116#5388.11.168.192.in-addr.arpa name = www.11.168.192.in-addr.arpa.看到结果了，完美！！ 八、智能DNS在我们访问WEB的时候，发现有的网站打开的速度非常快，有的网站打开的非常慢，这是为什么呢？原因就是很多公司为了提升用户的体验，自己的网站使用了CDN内容加速服务，让你直接在你本地城市的服务器上拿数据并展示给你看。什么是CDN我们暂且理解为本地缓存服务器就好，那么你是怎么准确知道你本地的缓存服务器的呢！因为很多CDN公司的DNS使用了智能解析服务，根据你的源IP判断你属于哪个城市，让后再把本地的缓存服务器解析给你，你就会直接去找该服务器拿数据了。 智能解析原理 在DNS中植入全世界的IP库以及IP对应的地域，当用户来请求解析时，DNS会根据其源IP来定位他属于哪个区域，然后去找这个区域的view视图查询对应的域名的区域数据库文件做解析。从而使得不同地域的用户解析不同。 教学案例:部署一台DNS智能解析服务器，对zutuanxue.com域名做智能解析： 上海的用户解析IP为 1.1.1.1 北京的用户解析IP为 2.2.2.2 其他用户解析为 3.3.3.3 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596智能解析a、设置主配文件定义IP库，DNS根据IP库判断源IP属于哪个区域根据地域定义视图，将该区域的客户端的解析请求都由该视图中的zone来解析[root@master named]# cat /var/named/chroot/etc/named.confoptions &#123; directory &quot;/var/named&quot;;&#125;;//定义IP库acl shanghai &#123; 192.168.11.50; &#125;;acl beijing &#123; 192.168.11.100; &#125;;//定义视图，通过IP匹配后，通过不同的区域数据库文件进行解析view sh &#123;\tmatch-clients &#123; shanghai; &#125;;\tzone &quot;zutuanxue.com&quot; IN &#123; type master; file &quot;zutuanxue.com.zone.sh&quot;;&#125;;&#125;;view bj &#123;\tmatch-clients &#123; beijing; &#125;;\tzone &quot;zutuanxue.com&quot; IN &#123; type master; file &quot;zutuanxue.com.zone.bj&quot;;&#125;;&#125;;view other &#123;\tmatch-clients &#123; any; &#125;; zone &quot;zutuanxue.com&quot; IN &#123; type master; file &quot;zutuanxue.com.zone.any&quot;;&#125;;&#125;;b、根据主配文件设置不同的区域数据库文件[root@master named]# cd /var/named/chroot/var/named[root@master named]# cp zutuanxue.com.zone zutuanxue.com.zone.bj[root@master named]# cp zutuanxue.com.zone zutuanxue.com.zone.sh[root@master named]# cp zutuanxue.com.zone zutuanxue.com.zone.any[root@master named]# chgrp named zutuanxue.com.zone.*[root@master named]# cat /var/named/chroot/var/named/zutuanxue.com.zone.sh $TTL 1D@ IN SOA zutuanxue.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS www.zutuanxue.com.www A 1.1.1.1[root@master named]# cat /var/named/chroot/var/named/zutuanxue.com.zone.bj$TTL 1D@ IN SOA zutuanxue.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS www.zutuanxue.com.www A 2.2.2.2[root@master named]# cat /var/named/chroot/var/named/zutuanxue.com.zone.any $TTL 1D@ IN SOA zutuanxue.com. rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS www.zutuanxue.com.www A 3.3.3.3c、测试依次修改主配的IP库中的IP为本机，观看解析情况[root@master named]# nslookup www.zutuanxue.comServer: 192.168.11.16Address: 192.168.11.16#53Name: www.zutuanxue.comAddress: 1.1.1.1"},{"path":"/2023/07/11/Linux常用服务器部署实战/DHCP服务/","content":"一、DHCP介绍在LAN(局域网)中我们常会遇到以下的情况： 123451）不知道如何配置IP地址及相关信息的员工，无法上网；2）IP地址配置冲突，无法上网；3）来访用户因不熟悉公司网络情况无法上网； 以上这些情况都是日常最常见也是最无脑的工作，公司网络管理员需要不停的去帮忙去解决这些问题，以此来保障公司网络的正常使用及员工的正常用网需求。而这些工作对于网络管理员来说实在是太低级、太无脑、太繁琐了，会消耗网络管理员的大量工作时间，也会影响公司员工的工作效能。那么如何通过其他的方法让计算机就能直接解决了上述问题，从而解放网络管理员呢？DHCP就是一个不二的选择。 DHCP(Dynamic Host Configuration Protocol，动态主机配置协议),通常被应用在局域网络环境中，主要作用是集中的管理、分配IP地址，使网络环境中的主机动态的获得IP地址、Gateway地址、DNS服务器地址等信息，并能够提升地址的使用率。由于DHCP是一个UDP协议，所以运行起来更加高效。 DHCP协议采用客户端&#x2F;服务器模型(C&#x2F;S模型)，服务端可以为客户端提供IP、掩码、网关、主机名、DNS等信息。客户端只需将IP获得方式设置为自动获取即可。 目前可以提供DHCP服务的设备有很多，比如: DHCP服务器(windows server、linux) 硬件路由器 家用宽带路由 二、DHCP应用场景1）公司局域网环境 2）家庭局域网环境 3）公共场合的wifi环境 4）宽带环境网络 123456789使用DHCP的优点：1）傻瓜式接入：用户只需懂得插网线到电脑，或者输入WiFi密码接入网络即可实现联网2）IP高效利用：及时回收IP机制，保证IP的高利用性，特别是对IP不足的网络3）避免IP冲突：避免IP冲突，保证网络的高效利用，保证公司员工及临时人员高效工作4）降低了公司网络管理员的工作量，提升了工作效率 三、DHCP工作原理image20200113193556339.png 3.1）工作方式IP获得需要通过发广播来实现客户端和服务器的通信，所以DHCP只能工作在局域网。 3.2）工作原理解析1、Client：向网络中发送广播，通过自己的UDP协议的68号端口向网络中发送DHCP Discover包，用来寻找网络中的DHCP Server.类似于你在你的公司大喊一声:”谁是公司老板”一样的道理。 2、Server：局域网中的所有DHCP服务器都能收到该Client发送的广播包，然后DHCP Server会检查自己的IP池中(也叫做作用域)是否还有可用IP可以分发。如果有的话，会直接将这个IP地址从池中拿出来，避免在发给别的客户端，并且通过自己的UDP协议的67号端口给Client发一个响应包DHCP Offer,同样通信是采用广播的方式，明确告诉其可以提供哪个IP给Client使用。类似于公司的几个老板都在公司喊了一声：“我是X老板，我有时间在哪个办公室接待你”。 3、Client：Client会收到局域网中的所有DHCP服务器发给自己的DHCP Offer包，默认选一个最优的DHCP Server进行IP获取（在这里就是第一个发送给他DHCP Offer的服务器算作最优）。然后继续向网络中通过UDP的68号端口发广播DHCP Resquest，明确指定DHCP Server IP地址和需要租用的IP地址,告诉它要从他这里获得IP信息。自然其他DHCP Server也能收到广播，确认不从自己这里拿IP信息后，会将上步从IP池中拿出来的IP在释放到池中，以便别人使用。类似于你在公司大喊一声：“李老板，我找你接待”，那么其他老板刚才计划接待你的时间就会被释放出来，用于接待别的客户。 4、Server：被确认的DHCP Server就会通过其UDP协议的67号端口发送DHCP ACK确认包，采用广播将IP、掩码、网关、DNS等信息还有IP租约一起发送给DHCP Client，Client确认IP可用后，根据IP租约开始计算使用时间。类似于李老板把你请进他的办公室，开始和你聊天，并计算聊天时间为30分钟，开始倒计时。 3.3)计算机获得IP的时间点a、计算机开机 b、网卡接通网络 c、重启网卡服务 3.4）租约更新阶段a、租约完成1&#x2F;2 b、租约完成7&#x2F;8 c、租约到期 四、DHCP服务器部署约定：本实验中使用过的机器为centos8.0_x86_64系统，计算机名称:localhost.localdomain,IP地址192.168.11.16&#x2F;24.请关闭防火墙和SELINUX。 4.1）DHCP安装1[root@zutuanxue ~]# dnf -y install dhcp-server 4.2）DHCP配置文件详解默认情况下，dhcp服务并没有提供配置文件，只是给提供了一个demo,存放在&#x2F;usr&#x2F;share&#x2F;doc&#x2F;dhcp-server&#x2F;目录下.我们将demo文件拷贝到&#x2F;etc&#x2F;dhcp目录下，并且命名为dhcpd.conf。 12[root@zutuanxue ~]# cp /usr/share/doc/dhcp-server/dhcpd.conf.example /etc/dhcp/dhcpd.conf cp：是否覆盖&quot;/etc/dhcp/dhcpd.conf&quot; y 配置文件详解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168[root@zutuanxue ~]# cat /etc/dhcp/dhcpd.conf# #号代表注释# DHCP服务配置文件分为全局配置和作用域配置，很好区分：subnet的就是作用域 不在subnet里面的就是全局设置。# dhcpd.conf## Sample configuration file for ISC dhcpd##DNS全局选项，指定DNS服务器的地址，可以是IP，也可以是域名。# option definitions common to all supported networks...# DNS的域名option domain-name &quot;example.org&quot;;#具体的DNS服务器option domain-name-servers ns1.example.org, ns2.example.org;#默认租约为600sdefault-lease-time 600;#最大租约为7200s，客户机会在default-lease-time快到期时向服务器续租，如果此时客户机死机/重启，而默认租约时间到期了，服务器并不会立即回收IP地址，而是等到最大租约时间到期，客户机还没有过来续约，才会回收IP地址。max-lease-time 7200;#动态DNS更新方式(none:不支持；interim:互动更新模式；ad-hoc:特殊更新模式)# Use this to enble / disable dynamic dns updates globally.#ddns-update-style none;#如果该DHCP服务器是本地官方DHCP就将此选项打开，避免其他DHCP服务器的干扰。#当一个客户端试图获得一个不是该DHCP服务器分配的IP信息，DHCP将发送一个拒绝消息，而不会等待请求超时。当请求被拒绝，客户端会重新向当前DHCP发送IP请求获得新地址。保证IP是自己发出去的## If this DHCP server is the official DHCP server for the local# network, the authoritative directive should be uncommented.#authoritative;# Use this to send dhcp log messages to a different log file (you also# have to hack syslog.conf to complete the redirection).# 日志级别log-facility local7;# No service will be given on this subnet, but declaring it helps the # DHCP server to understand the network topology.#作用域相关设置指令#subnet 定义一个作用域#netmask 定义作用域的掩码#range 允许发放的IP范围#option routers 指定网关地址#option domain-name-servers 指定DNS服务器地址#option broadcast-address 广播地址###案例:定义一个作用域 网段为10.152.187.0 掩码为255.255.255.0#此作用域不提供任何服务subnet 10.152.187.0 netmask 255.255.255.0 &#123;&#125;# This is a very basic subnet declaration.#案例:定义一个基本的作用域#网段10.254.239.0 掩码255.255.255.224#分发范围10.254.239.10-20#网关为rtr-239-0-1.example.org, rtr-239-0-2.example.orgsubnet 10.254.239.0 netmask 255.255.255.224 &#123; range 10.254.239.10 10.254.239.20; option routers rtr-239-0-1.example.org, rtr-239-0-2.example.org;&#125;# This declaration allows BOOTP clients to get dynamic addresses,# which we don&#x27;t really recommend.#案例:允许采用bootp协议的客户端动态获得地址#bootp DHCP的前身#BOOTP用于无盘工作站的局域网中，可以让无盘工作站从一个中心服务器上获得IP地址。通过BOOTP协议可以为局域网中的无盘工作站分配动态IP地址，#这样就不需要管理员去为每个用户去设置静态IP地址。subnet 10.254.239.32 netmask 255.255.255.224 &#123; range dynamic-bootp 10.254.239.40 10.254.239.60; option broadcast-address 10.254.239.31; option routers rtr-239-32-1.example.org;&#125;#案例:一个简单的作用域案例# A slightly different configuration for an internal subnet.subnet 10.5.5.0 netmask 255.255.255.224 &#123; range 10.5.5.26 10.5.5.30; option domain-name-servers ns1.internal.example.org; option domain-name &quot;internal.example.org&quot;; option routers 10.5.5.1; option broadcast-address 10.5.5.31; default-lease-time 600; max-lease-time 7200;&#125;# Hosts which require special configuration options can be listed in# host statements. If no address is specified, the address will be# allocated dynamically (if possible), but the host-specific information# will still come from the host declaration.##保留地址:可以将指定的IP分发给指定的机器，根据网卡的MAC地址来做触发#host: 启用保留。#hardware:指定客户端的mac地址#filename:指定文件名#server-name:指定下一跳服务器地址#fixed-address: 指定保留IP地址###案例:这个案例中分发给客户端的不是IP地址信息，而是告诉客户端去找toccata.fugue.com服务器，并且下载vmunix.passacaglia文件host passacaglia &#123; hardware ethernet 0:0:c0:5d:bd:95; filename &quot;vmunix.passacaglia&quot;; server-name &quot;toccata.fugue.com&quot;;&#125;# Fixed IP addresses can also be specified for hosts. These addresses# should not also be listed as being available for dynamic assignment.# Hosts for which fixed IP addresses have been specified can boot using# BOOTP or DHCP. Hosts for which no fixed address is specified can only# be booted with DHCP, unless there is an address range on the subnet# to which a BOOTP client is connected which has the dynamic-bootp flag# set.# 案例:保留地址，将指定IP(fantasia.fugue.com对应的IP)分给指定客户端网卡(MAC:08:00:07:26:c0:a5)host fantasia &#123; hardware ethernet 08:00:07:26:c0:a5; fixed-address fantasia.fugue.com;&#125;#超级作用域#超级作用域是DHCP服务中的一种管理功能，使用超级作用域，可以将多个作用域组合为单个管理实体。# You can declare a class of clients and then do address allocation# based on that. The example below shows a case where all clients# in a certain class get addresses on the 10.17.224/24 subnet, and all# other clients get addresses on the 10.0.29/24 subnet.#在局域网中，可以配置策略根据各个机器的具体信息分配IP地址和其他的网络参数，客户机的具体信息：客户机能够给dhcp服务提供的信息由有两个，#第一个就是网卡的dhcp-client-identifier（mac地址），#第二个就是设备的vendor-class-identifier。#管理员可以根据这两个信息给不同的机器分组。#案例:#按client某种类型分组DHCP,而不是按物理接口网段#例子: SUNW 分配地址段10.17.224.0/24# 非SUNW的主机,分配地址段10.0.29.0/24#定义一个dhcp类:foo#request广播中vendor-class-identifier字段对应的值前四个字节如果是&quot;SUNW&quot;,则视合法客户端.class &quot;foo&quot; &#123; match if substring (option vendor-class-identifier, 0, 4) = &quot;SUNW&quot;;&#125;#定义一个超级作用域: 224-29shared-network 224-29 &#123;#定义第一个作用域 subnet 10.17.224.0 netmask 255.255.255.0 &#123; option routers rtr-224.example.org; &#125;#定义第二个作用域 subnet 10.0.29.0 netmask 255.255.255.0 &#123; option routers rtr-29.example.org; &#125;#关连池,如果客户端匹配foo类，将获得该池地址 pool &#123; allow members of &quot;foo&quot;; range 10.17.224.10 10.17.224.250; &#125;#关连池,如果客户端配置foo类，则拒绝获得该段地址 pool &#123; deny members of &quot;foo&quot;; range 10.0.29.10 10.0.29.230; &#125;&#125; 4.3）DHCP启动12345[root@zutuanxue ~]# systemctl enable dhcpdCreated symlink from /etc/systemd/system/multi-user.target.wants/dhcpd.service to /usr/lib/systemd/system/dhcpd.service.[root@zutuanxue ~]# systemctl start dhcpd注意：可能发现无法启动DHCP服务，原因是DHCP在启动的时候检查配置文件，发现并没有有效作用域（和服务器同网段的作用域）。 五、DHCP作用域教学案例一、配置一个作用域，用于为本地局域网中的计算机发放IP信息。要求： 本地网段:192.168.11.0&#x2F;24 发放IP地址：192.168.11.153–252 网关：192.168.11.254 DNS1：202.106.0.20 DNS2：114.114.114.114 默认租约为两个小时 最大租约为3个小时 本DHCP服务器为本地权威DHCP，要求可以本地所有计算机获得IP都是由本DHCP发放 5.1)DHCP服务配置1234567891011121314151617[root@zutuanxue dhcp]# cat /etc/dhcp/dhcpd.confoption domain-name-servers 202.106.0.20, 114.114.114.114;#声明DNS服务器default-lease-time 7200; #定义默认租约时间max-lease-time 10800; #定义最大租约时间authoritative;\t#拒绝不正确的IP地址的要求log-facility local7;\t#定义日志subnet 192.168.11.0 netmask 255.255.255.0 &#123; range 192.168.11.153 192.168.11.252; option routers 192.168.11.254; option broadcast-address 192.168.11.255; default-lease-time 7200; max-lease-time 10800;&#125;请根据4.2中的讲解理解配置文件内容。 5.2）重启DHCP服务，生效配置1234567891011#重启dhcpd服务[root@zutuanxue dhcp]# systemctl restart dhcpd#查看启动情况，同时也验证了客户端使用的是68端口，服务端使用的是67端口[root@zutuanxue dhcp]# lsof -i :68COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEdhclient 55234 root 6u IPv4 110700 0t0 UDP *:bootpc [root@zutuanxue dhcp]# lsof -i :67COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEdnsmasq 1507 nobody 3u IPv4 27149 0t0 UDP *:bootps dhcpd 56570 dhcpd 7u IPv4 129157 0t0 UDP *:bootps 5.3）测试IP分发打开一个客户端机器，IP获得方式为自动获取，测试是否获得到了自己这个DHCP服务器发放的IP地址。本例子中测试机使用了centos 8系统。来看下测试结果吧！ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970711) 查看一下当前eth0的IP地址、MAC地址，并保证其IP获得方式为:DHCP[root@test 桌面]# ifconfig eth0eth0 Link encap:Ethernet HWaddr 00:0C:29:1A:F8:BD inet addr:172.16.44.132 Bcast:172.16.44.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe1a:f8bd/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:86 errors:0 dropped:0 overruns:0 frame:0 TX packets:63 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:15294 (14.9 KiB) TX bytes:6769 (6.6 KiB)2）使用dhclient命令来获得IP，看一下重要输出[root@test 桌面]# dhclient -d eth0Internet Systems Consortium DHCP Client 4.1.1-P1Copyright 2004-2010 Internet Systems Consortium.All rights reserved.For info, please visit https://www.isc.org/software/dhcp/Listening on LPF/eth0/00:0c:29:1a:f8:bdSending on LPF/eth0/00:0c:29:1a:f8:bdSending on Socket/fallbackDHCPDISCOVER on eth0 to 255.255.255.255 port 67 interval 6 (xid=0x316768c3) 发广播寻找DHCP服务器DHCPOFFER from 192.168.11.16 192.168.11.16DHCP服务器应答DHCPREQUEST on eth0 to 255.255.255.255 port 67 (xid=0x316768c3) client向服务器请求IP地址DHCPACK from 192.168.11.16 (xid=0x316768c3) 确认租赁关系bound to 192.168.11.156 -- renewal in 2983 seconds. client分得IP:192.168.11.156注意：看到这些信息后，按CTRL+C退出。dhclient是一个DHCP协议客户端，它使用DHCP协议或者BOOTP协议或在这两个协议都不可用时使用静态地址来配置一个或多个网络接口dhclient -r 释放IP地址dhclient -d 强制dhclient作为前台进程运行。 通常情况下，DHCP客户端将在前台运行,直到配置了一个接口,此时它将恢复为在后 台运行。 3) 服务器日志查看验证获取信息[root@zutuanxue ~]# tailf /var/log/messagesFeb 21 13:40:44 baism dhcpd: DHCPDISCOVER from 00:0c:29:1a:f8:bd via ens33Feb 21 13:40:45 baism dhcpd: DHCPOFFER on 192.168.11.156 to 00:0c:29:1a:f8:bd via ens33Feb 21 13:40:45 baism dhcpd: DHCPREQUEST for 192.168.11.156 (192.168.11.16) from 00:0c:29:1a:f8:bd via ens33Feb 21 13:40:45 baism dhcpd: DHCPACK on 192.168.11.156 to 00:0c:29:1a:f8:bd via ens334) 在client上通过ifconfig命令再次查看eth0 IP地址，验证是否为192.168.11.156[root@test 桌面]# ifconfig eth0eth0 Link encap:Ethernet HWaddr 00:0C:29:1A:F8:BD inet addr:192.168.11.156 Bcast:192.168.11.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe1a:f8bd/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:97 errors:0 dropped:0 overruns:0 frame:0 TX packets:67 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:17364 (16.9 KiB) TX bytes:7537 (7.3 KiB)5）查看网关，确定网关为192.168.11.254[root@test 桌面]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.11.0 0.0.0.0 255.255.255.0 U 0 0 0 eth1192.168.11.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1003 0 0 eth10.0.0.0 192.168.11.254 0.0.0.0 UG 0 0 0 eth06）查看DNS配置文件，看DNS是否为DHCP服务器发放的DNS服务器IP[root@test 桌面]# cat /etc/resolv.conf ; generated by /sbin/dhclient-scriptnameserver 202.106.0.20nameserver 114.114.114.114 5.4）通过DHCP服务器租约文件查看具体租约租约文件的路径: &#x2F;var&#x2F;lib&#x2F;dhcpd&#x2F;dhcpd.leases 1234567891011121314151617181920212223[root@zutuanxue ~]# cat /var/lib/dhcpd/dhcpd.leases# The format of this file is documented in the dhcpd.leases(5) manual page.# This lease file was written by isc-dhcp-4.3.6# authoring-byte-order entry is generated, DO NOT DELETEauthoring-byte-order little-endian;server-duid &quot;\\000\\001\\000\\001%\\257\\376\\022\\000\\014)c.\\345&quot;;lease 192.168.11.153 &#123; starts 2 2020/01/14 04:21:04;\t#开始时间 ends 2 2020/01/14 06:21:04; #结束时间 cltt 2 2020/01/14 04:21:04; binding state active; next binding state free; rewind binding state free; hardware ethernet 00:0c:29:6d:1c:b3; uid &quot;\\001\\000\\014)m\\034\\263&quot;;&#125;注意：当你发现这里的时间和你的服务器时间不一致的时候，建议你修改时区解决问题，一般是差8个小时，大家明白就好。 5.5）保留IP在IP租约到期后，如果无法续订租约，client只能乖乖交出IP地址，重新获得一个其他IP使用。但是在公司有些服务器的IP地址是不能变化的，因为变了用户就无法连接到服务器了，比如公司文件服务器、打印服务器等等。那么在这种环境中我们既想使用DHCP管理公司IP，又想实现部分机器的IP永久不变，那么怎么实现呢。 DHCP的作者在写DHCP的时候也想到了这个问题，提出了保留IP的概念，就是将某些IP保留，然后服务器来获得IP的时候，根据其MAC地址做匹配，将对应的IP分给它即可。 教学案例:希望这个MAC地址为00:0C:29:1A:F8:C7的网卡能永久获得IP 192.168.11.252，实现方式如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 a、在配置文件/etc/dhcp/dhcpd.conf末尾添加以下内容 host print &#123; hardware ethernet 00:0C:29:1A:F8:C7; fixed-address 192.168.11.252;&#125;host print host为指令，print是个名字，随便起，但是最好有意义，要不过一段你也记不住了。hardware ethernet 指定以太网网卡MAC地址fixed-address 指定要绑定的IPb、重启DHCP服务[root@zutuanxue ~]# systemctl restart dhcpdc、测试，登陆测试机，释放挡墙IP，重新获得新的IP，查看IP地址是否正确分发[root@test 桌面]# ifconfig eth1eth1 Link encap:Ethernet HWaddr 00:0C:29:1A:F8:C7 inet addr:192.168.11.155 Bcast:192.168.11.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe1a:f8c7/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:4071 errors:0 dropped:0 overruns:0 frame:0 TX packets:187 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:433880 (423.7 KiB) TX bytes:16888 (16.4 KiB)[root@test 桌面]# dhclient -r eth1[root@test 桌面]# dhclient -d eth1Internet Systems Consortium DHCP Client 4.1.1-P1Copyright 2004-2010 Internet Systems Consortium.All rights reserved.For info, please visit https://www.isc.org/software/dhcp/Listening on LPF/eth1/00:0c:29:1a:f8:c7Sending on LPF/eth1/00:0c:29:1a:f8:c7Sending on Socket/fallbackDHCPDISCOVER on eth1 to 255.255.255.255 port 67 interval 4 (xid=0x45c162c2)DHCPOFFER from 192.168.11.16DHCPREQUEST on eth1 to 255.255.255.255 port 67 (xid=0x45c162c2)DHCPACK from 192.168.11.16 (xid=0x45c162c2)bound to 192.168.11.252 -- renewal in 2881 seconds.^C[root@test 桌面]# ifconfig eth1eth1 Link encap:Ethernet HWaddr 00:0C:29:1A:F8:C7 inet addr:192.168.11.252 Bcast:192.168.11.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe1a:f8c7/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:4081 errors:0 dropped:0 overruns:0 frame:0 TX packets:191 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:436337 (426.1 KiB) TX bytes:17656 (17.2 KiB)完美！ 六、DHCP超级作用域体验了DHCP服务器给大家带来的方便后，我们工作轻松了很多，但是随着时间的推移，突然有这么一个问题急需你解决，由于公司的发展壮大，公司人员数量越来越多，公司一个网段的IP无法满足日常使用，所以又加了一个网段。但是默认情况下，DHCP服务器只能发放和自己网卡在同一网段的IP地址，目前我们DHCP的网卡IP地址为192.168.11.0段，我们新加的网段为192.168.12.0，那么怎么能让DHCP服务器既能发11网段，又能发放12网段呢？学会超级作用域就可以解决这个问题。 超级作用域：将两个或以上的不同网段的作用域合成一个作用域既是超级作用域。 案例:部署一个超级作用域，作用域是192.168.11.0&#x2F;24网段，192.168.12.0&#x2F;24网段。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133a、编辑配置文件[root@zutuanxue ~]# cat /etc/dhcp/dhcpd.confoption domain-name-servers 4.2.2.2, 4.2.2.1;default-lease-time 28800;max-lease-time 43200;#authoritative;log-facility local7;#share-network 部署一个超级作用域#supper 超级作用域名称，随便起，但是建议有意义。shared-network supper &#123;#192.168.11.0作用域subnet 192.168.11.0 netmask 255.255.255.0 &#123;range 192.168.11.150 192.168.11.150;option domain-name-servers 202.106.0.20, 114.114.114.114;option routers 192.168.11.254;default-lease-time 7200;max-lease-time 10800;&#125;#192.168.12.0作用域subnet 192.168.12.0 netmask 255.255.255.0 &#123;range 192.168.12.150 192.168.12.150;option domain-name-servers 202.106.0.20, 114.114.114.114;option routers 192.168.12.254;default-lease-time 7200;max-lease-time 10800;&#125;&#125;注意：案例中为了方便验证，我每个作用域只发布一个IP，否者测试无法保证能100%分到两个网段。b、重启DHCP服务，生效配置文件[root@zutuanxue dhcp]# systemctl restart dhcpdc、验证#释放两网卡IP[root@test 桌面]# dhclient -r eth0[root@test 桌面]# dhclient -r eth1#释放成功[root@test 桌面]# ifconfigeth0 Link encap:Ethernet HWaddr 00:0C:29:1A:F8:BD inet6 addr: fe80::20c:29ff:fe1a:f8bd/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:1591 errors:0 dropped:0 overruns:0 frame:0 TX packets:162 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:282324 (275.7 KiB) TX bytes:30619 (29.9 KiB)eth1 Link encap:Ethernet HWaddr 00:0C:29:1A:F8:C7 inet6 addr: fe80::20c:29ff:fe1a:f8c7/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:4719 errors:0 dropped:0 overruns:0 frame:0 TX packets:216 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:559954 (546.8 KiB) TX bytes:19582 (19.1 KiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:12 errors:0 dropped:0 overruns:0 frame:0 TX packets:12 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:720 (720.0 b) TX bytes:720 (720.0 b)#分别获取IP地址 [root@test 桌面]# dhclient -d eth0Internet Systems Consortium DHCP Client 4.1.1-P1Copyright 2004-2010 Internet Systems Consortium.All rights reserved.For info, please visit https://www.isc.org/software/dhcp/Listening on LPF/eth0/00:0c:29:1a:f8:bdSending on LPF/eth0/00:0c:29:1a:f8:bdSending on Socket/fallbackDHCPDISCOVER on eth0 to 255.255.255.255 port 67 interval 6 (xid=0x2574199a)DHCPOFFER from 192.168.11.16DHCPREQUEST on eth0 to 255.255.255.255 port 67 (xid=0x2574199a)DHCPACK from 192.168.11.16 (xid=0x2574199a)bound to 192.168.11.150 -- renewal in 3026 seconds.^C#确保都是来自我们实验中的DHCP服务器[root@test 桌面]# dhclient -d eth1Internet Systems Consortium DHCP Client 4.1.1-P1Copyright 2004-2010 Internet Systems Consortium.All rights reserved.For info, please visit https://www.isc.org/software/dhcp/Listening on LPF/eth1/00:0c:29:1a:f8:c7Sending on LPF/eth1/00:0c:29:1a:f8:c7Sending on Socket/fallbackDHCPDISCOVER on eth1 to 255.255.255.255 port 67 interval 7 (xid=0x2cebde11)DHCPOFFER from 192.168.11.16DHCPREQUEST on eth1 to 255.255.255.255 port 67 (xid=0x2cebde11)DHCPACK from 192.168.11.16 (xid=0x2cebde11)bound to 192.168.12.150 -- renewal in 3102 seconds.#确保都是来自我们实验中的DHCP服务器#查看IP情况，发现实验成功了，分别获得到了不同网段IP[root@test 桌面]# ifconfigeth0 Link encap:Ethernet HWaddr 00:0C:29:1A:F8:BD inet addr:192.168.11.150 Bcast:192.168.11.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe1a:f8bd/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:1613 errors:0 dropped:0 overruns:0 frame:0 TX packets:166 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:287076 (280.3 KiB) TX bytes:31387 (30.6 KiB)eth1 Link encap:Ethernet HWaddr 00:0C:29:1A:F8:C7 inet addr:192.168.12.150 Bcast:192.168.12.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe1a:f8c7/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:4741 errors:0 dropped:0 overruns:0 frame:0 TX packets:220 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:564706 (551.4 KiB) TX bytes:20350 (19.8 KiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:12 errors:0 dropped:0 overruns:0 frame:0 TX packets:12 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:720 (720.0 b) TX bytes:720 (720.0 b) 七、补充7.1) 如果客户端获得不到 IP会怎么办当客户端获得不到IP地址，会得到一个169.254开头的临时IP，此IP不能和其他网段通信，但是Client会继续向网络中发DHCP广播，继续坚持不懈申请IP。 7.2）DHCP会面临单机故障，如何解决两台设备互相分发对方网段一段IP，将作用域采用8&#x2F;2原则，彼此互相冗余，当一台服务器出现问题，不至于整个网段故障。 7.3）抓包验证方法1[root@zutuanxue dhcp]# tcpdump -nn -vvv -s 1500 -i ens33 host 192.168.11.16 and udp port 67 or udp port 68 7.4）如何发放计算机名称发放计算机名称只能在保留中完成，要求Client的计算机名配置文件中将对应字段删除。 12345678910111213141516171819202122232425option domain-name-servers 4.2.2.2, 4.2.2.1;default-lease-time 28800;max-lease-time 43200;authoritative;log-facility local7;subnet 192.168.11.0 netmask 255.255.255.0 &#123; range 192.168.11.153 192.168.11.252; option domain-name-servers 202.106.0.20, 114.114.114.114; option routers 192.168.11.254; option broadcast-address 192.168.11.255; default-lease-time 7200; max-lease-time 10800;&#125;host print &#123; #指定计算机名称 option host-name &quot;test.hello.com&quot;; hardware ethernet 00:0c:29:af:f1:84; fixed-address 192.168.11.252;&#125;注意：请把/etc/hostname 中的计算机名称清除 /etc/sysconfig/network中的hostname字段清除"},{"path":"/2023/07/11/Kubernetes云计算实战/集群安全介绍/","content":"一、机制说明 Kubernetes 作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。API Server 是集群内部各个组件通信的中介，也是外部控制的入口。所以 Kubernetes 的安全机制基本就是围绕保护 API Server 来设计的，Kubernetes 使用了认证（Authentication）、鉴权（Authorization）、准入控制（AdmissionControl）三步来保证API Server的安全 。 144.png 二、认证 AuthenticationHTTP Token 认证： 通过一个 Token 来识别合法用户，HTTP Token 的认证是用一个很长的特殊编码方式的并且难以被模仿的字符串 - Token 来表达客户的一种方式。Token 是一个很长的很复杂的字符串，每一个 Token 对应一个用户名存储在 API Server 能访问的文件中，当客户端发起 API 调用请求时，需要在 HTTP Header 里放入 Token。 HTTP Base 认证： 通过用户名+密码的方式进行认证，用户名+密码用 BASE64 算法进行编码后的字符串放在 HTTP Request 中的 Heather Authorization 域里发送给服务端，服务端收到后进行编码，获取用户名及密码。 HTTPS 证书认证： HTTPS 证书认证是最严格的认证，基于 CA 根证书签名的客户端身份认证方式。 1、HTTPS 证书认证： 145.png 2、需要认证的节点 146.png 两种类型 Kubenetes 组件对 API Server 的访问：kubectl、Controller Manager、Scheduler、kubelet、kube-proxy Kubernetes 管理的 Pod 对容器的访问：Pod（dashborad 也是以 Pod 形式运行） 安全性说明 Controller Manager、Scheduler 与 API Server 在同一台机器，所以直接使用 API Server 的非安全端口访问， –insecure-bind-address&#x3D;127.0.0.1 kubectl、kubelet、kube-proxy 访问 API Server 就都需要证书进行 HTTPS 双向认证 证书颁发 手动签发：通过 k8s 集群的跟 ca 进行签发 HTTPS 证书 自动签发：kubelet 首次访问 API Server 时，使用 token 做认证，通过后，Controller Manager 会为kubelet 生成一个证书，以后的访问都是用证书做认证了 3、kubeconfig kubeconfig 文件包含集群参数（CA证书、API Server地址），客户端参数（上面生成的证书和私钥），集群context 信息（集群名称、用户名）。Kubenetes 组件通过启动时指定不同的 kubeconfig 文件可以切换到不同的集群。 4、ServiceAccount Pod中的容器访问API Server。因为Pod的创建、销毁是动态的，所以要为它手动生成证书就不可行了。Kubenetes使用了Service Account解决Pod 访问API Server的认证问题。 5、Secret 与 SA 的关系 Kubernetes 设计了一种资源对象叫做 Secret，分为两类，一种是用于 ServiceAccount 的 service-account-token，另一种是用于保存用户自定义保密信息的 Opaque。ServiceAccount 中用到包含三个部分：Token、ca.crt、namespace。 1、token是使用 API Server 私钥签名的 JWT。用于访问API Server时，Server端认证 2、ca.crt，根证书。用于Client端验证API Server发送的证书 3、namespace, 标识这个service-account-token的作用域名空间 1# Json web token（JWT），是为了在网络应用环境间传递声明而执行的一种基于 JSON 的开放标准（RFC 7519），该 token 被设计为紧凑且安全的，特别适合用于分布式站点的单点登陆（SSO）场景，JWT 的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其他业务逻辑所必需声明的信息，该 token 也可以直接用于认证，也可以被加密。 默认情况下，每个 namespace 都会有一个 ServiceAccount，如果 Pod 在创建时没有指定 ServiceAccount，就会使用 Pod 所属的 namespace 的 ServiceAccount 147.png"},{"path":"/2023/07/11/Kubernetes云计算实战/部署EFK pod日志分析系统/","content":"EFK不是一个软件，而是一套解决方案，并且都是开源软件，之间互相配合使用，完美衔接，高效的满足了很多场合的应用，是目前主流的一种日志系统。EFK是三个开源软件的缩写，分别表示：Elasticsearch , Fluentd, Kibana 组件说明： EFK由ElasticSearch、Fluentd和Kiabana三个开源工具组成。 1、其中Elasticsearch是一款分布式搜索引擎，能够用于日志的检索 2、Fluentd是一个实时开源的数据收集器, 3、Kibana 是一款能够为Elasticsearch 提供分析和可视化的 Web 平台。 这三款开源工具的组合为日志数据提供了分布式的实时搜集与分析的监控系统。 一、环境准备123456789101112131415# 资源配置：Master: 4U4GNode-1: 4U4GNode-2: 4U4Gmkdir efkcd efkkubectl create namespace efk添加 Google incubator 仓库：helm repo add bitnami https://charts.bitnami.com/bitnami 二、部署 Elasticsearch12345678910111213141516171819202122232425262728293031323334353637383940414243helm fetch bitnami/elasticsearchtar zxvf elasticsearch-12.3.1.tgzcd elasticsearch/vim values.yaml# 因为是实验环境，需要修改一下配置文件，否则可能会因为资源问题而导致实验失败volumePermissions: enabled: false # 修改为 “false” image: registry: docker.io repository: bitnami/minideb tag: buster pullPolicy: Alwaysmaster: name: master replicas: 1 # 修改为 “1” persistence: enabled: false # 修改为 “false”coordinating: replicas: 1 # 修改为 “1” updateStrategy: type: RollingUpdatedata: name: data replicas: 1 # 修改为 “1” persistence: enabled: false # 修改为 “false”# 保存退出helm install . --name ela --namespace=efk -f values.yaml# 测试一下：kubectl run cirror-$RANDOM --rm -it --image=cirros -- /bin/shcurl Elasticsearch:Port/_cat/nodes 完成后我们查看一下： 185.png 三、部署 Fluentd1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071helm fetch stable/fluentdtar zxvf fluentd-2.4.1.tgzcd fluentdvim values.yaml# 更改其中 Elasticsearch 访问地址elasticsearch: host: &#x27;es-elasticsearch-coordinating-only&#x27; # 修改地址 port: 9200 scheme: &#x27;http&#x27; ssl_version: TLSv1_2 buffer_chunk_limit: 2M buffer_queue_limit: 8 logstash_prefix: &#x27;logstash&#x27; 在 system.conf 上方添加下列代码： containers.input.conf: |- &lt;source&gt; @id fluentd-containers.log @type tail path /var/log/containers/*.log pos_file /var/log/es-containers.log.pos tag raw.kubernetes.* read_from_head true &lt;parse&gt; @type multi_format &lt;pattern&gt; format json time_key time time_format %Y-%m-%dT%H:%M:%S.%NZ &lt;/pattern&gt; &lt;pattern&gt; format /^(?&lt;time&gt;.+) (?&lt;stream&gt;stdout|stderr) [^ ]* (?&lt;log&gt;.*)$/ time_format %Y-%m-%dT%H:%M:%S.%N%:z &lt;/pattern&gt; &lt;/parse&gt; &lt;/source&gt; &lt;match raw.kubernetes.**&gt; @id raw.kubernetes @type detect_exceptions remove_tag_prefix raw message log stream stream multiline_flush_interval 5 max_bytes 500000 max_lines 1000 &lt;/match&gt;vim templates/deployment.yaml 在 volumeMounts 与 volumes 下方进行挂载：volumeMounts: - name: varlog mountPath: /var/log - name: dockercontainers mountPath: /var/lib/docker/containers readOnly: truevolumes: - name: varlog hostPath: path: /var/log - name: dockercontainers hostPath: path: /var/lib/docker/containershelm install . --name flu --namespace=efk -f values.yaml 完成后查看： 186.png 四、部署 kibana123456789101112131415161718192021222324252627helm fetch bitnami/kibana# 这里要特别注意一下，Kibana 的版本要与Elasticsearch 的版本一直，否则会出错，需要特别、特别注意tar zxvf kibana-5.1.2.tgzcd kibana/vim values.yaml # 更改其中 Elasticsearch 访问地址# 更改 Service 中的 ClusterIP 为 NodePortelasticsearch: hosts: - es-elasticsearch-coordinating-only port: 9200service: port: 80 type: NodePortvolumePermissions: enabled: falsehelm install . --name kia --namespace=efk -f values.yaml 完成后查看效果： 187.png 通过暴露的端口号，进行 WEB 访问： 188.png 创建一下索引序列： 189.png 我们来以时间为例，创建索引： 190.png 通过时间序列分片： 191.png 分片成功： 192.png 查看我们收集的日志信息： 193.png"},{"path":"/2023/07/11/Kubernetes云计算实战/资源控制器之RS/","content":"RC （ReplicationController ）主要的作用就是用来确保容器应用的副本数始终保持在用户定义的副本数 。即如果有容器异常退出，会自动创建新的 Pod 来替代；而如果异常多出来的容器也会自动回收（已经成为过去时）。 Kubernetes 官方建议使用 RS（ReplicaSet ） 替代 RC （ReplicationController ） 进行部署，RS 跟 RC 没有本质的不同，只是名字不一样，并且 RS 支持集合式的 selector。 48.png RS 用示例： 12345678910111213141516171819202122vim rs.yamlapiVersion: apps/v1kind: ReplicaSetmetadata: name: mywebspec: replicas: 3 selector: matchLabels: tier: myweb template: metadata: labels: tier: myweb spec: containers: - name: nginx image: docker.io/nginx imagePullPolicy: IfNotPresent ports: - containerPort: 80 我们来查看下我们的 Pod 信息： 46.png 这个时候我们来随便删除一个其中的 Pod 后在查看下我们的 Pod 信息： 47.png 通过上述操作，我们可以看到，当我们定义了一个 RS 控制器的副本数目为 3 以后，那么，系统会始终保持我们的副本数为，不管是多了还是少了，系统始终会保持我们的副本数量与我们定义的数量一致（多删少建）。这个时候我们可以通过 kubectl get pod –show-labels 来查看我们 Pod 的标签： 51.png 这个时候可以看到我们在 rs.yanl 文件内所定义的标签，这个时候，我们来通过命令 kubectl label pod myweb-rkqjz tier&#x3D;my-nginx –overwrite&#x3D;True 修改我们 myweb-rkqjz 这个Pod 的标签然后看下效果： 52.png 这个时候我们需要注意一下 1“error: &#x27;tier&#x27; already has a value (myweb), and --overwrite is false“ 因为标签已经存在，所以后面需要接上 –overwrite&#x3D;True 才能修改，我们的标签，但是修改玩以后，因为 RS 是通过 Pod 的标签来确定哪些 Pod 是我管理的， 哪些 Pod 不是我管理的，当我们修改了其中一个 Pod 的标签以后，RS 发现我所管理的 Pod 数量与副本定义数量不符，所以会创建一个新的 Pod 来补足，这也就是为什么，当使用删除 RS 的命令 kubectl delete rs –all 以后，会有一个 Pod 没有被删除，因为该 Pod 标签与 rs.yaml 内定义的标签不符，所以不归该 RS 管理器管辖。"},{"path":"/2023/07/11/Kubernetes云计算实战/资源控制器之Deployment/","content":"Deployment 为 Pod 和 ReplicaSet 提供了一个声明式定义(declarative)方法，用来替代以前的ReplicationController 来方便的管理应用。典型的应用场景包括： 定义 Deployment 来创建 Pod 和 ReplicaSet 滚动升级和回滚应用 扩容和缩容 49.png Deployment 应用示例： 1234567891011121314151617181920212223242526vim deploy.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: my-nginxspec: selector: matchLabels: app: web-nginx replicas: 3 template: metadata: labels: app: web-nginx spec: containers: - name: web-nginx image: docker.io/nginx imagePullPolicy: IfNotPresent ports: - containerPort: 80kubectl create -f deploy.yaml --record\t## --record参数可以记录命令，我们可以很方便的查看每次 revision 的变化 创建完成后，我们可以查看下我们的 Pod 状态： 50.png 我们可以通过命令 kubectl scale deployment my-nginx –replicas&#x3D;5 将副本数量扩容到 5 个： 53.png 也可以通过该命令 kubectl scale deployment my-nginx –replicas&#x3D;2 缩容到 2 个： 54.png 这个时候我们注意一下，在缩容的时候，优先删除的是创建时间短的 Pod 。下面我们在来看一下 deployment 的升级与回滚： 查看当前的 Pod 当中的 nginx 的版本： kubectl exec Pod-name -it – nginx -v 升级 images 版本： kubectl set image deployment&#x2F;my-nginx web-nginx&#x3D;nginx:1.9.1 55.png 使用命令 kubectl get rs 命令查看 Pod 的更新过程： 56.png 当升级完成后，查看一下当前 Pod 的 nginx 的版本： 57.png 通过命令查看 deployment 的历史记录： kubectl rollout history deployment my-nginx 58.png 回滚到之前的版本： kubectl rollout undo deployment –to-revision&#x3D;1 59.png 回滚完成后，查看一下当前 Pod 的 nginx 的版本： 60.png 清理 Policy ： 可以通过设置 spec.revisonHistoryLimit 项来指定 deployment 最多保留多少 revision 历史记录。默认的会保留所有的 revision，如果将该项设置为 0，Deployment 就不允许回退了。"},{"path":"/2023/07/11/Kubernetes云计算实战/资源控制器之DaemonSet/","content":"DaemonSet 确保全部(或者一些) Node上运行一个 Pod 的副本，当有 Node 加入集群时，也会为他们新增一个 Pod，当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod 。 61.png DaemonSet 应用示例： 1234567891011121314151617181920vim daemonset.yamlapiVersion: apps/v1kind: DaemonSetmetadata: name: deamonset labels: app: daemonsetspec: selector: matchLabels: name: deamonset template: metadata: labels: name: deamonset spec: containers: - name: daemonset image: docker.io/nginx 创建完成后，查看pod状态： 62.png"},{"path":"/2023/07/11/Kubernetes云计算实战/服务部署与迁移的步骤/","content":"一、服务部署与迁移的步骤1.1、将应用封装进容器应用容器化是部署与迁移的第一步，需要设计并规划好镜像的构建方案，由于Docker镜像分层的特性，通常建议使用分层方式进行Docker镜像构建。 操作系统层：制作公司常用的系统版本如CentOS、Ubuntu，可以在官方镜像的基础上添加自己需要的软件包。 运行环境层：在已经构建的操作系统层的基础上，把业务常用的运行环境都打包好，如JDK7、JDK8、JDK8+Tomcat8、Python2、Python3等通用模板。 应用层：在已经构建好了通用运行环境的基础上，根据应用再进行调整，然后将代码放进去即可。 1.2、将容器放入Pod中应用容器化后，就需要考虑如何在Pod中运行，因为Pod是Kubernetes管理的最小单元，Kubernetes不直接管理容器，而是管理Pod，Pod里面包含容器。需要考虑是一个Pod中放置多个容器，还是一个Pod中放置一个容器，同时需要考虑Pod的资源限制，健康检查，数据持久化等。 1、3、使用Controllers管理Pod单一Pod如果出现故障，就会影响业务连续性，所以需要多副本，就像我们给一个Web应用做集群是一样的。Kubernetes提供了不同的Controller，需要根据应用的实际情况选择使用Deployment、DaemonSet、StatefulSet、Job、CronJob等，只需要在Pod的YAML模板上封装上对应的配置即可。 Deployment：封装了Pod的副本管理、部署更新、回滚、扩容、缩容等。 DaemonSet：保证所有的Node上有且只有一个Pod在运行。 StatefulSet：有状态的应用，为Pod提供唯一的标识，它可以保证部署和scale的顺序。 Job：使用Kubernetes运行单一任务。 CronJob：使用Kubernetes运行定时任务。 1.4、使用Service管理Pod访问使用Deployment通过多副本的方式保证了Pod的高可用和横向扩展，那么就需要考虑负载均衡，Kubernetes Service就是实现此功能，为应用创建对应的Service。目前Service的负载均衡支持两种实现方式：iptable 和 ipvs。 1.5、使用Ingress提供外部访问集群内部可以直接使用Service Name进行通信，因为在集群中定义的每个 Service，都会被指派一个 DNS 名称，外部要访问到Kubernetes集群，由于网络路由不通（也可以使用其它手段打通），可以通过Node Port、LoadBlancer、外部IP等对外暴露访问。不过这些都可以理解为4层的负载均衡，如果要实现7层的负载均衡，Kubernetes提供了Ingress。 在Kubernetes中由Ingress Controller来实现Ingress的功能，这个控制器比较特殊，因为其它的控制器基本上都是kube-controller-manager这个服务的一部分，而Ingress Controller确是独立的。 1.6、使用PV&#x2F;PVC管理持久化数据容器中的存储都是临时的，因此Pod重启的时候，内部的数据会发生丢失。实际应用中，我们有些应用是无状态，有些应用则需要保持状态数据，确保Pod重启之后能够读取到之前的状态数据，有些应用则作为集群提供服务。这三种服务归纳为无状态服务、有状态服务以及有状态的集群服务，其中后面两个存在数据保存与共享的需求，因此就要采用容器外的存储方案。 1.7、使用ConfigMap管理应用配置文件在DevOps的部署流水线中，我们强调代码和配置的分离，这样更容易实现流水线的编排。在Kubernetes中提供了ConfigMap资源对象，其实ConfigMap和Secret都是一种卷类型，可以从文件、文件夹等途径创建ConfigMap。然后再Pod中挂载使用。"},{"path":"/2023/07/11/Kubernetes云计算实战/搭建 Prometheus/","content":"一、Prometheus介绍Prometheus（普罗米修斯）是一套开源的监控、报警、时间序列数据库的组合，起始是由SoundCloud公司开发的。随着发展，越来越多公司和组织接受采用Prometheus，社会也十分活跃，他们便将它独立成开源项目，并且有公司来运作。Google SRE的书内也曾提到跟他们BorgMon监控系统相似的实现是Prometheus。现在最常见的Kubernetes容器管理系统中，通常会搭配Prometheus进行监控。​Prometheus基本原理是通过HTTP协议周期性抓取被监控组件的状态，这样做的好处是任意组件只要提供HTTP接口就可以接入监控系统，不需要任何SDK或者其他的集成过程，这样做非常适合虚拟化环境。 组件说明 1.MetricServer：是kubernetes集群资源使用情况的聚合器，收集数据给kubernetes集群内使用，如kubectl,hpa,scheduler等。 2.PrometheusOperator：是一个系统监测和警报工具箱，用来存储监控数据。 3.NodeExporter：用于各node的关键度量指标状态数据。 4.KubeStateMetrics：收集kubernetes集群内资源对象数据，制定告警规则。 5.Prometheus：采用pull方式收集apiserver，scheduler，controller-manager，kubelet组件数据，通过http协议传输。 6.Grafana：是可视化数据统计和监控平台。 二、grafana介绍Grafana是一个跨平台的开源的度量分析和可视化工具，可以通过将采集的数据查询然后可视化的展示，并及时通知。它主要有以下六大特点： 12345678910111213141、展示方式：快速灵活的客户端图表，面板插件有许多不同方式的可视化指标和日志，官方库中具有丰富的仪表盘插件，比如热图、折线图、图表等多种展示方式2、数据源：Graphite，InfluxDB，OpenTSDB，Prometheus，Elasticsearch，CloudWatch和KairosDB等3、通知提醒：以可视方式定义最重要指标的警报规则，Grafana将不断计算并发送通知，在数据达到阈值时通过Slack、PagerDuty等获得通知4、混合展示：在同一图表中混合使用不同的数据源，可以基于每个查询指定数据源，甚至自定义数据源5、注释：使用来自不同数据源的丰富事件注释图表，将鼠标悬停在事件上会显示完整的事件元数据和标记6、过滤器：Ad-hoc过滤器允许动态创建新的键/值过滤器，这些过滤器会自动应用于使用该数据源的所有查询。展示模版下载：https://grafana.com/grafana/dashboards 三、prometheus部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293git网站：https://github.com/coreos/kube-prometheusmkdir prometheuscd prometheusgit clone https://github.com/coreos/kube-prometheus.gitcd kube-prometheus修改 grafana-service.yaml 文件，使用 nodepode 方式访问 grafana：vim manifests/grafana-service.yamlapiVersion: v1kind: Servicemetadata: labels: app: grafana name: grafana namespace: monitoringspec: type: NodePort # 添加内容 ports: - name: http port: 3000 targetPort: http nodePort: 30100 # 添加内容 selector: app: grafana 修改 prometheus-service.yaml，改为 nodepodevim manifests/prometheus-service.yamlapiVersion: v1kind: Servicemetadata: labels: prometheus: k8s name: prometheus-k8s namespace: monitoringspec: type: NodePort # 添加内容 ports: - name: web port: 9090 targetPort: web nodePort: 30200 # 添加内容 selector: app: prometheus prometheus: k8s sessionAffinity: ClientIP 修改 alertmanager-service.yaml，改为 nodepodevim manifests/alertmanager-service.yamlapiVersion: v1kind: Servicemetadata: labels: alertmanager: main name: alertmanager-main namespace: monitoringspec: type: NodePort # 添加内容 ports: - name: web port: 9093 targetPort: web nodePort: 30300 # 添加内容 selector: alertmanager: main app: alertmanager sessionAffinity: ClientIP kubectl apply -f manifests/setupkubectl apply -f manifests/kubectl get pod -n monitoringkubectl get svc -n monitoring稍等两分钟执行：kubectl top nodekubectl top pod 执行完成后查看一下状态，首先是 Pod： 161.png 在看下SVC： 162.png 看下收集的 Node 的数据： 163.png 访问 prometheus 通过浏览器输入 Master IP ： 30200 164.png 我们可以在 status 下 Targets 里看到我们的节点状态： 165.png 显示 UP 状态 说明我们部署成功： 166.png prometheus 的 WEB 界面上提供了基本的查询，查询条件如下： 12345678910111.POD内存使用率sum(container_memory_rss&#123;container!=&quot;POD&quot;,container!=&quot;alermanager&quot;,image!=&quot;&quot;,pod!=&quot;&quot;&#125;)by(pod) / sum(container_spec_memory_limit_bytes&#123;container!=&quot;&quot;,container!=&quot;POD&quot;&#125;)by(pod) * 100 != +inf2.POD的CPU使用率sum(rate(container_cpu_usage_seconds_total&#123;image!=&quot;&quot;,container!=&quot;POD&quot;,container!=&quot;&quot;&#125;[1m])) by (pod,namespace) / (sum(container_spec_cpu_quota&#123;image!=&quot;&quot;,container!=&quot;POD&quot;,container!=&quot;&quot;&#125;/100000) by (pod,namespace)) * 1003.POD的文件系统使用量sum(container_fs_usage_bytes&#123;image!=&quot;&quot;,container!=&quot;POD&quot;,container!=&quot;&quot;&#125;) by(pod, namespace) / 1024 / 1024 / 1024 167.png 168.png 169.png 170.png 上述的查询有出现数据，说明 node-exporter 往 prometheus 中写入数据正常，接下来我们就可以部署grafana 组件，实现更友好的 webui 展示数据了 访问 grafana 查看 grafana 服务暴露的端口号： 12kubectl get service -n monitoring | grep grafanagrafana NodePort 10.109.190.229 &lt;none&gt; 3000:30100/TCP 28m 如上可以看到 grafana 的端口号是 30100，浏览器访问 http://MasterIP:30100 用户名密码默认 admin&#x2F;admin 171.png 修改密码后登陆： 172.png 添加数据源 173.png 选择模版： 174.png 数据信息已经自动填好 175.png 测试完好 176.png 添加插件 177.png 这样我们的数据可以正常显示 178.png"},{"path":"/2023/07/11/Kubernetes云计算实战/授权、鉴权与准入控制/","content":"认证过程，只是确认通信的双方都确认了对方是可信的，可以相互通信。而鉴权是确定请求方有哪些资源的权限。API Server 目前支持以下几种授权策略 （通过 API Server 的启动参数 “–authorization-mode” 设置） 1、AlwaysDeny：表示拒绝所有的请求，一般用于测试 2、AlwaysAllow：允许接收所有请求，如果集群不需要授权流程，则可以采用该策略 3、ABAC（Attribute-Based Access Control）：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制（已经淘汰） 4、Webbook：通过调用外部 REST 服务对用户进行授权 5、RBAC（Role-Based Access Control）：基于角色的访问控制，现行默认规则 RBAC 授权模式： RBAC（Role-Based Access Control）基于角色的访问控制，在 Kubernetes 1.5 中引入，现行版本成为默认标准。相对其它访问控制方式，拥有以下优势： ① 对集群中的资源和非资源均拥有完整的覆盖 ② 整个 RBAC 完全由几个 API 对象完成，同其它 API 对象一样，可以用 kubectl 或 API 进行操作 ③ 可以在运行时进行调整，无需重启 API Server 官方说明文档：https://kubernetes.io/zh/docs/reference/access-authn-authz/rbac/ 1、RBAC 的 API 资源对象说明 RBAC 引入了 4 个新的顶级资源对象：Role（角色）、ClusterRole（集群角色）、RoleBinding（角色绑定）、ClusterRoleBinding（集群角色绑定），4 种对象类型均可以通过 kubectl 与 API 操作 148.png 需要注意的是 Kubenetes 并不会提供用户管理，那么 User、Group、ServiceAccount 指定的用户又是从哪里来的呢？ Kubenetes 组件（kubectl、kube-proxy）或是其他自定义的用户在向 CA 申请证书时，需要提供一个证书请求文件 123456789101112131415161718192021222324252627&#123; &quot;CN&quot;: &quot;zutuanxue&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;HangZhou&quot;, &quot;L&quot;: &quot;XS&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ] &#125;#-----------------------------# 分割线 #--------------------------------------## API Server会把客户端证书的 CN 字段作为User，把 names.O 字段作为Group#kubelet 使用 TLS Bootstaping 认证时，API Server 可以使用 Bootstrap Tokens 或者 Token authenticationfile 验证 =token，无论哪一种，Kubenetes 都会为 token 绑定一个默认的 User 和 Group#Pod使用 ServiceAccount 认证时，service-account-token 中的 JWT 会保存 User 信息#有了用户信息，再创建一对角色/角色绑定(集群角色/集群角色绑定)资源对象，就可以完成权限绑定了 Role and ClusterRole 在 RBAC API 中，Role 表示一组规则权限，权限只会增加(累加权限)，不存在一个资源一开始就有很多权限而通过RBAC 对其进行减少的操作；Role 可以定义在一个 namespace 中，如果想要跨 namespace 则可以创建ClusterRole 123456789kind: RoleapiVersion: rbac.authorization.k8s.io/v1beta1metadata: namespace: default name: pod-readerrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [&quot;pods&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] ClusterRole 具有与 Role 相同的权限角色控制能力，不同的是 ClusterRole 是集群级别的，ClusterRole 可以用于: 集群级别的资源控制( 例如 node 访问权限 ) 非资源型 endpoints( 例如 &#x2F;healthz 访问 ) 所有命名空间资源控制(例如 pods ) 123456789kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1beta1metadata: # &quot;namespace&quot; omitted since ClusterRoles are not namespaced name: secret-readerrules:- apiGroups: [&quot;&quot;] resources: [&quot;secrets&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] RoleBinding and ClusterRoleBinding RoloBinding 可以将角色中定义的权限授予用户或用户组，RoleBinding 包含一组权限列表(subjects)，权限列表中包含有不同形式的待授予权限资源类型(users, groups, or service accounts)；RoloBinding 同样包含对被Bind 的 Role 引用；RoleBinding 适用于某个命名空间内授权，而 ClusterRoleBinding 适用于集群范围内的授权。 将 default 命名空间的 pod-reader Role 授予 jane 用户，此后 jane 用户在 default 命名空间中将具有 pod-reader 的权限： 12345678910111213kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: read-pods namespace: defaultsubjects:- kind: User name: jane apiGroup: rbac.authorization.k8s.ioroleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io RoleBinding 同样可以引用 ClusterRole 来对当前 namespace 内用户、用户组或 ServiceAccount 进行授权，这种操作允许集群管理员在整个集群内定义一些通用的 ClusterRole，然后在不同的 namespace 中使用RoleBinding 来引用。​ 例如，以下 RoleBinding 引用了一个 ClusterRole，这个 ClusterRole 具有整个集群内对 secrets 的访问权限；但是其授权用户 dave 只能访问 development 空间中的 secrets(因为 RoleBinding 定义在 development 命名空间)： 1234567891011121314# This role binding allows &quot;dave&quot; to read secrets in the &quot;development&quot; namespace.kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: read-secrets namespace: development # This only grants permissions within the &quot;development&quot; namespace.subjects:- kind: User name: dave apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 使用 ClusterRoleBinding 可以对整个集群中的所有命名空间资源权限进行授权；以下 ClusterRoleBinding 样例展示了授权 manager 组内所有用户在全部命名空间中对 secrets 进行访问 12345678910111213# This cluster role binding allows anyone in the &quot;manager&quot; group to read secrets in anynamespace.kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: read-secrets-globalsubjects:- kind: Group name: manager apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io Resources Kubernetes 集群内一些资源一般以其名称字符串来表示，这些字符串一般会在 API 的 URL 地址中出现；同时某些资源也会包含子资源，例如 logs 资源就属于 pods 的子资源，API 中 URL 样例如下： 1GET /api/v1/namespaces/&#123;namespace&#125;/pods/&#123;name&#125;/log 如果要在 RBAC 授权模型中控制这些子资源的访问权限，可以通过 &#x2F; 分隔符来实现，以下是一个定义 pods 资资源logs 访问权限的 Role 定义样例 123456789kind: RoleapiVersion: rbac.authorization.k8s.io/v1beta1metadata: namespace: default name: pod-and-pod-logs-readerrules:- apiGroups: [&quot;&quot;] resources: [&quot;pods/log&quot;] verbs: [&quot;get&quot;, &quot;list&quot;] to Subjects RoleBinding 和 ClusterRoleBinding 可以将 Role 绑定到 Subjects；Subjects 可以是 groups、users 或者service accounts Subjects 中 Users 使用字符串表示，它可以是一个普通的名字字符串，如 “alice”；也可以是 email 格式的邮箱地址，如 “&#116;&#x79;&#x73;&#99;&#x68;&#x6f;&#x6f;&#108;&#64;&#49;&#54;&#x33;&#46;&#99;&#111;&#x6d;”；甚至是一组字符串形式的数字 ID 。但是 Users 的前缀 system: 是系统保留的，集群管理员应该确保普通用户不会使用这个前缀格式 Groups 书写格式与 Users 相同，都为一个字符串，并且没有特定的格式要求；同样 system: 前缀为系统保留 创建一个用户，只能管理zutuanxue空间： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#创建对应的用户：useradd zutuanxuepasswd zutuanxue#准备证书相关信息：vim zutuanxue-csr.json&#123; &quot;CN&quot;: &quot;zutuanxue&quot;, # 用户名 &quot;hosts&quot;: [], # 为空表示任何主机都可以使用，添加了IP地址表示特定主机来使用 &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, # 组名 &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;# 下载证书生成工具wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64chmod a+x * cp cfssl_linux-amd64 /usr/local/bin/cfsslcp cfssljson_linux-amd64 /usr/local/bin/cfssljsoncp cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo#创建相关证书：cd /etc/kubernetes/pki/cfssl gencert -ca=ca.crt -ca-key=ca.key -profile=kubernetes /opt/pod/rbac/zutuanxue-csr.json | cfssljson -bare zutuanxue#设置集群参数export KUBE_APISERVER=&quot;https://192.168.1.160:6443&quot;kubectl config set-cluster kubernetes \\--certificate-authority=/etc/kubernetes/pki/ca.crt \\--embed-certs=true \\--server=$&#123;KUBE_APISERVER&#125; \\--kubeconfig=zutuanxue.kubeconfig#设置客户端认证参数kubectl config set-credentials zutuanxue \\--client-certificate=/etc/kubernetes/pki/zutuanxue.pem \\--client-key=/etc/kubernetes/pki/zutuanxue-key.pem \\--embed-certs=true \\--kubeconfig=zutuanxue.kubeconfig#设置上下文参数kubectl create namespace zutuanxuekubectl config set-context kubernetes \\--cluster=kubernetes \\--user=zutuanxue \\--namespace=zutuanxue \\--kubeconfig=zutuanxue.kubeconfig#切换默认上下文kubectl create rolebinding zutuanxue-admin-binding --clusterrole=admin --user=zutuanxue --namespace=zutuanxuemkdir /home/zutuanxue/.kubecp zutuanxue.kubeconfig /home/zutuanxue/.kube/configchown -R zutuanxue.zutuanxue /home/zutuanxue/.kube/config使用 zutuanxue 用户登录系统kubectl config use-context kubernetes --kubeconfig=.kube/config 准入控制准入控制是API Server的插件集合，通过添加不同的插件，实现额外的准入控制规则。甚至于API Server的一些主要的功能都需要通过 Admission Controllers 实现，这里我们列举几个插件的功能： NamespaceLifecycle：防止在不存在的 namespace 上创建对象，防止删除系统预置 namespace，删除namespace 时，连带删除它的所有资源对象 LimitRanger：确保请求的资源不会超过资源所在 Namespace 的 LimitRange 的限制。 ResourceQuota：确保请求的资源不会超过资源的 ResourceQuota 限制。 ServiceAccount：为Pod中的进程和外部用户提供身份信息。"},{"path":"/2023/07/11/Kubernetes云计算实战/指定pod运行在固定节点/","content":"一、指定固定节点：Pod.spec.nodeNamePod.spec.nodeName 将 Pod 直接调度到指定的 Node 节点上，会跳过 Scheduler 的调度策略，该匹配规则是强制匹配: 12345678910111213141516171819202122vim node-1.yaml apiVersion: apps/v1kind: Deploymentmetadata: name: mywebspec: selector: matchLabels: app: myweb replicas: 6 template: metadata: labels: app: myweb spec: nodeName: zutuanxue-node-1 containers: - name: myweb image: docker.io/nginx ports: - containerPort: 80 130.png 正常情况下，创建 6 个副本，应该是两个节点进行平分，因为我们指定了具体的运行节点，所以全部在 node-1 上进行了创建。 二、指定固定节点标签：Pod.spec.nodeSelectorPod.spec.nodeSelector：通过 kubernetes 的 label-selector 机制选择节点，由调度器调度策略匹配 label，而后调度 Pod 到目标节点，该匹配规则属于强制约束: 1234567891011121314151617181920212223vim node-2.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: mywebspec: selector: matchLabels: app: myweb replicas: 4 template: metadata: labels: app: myweb spec: nodeSelector: cname: zutuanxue containers: - name: myweb image: docker.io/nginx ports: - containerPort: 80 这个时候我们来看一下创建的情况： 131.png 因为没有对应标签的节点，所以创建卡主了，那么我们给 node-2 创建一个 “ cname：zutuanxue ” 这样的一个标签后，看下结果： 132.png"},{"path":"/2023/07/11/Kubernetes云计算实战/什么是 Kubernetes/","content":"一、什么是Kubernetes它是一个全新的基于容器技术的分布式架构领先方案，确切地说，Kubernetes是谷歌严格保密十几年的秘密武器Borg的一个开源版本。Borg是谷歌内部使用的大规模集群管理系统，它基于容器技术，目的是实现资源管理的自动化，以及跨多个数据中心的资源利用率的最大化。 1.png 环境不一致使得应用部署出现了各种问题，从而产生了Docker容器来解决应用部署的问题。而大集群上容器的部署、伸缩和管理的各种问题，衍生出来了容器编排引擎，比较出名的有K8S(Kubernetes) 和 Docker Swarm。 Kubernetes是一个针对容器应用，进行自动部署，弹性伸缩和管理的开源系统。主要功能是生产环境的容器编排，Kubernetes名字太长了，叫起来有点麻烦，而Kubernetes首字母与结尾字母之间有8个字母，因此被称作K8S。 如果我们使用Kubernetes： 1、与业务无关的底层代码或功能模块，都可以立刻从我们的视线中消失 2、不必再费心于负载均衡器的选型和部署实施问题 3、不必再考虑引入或自己开发一个复杂的服务治理框架 4、不必再头疼于服务监控和故障处理模块的开发 二、Kubernetes发展史K8S是建立在谷歌内部有超过15年的历史，来源于谷歌内部的Borg系统，集结了Borg的精华。 2014年6月 谷歌云计算专家埃里克·布鲁尔（Eric Brewer）在旧金山的发布会为这款新的开源工具揭牌。 2015年7月22日K8S迭代到 v 1.0并正式对外公布大约每100天更新一次，如今已是 V 1.18.1版本 三、Kubernetes架构图Kubernetes最初源于谷歌内部的Borg，提供了面向应用的容器集群部署和管理系统。Borg是谷歌内部的大规模集群管理系统，负责对谷歌内部很多核心服务的调度和管理。Borg的目的是让用户不必操心资源管理的问题，让他们专注于自己的核心业务，并且做到跨多个数据中心的资源利用率最大化。 2.png Kubernetes借鉴了Borg的设计理念，整体架构跟Borg非常像，如下图所示： 3.png 四、Kubernetes特点Kubernetes是一个开放的开发平台，它不局限于任何一种语言，没有限定任何编程接口，所以不论是用Java、Go、C++还是用Python编写的服务，都可以被映射为Kubernetes的Service（服务），并通过标准的TCP通信协议进行交互。此外，Kubernetes平台对现有的编程语言、编程框架、中间件没有任何侵入性，因此现有的系统也很容易改造升级并迁移到Kubernetes平台上。 Kubernetes作用Kubernetes提供了完善的管理工具（开发、部署、测试、运维、监控）因此，Kubernetes是一个全新的基于容器技术的分布式架构解决方案，并且是一个一站式完备的分布式系统开发和支撑平台。 Kubernetes同时具有完备的集群管理能力： 1、故障自愈 2、服务发现与负载均衡 3、自动部署与回滚 4、自动伸缩（扩容与缩容）"},{"path":"/2023/07/11/Kubernetes云计算实战/StatefulSet资源控制器/","content":"一、statefulset介绍StatefulSet 是为了解决有状态服务的问题而设计的资源控制器。 匹配 Pod name ( 网络标识 ) 的模式为：(statefulset名称)-(序号)，比如上面的示例：web-0，web-1，web-2 StatefulSet 为每个 Pod 副本创建了一个 DNS 域名，这个域名的格式为： $(podname).(headless server name)，也就意味着服务间是通过Pod域名来通信而非 Pod IP，因为当Pod所在Node发生故障时， Pod 会被飘移到其它 Node 上，Pod IP 会发生变化，但是 Pod 域名不会有变化 141.png 删除 web-0 后查看： 142.png StatefulSet 使用 Headless 服务来控制 Pod 的域名，这个域名的 FQDN 为：(service name).(namespace).svc.cluster.local，其中，“cluster.local” 指的是集群的域名 143.png 根据 volumeClaimTemplates，为每个 Pod 创建一个 pvc，pvc 的命名规则匹配模式：(volumeClaimTemplates.name)-(pod_name)，比如上面的 volumeMounts.name&#x3D;www， Podname&#x3D;web-[0-2]，因此创建出来的 PVC 是 www-web-0、www-web-1、www-web-2 删除 Pod 不会删除其 pvc，手动删除 pvc 将自动释放 pv 二、Statefulset的启停顺序 有序部署：部署StatefulSet时，如果有多个Pod副本，它们会被顺序地创建（从0到N-1）并且，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态。 有序删除：当Pod被删除时，它们被终止的顺序是从N-1到0。 有序扩展：当对Pod执行扩展操作时，与部署一样，它前面的Pod必须都处于Running和Ready状态。 三、StatefulSet使用场景 稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于 PVC 来实现。 稳定的网络标识符，即 Pod 重新调度后其 PodName 和 HostName 不变。 有序部署，有序扩展，基于 init containers 来实现。 有序收缩。"},{"path":"/2023/07/11/Kubernetes云计算实战/Service 的应用/","content":"ClusterIP clusterIP 主要在每个 node 节点使用 ipvs，将发向 clusterIP 对应端口的数据，转发到 kube-proxy 中。然后 kube-proxy 自己内部实现有负载均衡的方法，并可以查询到这个 service 下对应 pod 的地址和端口，进而把数据转发给对应的 pod 的地址和端口。 74.png 为了实现图上的功能，主要需要以下几个组件的协同工作： apiserver 用户通过kubectl命令向apiserver发送创建service的命令，apiserver接收到请求后将数据存储到etcd中。 kube-proxy kubernetes的每个节点中都有一个叫做kube-porxy的进程，这个进程负责感知service，pod的变化，并将变化的信息写入本地的iptables规则中。 ipvs 使用NAT等技术将virtualIP的流量转至endpoint中 示例： 123456789101112131415161718192021222324252627282930313233343536373839vim nginx.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: my-nginxspec: selector: matchLabels: app: web-nginx replicas: 3 template: metadata: labels: app: web-nginx spec: containers: - name: web-nginx image: docker.io/nginx imagePullPolicy: IfNotPresent ports: - containerPort: 80 #-----------------------------# 分割线 #--------------------------------------# vim nginx-svc.yamlapiVersion: v1kind: Servicemetadata: name: myappspec: type: ClusterIP selector: app: web-nginx ports: - name: http port: 80 targetPort: 80 我们先运行我们的资源清单，然后查看下是否可以正常访问： 75.png 为了方便分别当前是哪个 Pod 给我们提供的服务，我们依次将三个 Pod 内 index.html 的文件内容修改为 “1”、“2”、“3”，然后从新看一下： 76.png 我们在来看一下我们的 Pod 的 IP 地址 与 ipvs 的转发关系： 77.png 78.png Headless Service 有时不需要或不想要负载均衡，以及单独的 Service IP 。遇到这种情况，可以通过指定 Cluster IP(spec.clusterIP) 的值为 “None” 来创建 Headless Service 。这类 Service 并不会分配 Cluster IP， kube-proxy 不会处理它们，而且平台也不会为它们进行负载均衡和路由 12345678910111213141516vim headless.yamlapiVersion: v1kind: Servicemetadata: name: myappspec: selector: app: web-nginx clusterIP: &quot;None&quot; ports: - name: http port: 80 targetPort: 80dig -t A myapp.default.svc.cluster.local. @10.244.0.3 79.png 通过 dig 命令，我们可以看到，即使没有 SVC 的 IP 我们也可以通过域名的方式访问到我们的 Pod 80.png NodePort nodePort 的原理在于在 node 上开了一个端口，将向该端口的流量导入到 kube-proxy，然后由 kube-proxy 进一步到给对应的 pod 12345678910111213141516vim nodeport.yamlapiVersion: v1kind: Servicemetadata: name: myappspec: type: NodePort selector: app: web-nginx ports: - name: http port: 80 targetPort: 80 nodePort: 31000 # 可以通过宿主机的的31000端口访问nginx服务 # 有效端口范围为30000-32767 我们来查看一下相关的信息： 81.png 验证一下： 82.png 83.png 84.png LoadBalancer loadBalancer 和 nodePort 其实是同一种方式。区别在于 loadBalancer 比 nodePort 多了一步，就是可以调用cloud provider 去创建 LB 来向节点导流 ExternalName 这种类型的 Service 通过返回 CNAME 和它的值，可以将服务映射到 externalName 字段的内容( 例如：www.zutuanxue.com )。ExternalName Service 是 Service 的特例，它没有 selector，也没有定义任何的端口和Endpoint。相反的，对于运行在集群外部的服务，它通过返回该外部服务的别名这种方式来提供服务。 123456789vim external.yamlkind: ServiceapiVersion: v1metadata: name: my-servicespec: type: ExternalName externalName: www.zutuanxue.com 我们来查看一下： 85.png 86.png 当查询主机 my-service.defalut.svc.cluster.local ( SVC_NAME.NAMESPACE.svc.cluster.local )时，集群的DNS 服务将返回一个值 my.database.example.com 的 CNAME 记录。访问这个服务的工作方式和其他的相同，唯一不同的是重定向发生在 DNS 层，而且不会进行代理或转发。"},{"path":"/2023/07/11/Kubernetes云计算实战/PV 与 PVC介绍/","content":"一、概念介绍PersistentVolume （PV） 是由管理员设置的存储，它是群集的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。 PV 是Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、iSCSI 或特定于云供应商的存储系统。 PersistentVolumeClaim （PVC） 是用户存储的请求。它与 Pod 相似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存）。声明可以请求特定的大小和访问模式（例如，可以以读&#x2F;写一次或 只读多次模式挂载）。 静态 pv 集群管理员创建一些 PV。它们带有可供群集用户使用的实际存储的细节。它们存在于 Kubernetes API 中，可用于消费。 动态 当管理员创建的静态 PV 都不匹配用户的 PersistentVolumeClaim 时，集群可能会尝试动态地为 PVC 创建卷。此配置基于 StorageClasses ：PVC 必须请求 [存储类]，并且管理员必须创建并配置该类才能进行动态创建。声明该类为 “” 可以有效地禁用其动态配置 要启用基于存储级别的动态存储配置，集群管理员需要启用 API server 上的 DefaultStorageClass [准入控制器]。例如，通过确保 DefaultStorageClass 位于 API server 组件的 –admission-control 标志，使用逗号分隔的有序值列表中，可以完成此操作。 绑定 master 中的控制环路监视新的 PVC，寻找匹配的 PV（如果可能），并将它们绑定在一起。如果为新的 PVC 动态调配 PV，则该环路将始终将该 PV 绑定到 PVC。否则，用户总会得到他们所请求的存储，但是容量可能超出要求的数量。一旦 PV 和 PVC 绑定后， PersistentVolumeClaim 绑定是排他性的，不管它们是如何绑定的。 PVC 跟PV 绑定是一对一的映射。 二、持久化卷持久化卷声明的保护 PVC 保护的目的是确保由 pod 正在使用的 PVC 不会从系统中移除，因为如果被移除的话可能会导致数据丢失 1# 注意 ：当 pod 状态为 “pending” 并且 Pod 已经分配给节点 或者 Pod 为 “running” 状态时，pvc 处于活动状态。 当启用PVC 保护 alpha 功能时，如果用户删除了一个 pod 正在使用的 PVC，则该 PVC 不会被立即删除。PVC 的删除将被推迟，直到 PVC 不再被任何 pod 使用。 持久化卷类型 PersistentVolume 类型以插件形式实现。Kubernetes 目前支持以下插件类型： 1GCEPersistentDisk、AWSElasticBlockStore、AzureFile、AzureDisk、FC(Fibre Channel)、FlexVolume、Flocker、NFS、iSCSI、RBD、(Ceph Block Device)、CephFS、Cinder、(OpenStack block storage)、Glusterfs、VsphereVolume、Quobyte、Volumes、HostPath等等** 持久卷演示代码： 123456789101112131415161718apiVersion: v1kind: PersistentVolumemetadata: name: pv0001spec: capacity: storage: 5Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: slow mountOptions: - hard - nfsvers=4.1 nfs: path: /tmp server: 192.168.1.169 三、访问模式PV 访问模式 PersistentVolume 可以以资源提供者支持的任何方式挂载到主机上。如下表所示，供应商具有不同的功能，每个 PV 的访问模式都将被设置为该卷支持的特定模式。例如，NFS 可以支持多个读&#x2F;写客户端，但特定的 NFS PV 可能以只读方式导出到服务器上。每个 PV 都有一套自己的用来描述特定功能的访问模式。 ReadWriteOnce——该卷可以被单个节点以读&#x2F;写模式挂载 ReadOnlyMany——该卷可以被多个节点以只读模式挂载 ReadWriteMany——该卷可以被多个节点以读&#x2F;写模式挂载 在命令行中，访问模式缩写为： RWO - ReadWriteOnce ROX - ReadOnlyMany RWX - ReadWriteMany 1# ！注意 ：一个卷一次只能使用一种访问模式进行挂载，即使它支持很多访问模式，GCEPersistentDisk 可以由单个节点做为 ReadWriteOnce 模式挂载，或者由多个节点以 ReadOnlyMany 模式挂载，但是不能同时挂载。 Volume 插件 ReadWriteOnce ReadOnlyMany ReadWriteMany AWSElasticBlockStoreAWSElasticBlockStore ✓ - - AzureFile ✓ ✓ ✓ AzureDisk ✓ - - CephFS ✓ ✓ ✓ Cinder ✓ - - FC ✓ ✓ - FlexVolume ✓ ✓ - Flocker ✓ - - GCEPersistentDisk ✓ ✓ - Glusterfs ✓ ✓ ✓ HostPath ✓ - - iSCSI ✓ ✓ - PhotonPersistentDisk ✓ - - Quobyte ✓ ✓ ✓ NFS ✓ ✓ ✓ RBD ✓ ✓ - VsphereVolume ✓ - - （当 pod 并列时有效） PortworxVolume ✓ - ✓ ScaleIO ✓ ✓ - ScaleIO ✓ - - 四、回收策略Retain（保留）——手动回收 Recycle（回收）——基本擦除（ rm -rf &#x2F;thevolume&#x2F;* ）【已被废弃】 Delete（删除）——关联的存储资产（例如 AWS EBS、GCE PD、Azure Disk 和 OpenStack Cinder 卷）将被删除 五、状态卷可以处于以下的某种状态： Available（可用）——一块空闲资源还没有被任何声明绑定 Bound（已绑定）——卷已经被声明绑定 Released（已释放）——声明被删除，但是资源还未被集群重新声明 Failed（失败）——该卷的自动回收失败 命令行会显示绑定到 PV 的 PVC 的名称"},{"path":"/2023/07/11/Kubernetes云计算实战/Pod 的资源控制器类型/","content":"一、Pod 的资源控制器类型什么是控制器呢？简单来说，控制器就好比是影视剧里面的剧本，演员会根据剧本所写的内容来针对不同的角色进行演绎，而我们的控制器就好比是剧本，Kubernetes 会根据我们所定义的规则，或者是按照我们写好的 “剧本” 来完成创建我们的 Pod 。 控制器类型 ReplicationController 与 ReplicaSet Replicationcontroller (RC) 用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的 Pod 来替代，而如果异常多出来的容器也会自动回收。 在新版本的 Kubernetes 中建议使用 Replicaset 来取代 ReplicationController . Replicaset 跟ReplicationController 没有本质的不同，只是名字不一样，并且 Replicaset 支持集合式的 selector。 Deployment Deployment 为 Pod 和 Replicaset 提供了一个声明式定义 declarative 方法，用来替代以前的ReplicationController 来方便的管理应用。 DaemonSet DoernonSet 确保全部(或者一些) Node 上运行一个 Pod 的副本，当有 Node 加入集群时，也会为他们新增一个 Pod，当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有Pod。 StateFulSet（适用于有状态服务） StatefulSet 作为 Controller 为 Pod 提供唯-的标识。 它可以保证部署和 scale 的顺序 StatefulSet 是为了解决有状态服务的问题(对应 Deployments 和 ReplicaSets 是为无状态服务而设计)。 Job 与 cronJob Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束， Cron Job 管理基于时间的 Job ，其作用与计划任务类似。 Horizontal Pod Autoscaling 应用的资源使用率通常都有高峰和低谷的时候，如何削峰填谷，提高集群的整体资源利用率，让 service 中的 Pod 个数自动调整呢？这就有赖于 Horizontal Pod Autoscaling 了，顾名思义，使 Pod 水平自动缩放"},{"path":"/2023/07/11/Kubernetes云计算实战/Pod 的存储之volume/","content":"容器磁盘上的文件的生命周期是短暂的，这就使得在容器中运行重要应用时会出现一些问题。首先，当容器崩溃时，kubelet 会重启它，但是容器中的文件将丢失——容器以干净的状态（镜像最初的状态）重新启动。其次，在Pod 中同时运行多个容器时，这些容器之间通常需要共享文件。Kubernetes 中的 Volume 抽象就很好的解决了这些问题。 背景 Kubernetes 中的卷有明确的寿命，与封装它的 Pod 相同。所以，卷的生命比 Pod 中的所有容器都长，当这个容器重启时数据仍然得以保存。当然，当 Pod 不再存在时，卷也将不复存在。也许更重要的是，Kubernetes支持多种类型的卷，Pod 可以同时使用任意数量的卷。 卷的类型 Kubernetes 支持以下类型的卷： awsElasticBlockStore、azureDisk、azureFile、cephfs、csi、downwardAPI、emptyDir、fc、flocker、gcePersistentDisk、gitRepo glusterfs、hostPath、iscsi、local、nfs、persistentVolumeClaim、projected、portworxVolume、quobyte、rbd、scaleIO、secret、storageos、vsphereVolume emptyDir 当 Pod 被分配给节点时，首先创建 emptyDir 卷，并且只要该 Pod 在该节点上运行，该卷就会存在。正如卷的名字所述，它最初是空的。Pod 中的容器可以读取和写入 emptyDir 卷中的相同文件，尽管该卷可以挂载到每个容器中的相同或不同路径上。当出于任何原因从节点中删除 Pod 时， emptyDir 中的数据将被永久删除。 emptyDir 的用法有： 1、暂存空间，例如用于基于磁盘的合并排序 2、用作长时间计算崩溃恢复时的检查点 3、Web服务器容器提供数据时，保存内容管理器容器提取的文件 123456789101112131415161718192021222324vim vomule-pod.yamlapiVersion: v1kind: Podmetadata: name: test-vomulespec: containers: - image: docker.io/nginx imagePullPolicy: IfNotPresent name: vomule-pod-1 volumeMounts: - mountPath: /test-1 name: volume - image: docker.io/busybox name: vomule-pod-2 command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;sleep 6000s&quot;] imagePullPolicy: IfNotPresent volumeMounts: - mountPath: /test-2 name: volume volumes: - name: volume emptyDir: &#123;&#125; 我们来看一下效果： 117.png hostPath hostPath 卷将主机节点的文件系统中的文件或目录挂载到集群中。 hostPath 的用途如下： 运行需要访问 Docker 内部的容器；使用 &#x2F;var&#x2F;lib&#x2F;docker 的 hostPath。 在容器中运行 cAdvisor；使用 &#x2F;dev&#x2F;cgroups 的 hostPath。 允许 pod 指定给定的 hostPath 是否应该在 pod 运行之前存在，是否应该创建，以及它应该以什么形式存在。 除了所需的 path 属性之外，用户还可以为 hostPath 卷指定 type 值 行为 空字符串（默认）用于向后兼容，这意味着在挂载 hostPath 卷之前不会执行任何检查。 DirectoryOrCreate 如果在给定的路径上没有任何东西存在，那么将根据需要在那里创建一个空目录，权限设置为 0755，与 Kubelet 具有相同的组和所有权。 Directory 给定的路径下必须存在目录 FileOrCreate 如果在给定的路径上没有任何东西存在，那么会根据需要创建一个空文件，权限设置为 0644，与 Kubelet 具有相同的组和所有权。 File 给定的路径下必须存在文件 Socket 给定的路径下必须存在 UNIX 套接字 CharDevice 给定的路径下必须存在字符设备 BlockDevice 给定的路径下必须存在块设备 使用这种卷类型是请注意，因为： 由于每个节点上的文件都不同，具有相同配置（例如从 podTemplate 创建的）的 pod 在不同节点上的行为可能会有所不同。 当 Kubernetes 按照计划添加资源感知调度时，将无法考虑 hostPath 使用的资源。 在底层主机上创建的文件或目录只能由 root 写入。您需要在特权容器中以 root 身份运行进程，或修改主机上的文件权限以便写入hostPath 卷。 12345678910111213141516171819vim vomule-pod-1.yamlapiVersion: v1kind: Podmetadata: name: test-vomule-1spec: containers: - image: docker.io/nginx imagePullPolicy: IfNotPresent name: vomule-pod-3 volumeMounts: - mountPath: /test name: test-volume volumes: - name: test-volume hostPath: path: /date type: Directory 我们来查看一下结果： 118.png"},{"path":"/2023/07/11/Kubernetes云计算实战/Pod 的存储之Secret/","content":"一、Secret 存在意义Secret 解决了密码、token、密钥等敏感数据的配置问题，而不需要把这些敏感数据暴露到镜像或者 Pod Spec中。Secret 可以以 Volume 或者环境变量的方式使用。 Secret 有三种类型： Service Account ： 用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount 目录中。 Opaque：base64 编码格式的Secret，用来存储密码、密钥等 kubernetes.io&#x2F;dockerconfigjson： 用来存储私有 docker registry 的认证信息 1.1、Service AccountService Account 用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod的&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount 目录中。 123kubectl exec kube-proxy-hz44s -n kube-system -it -- /bin/shcd /run/secrets/kubernetes.io/serviceaccount 来看一下查看到的结果： 111.png ca.crt 112.png token 113.png 1.2、Opaque Secret1.2.1、创建说明： Opaque 类型的数据是一个 map 类型，要求 value 是 base64 编码格式： 123456789101112131415161718echo -n &quot;admin&quot; | base64YWRtaW4=echo -n &quot;123456789&quot; | base64MTIzNDU2Nzg5#-----------------------------# 分割线 #--------------------------------------#vim secrets.yamlapiVersion: v1kind: Secretmetadata: name: mysecrettype: Opaquedata: password: MTIzNDU2Nzg5 username: YWRtaW4= 1.2.2、使用方式 a、将 Secret 挂载到 Volume 中： 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: seret-test labels: name: seret-testspec: volumes: - name: secrets secret: secretName: mysecret containers: - name: db image: docker.io/nginx volumeMounts: - name: secrets mountPath: &quot;/etc/secret&quot; readOnly: true 我们来看一下结果： 114.png b、将 Secret 导出到环境变量中： 1234567891011121314151617181920212223242526272829303132vim secret-pod-1.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: pod-deploymentspec: selector: matchLabels: app: pod-deployment replicas: 2 template: metadata: labels: app: pod-deployment spec: containers: - name: pod-1 image: docker.io/nginx ports: - containerPort: 80 env: - name: TEST_USER valueFrom: secretKeyRef: name: mysecret key: username - name: TEST_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password 我们来看一下结果： 115.png"},{"path":"/2023/07/11/Kubernetes云计算实战/Pod 的存储之Configmap/","content":"一、Configmap介绍ConfigMap 功能在 Kubernetes1.2 版本中引入，许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。ConfigMap API 给我们提供了向容器中注入配置信息的机制，ConfigMap 可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制大对象。 1、使用目录创建 123456789101112131415161718192021在我们的 configmap-map 文件夹下有两个文件分别为： test-1 与 test-2 里面的内容分别为：cat test-1 :enemies=alienslives=3enemies.cheat=trueenemies.cheat.level=noGoodRottensecret.code.passphrase=UUDDLRLRBABASsecret.code.allowed=truesecret.code.lives=30cat test-2 :color.good=purplecolor.bad=yellowallow.textmode=truehow.nice.to.look=fairlyNice创建：kubectl create configmap zutuanxue --from-file=configmap-test# —from-file 指定在目录下的所有文件都会被用在 ConfigMap 里面创建一个键值对，键的名字就是文件名，值就是文件的内容 创建完成后我们来看一下信息： 101.png 通过命令 kubectl get configmaps zutuanxue -o yaml 查看一下完整的信息： 102.png 2、使用文件创建 12345我们依然使用 test-1 与 test-2 这两个文件kubectl create configmap zutuanxue-1 --from-file=configmap-test/test-2# —from-file 这个参数可以使用多次，你可以使用两次分别指定上个实例中的那两个配置文件，效果就跟指定整个目录是一样的 我们来看一下效果： 103.png 3、使用字面值创建 123使用文字值创建，利用 —from-literal 参数传递配置信息，该参数可以使用多次，格式如下：kubectl create configmap zutuanxue --from-literal=test.how=hello-word --from-literal=test.type=hi-word 我们来看一下效果： 104.png 二、Pod 中使用 ConfigMap1、使用 ConfigMap 来替代环境变量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051vim test.yamlapiVersion: v1kind: ConfigMapmetadata: name: special-config namespace: defaultdata: special.how: hello-word special.type: hi-word #-----------------------------# 分割线 #--------------------------------------#vim test-env.yamlapiVersion: v1kind: ConfigMapmetadata: name: env-config namespace: defaultdata: log_level: INFO #-----------------------------# 分割线 #--------------------------------------#vim test-pod.yamlapiVersion: v1kind: Podmetadata: name: dapi-test-podspec: containers: - name: test-container image: docker.io/busybox command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot; ] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type envFrom: - configMapRef: name: env-config restartPolicy: Never 运行以后我们来看一下结果： 105.png 2、用 ConfigMap 设置命令行参数 123456789101112131415161718192021222324252627282930313233343536这里我们依然使用 test.yaml 文件内的参数：apiVersion: v1kind: ConfigMapmetadata: name: special-config namespace: defaultdata: special.how: hello-word special.type: hi-word #-----------------------------# 分割线 #--------------------------------------#vim test-pod-1.yamlapiVersion: v1kind: Podmetadata: name: dapi-test-pod-1spec: containers: - name: test-container image: docker.io/busybox command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo $(SPECIAL_LEVEL_KEY) $(SPECIAL_TYPE_KEY)&quot; ] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type restartPolicy: Never 运行以后我们来看一下结果： 106.png 3、通过数据卷插件使用ConfigMap 12345678910111213141516171819202122232425262728293031323334这里我们依然使用 test.yaml 文件内的参数：apiVersion: v1kind: ConfigMapmetadata: name: special-config namespace: defaultdata: special.how: hello-word special.type: hi-word #-----------------------------# 分割线 #--------------------------------------#在数据卷里面使用这个 ConfigMap，有不同的选项。最基本的就是将文件填入数据卷，在这个文件中，键就是文件名，键值就是文件内容。#-----------------------------# 分割线 #--------------------------------------#vim test-pod-2.yamlapiVersion: v1kind: Podmetadata: name: dapi-test-pod-2spec: containers: - name: test-container image: docker.io/busybox command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600s&quot; ] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config restartPolicy: Never 运行以后我们来看一下结果： 107.png"},{"path":"/2023/07/11/Kubernetes云计算实战/Pod 的健康检查-探针/","content":"一、Pod 的健康检查-探针1.1、探针基本概念探针是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 调用由容器实现的 Handler 有三种类型的处理程序: 1、ExecAction: 在容器内执行指定命令。如果命令退出时返回码为0则认为诊断成功。 2、TCPSocketAction: 对指定端口上的容器的IP地址进行 TCP 检查，如果端口打开则诊断被认为是成功的。 3、HTTPGetAction: 对指定的端口和路径上的容器的IP地址执行 HTTP Get 请求。如果响应的状态码大于等于 200 且小于 400，则诊断被认为是成功的。 每次探测都将获得以下三种结果之: 成功:容器通过了诊断。 失败:容器未通过诊断。 未知:诊断失败，因此不会采取任何行动。 探测方式 1、livenessProbe: 指示容器是否正在运行。如果存活探测失败，则 kubelet 会杀死容器，并且容器将受到其重启策略的影响。如果容器不提供存活探针，则默认状态为 Success 。 2、readinessProbe: 指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与 Pod 匹配的所有 Service 的端点中删除该 Pod 的 IP 地址。初始延迟之前的就绪状态默认为 Failure 如果容器不提供就绪探针，则默认状态为 Success 。 1.2、探针实现就绪检测： 1234567891011121314151617vim readinessProbe-httpget.yamlapiVersion: v1kind: Podmetadata: name: readiness-httpget-podspec: containers: - name: readiness-httpget-container image: docker.io/nginx imagePullPolicy: IfNotPresent readinessProbe: httpGet: port: 80 path: /index.html initialDelaySeconds: 1 periodSeconds: 3 我们先运行该 Pod 然后查看其状态： 33.png 已经成功开始运行，这个时候我们进入到该 Pod 然后将其 index.html 文件删除后，在看其状态： 34.png 这个时候我们可以看到，虽然容器处于 Running 状态，但是却处于 No Ready 的状态，这个时候我们通过kubectl describe pod readiness-httpget-pod 命令，查看一下具体的信息： 35.png 我们看到，显示 “Readiness probe failed: HTTP probe failed with statuscode: 404” 就绪探测失败，错误代码 404 表明页面不存在。 1.3、存活检测： EXEC 1234567891011121314151617vim livenessProbe-exec.yamlapiVersion: v1kind: Podmetadata: name: liveness-exec-podspec: containers: - name: liveness-exec-container image: docker.io/busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;touch /tmp/live ; sleep 60; rm -rf /tmp/live; sleep 3600&quot;] livenessProbe: exec: command: [&quot;test&quot;,&quot;-e&quot;,&quot;/tmp/live&quot;] initialDelaySeconds: 1 periodSeconds: 3 然后查看下我们 Pod 的实时状态： 36.png 经过一段时间等待，我们发现 liveness-exec-pod 出现了重启的现象，这是因为，在我们创建这个 Pod 的时候，我们会在 &#x2F;tmp 下创建一个 live 的文件，60 秒以后会将其删除，当进行存活检测的时候发现该文件没有了，那么 Pod 认为里面的容器死亡了，就会重启，那么就会重新执行一遍 yaml 文件内的配置，这个时候 live 文件又存在了，但是 60 秒以后，又会被删除，就会在重启一遍，以此类推。 HTTPGET 123456789101112131415161718192021vim livenessProbe-httpget.yamlapiVersion: v1kind: Podmetadata: name: liveness-httpget-podspec: containers: - name: liveness-httpget-container image: docker.io/nginx imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 livenessProbe: httpGet: port: http path: /index.html initialDelaySeconds: 1 periodSeconds: 3 timeoutSeconds: 10 然后我们查看一下 Pod 的状态： 37.png 这个时候我们通过 “kubectl exec liveness-httpget-pod -it – rm -rf &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;index.html” 命令将 index.html 文件删除掉，我们在进行查看 Pod 的状态： 38.png 经过一段时间等待，我们发现 liveness-httpget-pod 出现了重启的现象，这是因为，当我们手动删除了 index.html 文件后，当进行存活检测的时候发现该文件没有了，那么 Pod 认为里面的容器死亡了，就会重启，那么就会重新执行一遍 yaml 文件内的配置，这个时候 index.html 文件又存在了，如果我们再次删除该文件，就会在重启一遍，以此类推。 TCPSocket 123456789101112131415vim livenessProbe-tcp.yamlapiVersion: v1kind: Podmetadata: name: probe-tcpspec: containers: - name: nginx image: docker.io/nginx livenessProbe: initialDelaySeconds: 5 timeoutSeconds: 1 tcpSocket: port: 808 然后我们查看一下 Pod 的状态： 39.png 我们可以看到，开始的时候，Pod 创建成功，但是 30 秒以后，重启了第一次，在经过 30 秒以后，又重启了一次，这是因为， nginx 默认开启的端口为 80 ，而当我们开始存活检测的时候，端口为 808 ，因为没有这个端口，所以认定 Pod 死亡，所以重启，当又开始存活检测的时候，依然没有端口，所以继续重启，以此类推。"},{"path":"/2023/07/11/Kubernetes云计算实战/Pod 的 Service 介绍/","content":"一、Service 介绍Kubernetes Service 定义了这样一种抽象： 一个 Pod 的逻辑分组，一种可以访问它们的策略，通常称为微服务。 这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector 。 69.png Service能够提供负载均衡的能力，但是在使用上有以下限制： 只提供4层负载均衡能力，而没有7层功能，但有时我们可能需要更多的匹配规则来转发请求，这点上 4 层负载均衡是不支持的 Service的网络类型 ClusterIp： 默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟 IP 70.png NodePort： 在 ClusterIP 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过 : NodePort 来访问该服务 71.png LoadBalancer： 在 NodePort 的基础上，借助 cloud provider 创建一个外部负载均衡器，并将请求转发到: NodePort ExternalName： 把集群外部的服务引入到集群内部来，在集群内部直接使用。没有任何类型代理被创建，这只有 kubernetes 1.7 或更高版本的 kube-dns 才支持 二、Service 的代理模式分类VIP 和 Service 代理 在 Kubernetes 集群中，每个 Node 运行一个 kube-proxy 进程。 kube-proxy 负责为 Service 实现了一种VIP（虚拟 IP）的形式，而不是 ExternalName 的形式。 在 Kubernetes v1.0 版本，代理完全在 userspace。在Kubernetes v1.1 版本，新增了 iptables 代理，但并不是默认的运行模式。 从 Kubernetes v1.2 起，默认就是iptables 代理。 在 Kubernetes v1.8.0-beta.0 中，添加了 ipvs 代理 在 Kubernetes 1.14 版本开始默认使用 ipvs 代理 在 Kubernetes v1.0 版本， Service 是 “4层”（TCP&#x2F;UDP over IP）概念 在 Kubernetes v1.1 版本，新增了 Ingress API（beta 版），用来表示 “7层”（HTTP）服务 userspace 代理模式 72.png iptables 代理模式 73.png ipvs 代理模式 这种模式，kube-proxy 会监视 Kubernetes Service 对象和 Endpoints ，调用 netlink 接口以相应地创建ipvs 规则并定期与 Kubernetes Service 对象和 Endpoints 对象同步 ipvs 规则，以确保 ipvs 状态与期望一致。访问服务时，流量将被重定向到其中一个后端 Pod 与 iptables 类似，ipvs 于 netfilter 的 hook 功能，但使用哈希表作为底层数据结构并在内核空间中工作。这意味着 ipvs 可以更快地重定向流量，并且在同步代理规则时具有更好的性能。此外，ipvs 为负载均衡算法提供了更多选项，例如： rr ：轮询调度 lc ：最小连接数 dh ：目标哈希 sh ：源哈希 sed ：最短期望延迟 nq ： 不排队调度"},{"path":"/2023/07/11/Kubernetes云计算实战/Pod 的 NameSpace/","content":"一、Pod 的 NameSpace使用 kubectl 管理命名空间及其包含的资源相当简单。在这一节中，我们将演示一些最常见的命名空间操作，便于你开始有效地分割资源。 在我们进行创建命名空间之前，先说一下 Kubernetes 是如何自动设置它的，在默认情况下，新的集群上有三个命名空间： default： 向集群中添加对象而不提供命名空间，这样它会被放入默认的命名空间中。在创建替代的命名空间之前，该命名空间会充当用户新添加资源的主要目的地，无法删除。 kube-public： 此命名空间是自动创建的，并且所有用户（包括未经过身份验证的用户）都可以读取。此命名空间主要用于群集使用，以防某些资源在整个群集中可见且可公开读取。此命名空间的公共方面只是一个约定，而不是一个要求。 kube-system： kube-system 命名空间用于 Kubernetes 管理的 Kubernetes 组件，一般规则是，避免向该命名空间添加普通的工作负载。它一般由系统直接管理，因此具有相对宽松的策略。 要显示集群中可用的所有命名空间，使用 kubectl get namespaces 命令： 40.png 使用 kubectl get namespaces kube-system 指定namespaces 查看： 41.png 使用 kubectl describe namespaces kube-system 指定namespaces查看详情： 42.png namespaces status 有两个状态： Active ： 命名空间正在使用中 Terminating ： 正在删除命名空间，不能用于新对象 使用 kubectl create namespace test 创建 namespaces ： 43.png 使用 kubectl delete namespaces test 删除 namespaces ： 44.png 正常使用 namespaces ，只需要在我们创建的资源清单内指定即可： 12345678910111213apiVersion: v1kind: Podmetadata: name: nginx namespaces: test # 指定所属 namespaces labels: app: webspec: containers: - name: nginx image: docker.io/nginx ports: - containerPort: 80 45.png 可以看到，如果我们不指定查看具体是那个命名空间的 Pod ，那么会默认显示为 default 空间内的 Pod 信息。"},{"path":"/2023/07/11/Kubernetes云计算实战/Pod 的 init Containers/","content":"Pod 我们可以分为两类，一种属于自主式 Pod ，还有一种属于控制器管理的 Pod 。 一、Pod 的 initContainers基本概念： Pod能够具有多个容器，应用运行在容器里面，但是它也可能有一个或多个先于应用容器启动的Init容器，Init容器与普通的容器非常像，除了如下两点: Init容器总是运行到成功完成为止 每个Init容器都必须在下一个Init容器启动之前成功完成 如果Pod的Init容器失败, Kubernetes 会不断地重启该Pod,直到Init容器成功为止。然而，如果Pod对应的restartPolicy为Never，它不会重新启动。 它的优势： 因为Init容器具有与应用程序容器分离的单独镜像，所以它们的启动相关代码具有如下优势: 1、它们可以包含并运行实用工具， 但是出于安全考虑，是不建议在应用程序容器镜像中包含这些实用工具的 2、它们可以包含使用工具和定制化代码来安装，但是不能出现在应用程序镜像中。例如，创建 镜像没必要FROM另一个镜像，只需要在安装过程中使用类似sed、 awk、python或dig这样的工具。 3、应用程序镜像可 以分离出创建和部署的角色，而没有 必要联合它们构建一个单独的镜像。 4、Init容器使用Linux Namespace, 所以相对应用程序容器来说具有不同的文件系统视图。因此，它们能够具有访问Secret 的权限，而应用程序容器则不能。 5、它们必须在应用程序 容器启动之前运行完成， 而应用程序容器是并行运行的， 所以Init容器能够提供了-种简单的阻塞或延迟应用容器的启动的方法，直到满足了一组先决条件。 initContainers示例： 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: initc-demo labels: app: myappspec: containers: - name: myapp-container image: docker.io/busybox command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;] initContainers: - name: init-myservice image: docker.io/busybox command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#x27;] - name: init-mydb image: busybox command: [&#x27;sh&#x27;, &#x27;-c&#x27;, &#x27;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#x27;] 我们创建模版资源后查看结果为： 29.png 我们查看一下日志： 30.png 这个时候我们可以看到因为解析不成功，所以初始化程序卡住了，那么先创建满足第一个解析的service资源： 123456789kind: ServiceapiVersion: v1metadata: name: myservicespec: ports: - protocol: TCP port: 80 targetPort: 9376 创建完成后我们在查看一下 Pod 的状态： 31.png 第一个 init 初始化程序已经成功，这是因为，我们创建名为“myservice”的 SVC 的数据会写到我们内部的DNS（coreDNS） 上，因为可以正常的解析了，所以第一个 init 初始化程序完成，同理我们加入第二个 init 初始化程序的 SVC 后查看 Pod 状态： 123456789kind: ServiceapiVersion: v1metadata: name: mydbspec: ports: - protocol: TCP port: 80 targetPort: 9377 32.png 这个时候我们可以看到，第二个 init 初始化程序已经完成，我们的主容器 Pod 开始初始化，最后成功开始运行。 initContainers特殊说明（重要点） 1、在 Pod 启动过程中，Init 容器会按顺序在网络和数据卷初始化之后启动。每个容器必须在下一个容器启动之前成功退出。 2、如果由于运行时或失败退出，将导致容器启动失败，它会根据 Pod 的 restartPolicy 指定的策略进行重试。然而，如果 Pod 的 restartPolicy 设置为 Always , Init 容器失败时会使用 RestartPolicy 策略。 3、在所有的Init容器没有成功之前，Pod 将不会变成 Ready 状态。Init 容器的端口将不会在 Service 中进行聚集。正在初始化中的 Pod 处于 Pending 状态，但会将 Initializing 状态设置为 true。 4、如果 Pod 重启，所有 Init 容器必须重新执行。 5、对 Init 容器 spec 的修改被限制在容器 image 字段， 修改其他字段都不会生效。 更改 Init 容器的 image字段，等价于重启该 Pod。 6、Init 容器具有应用容器的所有字段。除了 readinessProbe , 因为Init容器无法定义不同于完成 (completion) 的就绪 (readiness) 之外的其他状态。这会在验证过程中强制执行。 7、在 Pod 中的每个 app 和 Init 容器的名称必须唯一，与任何其它容器共享同个名称，会在验证时抛出错误。"},{"path":"/2023/07/11/Kubernetes云计算实战/Pod 介绍/","content":"一、什么是 PodPod 是 kubernetes 集群中最小的部署和管理的基本单元，协同寻址，协同调度。 Pod 是一个或多个容器的集合，是一个或一组服务（进程）的抽象集合。 Pod 中可以共享网络和存储（可以简单理解为一个逻辑上的虚拟机，但并不是虚拟机）。 Docker 是目前 Pod 最常用的容器环境，但仍支持其他容器环境。 27.png 我们可以看到，当我们启动一个 Pod 以后，每个 Pod 内都会有一个 Pause 的容器 每个 Pod 里运行着一个特殊的被称之为 Pause 的容器，其他容器则为业务容器，这些业务容器共享 Pause 容器的网络栈和 Volume 挂载卷，因此他们之间通信和数据交换更为高效，在设计时我们可以充分利用这一特性将一组密切相关的服务进程放入同一个 Pod 中。同一个 Pod 里的容器之间仅需通过 localhost 就能互相通信。 二、Pod 的网络 每个Pod被分配了唯一的IP地址，该Pod内的所有容器共享一个网络空间，包括IP和端口。 同个Pod不同容器之间通过localhost通信，Pod内端口不能冲突。 不同Pod之间的通信则通过IP+端口的形式来访问到Pod内的具体服务（容器）。 28.png 三、Pod 的用法Pod 实际上是容器的集合，在 kubernetes 中对运行容器的要求为 “容器的主程序需要一直在前台运行，而不是后台运行“ 当多个应用之间是紧耦合的关系时，可以将多个应用一起放在一个Pod中，同个Pod中的多个容器之间互相访问可以通过localhost来通信。 相关命令： 操作 命令 创建 kubectl create -f 文件名.yaml 查询运行状态 kubectl get pods -n 空间名称，如果不指定则默认显示default空间内的 pod 查询详情 kebectl describe pod Pod名称 -n 空间名称，如果不指定则默认显示default空间内的 pod 删除 kubectl delete pod Pod名称 &#x2F; kubectl delete pod –all 更新 kubectl replace 文件名.yaml 四、Pod 定义文件在 kubernetes 中，一般使用 yaml 格式的文件来创建符合我们预期期望的 pod 基本语法为： 缩进时不允许使用Tab键，只允许使用空格 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 #标识注释，从这个字符一直到行尾，都会被解释器忽略 这样的 yaml 文件我们一般称为资源清单，如下表所示： 12345678910111213必选字段：apiVersion: v1 #必选，版本号，例如v1kind: Pod #必选，资源类别metadata: #必选，元数据 name: string #必选，Pod名称 namespace: string #创建资源所属于的命名空间，不写的话默认创建在default空间 labels: #自定义标签 - name: string #自定义标签名称spec: #必选，Pod中容器的详细定义 containers: #必选，Pod中容器列表 - name: string #必选，容器名称 image: string #必选，容器的镜像名称 示例文件： 123456789101112apiVersion: v1kind: Podmetadata: name: nginx labels: app: webspec: containers: - name: nginx image: docker.io/nginx ports: - containerPort: 80 完整资源清单详情示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576apiVersion: v1 #必选，版本号，例如v1kind: Pod #必选，Podmetadata: #必选，元数据 name: string #必选，Pod名称 namespace: string #创建资源所属于的命名空间，不写的话默认创建在default空间 labels: #自定义标签 - name: string #自定义标签名字 annotations: #自定义注释列表 - name: stringspec: #必选，Pod中容器的详细定义 containers: #必选，Pod中容器列表 - name: string #必选，容器名称 image: string #必选，容器的镜像名称 imagePullPolicy: [Always | Never | IfNotPresent] #获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像，否则下载镜像，Nerver表示仅使用本地镜像 command: [string] #容器的启动命令列表，如不指定，使用打包时使用的启动命令 args: [string] #容器的启动命令参数列表 workingDir: string #容器的工作目录 volumeMounts: #挂载到容器内部的存储卷配置 - name: string #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 mountPath: string #存储卷在容器内mount的绝对路径，应少于512字符 readOnly: boolean #是否为只读模式 ports: #需要暴露的端口库号列表 - name: string #端口号名称 containerPort: int #容器需要监听的端口号 hostPort: int #容器所在主机需要监听的端口号，默认与Container相同 protocol: string #端口协议，支持TCP和UDP，默认TCP env: #容器运行前需设置的环境变量列表 - name: string #环境变量名称 value: string #环境变量的值 resources: #资源限制和请求的设置 limits: #资源限制的设置 cpu: string #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数 memory: string #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数 requests: #资源请求的设置 cpu: string #Cpu请求，容器启动的初始可用数量 memory: string #内存清楚，容器启动的初始可用数量 livenessProbe: #对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可 exec: #对Pod容器内检查方式设置为exec方式 command: [string] #exec方式需要制定的命令或脚本 httpGet: #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port path: string port: number host: string scheme: string HttpHeaders: - name: string value: string tcpSocket: #对Pod内个容器健康检查方式设置为tcpSocket方式 port: number initialDelaySeconds: 0 #容器启动完成后首次探测的时间，单位为秒 timeoutSeconds: 0 #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 periodSeconds: 0 #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 successThreshold: 0 failureThreshold: 0 securityContext: privileged:false restartPolicy: [Always | Never | OnFailure] #Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod nodeSelector: obeject #设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定 imagePullSecrets: #Pull镜像时使用的secret名称，以key：secretkey格式指定 - name: string hostNetwork:false #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 volumes: #在该pod上定义共享存储卷列表 - name: string #共享存储卷名称 （volumes类型有很多种） emptyDir: &#123;&#125; #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 hostPath: string #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: string #Pod所在宿主机的目录，将被用于同期中mount的目录 secret: #类型为secret的存储卷，挂载集群与定义的secre对象到容器内部 scretname: string items: - key: string path: string configMap: #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: string items: - key: string path: string"},{"path":"/2023/07/11/Kubernetes云计算实战/Kubernetes集群调度介绍/","content":"一、Kubernetes调度Scheduler 是 kubernetes 的调度器，主要的任务是把定义的 pod 分配到集群的节点上。听起来非常简单，但有很多要考虑的问题： 公平：如何保证每个节点都能被分配资源 资源高效利用：集群所有资源最大化被使用 效率：调度的性能要好，能够尽快地对大批量的 pod 完成调度工作 灵活：允许用户根据自己的需求控制调度的逻辑 Sheduler 是作为单独的程序运行的，启动之后会一直监听 API Server，获取 PodSpec.NodeName 为空的 pod，对每个 pod 都会创建一个 binding，表明该 pod 应该放到哪个节点上。 1.1、调度过程调度分为几个部分： 首先是过滤掉不满足条件的节点，这个过程称为预选（predicate） ； 然后对通过的节点按照优先级排序，这个是优选（priority） ； 最后从中选择优先级最高的节点。如果中间任何一步骤有错误，就直接返回错误。 预选有一系列的算法可以使用： PodFitsResources ：节点上剩余的资源是否大于 pod 请求的资源 PodFitsHost ：如果 pod 指定了 NodeName，检查节点名称是否和 NodeName 匹配 PodFitsHostPorts ：节点上已经使用的 port 是否和 pod 申请的 port 冲突 PodSelectorMatches ：过滤掉和 pod 指定的 label 不匹配的节点 NoDiskConflict ：已经 mount 的 volume 和 pod 指定的 volume 不冲突，除非它们都是只读 如果在预选过程中没有合适的节点，pod 会一直在 pending 状态，不断重试调度，直到有节点满足条件。经过这个步骤，如果有多个节点满足条件，就继续优选过程，按照优先级大小对节点排序，优先级由一系列键值对组成，键是该优先级项的名称，值是它的权重（该项的重要性）。这些优先级选项包括： LeastRequestedPriority ：通过计算 CPU 和 Memory 的使用率来决定权重，使用率越低权重越高。换句话说，这个优先级指标倾向于资源使用比例更低的节点。 BalancedResourceAllocation ：节点上 CPU 和 Memory 使用率越接近，权重越高。这个应该和上面的一起使用，不应该单独使用。 ImageLocalityPriority ：倾向于已经有要使用镜像的节点，镜像总大小值越大，权重越高 通过算法对所有的优先级项目和权重进行计算，得出最终的结果。 1.2、自定义调度器除了 kubernetes 自带的调度器，你也可以编写自己的调度器。通过 spec:schedulername 参数指定调度器的名字，可以为 pod 选择某个调度器进行调度。比如下面的 pod 选择 my-scheduler 进行调度，而不是默认的default-scheduler ： 1234567891011apiVersion: v1kind: Podmetadata: name: annotation-second-scheduler labels: name: multischeduler-examplespec: schedulername: my-scheduler containers: - name: pod-with-second-annotation-container image: gcr.io/google_containers/pause:2.0"},{"path":"/2023/07/11/Kubernetes云计算实战/Kubernetes节点与令牌管理/","content":"一、令牌管理查看令牌 1[root@master ~]# kubeadm token list 删除令牌 1[root@master ~]# kubeadm token delete &lt;令牌值&gt; 创建令牌-临时令牌 123临时 token 生成：[root@master ~]# kubeadm token create 此 token 的有效期为 24 小时，过期后需要重新生成 token 。 创建令牌-临时令牌 12345永久 token 生成：[root@master ~]# kubeadm token create --ttl 0此 token 的有有效期为永久有效。为了安全起见，建议使用临时 token ，而不要使用永久的 token 。 二、K8S节点管理2.1、查看节点1234567查看当前的节点信息：[root@master ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster Ready master 4h40m v1.18.1node-1 Ready &lt;none&gt; 4h39m v1.18.1node-2 Ready &lt;none&gt; 3h58m v1.18.1 2.2、删除节点驱逐即将删除node节点上的pod 如果需要从集群中移除 node-2 这个 Node ，在 master上执行下面的命令，安全驱逐节点上面所有的 pod,该命令执行成功后 node节点开始释放所有 pod ，并且不接收新的 pod 进程 1234567891011121314[root@master ~]# kubectl drain node-2 --delete-local-data --force --ignore-daemonsets注：默认情况下，kubectl drain 会忽略那些不能杀死的系统类型的 pod参数说明：--force：当一些pod不是经 ReplicationController, ReplicaSet, Job, DaemonSet 或者 StatefulSet 管理的时候就需要用 --force 来强制执行 (例如:kube-proxy) --ignore-daemonsets：无视 DaemonSet 管理下的 Pod --delete-local-data：如果有 mount local volumn 的 pod，会强制杀掉该 pod 并把料清除掉，另外如果跟本身的配置信息有冲突时，drain就不会执行该命令会安全驱逐节点上面所有的 pod ，安全驱逐的方式将会允许 pod 里面的容器遵循指定的 Pod DisruptionBudgets 执行优雅的中止。 kubectl drain 返回成功表明所有的 pod （除了前面排除的那些）已经被安全驱逐（遵循期望优雅的中止期，并且没有违反任何应用程序级别的中断预算）。然后，通过对物理机断电或者在云平台上删除节点所在的虚拟机，都能安全的将节点移除。 恢复node，继续接收新pod节点上的pod被驱逐后，如果不删除node的话，进行完对应的升级或维护后可以恢复node,恢复接收新的pod进程 1[root@master ~]# kubectl uncordon node-2 删除节点 1[root@master ~]# kubectl delete node &lt;节点名称&gt; 删除后进行查看 12345[root@master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSIONmaster Ready master 4h40m v1.18.1node-1 Ready &lt;none&gt; 4h39m v1.18.1 2.3、集群节点扩展Master 节点加入集群 1234kubeadm join 192.168.2.100:6444 \\--token abcdef.0123456789abcdef \\--discovery-token-ca-cert-hash sha256:ec36d9832497453d5297e86f13928a3374e831da8861372f2086ea79c000bad7 \\--control-plane --certificate-key 80847d457d198a8ce1483817e11de8a472ff68b94410db2574e55c2f56f1b7be Node节点加入集群 123kubeadm join 192.168.2.100:6444 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:ec36d9832497453d5297e86f13928a3374e831da8861372f2086ea79c000bad7 以上信息为高可用的加入信息，这里所显示的 token 的有效期为 24 小时，在有效期内，可以直接使用命令加入我们的集群，如果超过了有效期的话，那么我们的 token 已经过期，就需要我们重新生成 token ，然后在进行加入。 2.4、token过期的解决方案token 过期后，生成新的token 2.4.1、节点加入单master集群 创建新的token 1234[root@master ~]# kubeadm token createW0410 16:22:44.706213 11426 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]oqghzy.40dftxcaeegan10t &lt; 这一条信息是我们新生成的 token &gt; 获取ca证书的hash值 token 生成完后，我们还需要获取 ca 证书 sha256 编码 hash 值，查看当前 k8s 集群的 ca 证书 sha256 编码 hash 值，我们的 ca 证书默认存放在 &#x2F;etc&#x2F;kubernetes&#x2F;pki 目录下： 123[root@master ~]# openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#x27;s/^.* //&#x27;a5a41919d1200e21bcafe066a1423ca904aaa70a9dd1582ea668993e8e831fc7 &lt; 这一条信息就是我们的 hash 值 &gt; 将新master加入单master的集群 然后我们通过新生成的 token 和 ca 证书 sha256 编码 hash 值重新组装得到有效的 work node 加入集群命令： 1234567891011[root@master ~]# kubeadm join 192.168.2.20:6443 --token oqghzy.40dftxcaeegan10t \\ --discovery-token-ca-cert-hash sha256:a5a41919d1200e21bcafe066a1423ca904aaa70a9dd1582ea668993e8e831fc7 这里需要注意一下，如果是加入单 master 集群，那么我们使用的 IP 地址为我们 master 的 IP 地址与 6443 端口。 #或者我们也可以使用命令，直接生成出包含新的token与hash值的完整加入命令，这样更加轻松有效。[root@master ~]# kubeadm token create --print-join-commandkubeadm join 192.168.2.100:6444 --token 1kuag1.elna9kktnznxr50m --discovery-token-ca-cert-hash sha256:a5a41919d1200e21bcafe066a1423ca904aaa70a9dd1582ea668993e8e831fc7 2.4.2、节点加入高可用集群 高可用集群与单master集群不同的地方在于还要生成用于新master加入的证书 首先生成新的 token 1[root@master ~]# kubeadm token create --print-join-command 生成新的用于 master 加入的证书 123456[root@master ~]# kubeadm init phase upload-certs --upload-certsW0410 16:49:45.773081 21497 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io][upload-certs] Storing the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace[upload-certs] Using certificate key:1d57c7bbf579b9bdcf3441cd45dd01a2a066e75b45fe672a0f5295e07a337d0d &lt; 这一条信息是用于 master 加入的证书信息 &gt; 然后我们通过新生成的 token 和 ca 证书 sha256 编码 hash 值还有新生成的 master 证书的值，重新组装得到有效的 master 加入集群命令： 1234kubeadm join 192.168.2.100:6444 \\ --token 1kuag1.elna9kktnznxr50m \\ --discovery-token-ca-cert-hash sha256:a5a41919d1200e21bcafe066a1423ca904aaa70a9dd1582ea668993e8e831fc7 \\ --control-plane --certificate-key 1d57c7bbf579b9bdcf3441cd45dd01a2a066e75b45fe672a0f5295e07a337d0d"},{"path":"/2023/07/11/Kubernetes云计算实战/Kubernetes节点与 Pod 亲和性/","content":"一、节点亲和性策略介绍pod.spec.nodeAffinity preferredDuringSchedulingIgnoredDuringExecution：软策略 requiredDuringSchedulingIgnoredDuringExecution：硬策略 12preferred：首选，较喜欢required：需要，必修 键值运算关系： In：label 的值在某个列表中 NotIn：label 的值不在某个列表中 Gt：label 的值大于某个值 Lt：label 的值小于某个值 Exists：某个 label 存在 DoesNotExist：某个 label 不存在 二、节点与Pod硬亲和性requiredDuringSchedulingIgnoredDuringExecution 12345678910111213141516171819202122#创建pod的模板yaml文件vim affinity.yamlapiVersion: v1kind: Podmetadata: name: affinity labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: docker.io/nginx affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: NotIn values: - node-1 通过修改 Pod 名称的方式多创建几个 Pod 查看结果： 119.png 这个时候，我们将 operator 修改为 “In” ，node-1 修改为 node-3， 123456789101112131415161718192021vim affinity.yamlapiVersion: v1kind: Podmetadata: name: affinity-3 labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: docker.io/nginx affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - node-3 查看下结果： 120.png 这个时候可以看到，我们新创建的 Pod 一直处于 Pending 的状态，这是因为我们没有Node-3这个节点，且采用的是硬亲和性策略的原因所导致的。 三、节点与Pod软亲和性preferredDuringSchedulingIgnoredDuringExecution为了解决上述因为硬亲和性创建Pod不成功的问题，我们通过设置软亲和性策略后再次创建一个pod affinity-pod-a测试。 12345678910111213141516171819202122vim affinity-1.yamlapiVersion: v1kind: Podmetadata: name: affinity-a labels: app: node-affinity-pod-aspec: containers: - name: with-node-affinity-a image: docker.io/nginx affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: kubernetes.io/hostname operator: In values: - node-3 我们没有 node-3 节点，这个时候我们创建看一下： 121.png 我们再将 node-3 修改为 node-1 看一下： 122.png 通过实验我们得出关于节点与pod亲和力策略 硬限制是：我必须在某个节点或我必须不在某个节点。 软限制是：我想在某个节点或我不想在某个节点，实在不行，我也可以将就。 软硬限制结合策略策略优先级：先满足硬限制，然后满足软限制 1234567891011121314151617181920212223242526272829软硬限制可以结合使用，先满足硬限制，然后满足软限制=apiVersion: v1kind: Podmetadata: name: affinity labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: docker.io/nginx affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: NotIn values: - node-2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: source operator: In values: - zutuanxue_com 四、Pod 亲和性pod.spec.affinity.podAffinity&#x2F;podAntiAffinity preferredDuringSchedulingIgnoredDuringExecution：软策略 requiredDuringSchedulingIgnoredDuringExecution：硬策略 12podAffinity: pod之间亲和，pod在同一网段podAntiAffinity：pod之间反亲和，pod在不同网段 4.1、pod亲和性1234567891011121314151617181920212223242526272829303132333435363738vim test-pod.yamlapiVersion: v1kind: Podmetadata: name: pod-1 labels: app: pod-1spec: containers: - name: pod-1 image: docker.io/busybox command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600s&quot; ] #-----------------------------# 分割线 #--------------------------------------#vim affinity-pod.yamlapiVersion: v1kind: Podmetadata: name: pod-3 labels: app: pod-3spec: containers: - name: pod-3 image: docker.io/nginx affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - pod-1 topologyKey: kubernetes.io/hostname 我们来看一下结果： 123.png 五、关于亲和性总结 调度策略 匹配标签 操作符 拓扑域支持 调度目标 nodeAffinity 主机 In, NotIn, Exists,DoesNotExist, Gt, Lt 否 指定主机 podAffinity POD In, NotIn, Exists,DoesNotExist 是 POD与指定POD同一拓扑域 podAnitAffinity POD In, NotIn, Exists,DoesNotExist 是 POD与指定POD不在同一拓扑域"},{"path":"/2023/07/11/Kubernetes云计算实战/Kubernetes污点和容忍/","content":"一、Taint 和 Toleration介绍节点亲和性，是 pod 的一种属性（偏好或硬性要求），它使 pod 被吸引到一类特定的节点。Taint 则相反，它使节点能够排斥一类特定的pod，Taint 和 toleration 相互配合，可以用来避免 pod 被分配到不合适的节点上。每个节点上都可以应用一个或多个taint ，这表示对于那些不能容忍这些 taint 的 pod，是不会被该节点接受的。如果将 toleration 应用于 pod上，则表示这些 pod 可以（但不要求）被调度到具有匹配 taint 的节点上。 二、污点(Taint)2.1、 污点 ( Taint ) 的组成使用 kubectl taint 命令可以给某个Node节点设置污点，Node 被设置上污点之后就和 Pod 之间存在了一种相斥的关系，可以让 Node 拒绝 Pod 的调度执行，甚至将 Node 已经存在的 Pod 驱逐出去。 1污点的对象是: 节点 每个污点的组成： key&#x3D;value:effect 每个污点有一个 key 和 value 作为污点的标签，其中 value 可以为空，effect 描述污点的作用。当前 taint effect 支持如下三个选项： NoSchedule ：表示 k8s 将不会将 Pod 调度到具有该污点的 Node 上。 PreferNoSchedule ：表示 k8s 将尽量避免将 Pod 调度到具有该污点的 Node 上。 NoExecute ：表示 k8s 将不会将 Pod 调度到具有该污点的 Node 上，同时会将 Node 上已经存在的 Pod 驱逐出去。 124.png 我们的 Master 节点上本来就已经有了污点，所以我们在创建 Pod 的时候，才不会将 Pod 创建在 Master 节点上。 2.2、污点的设置、查看和去除设置污点kubectl taint nodes node1 key1&#x3D;value1:NoSchedule 125.png 这里我们打了一个 NoExecute 的标签，这个时候我们可以看到，之前在 node-1 上的 Pod 已经被驱离，因为这是自助式的 Pod ，没有我们的资源管理器进行管理的 Pod ，所以被驱离以后没有在被创建出来。 节点说明中，查找 Taints 字段kubectl describe pod pod-name 126.png 去除污点kubectl taint nodes node1 key1:NoSchedule- 127.png 三、容忍(Tolerations)设置了污点的 Node 将根据 taint 的 effect：NoSchedule、PreferNoSchedule、NoExecute 和 Pod 之间产生互斥的关系，Pod 将在一定程度上不会被调度到 Node 上。 但我们可以在 Pod 上设置容忍 ( Toleration ) ，意思是设置了容忍的 Pod 将可以容忍污点的存在，可以被调度到存在污点的 Node 上。 1容忍的对象是: pod 比如，我们现在将 node-1 与 node-2 都标记上污点，这个时候我们来创建一个 Pod 看一下： 128.png pod.spec.tolerations 1234567891011121314151617181920212223tolerations:- key: &quot;key1&quot; operator: &quot;Equal&quot; value: &quot;value1&quot; effect: &quot;NoSchedule&quot; tolerationSeconds: 3600# 其中 key, vaule, effect 要与 Node 上设置的 taint 保持一致# operator 的值为 Exists 将会忽略 value 值# tolerationSeconds 用于描述当 Pod 需要被驱逐时可以在 node 上继续保留运行的时间# 1、当不指定 key 值时，表示容忍所有的污点 key：tolerations:- operator: &quot;Exists&quot;# 2、当不指定 effect 值时，表示容忍所有的污点作用tolerations:- key: &quot;key&quot;operator: &quot;Exists&quot;# 3、有多个 Master 存在时，防止资源浪费，可以如下设置kubectl taint nodes Node-Name node-role.kubernetes.io/master=:PreferNoSchedule 这个时候我们来设置一下，看下效果： 12345678910111213141516171819vim tole-pod.yamlapiVersion: v1kind: Podmetadata: name: pod-1 labels: app: pod-1spec: containers: - name: pod-1 image: docker.io/busybox command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600s&quot; ] tolerations: - key: &quot;node&quot; operator: &quot;Equal&quot; value: &quot;zutuaxue&quot; effect: &quot;NoExecute&quot; tolerationSeconds: 30 # 容忍时间，超过该时间后将其驱离 129.png"},{"path":"/2023/07/11/Kubernetes云计算实战/Kubernetes 证书介绍/","content":"一、证书机制说明Kubernetes 作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。API Server 是集群内部各个组件通信的中介，也是外部控制的入口。所以 Kubernetes 的安全机制基本就是围绕保护 API Server 来设计的，Kubernetes 使用了认证（Authentication）、鉴权（Authorization）、准入控制（AdmissionControl）三步来保证API Server的安全 。 二、证书认证（Authentication）HTTP Token 认证： 通过一个 Token 来识别合法用户，HTTP Token 的认证是用一个很长的特殊编码方式的并且难以被模仿的字符串 - Token 来表达客户的一种方式。Token 是一个很长的很复杂的字符串，每一个 Token 对应一个用户名存储在 API Server 能访问的文件中，当客户端发起 API 调用请求时，需要在 HTTP Header 里放入 Token。 HTTP Base 认证： 通过用户名+密码的方式进行认证，用户名+密码用 BASE64 算法进行编码后的字符串放在 HTTP Request 中的 Heather Authorization 域里发送给服务端，服务端收到后进行编码，获取用户名及密码。 HTTPS 证书认证： HTTPS 证书认证是最严格的认证，基于 CA 根证书签名的客户端身份认证方式。 三、证书授权与鉴权（Authorization）AlwaysDeny：表示拒绝所有的请求，一般用于测试 AlwaysAllow：允许接收所有请求，如果集群不需要授权流程，则可以采用该策略 Webbook：**通过调用外部 REST 服务对用户进行授权 RBAC（Role-Based Access Control）：基于角色的访问控制，现行默认规则 ABAC（Attribute-Based Access Control）： 基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制 四、证书准入控制准入控制是API Server的插件集合，通过添加不同的插件，实现额外的准入控制规则。甚至于API Server的一些主要的功能都需要通过 Admission Controllers 实现，这里我们列举几个插件的功能： NamespaceLifecycle：防止在不存在的 namespace 上创建对象，防止删除系统预置 namespace，删除namespace 时，连带删除它的所有资源对象 LimitRanger：确保请求的资源不会超过资源所在 Namespace 的 LimitRange 的限制。 ResourceQuota：确保请求的资源不会超过资源的 ResourceQuota 限制。 ServiceAccount：为Pod中的进程和外部用户提供身份信息。"},{"path":"/2023/07/11/Kubernetes云计算实战/Kubernetes 网络介绍/","content":"Service是Kubernetes的核心概念，通过创建Service，可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发到后端的各个容器应用上。 Kubernetes 的网络模型假定了所有 Pod 都在一个可以直接连通的扁平的网络空间中，这在GCE （ Google Compute Engine ）里面是现成的网络模型， Kubernetes 假定这个网络已经存在。而在私有云里搭建Kubernetes 集群，就不能假定这个网络已经存在了。我们需要自己实现这个网络假设，将不同节点上的 Docker 容器之间的互相访问先打通，然后运行 Kubernetes。 一、Flannel 网络Flannel 是 CoreOS 团队针对 Kubernetes 设计的一个网络规划服务，简单来说，它的功能是让集群中的不同节点主机创建的 Docker 容器都具有全集群唯一的虚拟 IP 地址。而且它还能在这些 IP 地址之间建立一个覆盖网络（ Overlay Network ），通过这个覆盖网络，将数据包原封不动地传递到目标容器内。 ETCD 与 Flannel 之间的关系： 存储管理 Flannel 可分配的 IP 地址段资源 监控 ETCD 中每个 Pod 的实际地址，并在内存中建立维护 Pod 1.1、Flannel 网络流程图：4.png 1.2、 Service 不同情况下网络通信方式同Pod内部通讯：同一个 Pod 共享同一个网络命名空间，共享同一个 Linux 协议栈。 不同pod通讯： 不在同一台主机：docker0 网段与宿主机网卡是两个完全不同的 IP 网段，不同 Node 之间的通信只能通过宿主机的物理网卡进行 同一台机器：由 Docker0 网桥直接转发请求 Pod与Service： 目前基于性能考虑，全部为 iptables 维护和转发 Pod与外网：Pod 向外网发送请求，查找路由表 , 转发数据包到宿主机的网卡，宿主网卡完成路由选择后，iptables行Masquerade ，把源 IP 更改为宿主网卡的 IP ，然后向外网服务器发送请求。"},{"path":"/2023/07/11/Kubernetes云计算实战/Kubernetes 概念介绍/","content":"一、Master Master指的是集群控制节点，在每个Kubernetes集群里都需要有一个Master来负责整个集群的管理和控制，基本上Kubernetes的所有控制命令都发给它，它负责具体的执行过程，我们后面执行的所有命令基本都是在Master上运行的 Master上运行的核心组件： Kubernetes API Server（kube-apiserver）： 提供了HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口，也是集群控制的入口进程。 Kubernetes Controller Manager（kube-controller-manager）： Kubernetes里所有资源对象的自动化控制中心，可以将其理解为资源对象的“大总管”。 Kubernetes Scheduler（kube-scheduler）： 负责资源调度（Pod调度）的进程，相当于公交公司的“调度室”。 二、Node Node是Kubernetes集群中的工作负载节点，每个Node都会被Master分配一些工作负载（Docker容器），当某个Node宕机时，其上的工作负载会被Master自动转移到其他节点上。 Node上运行的核心组件： kubelet： 负责Pod对应的容器的创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能。 kube-proxy： 实现Kubernetes Service的通信与负载均衡机制的重要组件。 三、Etcdetcd 的官方将它定位成一个可信赖的分布式键值存储服务，保存了整个集群的状态，它能够为整个分布式集群存储一些关键数据，协助分布式集群的正常运转。 四、PodPod是Kubernetes最重要的基本概念，我们看到每个Pod都有一个特殊的被称为“根容器”的Pause容器。Pause容器对应的镜像属于Kubernetes平台的一部分，除了Pause容器，每个Pod还包含一个或多个紧密相关的用户业务容器。 五、Label Label（标签）是Kubernetes系统中另外一个核心概念。一个Label是一个key&#x3D;value的键值对，其中key与value由用户自己指定。Label可以被附加到各种资源对象上，例如Node、Pod、Service、RC等，一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上。Label通常在资源对象定义时确定，也可以在对象创建后动态添加或者删除。 6、ReplicationController（RC）用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的 Pod 来替代；而如果异常多出来的容器也会自动回收。在新版本的 Kubernetes 中建议使用 ReplicaSet 来取代 ReplicationControlle。 七、ReplicaSet（RS）ReplicaSet 跟 ReplicationController 没有本质的不同，只是名字不一样，并且ReplicaSet 支持集合式的 selector虽然 ReplicaSet 可以独立使用，但一般还是建议使用 Deployment 来自动管理ReplicaSet ，这样就无需担心跟其他机制的不兼容问题（比如 ReplicaSet 不支持rolling-update 但 Deployment 支持）。 八、DeploymentDeployment 为 Pod 和 ReplicaSet 提供了一个 声明式定义 (declarative) 方法，用来替代以前的 ReplicationController 来方便的管理应用。典型的应用场景包括： 1、定义 Deployment 来创建 Pod 和 ReplicaSet 2、滚动升级和回滚应用 3、扩容和缩容 4、暂停和继续 Deployment 九、DaemonSetDaemonSet 确保全部（或者一些） Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod，使用 DaemonSet 的一些典型用法： 1、运行集群存储 daemon ，例如在每个 Node 上运行 glusterd 、 ceph 。 2、在每个 Node 上运行日志收集 daemon ，例如 fluentd 、 logstash 。 3、在每个 Node 上运行监控 daemon ，例如 Prometheus Node Exporter 十、Horizontal Pod AutoscalingHorizontal Pod Autoscaling 仅适用于 Deployment 和 ReplicaSet ，在 V1 版本中仅支持根据 Pod的 CPU 利用率扩所容，在 v1alpha 版本中，支持根据内存和用户自定义的 metric 扩缩容。 十一、StatefulSetStatefulSet 是为了解决有状态服务的问题（对应 Deployments 和 ReplicaSets 是为无状态服务而设计），其应用场景包括： 1、稳定的持久化存储，即 Pod 重新调度后还是能访问到相同的持久化数据，基于 PVC 来实现 2、稳定的网络标志，即 Pod 重新调度后其 PodName 和 HostName 不变，基于 Headless Service（即没有 Cluster IP 的 Service ）来实现 3、有序部署，有序扩展，即 Pod 是有顺序的，在部署或者扩展的时候要依据定义的顺序依次依次进行（即从 0 到 N-1 ，在下一个 Pod 运行之前所有之前的 Pod 必须都是 Running 和 Ready 状态），基于 init containers 来实现 4、有序收缩，有序删除（即从 N-1 到 0 0 ） 十二、JobJob 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 。 十三、Cron JobCron Job 管理基于时间的 Job ，即： 1、在给定时间点只运行一次2、周期性地在给定时间点运行 十四、ConfigMapConfigMap 功能在 Kubernetes1.2 版本中引入，许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。ConfigMap API 给我们提供了向容器中注入配置信息的机制，ConfigMap 可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制大对象。 十五、SecretSecret 解决了密码、token、密钥等敏感数据的配置问题，而不需要把这些敏感数据暴露到镜像或者 Pod Spec中。Secret 可以以 Volume 或者环境变量的方式使用。 十六、Volume容器磁盘上的文件的生命周期是短暂的，这就使得在容器中运行重要应用时会出现一些问题。首先，当容器崩溃时，kubelet 会重启它，但是容器中的文件将丢失——容器以干净的状态（镜像最初的状态）重新启动。其次，在Pod 中同时运行多个容器时，这些容器之间通常需要共享文件。Kubernetes 中的 Volume 就很好的解决了这些问题 十七、PersistentVolume （PV）PersistentVolume是由管理员设置的存储，它是群集的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。 PV 是Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、iSCSI 或特定于云供应商的存储系统。 十八、PersistentVolumeClaim （PVC）PersistentVolumeClaim是用户存储的请求。它与 Pod 相似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存）。声明可以请求特定的大小和访问模式（例如，可以以读&#x2F;写一次或 只读多次模式挂载）。 十九、ServiceService是Kubernetes的核心概念，通过创建Service，可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发到后端的各个容器应用上。 二十、NameSpaceNamespace（命名空间）是Kubernetes系统中的另一个非常重要的概念，Namespace在很多情况下用于实现多租户的资源隔离。"},{"path":"/2023/07/11/Kubernetes云计算实战/Kubernetes NameSpace 介绍/","content":"Kubernetes使用命名空间的概念帮助解决集群中在管理对象时的复杂性问题。命名空间允许将对象分组到一起，便于将它们作为一个单元进行筛选和控制。无论是应用自定义的访问控制策略，还是为了测试环境而分离所有组件，命名空间都是一个按照组来处理对象、强大且灵活的概念。 一、什么是命名空间，为什么它很重要命名空间（namespace）是Kubernetes提供的组织机制，用于给集群中的任何对象组进行分类、筛选和管理，每一个添加到Kubernetes集群的工作负载必须放在一个命名空间中。 命名空间为集群中的对象名称赋予作用域虽然在命名空间中名称必须是唯一的，但是相同的名称可以在不同的命名空间中使用。这对于某些场景来说可能帮助很大。例如，如果使用命名空间来划分应用程序生命周期环境（如开发、staging、生产），则可以在每个环境中维护利用同样的名称维护相同对象的副本。 命名空间还可以让用户轻松地将策略应用到集群的具体部分你可以通过定义ResourceQuota对象来控制资源的使用，该对象在每个命名空间的基础上设置了使用资源的限制。类似地，当在集群上使用支持网络策略的CNI（容器网络接口）时，比如Calico或Canal（calico用于策略，flannel用于网络）。你可以将NetworkPolicy应用到命名空间，其中的规则定义了pod之间如何彼此通信。不同的命名空间可以有不同的策略。 使用命名空间最大的好处之一是能够利用Kubernetes RBAC（基于角色的访问控制） RBAC允许您在单个名称下开发角色，这样将权限或功能列表分组。ClusterRole对象用于定义集群规模的使用模式，而角色对象类型（Role object type）应用于具体的命名空间，从而提供更好的控制和粒度。在角色创建后，RoleBinding可以将定义的功能授予单个命名空间上下文中的具体具体用户或用户组。通过这种方式，命名空间可以使得集群操作者能够将相同的策略映射到组织好的资源集合。 二、常见的命名空间使用模式将命名空间映射到团队或项目上：在设置命名空间时有一个惯例是，为每个单独的项目或者团队创建一个命名空间，通过给团队提供专门的命名空间，你可以用RBAC策略委托某些功能来实现自我管理和自动化。 使用命名空间对生命周期环境进行分区：命名空间非常适合在集群中划分开发、staging以及生产环境。通常情况下我们会被建议将生产工作负载部署到一个完全独立的集群中，来确保最大程度的隔离。不过对于较小的团队和项目来说，命名空间会是一个可行的解决方案。 使用命名空间隔离不同的使用者：根据使用者对工作负载进行分段。比如，如果你的集群为多个客户提供基础设施，那么按命名空间进行分段就能够实现管理每个客户，同时跟踪账单的去向。"},{"path":"/2023/07/11/Kubernetes云计算实战/Kebetnetes命令行工具kubectl/","content":"为了方便在命令行下对集群、节点、pod进行管理，kubernetes官方提供了一个管理命令:kubectl kubectl作为客户端CLI工具，可以让用户通过命令行对Kubernetes集群进行操作。 一、kubectl介绍kubectl命令行的语法：12345678910111213141516kubectl [command] [TYPE] [NAME] [flags]command：子命令，用于操作Kubernetes集群资源对象的命令，例如create、delete、describe、get、apply等TYPE：资源对象的类型，区分大小写，能以单数、复数或简写形式表示。例如以下3种TYPE是等价的\t- kubectl get pod pod-name\t- kubectl get pods pod-name\t- kubectl get po pod-nameNAME：资源对象的名称，区分大小写，如果不指定名称，系统将返回所有Pod的列表flags：kubectl子命令的可选参数，比如可以使用 “-o wide“ 来显示更多的信息 二、kubectl常用命令 新建资源：kubectl create -f pod.yaml 19.png 删除资源-根据YAML文件: kubectl delete -f pod.yaml 20.png 删除资源-根据pod名字: kubectl delete pod nginx 21.png 删除资源-删除所有pod: kubectl delete pod –all 22.png 查看node信息：kubectl get nodes 23.png 查看pod信息：kubectl get pod -o wide&#x2F;yaml 24.png 查看所有信息：kubectl get all 25.png 查看pod详细信息：kubectl describe pod nginx 26.png 查看kube-system空间内的pod：kubectl get pod -n kube-system 9.png 三、帮助如果在使用命令过程中出现问题，那么我们也可以通过使用 –help来获取 kubectl 命令的使用说明： 获取 kubectl 的使用说明： kubectl –help 获取 kubectl 子命令的使用说明：kubectl get –help &#x2F; kubectl delete –help 获取资源控制器说明： kubectl explain pod &#x2F; rs &#x2F; deployment &#x2F; ·····"},{"path":"/2023/07/11/Kubernetes云计算实战/Job 与 Cronjob/","content":"一、JobJob 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束。 特殊说明： 1、spec.template 格式同 Pod 2、RestartPolicy 仅支持 Never 或 OnFailure 3、单个 Pod 时，默认 Pod 成功运行后 Job 即结束 4、spec.completions 标志 Job 结束需要成功运行的 Pod 个数，默认为 1 5、spec.parallelism 标志并行运行的 Pod 的个数，默认为 1 6、spec.activeDeadlineSeconds 标志失败 Pod 的重试最大时间，超过这个时间不会继续重试 Job 应用示例： 12345678910111213141516vim job.yamlapiVersion: batch/v1kind: Jobmetadata: name: jobspec: template: metadata: name: job spec: containers: - name: job image: docker.io/perl command: [&quot;perl&quot;, &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;] restartPolicy: Never 然后我们来看一下 Pod 的信息： 63.png 我们在来看下日志信息： 64.png 任务完成， π 的2000位信息。 二、CronjobCron Job 管理基于时间的 Job，即： 在给定时间点只运行一次 周期性地在给定时间点运行 使用条件： 当前使用的 Kubernetes 集群，版本 &gt;&#x3D; 1.8 典型的用法： 在给定的时间点调度 Job 运行 创建周期性运行的 Job，例如：数据库备份、发送邮件 CronJob Spec： spec.template 格式同 Pod RestartPolicy 仅支持 Never 或 OnFailure 单个 Pod 时，默认 Pod 成功运行后 Job 即结束 spec.schedule： 调度，必需字段，指定任务运行周期，格式同 Cron spec.jobTemplate： Job 模板，必需字段，指定需要运行的任务，格式同 Job spec.startingDeadlineSeconds： 启动 Job 的期限（秒级别），该字段是可选的。如果因为任何原因而错过了被调度的时间，那么错过执行时间的 Job 将被认为是失败的。如果没有指定，则没有期限 spec.concurrencyPolicy： 并发策略，该字段也是可选的。它指定了如何处理被 Cron Job 创建的 Job 的并发执行。只允许指定下面策略中的一种： Allow （默认）： 允许并发运行 Job Forbid ： 禁止并发运行，如果前一个还没有完成，则直接跳过下一个 Replace ： 取消当前正在运行的 Job，用一个新的来替换 注意，当前策略只能应用于同一个 Cron Job 创建的 Job。如果存在多个 Cron Job，它们创建的 Job 之间总是允许并发运行。 spec.suspend ： 挂起，该字段也是可选的。如果设置为 true ，后续所有执行都会被挂起。它对已经开始执行的 Job 不起作用，默认值为 false spec.successfulJobsHistoryLimit 和 spec.failedJobsHistoryLimit ： 历史限制，是可选的字段。它们指定了可以保留多少完成和失败的 Job 。默认情况下，它们分别设置为 3 和 1 。设置限制的值为 0 ，相关类型的 Job 完成后将不会被保留。 Cronjob 应用示例： 1234567891011121314151617181920vim cronjob.yamlapiVersion: batch/v1beta1kind: CronJobmetadata: name: hellospec: schedule: &quot;*/1 * * * *&quot; jobTemplate: spec: template: spec: containers: - name: hello image: docker.io/busybox args: - /bin/sh - -c - date; echo Hello from the Kubernetes cluster restartPolicy: OnFailure 然后我们来运行我们的 Cronjob： 65.png 我们来查看一下我们的 Pod ： 66.png 我们来查看一下我们的 Job ： 67.png 我们来查看一下我们的日志信息： 68.png"},{"path":"/2023/07/11/Kubernetes云计算实战/istio集群服务治理/","content":"一、Service Mesh 服务网格是什么随着服务网络的规模和复杂性不断的增长，它将会变得越来越难以理解和管理。它的需求包括服务发现、负载均衡、故障恢复、度量和监控等。服务网络通常还有更复杂的运维需求，比如 A&#x2F;B 测试、灰度发布、速率限制、访问控制和端到端认证。 服务网格用来描述组成这些应用程序的微服务网络以及它们之间的交互。简单来说，Service Mesh 可以看做是传统代理的升级版，用来解决现在微服务框架中出现的问题，可以把 Service Mesh 看做是分布式的微服务代理，在传统模式下，代理一般是集中式的单独的服务器，所有的请求都要先通过代理，然后再流入转发到实际的后端，而在 Service Mesh 中，代理变成了分布式的，它常驻在了应用的身边，这样的话，应用所有的流量都被代理接管，那么这个代理就能为整个通信带来更多的功能，比如： 拦截：代理可以选择性拦截传输的网络流量，比如一些公司限制员工在上班的时候不能访问某些游戏或者电商网站； 统计：既然所有的流量都经过代理，那么代理也可以用来统计网络中的数据信息，比如了解哪些人在访问哪些网站，通信的应答延迟等； 缓存：如果通信双方比较”远“，访问比较慢，那么代理可以把最近访问的数据缓存在本地，后面的访问不用访问后端来做到加速，CDN 就是这个功能的典型场景； 分发：如果某个通信方有多个服务器后端，代理可以根据某些规则来选择如何把流量发送给多个服务器，也就是我们常说的负载均衡功能，比如 Nginx 软件； 跳板：如果 A、B 双方因为某些原因不能直接访问，而代理可以和双方通信，那么通过代理，双方可以绕过原来的限制进行通信。 2.png 二、istio 是什么Istio 提供一种简单的方式来为已部署的服务建立网络，该网络具有负载均衡、服务间认证、监控等功能，而不需要对服务的代码做任何改动，官网给的介绍如下（官网地址：https://istio.io）： 1.png 连接：智能控制服务之间的流量和API调用，进行一系列测试，并通过红&#x2F;黑部署逐步升级 保护：通过托管身份验证、授权和服务之间通信加密自动保护您的服务 控制：应用策略并确保其执行，使得资源在消费者之间公平分配 观测：对您的服务进行多样化、自动化的追踪、监控以及记录日志，以便实时了解正在发生的事情 三、istio 架构Istio 服务网格从逻辑上分为数据平面和控制平面。 数据平面：由一组智能代理（Envoy）组成，被部署为 sidecar。这些代理负责协调和控制微服务之间的所有 网络通信。他们还收集和报告所有网格流量的遥测数据。 控制平面：管理并配置代理来进行流量路由。 下面是官方给的架构图，核心组件有：Proxy代理、Mixer混合器、Pilot引导、Citadel堡垒，以及Galley 3.png 可以看到，Istio 就是我们上面提到的 Service Mesh 架构的一种实现，服务之间的通信（比如这里的 Service A 访问 Service B）会通过代理（默认是 Envoy）来进行，而且中间的网络协议支持 HTTP&#x2F;1.1，HTTP&#x2F;2，gRPC 或者 TCP，可以说覆盖了主流的通信协议。 控制中心做了进一步的细分，分成了 Pilot、Mixer、Citadel 以及Galley。 四、istio 核心组件介绍Mixer混合器： 顾名思义，Mixer混合了各种策略以及后端数据采集或遥测系统的适配器，从而实现了前端Proxy与后端系统的隔离与汇合。Mixer是一个灵活的插件模型，它一端连着Envoy，同时我们可以将日志、监控、遥测等各种系统“插入”到Mixer的另一端中，从而得到我们想要的数据或结果。 Pilot引导： 简单来说，Pilot是为我们提供配置智能路由（如A&#x2F;B测试、灰度发布等）、弹性（超时、重发、熔断等）等功能的管理系统，它提供了一系列rules api，允许运维人员指定一系列高级的流量管理规则。Pilot负责将我们的配置转换并写入到每个sidecar（Enovy）。 Citadel堡垒： 它管理着集群的密钥和证书，是集群的安全部门。典型的如果我们的服务是跨网络通讯（Istio允许我们建立一个安全的集群的集群网络），开发人员想省事懒得对通讯数据进行加解密和身份认证，这事就可以交给Citadel来处理了。 Galley： 它并不直接向数据面提供业务能力，而是在控制面上向其他组件提供支持。Galley 作为负责配置管理的组件，验证配置信息的格式和内容的正确性，并将这些配置信息提供给管理面的Pilot和Mixer服务使用，在新的版本中Galley的作用越来越核心。 五、为什么使用 istio通过负载均衡、服务间的身份验证、监控等方法，Istio 可以轻松地创建一个已经部署了服务的网络，而服务的代码只需很少更改甚至无需更改。通过在整个环境中部署一个特殊的 sidecar 代理为服务添加 Istio 的支持，而代理会拦截微服务之间的所有网络通信，然后使用其控制平面的功能来配置和管理 Istio，这包括： 1、为 HTTP、gRPC、WebSocket 和 TCP 流量自动负载均衡。 2、通过丰富的路由规则、重试、故障转移和故障注入对流量行为进行细粒度控制。 3、可插拔的策略层和配置 API，支持访问控制、速率限制和配额。 4、集群内（包括集群的入口和出口）所有流量的自动化度量、日志记录和追踪。 5、在具有强大的基于身份验证和授权的集群中实现安全的服务间通信。 6、Istio 为可扩展性而设计，可以满足不同的部署需求。"},{"path":"/2023/07/11/Kubernetes云计算实战/istio指标收集与查询/","content":"一、istio指标收集与查询1、通过 Prometheus 查询度量指标123456789101112131415161718192021222324252627282930313233343536373839采集新的指标应用配置新指标的 YAML 文件，该指标将由 Istio 自动生成和采集kubectl apply -f metrics.yaml修改 prometheus 的 svc 模式由 ClusterIP 为 NodePortkubectl edit svc prometheus -n istio-system查看 prometheus 的端口kubectl get svc -n istio-system通过浏览器进行访问http://IP:PORT上述链接打开 Prometheus 并执行对 istio_double_request_count 指标值的查询语句因为没有数据，我们通过下列命令模拟产生数据，随便打开一个终端，执行以下命令watch -n 1 curl -o /dev/null -s -w %&#123;http_code&#125; http://182.61.167.80:31380/productpage其他查询：请求 productpage 服务的总次数：istio_requests_total&#123;destination_service=&quot;productpage.default.svc.cluster.local&quot;&#125;请求 reviews 服务 V3 版本的总次数：istio_requests_total&#123;destination_service=&quot;reviews.default.svc.cluster.local&quot;, destination_version=&quot;v3&quot;&#125;该查询返回所有请求 reviews 服务 v3 版本的当前总次数。过去 5 分钟 productpage 服务所有实例的请求频次：rate(istio_requests_total&#123;destination_service=~&quot;productpage.*&quot;, response_code=&quot;200&quot;&#125;[5m]) 13.png 14.png 15.png 16.png 2、使用 Grafana 可视化指标1234567891011修改 grafana 的 svc 模式由 ClusterIP 为 NodePortkubectl edit svc grafana -n istio-system查看 grafana 的端口kubectl get svc -n istio-system通过浏览器进行访问http://IP:PORT 17.png 18.png 19.png 20.png 21.png 22.png"},{"path":"/2023/07/11/Kubernetes云计算实战/istio分布式追踪与可视化/","content":"一、istio分布式追踪官方网站：https://www.jaegertracing.io/ 1234567891011修改 tracing 的 svc 模式由 ClusterIP 为 NodePortkubectl edit svc tracing -n istio-system查看 tracing 的端口kubectl get svc -n istio-system通过浏览器进行访问http://IP:PORT/jaeger 23.png 24.png 25.png 26.png 27.png 二、 网络可视化12345678910111213141516171819202122232425262728293031323334353637首先，定义要用作 Kiali 用户名和密码的凭据。KIALI_USERNAME=$(read -p &#x27;Kiali Username: &#x27; uval &amp;&amp; echo -n $uval | base64)当提示出现时输入 Kiali 用户名：KIALI_PASSPHRASE=$(read -sp &#x27;Kiali Passphrase: &#x27; pval &amp;&amp; echo -n $pval | base64)当提示出现时输入 Kiali 密码：运行以下命令创建 secret：NAMESPACE=istio-systemcat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Secretmetadata: name: kiali namespace: $NAMESPACE labels: app: kialitype: Opaquedata: username: $KIALI_USERNAME passphrase: $KIALI_PASSPHRASEEOF修改 kiali 的 svc 模式由 ClusterIP 为 NodePortkubectl edit svc kiali -n istio-system查看 kiali 的端口kubectl get svc -n istio-system通过浏览器进行访问http://IP:PORT"},{"path":"/2023/07/11/Kubernetes云计算实战/istio 部署/","content":"一、istio 部署下载地址：https://github.com/istio/istio/releases 网盘链接:https://pan.baidu.com/s/1L4CK2icK6teT5Ef4eiJwKw 密码:i16u 资源配置： master 2U2G node 2U8G 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748curl -L https://git.io/getLatestIstio | ISTIO_VERSION=1.5.4 sh -kubectl create namespace istio-systemcd istio-1.5.4使用 helm template 生成配置文件进行安装：初始化：helm template install/kubernetes/helm/istio-init --name istio-init --namespace istio-system &gt; init.yamlkubectl apply -f init.yaml等初始化 pod 完成后，就可以执行 istio 安装了安装：vim install/kubernetes/helm/istio/values.yaml编辑 valuse.yaml 文件，确认需要安装启动的组件helm template install/kubernetes/helm/istio --name istio --namespace istio-system &gt; istio.yamlkubectl apply -f istio.yaml或使用 helm install 由 helm 服务来进行安装：初始化：helm install install/kubernetes/helm/istio-init --name istio-init --namespace istio-systemvim install/kubernetes/helm/istio/values.yaml编辑 valuse.yaml 文件，确认需要安装启动的组件安装：helm install install/kubernetes/helm/istio --name istio --namespace istio-system查看 istio 的状态 kubectl get pod -n istio-systemkubectl get svc -n istio-system这里需要注意，因为是实验环境，如果集群运行在一个不支持外部负载均衡器的环境中，istio-ingressgateway 的 EXTERNAL-IP 将显示为 &lt;pending&gt; 状态。我们需要使用服务的 NodePort 或 端口转发来访问网关，我们这里使用 NodePort 来进行访问，所以需要进行如下修改：kubectl edit svc istio-ingressgateway -n istio-system在文件末尾将 LoadBalancer 修改为 NodePort 后保存退出即可。 4.png 5.png Istio 对 Pod 和服务的要求 要成为服务网格的一部分，Kubernetes 集群中的 Pod 和服务必须满足以下几个要求： **需要给端口正确命名:**服务端口必须进行命名。端口名称只允许是&lt;协议&gt;[-&lt;后缀&gt;-]模式，其中&lt;协议&gt;部分可选择范围包括 grpc、http、http2、https、mongo、redis、tcp、tls 以及 udp，Istio 可以通过对这些协议的支持来提供路由能力。例如 name: http2-foo 和 name: http 都是有效的端口名，但 name: http2foo 就是无效的。如果没有给端口进行命名，或者命名没有使用指定前缀，那么这一端口的流量就会被视为普通 TCP 流量（除非显式的用 Protocol: UDP 声明该端口是 UDP 端口）。 **Pod 端口:**Pod 必须包含每个容器将监听的明确端口列表。在每个端口的容器规范中使用 containerPort。任何未列出的端口都将绕过 Istio Proxy。 **关联服务:**Pod 不论是否公开端口，都必须关联到至少一个 Kubernetes 服务上，如果一个 Pod 属于多个服务，这些服务不能在同一端口上使用不同协议，例如 HTTP 和 TCP。 **Deployment 应带有 app 以及 version 标签:**在使用 Kubernetes Deployment 进行 Pod 部署的时候，建议显式的为 Deployment 加上 app 以及 version 标签。每个 Deployment 都应该有一个有意义的 app 标签和一个用于标识 Deployment 版本的 version 标签。app 标签在分布式追踪的过程中会被用来加入上下文信息。Istio 还会用 app 和 version 标签来给遥测指标数据加入上下文信息。 **Application UID:**不要使用 ID（UID）值为 1337 的用户来运行应用。 **NET_ADMIN 功能:**如果您的集群中实施了 Pod 安全策略，除非您使用 Istio CNI 插件，您的 pod 必须具有NET_ADMIN功能。 二、部署 Bookinfo 示例这个示例部署了一个用于演示多种 Istio 特性的应用，该应用由四个单独的微服务构成。 这个应用模仿在线书店的一个分类，显示一本书的信息。 页面上会显示一本书的描述，书籍的细节（ISBN、页数等），以及关于这本书的一些评论。 Bookinfo 应用分为四个单独的微服务： productpage. 这个微服务会调用 details 和 reviews 两个微服务，用来生成页面。 details. 这个微服务中包含了书籍的信息。 reviews. 这个微服务中包含了书籍相关的评论。它还会调用 ratings 微服务。 ratings. 这个微服务中包含了由书籍评价组成的评级信息。 reviews 微服务有 3 个版本： v1 版本不会调用 ratings 服务。 v2 版本会调用 ratings 服务，并使用 1 到 5 个黑色星形图标来显示评分信息。 v3 版本会调用 ratings 服务，并使用 1 到 5 个红色星形图标来显示评分信息。 下图展示了这个应用的端到端架构。 6.png Bookinfo 应用中的几个微服务是由不同的语言编写的。 这些服务对 Istio 并无依赖，但是构成了一个有代表性的服务网格的例子：它由多个服务、多个语言构成，并且 reviews 服务具有多个版本。 1234567891011121314151617181920212223242526272829303132333435363738394041部署前准备：\t1、kubernetes 集群部署完成\t2、helm 部署完成# Istio 默认自动注入 Sidecar. 请为 default 命名空间打上标签 istio-injection=enabledkubectl label namespace default istio-injection=enabled# 使用 kubectl 部署应用kubectl apply -f bookinfo.yaml# 确认 Bookinfo 应用是否正在运行，请在某个 Pod 中用 curl 命令对应用发送请求，例如 ratingskubectl exec -it $(kubectl get pod -l app=ratings -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -c ratings -- curl productpage:9080/productpage | grep -o &quot;&lt;title&gt;.*&lt;/title&gt;&quot;现在 Bookinfo 服务启动并运行中，我们需要使应用程序可以从外部访问 Kubernetes 集群，例如使用浏览器。可以用 Istio Gateway 来实现这个目标。# 为应用程序定义 Ingress 网关kubectl apply -f bookinfo-gateway.yaml# 在 Kubernetes 环境中，使用 Kubernetes Ingress 资源来指定需要暴露到集群外的服务。 在 Istio 服务网格中，更好的选择（同样适用于 Kubernetes 及其他环境）是使用一种新的配置模型，名为 Istio Gateway。 Gateway 允许应用一些诸如监控和路由规则的 Istio 特性来管理进入集群的流量启动 httpbin 样例程序kubectl apply -f httpbin.yaml执行如下指令，明确自身 Kubernetes 集群环境支持外部负载均衡kubectl get svc istio-ingressgateway -n istio-system若自身环境未使用外部负载均衡器，需要通过 NodePort 访问,执行如下命令,设置 ingress 端口：export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#x27;&#123;.spec.ports[?(@.name==&quot;http2&quot;)].nodePort&#125;&#x27;)export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=&#x27;&#123;.spec.ports[?(@.name==&quot;https&quot;)].nodePort&#125;&#x27;)在使用 Istio 控制 Bookinfo 版本路由之前，我们需要在目标规则中定义好可用的应用默认目标规则，命名为 subsets kubectl apply -f destination-rule-all.yaml浏览器访问测试：http://IP:port/productpage 10.png 7.png 8.png 9.png"},{"path":"/2023/07/11/Kubernetes云计算实战/Helm/","content":"一、Helm 是什么在没使用 helm 之前，向 kubernetes 部署应用，我们要依次部署 deployment、svc 等，步骤较繁琐。况且随着很多项目微服务化，复杂的应用在容器中部署以及管理显得较为复杂，helm 通过打包的方式，支持发布的版本管理和控制，很大程度上简化了 Kubernetes 应用的部署和管理。 Helm 本质就是让 K8s 的应用管理（Deployment,Service 等 ) 可配置，能动态生成。通过动态生成 K8s 资源清单文件（deployment.yaml，service.yaml）。然后调用 Kubectl 自动执行 K8s 资源部署。 Helm 是官方提供的类似于 YUM 的包管理器，是部署环境的流程封装。Helm 有两个重要的概念：chart 和release。 二、Helm 相关组件Helm 包含两个组件，分别是 helm 客户端 和 Tiller 服务器： helm ： 是一个命令行工具，用于本地开发及管理chart，chart仓库管理等 Tiller： 是 Helm 的服务端。Tiller 负责接收 Helm 的请求，与 k8s 的 apiserver 交互，根据chart来生成一个 release 并管理 release chart： Helm的打包格式叫做chart，所谓chart就是一系列文件, 它描述了一组相关的 k8s 集群资源 release： 使用 helm install 命令在 Kubernetes 集群中部署的 Chart 称为 Release 三、Helm 原理150.png 创建 或 删除 release helm 客户端从指定的目录或本地tar文件或远程repo仓库解析出chart的结构信息 helm 客户端指定的 chart 结构和 values 信息通过 gRPC 传递给 Tiller Tiller 服务端根据 chart 和 values 生成一个 release Tiller 将install release请求直接传递给 kube-apiserver 更新release helm 客户端将需要更新的 chart 的 release 名称 chart 结构和 value 信息传给 Tiller Tiller 将收到的信息生成新的 release，并同时更新这个 release 的 history Tiller 将新的 release 传递给 kube-apiserver 进行更新 四、Helm 部署12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182wget https://storage.googleapis.com/kubernetes-helm/helm-v2.16.7-linux-amd64.tar.gztar zxvf helm-v2.16.7-linux-amd64.tar.gz cd linux-amd64/lsLICENSE README.md helm tillercp helm /usr/local/bin/安装好 helm 客户端后，就可以通过以下命令将 Tiller 安装在 kubernetes 集群中 ：helm init# 这个地方默认使用 “https://kubernetes-charts.storage.googleapis.com” 作为缺省的 stable repository 的地址，但由于国内有一张无形的墙的存在，googleapis.com 是不能访问的。可以使用阿里云的源来配置 ：helm init --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.16.7 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts执行上面命令后，可以通过 kubectl get pod -n kube-system 来查看 tiller 的安装情况 ： 由于 kubernetes 从1.6 版本开始加入了 RBAC 授权。当前的 Tiller 没有定义用于授权的ServiceAccount， 访问 API Server 时会被拒绝，需要给 Tiller 加入授权:创建 Kubernetes 的服务帐号和绑定角色:kubectl create serviceaccount --namespace kube-system tiller# serviceaccount &quot;tiller&quot; createdkubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller# clusterrolebinding.rbac.authorization.k8s.io &quot;tiller-cluster-rule&quot; created给 Tiller 的 deployments 添加刚才创建的 ServiceAccount :kubectl patch deploy --namespace kube-system tiller-deploy -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;template&quot;:&#123;&quot;spec&quot;:&#123;&quot;serviceAccount&quot;:&quot;tiller&quot;&#125;&#125;&#125;&#125;&#x27;# deployment.extensions &quot;tiller-deploy&quot; patched查看 Tiller deployments 资源是否绑定 ServiceAccount :kubectl get deploy -n kube-system tiller-deploy -o yaml | grep serviceAccount# serviceAccount: tiller# serviceAccountName: tiller查看 Tiller 是否安装成功 ： helm version # Client: &amp;version.Version&#123;SemVer:&quot;v2.16.7&quot;, # Server: &amp;version.Version&#123;SemVer:&quot;v2.16.7&quot;, helm 有很多子命令和参数，为了提高使用命令行的效率，通常建议安装 helm 的 bash 命令补全脚本：source &lt;(helm completion bash)echo &quot;source &lt;(helm completion bash)&quot; &gt;&gt; ~/.bashrc添加 helm chart 仓库：helm repo add stable https://kubernetes-charts.storage.googleapis.comhelm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/chartshelm repo add alihub https://apphub.aliyuncs.comhelm repo add svc-cat https://svc-catalog-charts.storage.googleapis.comhelm repo add weiruan-1 http://mirror.azure.cn/kubernetes/chartshelm repo add weiruan-2 http://mirror.azure.cn/kubernetes/charts-incubatorhelm repo add weiruan-3 http://mirror.azure.cn/kubernetes/svc-catalog-chartshelm repo add bitnami https://charts.bitnami.com/bitnamihelm repo add elastic https://helm.elastic.cohelm repo add kiwigrid https://kiwigrid.github.iohelm repo add jetstack https://charts.jetstack.io更新仓库：helm repo update 149.png Helm 常用命令 123456789101112131415161718192021222324252627282930# 创建一个chart范例helm create HELM-NAME# 检查chart语法helm lint ./HELM-NAME# 使用默认chart部署到k8shelm install --name RELEASE-NAME ./HELM-NAME --set service.type=NodePort# 查看当前的部署列表helm ls# 查询一个特定的 Release 的状态helm status RELEASE-NAME# 打包charthelm package ./HELM-NAME --debug# 使用包去做release部署helm install --name RELEASE-NAME HELM-NAME-0.1.0.tgz --set service.type=NodePort# 升级当前releasehelm upgrade RELEASE-NAME ./HELM-NAME# 回滚当前releasehelm rollback RELEASE-NAME 3（版本号）# 删除该releasehelm delete RELEASE-NAMEhelm del --purge RELEASE-NAME 五、Helm 自定义模板1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556创建自描述文件 Chart.yaml , 这个文件必须有 name 和 version 定义：vim Chart.yamlname: hello-worldversion: 1.0创建模板文件， 用于生成 Kubernetes 资源清单,模板文件名必须为 templates：mkdir templatesvim templates/deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: helm-nginxspec: selector: matchLabels: app: helm-nginx replicas: 3 template: metadata: labels: app: helm-nginx spec: containers: - name: helm-nginx image: docker.io/nginx imagePullPolicy: IfNotPresent ports: - containerPort: 80vim templates/service.yamlapiVersion: v1kind: Servicemetadata: name: helm-nginx-svcspec: type: NodePort ports: - port: 80 targetPort: 80 protocol: TCP selector: app: helm-nginx使用命令 helm install RELATIVE_PATH_TO_CHART 创建一次Releasehelm install . 151.png 查看下我们创建以后的资源： 152.png 访问测试： 153.png 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748通过 values.yaml 配置 helm 应用：vim values.yamlimage: repository: docker.io/nginx tag: latest pullPolicy: IfNotPresentvim templates/deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: helm-nginx-1spec: selector: matchLabels: app: helm-nginx-1 replicas: 3 template: metadata: labels: app: helm-nginx-1 spec: containers: - name: helm-nginx image: &#123;&#123; .Values.image.repository &#125;&#125;:&#123;&#123; .Values.image.tag &#125;&#125; imagePullPolicy: IfNotPresent ports: - containerPort: 80 vim templates/service.yamlapiVersion: v1kind: Servicemetadata: name: helm-nginx-svc-1spec: type: NodePort ports: - port: 80 targetPort: 80 protocol: TCP selector: app: helm-nginx-1 使用模板动态生成K8s资源清单，非常需要能提前预览生成的结果，使用 –dry-run 选项来打印出生成的清单文件内容，而不执行部署： helm install . –dry-run 154.png 这里看见报错了，这是因为，我们刚刚已经创了对应的资源，所以报错说 service “helm-nginx-svc” 已经存在了。"},{"path":"/2023/07/11/Kubernetes云计算实战/Harbor 镜像仓库部署/","content":"一、创建自签证书：1.1、准备工作 检查是否已经安装 openssl： openssl version 创建存放证书目录并进入目录 12[root@zutuanxue ~]# mkdir /opt/harbor-ca-key[root@zutuanxue ~]# cd /opt/harbor-ca-key 1.2、创建秘钥生成私钥 1234567[root@zutuanxue harbor-ca-key]# openssl genrsa -des3 -out server.pass.key 2048# genra\t生成RSA私钥# -des3\tdes3算法# -out server.key 生成的私钥文件名# 2048 私钥长度# 设置密码，密麻麻长度不能少于4位 去除私钥中的密码 123[root@zutuanxue harbor-ca-key]# openssl rsa -in server.pass.key -out server.key# 有密码的私钥是server.pass.key，没有密码的私钥是server.key 生成CSR(证书签名请求) 1234567891011121314151617181920212223242526[root@zutuanxue harbor-ca-key]# openssl req -new -key server.key -out server.csr -subj &quot;/C=CN/ST=bj/L=bj/O=zutuanxue/OU=zutuanxue/CN=www.zutuanxue.com&quot;subj参数说明如下：/C=国家/ST=省/L=城市/O=组织或企业/OU=部门/CN=域名或IP第四步：生成自签名SSL证书openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt# -days 证书有效期# X.509证书包含三个文件：key，csr，crt。# key是服务器上的私钥文件，用于对发送给客户端数据的加密，以及对从客户端接收到数据的解密# csr是证书签名请求文件，用于提交给证书颁发机构（CA）对证书签名# crt是由证书颁发机构（CA）签名后的证书，或者是开发者自签名的证书，包含证书持有人的信息，持有人的公钥，以及签署者的签名等信息# 在密码学中，X.509是一个标准，规范了公开秘钥认证、证书吊销列表、授权凭证、凭证路径验证算法等。 二、部署 Harbor准备工作 Harbor 离线安装包 docker-compose 2.1、部署前准备解压 Harboe 离线安装包后，进入解压后的目录，编辑 harbor.yaml 文件 修改 hostname 字段,改为自己的主机名 1hostname: www.zutuanxue.com 修改 certificate 与 private_key 字段如下，修改为你自己环境下的证书存放目录： 12certificate: /opt/harbor-ca-key/server.crtprivate_key: /opt/harbor-ca-key/server.key 修改 harbor_admin_password 字段，设置管理员用户的密码 1默认密码为 Harbor12345 ，如果配置文件内保持了默认密码的话，可以在搭建完成后在 web 页面进行密码修改操作。 2.2、安装Harbor在解压后的 Harbor 目录内，有 “prepare” 初始化文件以及 ”install.sh“ 安装文件，先执行初始化操作 .&#x2F;prepare 初始化完成以后执行安装操作 .&#x2F;install.sh 然后等待安装完成即可。 12[root@zutuanxue Harbor]# ./prepare[root@zutuanxue Harbor]# ./install.sh 2.3、验证Harbor仓库使用docker客户端连接Harbor仓库，验证是否能够正确连接 设置仓库URL因为我们使用的是自签证书，所以我们要在需要进行 docker login 的节点上编辑 daemon.json 文件，添加信任，否则话我们将无法正常进行 docker login 的操作： 123456789101112[root@zutuanxue Harbor]# vim /etc/docker/daemon.json添加内容如下：&#123;&quot;insecure-registries&quot;: [&quot;https://www.zutuanxue.com&quot;]&#125;保存退出，重启 docker 服务即可。[root@zutuanxue docker]# systemctl restart docker 如果你 hostname 字段设置的是域名，记得在 &#x2F;etc&#x2F;hosts 文件内添加解析，示例如下： 1234vim /etc/hosts192.168.1.150\twww.zutuanxue.com添加完成后保存退出即可。 登录验证 1234567891011121314151617完成后可以进行验证：docker login www.zutuanxue.comUsername：adminPassword：Harbor12345输入完密码后显示如下信息Authenticating with existing credentials...WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded证明登录成功。 同样，如果你想 web 登录进行管理，那么你需要修改你宿主机的 hosts 文件,在里面添加对应的解析条目 MAC 系统设置 1打开终端 → sudo vim /etc/hosts → 添加 IP 与 域名 的解析即可 Windows 系统设置 1231、打开计算机后，点击进入C盘，找到 windows 文件夹2、在windows文件中找到System32 → drivers → etc ，进入到 etc 文件夹中就能看到 hosts 文件3、在末尾添加对应解析即可，然后保存退出 添加完解析后，打开浏览器，输入我们设置的域名即可访问，因为我们使用的是自签证书，所以浏览器会有安全提示，说我们访问的网站不安全，直接无视该信息，点击继续访问即可，然后输入我们的用户名 admin 密码 Harbor12345 即可成功登陆。"},{"path":"/2023/07/11/Docker容器实战部署/RHEL Podman命令/","content":"Podman介绍Podman 是一个开源的容器运行时项目，可在大多数 Linux 平台上使用。Podman 提供与 Docker 非常相似的功能。正如前面提到的那样，它不需要在你的系统上运行任何守护进程，并且它也可以在没有 root 权限的情况下运行。Podman 可以管理和运行任何符合 OCI（Open Container Initiative）规范的容器和容器镜像。Podman 提供了一个与 Docker 兼容的命令行前端来管理 Docker 镜像。 Podman 官网地址：https://podman.io/ Podman 项目地址：https://github.com/containers/libpod Podman 和docker不同之处？ docker 需要在我们的系统上运行一个守护进程(docker daemon)，而podman 不需要 启动容器的方式不同： docker cli 命令通过API跟 Docker Engine(引擎)交互告诉它我想创建一个container，然后docker Engine才会调用OCI container runtime(runc)来启动一个container。这代表container的process(进程)不会是Docker CLI的child process(子进程)，而是Docker Engine的child process。 Podman是直接给OCI containner runtime(runc)进行交互来创建container的，所以container process直接是podman的child process。 因为docke有docker daemon，所以docker启动的容器支持--restart策略，但是podman不支持，如果在k8s中就不存在这个问题，我们可以设置pod的重启策略，在系统中我们可以采用编写systemd服务来完成自启动 docker需要使用root用户来创建容器，但是podman不需要 Podman安装1# yum -y install podman Podman命令镜像管理命令镜像搜索 podman search12345678910111213141516171819202122232425262728293031323334[root@node4 ~]# podman search centosINDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATED Podman.io Podman.io/blacklabelops/centos CentOS Base Image! Built and Updates Daily! 1 [OK] INDEXNAME 镜像名字DESCRIPTION\t描述SATRS 星级 数字越大代表使用人数越多OFFICIAL 是否为官方镜像AUTOMATED 拓展知识：根据本地的/etc/containers/registries.conf文件中定义的去搜索#默认情况下，使用podman搜索从容器仓库中搜索镜像时，基于registries.conf文件，podman按顺序在registry.redhat.io、registry.access.redhat.com、quay.io和docker.io中查找请求的镜像。[registries.search]registries = [&#x27;registry.redhat.io&#x27;, &#x27;registry.access.redhat.com&#x27;, &#x27;quay.io&#x27;, &#x27;docker.io&#x27;]#要添加对不需要身份验证的容器仓库（不安全容器仓库）的访问，必须在[registries.Unsecure]部分下添加该容器仓库的名称。[registries.insecure] registries = []#要禁止从本地系统访问的任何容器仓库都需要添加到[registries.block]部分下。[registries.block] registries = []关于配置容器容器仓库，您还应该了解以下几点：1、确保每个容器仓库都用单引号括起来。2、如果为registries=值设置了多个仓库，则必须用逗号分隔这些仓库。3、仓库可以通过IP地址或主机名来标识。4、如果仓库使用非标准端口（即，安全端口不是TCP端口443，不安全端口不是80），则应使用仓库名输入该端口号。例如：host.example.com:99995、按照Registries.conf文件每个部分的显示顺序搜索仓库。6、如果您是运行podman和相关工具的普通用户（无根），则可以创建自己的registries.conf文件来覆盖默认设置。 本地镜像查看 podman images123[root@node4 ~]# podman imagesREPOSITORY TAG IMAGE ID CREATED SIZEPodman.io/blacklabelops/centos latest 73f5fb57a402 13 months ago 391 MB 从仓库镜像拉取 podman pull [imange_name]12345678910[root@node4 ~]# podman pull Podman.io/blacklabelops/centosTrying to pull Podman.io/blacklabelops/centos...Getting image source signaturesCopying blob 18b8eb7e7f01: 69.75 MiB / 69.96 MiB [=============================]Copying blob 18b8eb7e7f01: 69.96 MiB / 69.96 MiB [=========================] 33sCopying blob 18b8eb7e7f01: 69.96 MiB / 69.96 MiB [=========================] 33sCopying blob 9d438d3ad7e8: 61.22 MiB / 61.22 MiB [=========================] 33sCopying config 73f5fb57a402: 3.98 KiB / 3.98 KiB [==========================] 0sWriting manifest to image destinationStoring signatures73f5fb57a402c17df1a74ddb154c4d2e2cd30c366e224d9cb6087ab9c6339d58 本地镜像删除 podman rmi [IMAGE_ID|REPOSITORY]123456方法一: podman rmi IMAGE_ID[root@node4 ~]# podman rmi 73f5fb57a40273f5fb57a402c17df1a74ddb154c4d2e2cd30c366e224d9cb6087ab9c6339d58方法二: podman rmi REPOSITORY[root@node4 ~]# podman rmi Podman.io/blacklabelops/centos73f5fb57a402c17df1a74ddb154c4d2e2cd30c366e224d9cb6087ab9c6339d58 镜像上传到仓库 podman push镜像管理综合命令 podman image123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138[root@node4 ~]# podman imageNAME: podman image - Manage imagesUSAGE: podman image command [command options] [arguments...]COMMANDS: build Build an image using instructions from Podmanfiles #根据Podmanfiles创建image history Show history of a specified image #显示指定镜像的历史信息 import Import a tarball to create a filesystem image #导入一个文件系统压缩包 exists Check if an image exists in local storage #检查本地是否存在某个镜像 inspect Displays the configuration of a container or image #显示容器或镜像的详细信息 load Load an image from Podman archive #将镜像文件导入到镜像仓库 list, ls list images in local storage #列出本地存储中的镜像 prune Remove unused images #移除未使用的镜像 pull Pull an image from a registry #下载一个镜像到本地 push Push an image to a specified destination #上传一个镜像到仓库 rm removes one or more images from local storage #删除一个或多个本地镜像 save Save image to an archive #将一个镜像保存为一个镜像文件 tag Add an additional name to a local image #添加一个额外的名称给本地镜像 trust Manage container image trust policy #信任容器镜像 sign Sign an image #生成镜像签名，可以根据签名验证镜像的完整性OPTIONS: --help, -h show help 镜像历史信息[root@node4 ~]# podman image history 73f5fb57a402ID CREATED CREATED BY SIZE COMMENT73f5fb57a402 13 months ago /bin/sh -c #(nop) LABEL maintainer=Steffen... 0B &lt;missing&gt; 13 months ago |1 BUILD_DATE=06/10/2018-01:06+0200 /bin/s... 64.2MB &lt;missing&gt; 13 months ago /bin/sh -c #(nop) ARG BUILD_DATE=undefined 64.2MB &lt;missing&gt; 15 months ago /bin/sh -c #(nop) CMD [&quot;/bin/bash&quot;] 64.2MB &lt;missing&gt; 15 months ago /bin/sh -c #(nop) LABEL name=CentOS Base I... 64.2MB &lt;missing&gt; 15 months ago /bin/sh -c #(nop) ADD file:d6a1da927f0b7a7... 73.36MB 镜像导入来自系统压缩包 导入时文件越大越慢[root@node4 ~]# podman image import centos8.tarGetting image source signaturesCopying blob 84d82847ae58: 1.29 GiB / 1.31 GiB [===============================]Copying blob 84d82847ae58: 1.31 GiB / 1.31 GiB [===========================] 14sCopying config 2d42f6c756bc: 419 B / 419 B [================================] 0sWriting manifest to image destinationStoring signatures2d42f6c756bc02640bbb77319b5f1b3a2c51f70fd64d4919d8eb5c0d078c87a7监测本地镜像是否存在，结合$?[root@node4 ~]# podman image exists 2d42f6c756bc;echo $?0[root@node4 ~]# podman image exists 2d42f6c756bcxxxx;echo $?1镜像下载[root@node4 ~]# podman image pull Podman.io/blacklabelops/centosTrying to pull Podman.io/blacklabelops/centos...Getting image source signaturesCopying blob 18b8eb7e7f01: 69.92 MiB / 69.96 MiB [=============================]Copying blob 18b8eb7e7f01: 69.96 MiB / 69.96 MiB [=========================] 23sCopying blob 18b8eb7e7f01: 69.96 MiB / 69.96 MiB [=========================] 24sCopying blob 9d438d3ad7e8: 61.22 MiB / 61.22 MiB [=========================] 24sCopying config 73f5fb57a402: 3.98 KiB / 3.98 KiB [==========================] 0sWriting manifest to image destinationStoring signatures73f5fb57a402c17df1a74ddb154c4d2e2cd30c366e224d9cb6087ab9c6339d58镜像查看 list[root@node4 ~]# podman image listREPOSITORY TAG IMAGE ID CREATED SIZEPodman.io/blacklabelops/centos latest 73f5fb57a402 13 months ago 391 MB镜像查看 ls[root@node4 ~]# podman image lsREPOSITORY TAG IMAGE ID CREATED SIZEPodman.io/blacklabelops/centos latest 73f5fb57a402 13 months ago 391 MB镜像删除[root@node4 ~]# podman image rm 73f5fb57a40273f5fb57a402c17df1a74ddb154c4d2e2cd30c366e224d9cb6087ab9c6339d58[root@node4 ~]# podman image tag 2d42f6c756bc tyschool_centos8_1905[root@node4 ~]# podman image listREPOSITORY TAG IMAGE ID CREATED SIZElocalhost/tyschool_centos8_1905 latest 2d42f6c756bc 5 hours ago 1.4 GB导出一个镜像到文件 -o output[root@node4 ~]# podman image save -o centos_7_base Podman.io/blacklabelops/centosGetting image source signaturesCopying blob 129b697f70e9: 194.43 MiB / 195.64 MiB [===========================]Copying blob 129b697f70e9: 195.64 MiB / 195.64 MiB [========================] 6sCopying blob 129b697f70e9: 195.64 MiB / 195.64 MiB [========================] 6sCopying blob a39553b46393: 177.41 MiB / 177.41 MiB [========================] 6sCopying config 73f5fb57a402: 3.98 KiB / 3.98 KiB [==========================] 0sWriting manifest to image destinationStoring signatures导入一个镜像文件到本地仓库 -i input [root@node4 ~]# podman image load -i centos_7_base Getting image source signaturesCopying blob 129b697f70e9: 183.88 MiB / 195.64 MiB [=========================&gt;-]Copying blob a39553b46393: 171.16 MiB / 177.41 MiB [===========================]Copying blob 129b697f70e9: 195.64 MiB / 195.64 MiB [========================] 4sCopying blob a39553b46393: 177.41 MiB / 177.41 MiB [========================] 4sCopying config 73f5fb57a402: 3.98 KiB / 3.98 KiB [==========================] 0sWriting manifest to image destinationStoring signaturesLoaded image(s): docker.io/blacklabelops/centos:latest删除未使用的镜像[root@node4 ~]# podman image prune --all2d42f6c756bc02640bbb77319b5f1b3a2c51f70fd64d4919d8eb5c0d078c87a7b9e394903cd716d89ca1fb6758bfa08dd6ec6a5966fa925c9cf58738062eba0573f5fb57a402c17df1a74ddb154c4d2e2cd30c366e224d9cb6087ab9c6339d58 容器管理命令容器查看 ps123456789#显示开机容器[root@node4 ~]# podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES#显示所有容器，包括没开机的[root@node4 ~]# podman ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES344ce4a0a6b4 localhost/tyschool_centos8_1905:latest /bin/bash 54 seconds ago Exited (0) 50 seconds ago ty278c97bb19bec docker.io/mcnaughton/centos-base:latest /bin/bash 3 minutes ago Exited (0) About a minute ago ty1 容器创建 run方法一：根据本地镜像创建容器 1234567891011[root@node4 ~]# podman imagesREPOSITORY TAG IMAGE ID CREATED SIZElocalhost/tyschool_centos8_1905 latest 2d42f6c756bc 7 hours ago 1.4 GBdocker.io/blacklabelops/centos latest 73f5fb57a402 13 months ago 391 MB[root@node4 ~]# podman run -it -name ty2 localhost/tyschool_centos8_1905 /bin/bash-i 开启容器交互-t 分配一个TTY终端[假的]拓展--privileged 扩展容器权限 方法二: 容器创建的时候，优先从本地仓库找镜像，本地没有就回去远程仓库拉取到本地 1234567891011121314本地仓库没有镜像[root@node4 ~]# podman run --name ty1 -it docker.io/mcnaughton/centos-base /bin/bashTrying to pull docker.io/mcnaughton/centos-base...Getting image source signaturesCopying blob a02a4930cb5d: 0 B / 71.68 MiB [-----------------------------------]Copying blob a02a4930cb5d: 30.30 MiB / 71.68 MiB [============&gt;----------------]Copying blob a02a4930cb5d: 71.27 MiB / 71.68 MiB [=============================]Copying blob a02a4930cb5d: 71.68 MiB / 71.68 MiB [=========================] 34sCopying blob a02a4930cb5d: 71.68 MiB / 71.68 MiB [=========================] 34sCopying blob f6168f316445: 23.45 MiB / 23.45 MiB [=========================] 34sCopying blob cf55ab518523: 99.57 MiB / 99.57 MiB [=========================] 34sCopying blob 68b1bf62d7e6: 1.19 KiB / 1.19 KiB [===========================] 34sCopying config b9e394903cd7: 4.99 KiB / 4.99 KiB [==========================] 0sWriting manifest to image destinationStoring signatures 容器启动、关闭、重启、暂停、恢复1234567891011121314151617181920212223242526272829303132333435363738394041#启动容器 start[root@node4 ~]# podman start ty1ty1查看容器开启了[root@node4 ~]# podman psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES78c97bb19bec docker.io/mcnaughton/centos-base:latest /bin/bash 4 minutes ago Up 5 seconds ago ty1#关闭容器 stop[root@node4 ~]# podman stop ty178c97bb19bec488b8bf5a6f68cdff9ecc20980b3c2c9e2d4c56a0946f539bd02查看容器关闭了[root@node4 ~]# podman psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES#重启容器 restart[root@node4 ~]# podman restart ty178c97bb19bec488b8bf5a6f68cdff9ecc20980b3c2c9e2d4c56a0946f539bd02[root@node4 ~]# [root@node4 ~]# podman psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES78c97bb19bec docker.io/mcnaughton/centos-base:latest /bin/bash 6 minutes ago Up 2 seconds ago ty1#暂停容器 pause[root@node4 ~]# podman pause ty178c97bb19bec488b8bf5a6f68cdff9ecc20980b3c2c9e2d4c56a0946f539bd02查看状态[root@node4 ~]# podman ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES344ce4a0a6b4 localhost/tyschool_centos8_1905:latest /bin/bash 4 minutes ago Exited (0) 4 minutes ago ty278c97bb19bec docker.io/mcnaughton/centos-base:latest /bin/bash 6 minutes ago Paused ty1#恢复暂停容器 unpause[root@node4 ~]# podman unpause ty178c97bb19bec488b8bf5a6f68cdff9ecc20980b3c2c9e2d4c56a0946f539bd02查看状态[root@node4 ~]# podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES78c97bb19bec docker.io/mcnaughton/centos-base:latest /bin/bash 6 minutes ago Up 25 seconds ago ty1 容器性能查看 top12345podman top 容器名称[root@node4 ~]# podman top ty1USER PID PPID %CPU ELAPSED TTY TIME COMMANDroot 1 0 0.000 6m9.377354027s pts/0 0s /bin/bash 容器连接 exec123连接一个运行容器，执行/bin/bash命令[root@node4 ~]# podman exec -it ty1 /bin/bash[root@78c97bb19bec /]# 容器连接 attach123将一个运行容器的标准输出、标准错误输出、标准输入调到前台[root@node4 ~]# podman attach ty1[root@78c97bb19bec /]# 根据容器生成镜像 export12345678910111213141516[root@node4 ~]# podman export -o ty1.tar ty1[root@node4 ~]# podman import ty1.tar baism:ty1Getting image source signaturesCopying blob 854836d1c5c3: 491.28 MiB / 505.18 MiB [===========================]Copying blob 854836d1c5c3: 505.18 MiB / 505.18 MiB [========================] 5sCopying config 25581780c97b: 419 B / 419 B [================================] 0sWriting manifest to image destinationStoring signatures25581780c97b41ed62e0d6a9e41f8725cfaa93653e32adbb65369d3e527d235cpodman import ty1.tar baism:ty1baism:ty1 自定义仓库的名称:标签 打包更改过的容器为镜像 commit12345678910111213141516[root@node4 ~]# podman commit ty1 baism:latestGetting image source signaturesSkipping blob 071d8bd76517 (already present): 200.44 MiB / 200.44 MiB [=====] 0sSkipping blob 3c8ab5053a82 (already present): 57.01 MiB / 57.01 MiB [=======] 0sSkipping blob ba3cdff1294c (already present): 286.14 MiB / 286.14 MiB [=====] 0sSkipping blob e25e400e5c38 (already present): 28.50 KiB / 28.50 KiB [=======] 0sSkipping blob 071d8bd76517 (already present): 200.44 MiB / 200.44 MiB [=====] 1sSkipping blob 071d8bd76517 (already present): 200.44 MiB / 200.44 MiB [=====] 1sSkipping blob 3c8ab5053a82 (already present): 57.01 MiB / 57.01 MiB [=======] 1sSkipping blob ba3cdff1294c (already present): 286.14 MiB / 286.14 MiB [=====] 1sSkipping blob e25e400e5c38 (already present): 28.50 KiB / 28.50 KiB [=======] 1sCopying blob 83e9209f930c: 114.44 MiB / 114.44 MiB [========================] 1sCopying config d558217acef1: 4.08 KiB / 4.08 KiB [==========================] 0sWriting manifest to image destinationStoring signaturesd558217acef109e465d5ce65d60de7c8619cc3c8cbbcde57e418555516ba3ec0"},{"path":"/2023/07/11/Docker容器实战部署/Docker镜像管理/","content":"一、docker镜像管理1.1、镜像搜索-search12345678910111213141516从docker镜像仓库模糊搜索镜像用法：\tdocker search 镜像关键字[root@zutuanxue ~]# docker search centosNAME DESCRIPTION STARS OFFICIAL AUTOMATEDcentos The official build of CentOS. 5674 [OK] #字段说明：NAME:镜像名称DESCRIPTION:镜像描述 STARS：镜像星级，数字越大表示用的人越多OFFICIAL:是否为官方 跟[OK]说明是官方AUTOMATED: 是否为自动化构建的镜像 1.2、镜像下载-pull命令从docker指定的仓库下载镜像到本地用法:docker pull 镜像名称 12345678[root@zutuanxue ~]# docker pull centosUsing default tag: latestlatest: Pulling from library/centos729ec3a6ada3: Pull complete Digest: sha256:f94c1d992c193b3dc09e297ffd54d8a4f1dc946c37cbeceb26d35ce1647f88d9Status: Downloaded newer image for centos:latestdocker.io/library/centos:latest 1.3、本地镜像查看-images命令查看本地存储的镜像 1234567891011[root@zutuanxue ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/gitlab/gitlab-ce latest 515ad1a75677 7 weeks ago 1.9 GBdocker.io/redis latest 1319b1eaa0b7 7 weeks ago 104 MB#字段说明：REPOSITORY:镜像的名字TAG：镜像的标签IMAGE ID：镜像的ID号CREATED：镜像建立时间SIZE: 镜像大小 1.4、镜像详细信息-inspect命令显示镜像的详细导入由save保存出来的压缩文件镜像 用法:docker load -i 镜像压缩文件名称 [镜像名称或者ID] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109[root@zutuanxue ~]# docker load -i centos_base.tar Loaded image: centos:latest信息用法:\tdocker inspect [镜像名称或者ID][root@zutuanxue ~]# docker inspect 0f3e07c0138f [ &#123; &quot;Id&quot;: &quot;sha256:0f3e07c0138fbe05abcb7a9cc7d63d9bd4c980c3f61fea5efa32e7c4217ef4da&quot;, &quot;RepoTags&quot;: [ &quot;centos:latest&quot; ], &quot;RepoDigests&quot;: [ &quot;centos@sha256:f94c1d992c193b3dc09e297ffd54d8a4f1dc946c37cbeceb26d35ce1647f88d9&quot; ], &quot;Parent&quot;: &quot;&quot;, &quot;Comment&quot;: &quot;&quot;, &quot;Created&quot;: &quot;2019-10-01T23:19:57.105928163Z&quot;, &quot;Container&quot;: &quot;711572e3c0c1ac06d5c13c4e668ec170b8ad8786b5f0949f884a5f7fd350d856&quot;, &quot;ContainerConfig&quot;: &#123; &quot;Hostname&quot;: &quot;711572e3c0c1&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot; ], &quot;Cmd&quot;: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;#(nop) &quot;, &quot;CMD [\\&quot;/bin/bash\\&quot;]&quot; ], &quot;ArgsEscaped&quot;: true, &quot;Image&quot;: &quot;sha256:c0bda62fdbad65a3c6a1843d293a3a47d8233115cc6d384e3cb07c53580a2b43&quot;, &quot;Volumes&quot;: null, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: null, &quot;OnBuild&quot;: null, &quot;Labels&quot;: &#123; &quot;org.label-schema.build-date&quot;: &quot;20190927&quot;, &quot;org.label-schema.license&quot;: &quot;GPLv2&quot;, &quot;org.label-schema.name&quot;: &quot;CentOS Base Image&quot;, &quot;org.label-schema.schema-version&quot;: &quot;1.0&quot;, &quot;org.label-schema.vendor&quot;: &quot;CentOS&quot; &#125; &#125;, &quot;DockerVersion&quot;: &quot;18.06.1-ce&quot;, &quot;Author&quot;: &quot;&quot;, &quot;Config&quot;: &#123; &quot;Hostname&quot;: &quot;&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot; ], &quot;Cmd&quot;: [ &quot;/bin/bash&quot; ], &quot;ArgsEscaped&quot;: true, &quot;Image&quot;: &quot;sha256:c0bda62fdbad65a3c6a1843d293a3a47d8233115cc6d384e3cb07c53580a2b43&quot;, &quot;Volumes&quot;: null, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: null, &quot;OnBuild&quot;: null, &quot;Labels&quot;: &#123; &quot;org.label-schema.build-date&quot;: &quot;20190927&quot;, &quot;org.label-schema.license&quot;: &quot;GPLv2&quot;, &quot;org.label-schema.name&quot;: &quot;CentOS Base Image&quot;, &quot;org.label-schema.schema-version&quot;: &quot;1.0&quot;, &quot;org.label-schema.vendor&quot;: &quot;CentOS&quot; &#125; &#125;, &quot;Architecture&quot;: &quot;amd64&quot;, &quot;Os&quot;: &quot;linux&quot;, &quot;Size&quot;: 219583055, &quot;VirtualSize&quot;: 219583055, &quot;GraphDriver&quot;: &#123; &quot;Data&quot;: &#123; &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/e84fb0b30e3f1cd4a40d2ee6ed522736aedad13fcfce3571075ebbbd665aab4a/merged&quot;, &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/e84fb0b30e3f1cd4a40d2ee6ed522736aedad13fcfce3571075ebbbd665aab4a/diff&quot;, &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/e84fb0b30e3f1cd4a40d2ee6ed522736aedad13fcfce3571075ebbbd665aab4a/work&quot; &#125;, &quot;Name&quot;: &quot;overlay2&quot; &#125;, &quot;RootFS&quot;: &#123; &quot;Type&quot;: &quot;layers&quot;, &quot;Layers&quot;: [ &quot;sha256:9e607bb861a7d58bece26dd2c02874beedd6a097c1b6eca5255d5eb0d2236983&quot; ] &#125;, &quot;Metadata&quot;: &#123; &quot;LastTagTime&quot;: &quot;0001-01-01T00:00:00Z&quot; &#125; &#125;] 1.5、本地镜像删除-rmi命令删除本地镜像库中的某个镜像 用法:docker rmi [镜像名称或者ID] 123456[root@zutuanxue ~]# docker rmi centosUntagged: centos:latestUntagged: centos@sha256:f94c1d992c193b3dc09e297ffd54d8a4f1dc946c37cbeceb26d35ce1647f88d9Deleted: sha256:0f3e07c0138fbe05abcb7a9cc7d63d9bd4c980c3f61fea5efa32e7c4217ef4daDeleted: sha256:9e607bb861a7d58bece26dd2c02874beedd6a097c1b6eca5255d5eb0d2236983 1.6、镜像保存-save命令保存镜像为压缩文件 用法:docker save -o 压缩文件名称 [镜像名称或者ID] 12345[root@zutuanxue ~]# docker save -o centos_base.tar centos[root@zutuanxue ~]# lsanaconda-ks.cfg centos_base.tar 1.7、镜像载入-load命令导入由save保存出来的压缩文件镜像 用法:docker load -i 镜像压缩文件名称 [镜像名称或者ID] 123[root@zutuanxue ~]# docker load -i centos_base.tar Loaded image: centos:latest 1.8、镜像管理命令-image命令镜像管理命令，和上面的命令相似 1234567891011121314151617[root@zutuanxue ~]# docker image --helpUsage:\tdocker image COMMANDManage imagesCommands: build Build an image from a Dockerfile history Show the history of an image import Import the contents from a tarball to create a filesystem image inspect Display detailed information on one or more images load Load an image from a tar archive or STDIN ls List images prune Remove unused images pull Pull an image or a repository from a registry push Push an image or a repository to a registry rm Remove one or more images save Save one or more images to a tar archive (streamed to STDOUT by default) tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE"},{"path":"/2023/07/11/Docker容器实战部署/Docker的介绍/","content":"一、虚拟化和容器虚拟化介绍操作系统层虚拟化是指通过划分一个宿主操作系统的特定部分，产生一个个隔离的操作执行环境。操作系统层的虚拟化是操作系统内核直接提供的虚拟化，虚拟出的操作系统之间共享底层宿主操作系统内核和底层的硬件资源。操作系统虚拟化的关键点在于将操作系统与上层应用隔离开，将对操作系统资源的访问进行虚报化，使上层应用觉得自己独占操作系统。 操作系统虚拟化的好处是实现了虚拟操作系统与物理操作系统的隔离并且有效避免物理操作系统的重复安装。比较有名的操作系统虚报化解决方案有Virtual Server、Zone、Virtuozzo 及虚拟专用服务器(Vital Pnvate Sever,VPS)。VPS是利用虚拟服务器软件在一台物理机上创建多个相互隔离的小服务器。这些小服务器本身就有自己的操作系统，其运行和管理与独立主机完全相。其可以保证用户独享资源，且可以节约成本。 虚拟化分类 仿真虚拟化 [对系统硬件没有要求,性能最低] VMware 半虚拟化 [虚拟机可以使用真机物理硬件，性能高，需要改内核] xen 硬件辅助虚拟化 vmware kvm 需要硬件支持 【cpu 主板】 不需要改内核 可以直接使用真机硬件，性能最贴近宿主机 容器虚拟化 lxc docker 主机虚拟化和容器虚拟化特点主机虚拟化vmachines.png 应用程序运行环境强隔离 虚拟机操作系统与底层操作系统无关化 虚拟机内部操作不会影响到物理机 拥有操作系统会占用部署资源及存储 网络传输效率低 当应用程序需要调用硬件响应用户访问时间延迟大 容器虚拟化container_virtual.png 可以实现应用程序的隔离 直接使用物理机的操作系统可以快速响应用户请求 不占用部署时间 占用少量磁盘空间 容器虚拟化缺点：学习成本增加、操作控制麻烦、网络控制与主机虚拟化有所区别、服务治理。 容器的发展 LXC 2008 是第一套完整的容器管理解决方案 不需要任何补丁直接运行在linux内核之上管理容器 创建容器慢，不方便移置 Docker 2013 dotcloud 是在LXC基础上发展起来的 拥有一套容器管理生态系统 生态系统包含：容器镜像、注册表、RESTFul API及命令行操作界面 属于容器管理系统 Docker版本介绍 2017之前版本 1.7 ,1.8,1.9,1.10,1.11,1.12,1.13 2017年3月1日后 把docker做商业开源 docker-ce docker-ee 17-03-ce 17-06-ce 18-03-ce 18-06-ce 18-09-ce 19.03-ce 二、docker介绍docker.jpeg Docker 是一个开源项目，诞生于 2013 年初，最初是 dotCloud 公司内部的一个业余项目。它基于 Google 公司推出的 Go 语言实现。 项目后来加入了 Linux 基金会，遵从了 Apache 2.0 协议，项目代码在 GitHub 上进行维护。 Docker 自开源后受到广泛的关注和讨论，以至于 dotCloud 公司后来都改名为 Docker Inc。Redhat 已经在其 RHEL6.5 中集中支持 Docker；Google 也在其 PaaS 产品中广泛应用。 Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。 在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单。 为什么要用 Docker作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。 首先，Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多。 其次，Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。 容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小。传统虚拟机方式运行 10 个不同的应用就要起 10 个虚拟机，而Docker 只需要启动 10 个隔离的应用即可。 具体说来，Docker 在如下几个方面具有较大的优势。 更快速的交付和部署对开发和运维（devop）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码。 Docker 可以快速创建容器，快速迭代应用程序，并让整个过程全程可见，使团队中的其他成员更容易理解应用程序是如何创建和工作的。 Docker 容器很轻很快！容器的启动时间是秒级的，大量地节约开发、测试、部署的时间。 更高效的虚拟化Docker 容器的运行不需要额外的 hypervisor 支持，它是内核级的虚拟化，因此可以实现更高的性能和效率。 更轻松的迁移和扩展Docker 容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、个人电脑、服务器等。 这种兼容性可以让用户把一个应用程序从一个平台直接迁移到另外一个。 更简单的管理使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分发和更新，从而实现自动化并且高效的管理。 对比传统虚拟机总结 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 Docker基本架构Docker 采用了 C&#x2F;S架构，包括客户端和服务端。 Docker daemon 作为服务端接受来自客户的请求，并处理这些请求（创建、运行、分发容器）。 客户端和服务端既可以运行在一个机器上，也可通过 socket 或者 RESTful API 来进行通信。 docker基本架构.png docker daemon 一般在宿主主机后台运行，等待接收来自客户端的消息。 Docker 客户端则为用户提供一系列可执行命令，用户用这些命令实现跟 Docker daemon 交互。 容器 — 镜像 — 仓库 — daemon — client 之间的关系 clientdaemon.jpg 三、 Docker的名字空间名字空间是 Linux 内核一个强大的特性。每个容器都有自己单独的名字空间，运行在其中的应用都像是在独立的操作系统中运行一样。名字空间保证了容器之间彼此互不影响。 namespace.png pid 名字空间 不同用户的进程就是通过 pid 名字空间隔离开的，且不同名字空间中可以有相同 pid。所有的 LXC 进程在 Docker 中的父进程为Docker进程，每个 LXC 进程具有不同的名字空间。同时由于允许嵌套，因此可以很方便的实现嵌套的 Docker 容器。 net 名字空间 有了 pid 名字空间, 每个名字空间中的 pid 能够相互隔离，但是网络端口还是共享 host 的端口。网络隔离是通过 net 名字空间实现的， 每个 net 名字空间有独立的 网络设备, IP 地址, 路由表, &#x2F;proc&#x2F;net 目录。这样每个容器的网络就能隔离开来。Docker 默认采用 veth 的方式，将容器中的虚拟网卡同 host 上的一 个Docker 网桥 docker0 连接在一起。 ipc 名字空间 容器中进程交互还是采用了 Linux 常见的进程间交互方法(interprocess communication - IPC), 包括信号量、消息队列和共享内存等。然而同 VM 不同的是，容器的进程间交互实际上还是 host 上具有相同 pid 名字空间中的进程间交互，因此需要在 IPC 资源申请时加入名字空间信息，每个 IPC 资源有一个唯一的 32 位 id。 mnt 名字空间 类似 chroot，将一个进程放到一个特定的目录执行。mnt 名字空间允许不同名字空间的进程看到的文件结构不同，这样每个名字空间 中的进程所看到的文件目录就被隔离开了。同 chroot 不同，每个名字空间中的容器在 &#x2F;proc&#x2F;mounts 的信息只包含所在名字空间的 mount point。 uts 名字空间 UTS(“UNIX Time-sharing System”) 名字空间允许每个容器拥有独立的 hostname 和 domain name, 使其在网络上可以被视作一个独立的节点而非 主机上的一个进程。 user 名字空间 每个容器可以有不同的用户和组 id, 也就是说可以在容器内用容器内部的用户执行程序而非主机上的用户。"},{"path":"/2023/07/11/Docker容器实战部署/Docker容器管理/","content":"一、docker容器管理1.1 容器查看-ps命令显示本地容器列表，但是默认不显示关闭的容器，只显示运行中的容器，除非加上命令选项 -a 用法:docker ps [-a 显示所有容器，默认只显示运行的] 123root@zutuanxue ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8f4c3f823843 centos &quot;/bin/bash&quot; 3 seconds ago Exited(0) 3 seconds ago centos7_6 1.2、容器详细信息-inspect命令显示容器的详细信息 用法:docker inspect [容器名称或者ID] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101[root@zutuanxue ~]# docker inspect centos[ &#123; &quot;Id&quot;: &quot;sha256:0f3e07c0138fbe05abcb7a9cc7d63d9bd4c980c3f61fea5efa32e7c4217ef4da&quot;, &quot;RepoTags&quot;: [ &quot;centos:latest&quot;, &quot;zutuanxue_centos:v1&quot; ], &quot;RepoDigests&quot;: [], &quot;Parent&quot;: &quot;&quot;, &quot;Comment&quot;: &quot;&quot;, &quot;Created&quot;: &quot;2019-10-01T23:19:57.105928163Z&quot;, &quot;Container&quot;: &quot;711572e3c0c1ac06d5c13c4e668ec170b8ad8786b5f0949f884a5f7fd350d856&quot;, &quot;ContainerConfig&quot;: &#123; &quot;Hostname&quot;: &quot;711572e3c0c1&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot; ], &quot;Cmd&quot;: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;#(nop) &quot;, &quot;CMD [\\&quot;/bin/bash\\&quot;]&quot; ], &quot;ArgsEscaped&quot;: true, &quot;Image&quot;: &quot;sha256:c0bda62fdbad65a3c6a1843d293a3a47d8233115cc6d384e3cb07c53580a2b43&quot;, &quot;Volumes&quot;: null, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: null, &quot;OnBuild&quot;: null, &quot;Labels&quot;: &#123; &quot;org.label-schema.build-date&quot;: &quot;20190927&quot;, &quot;org.label-schema.license&quot;: &quot;GPLv2&quot;, &quot;org.label-schema.name&quot;: &quot;CentOS Base Image&quot;, &quot;org.label-schema.schema-version&quot;: &quot;1.0&quot;, &quot;org.label-schema.vendor&quot;: &quot;CentOS&quot; &#125; &#125;, &quot;DockerVersion&quot;: &quot;18.06.1-ce&quot;, &quot;Author&quot;: &quot;&quot;, &quot;Config&quot;: &#123; &quot;Hostname&quot;: &quot;&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;Tty&quot;: false, &quot;OpenStdin&quot;: false, &quot;StdinOnce&quot;: false, &quot;Env&quot;: [ &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot; ], &quot;Cmd&quot;: [ &quot;/bin/bash&quot; ], &quot;ArgsEscaped&quot;: true, &quot;Image&quot;: &quot;sha256:c0bda62fdbad65a3c6a1843d293a3a47d8233115cc6d384e3cb07c53580a2b43&quot;, &quot;Volumes&quot;: null, &quot;WorkingDir&quot;: &quot;&quot;, &quot;Entrypoint&quot;: null, &quot;OnBuild&quot;: null, &quot;Labels&quot;: &#123; &quot;org.label-schema.build-date&quot;: &quot;20190927&quot;, &quot;org.label-schema.license&quot;: &quot;GPLv2&quot;, &quot;org.label-schema.name&quot;: &quot;CentOS Base Image&quot;, &quot;org.label-schema.schema-version&quot;: &quot;1.0&quot;, &quot;org.label-schema.vendor&quot;: &quot;CentOS&quot; &#125; &#125;, &quot;Architecture&quot;: &quot;amd64&quot;, &quot;Os&quot;: &quot;linux&quot;, &quot;Size&quot;: 219583055, &quot;VirtualSize&quot;: 219583055, &quot;GraphDriver&quot;: &#123; &quot;Data&quot;: &#123; &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/7e9695593c24efc2b9e7cbe8ee2ce7c299e8cde85d73668b94f91284554d3e57/merged&quot;, &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/7e9695593c24efc2b9e7cbe8ee2ce7c299e8cde85d73668b94f91284554d3e57/diff&quot;, &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/7e9695593c24efc2b9e7cbe8ee2ce7c299e8cde85d73668b94f91284554d3e57/work&quot; &#125;, &quot;Name&quot;: &quot;overlay2&quot; &#125;, &quot;RootFS&quot;: &#123; &quot;Type&quot;: &quot;layers&quot;, &quot;Layers&quot;: [ &quot;sha256:9e607bb861a7d58bece26dd2c02874beedd6a097c1b6eca5255d5eb0d2236983&quot; ] &#125;, &quot;Metadata&quot;: &#123; &quot;LastTagTime&quot;: &quot;2019-11-15T05:18:05.72378385-05:00&quot; &#125; &#125;] 1.3、容器创建-run命令容器创建命令 用法:docker run [options] 镜像名称 123456789101112131415#后台执行容器[root@zutuanxue ~]# docker run -d --name centos7_6 centos #前台执行的容器[root@zutuanxue ~]# docker run -it --name centos7_5 centos /bin/bash[root@5a1f02b4041c /]# -i 交互式创建-t 创建一个伪终端-d 后台执行--name 容器名称/bin/bash 在伪终端中执行的命令 1.4、容器删除-rm命令删除一个本地容器 用法:docker rm [容器名称或者ID] [–force] 12345[root@zutuanxue ~]# docker rm centos7_5centos7_5默认删除的容器必须是关闭状态，建议如果希望删除一个运行的容器，可以先关闭在删除。当然也可以在后面直接加上--force 强制删除一个运行中的容器 1.5、容器执行命令-exec命令在运行容器中执行一个命令，如果想在容器中执行一个命令，那么这个exec命令就很有用了。 用法:docker exec [容器名称或者ID] 命令 1234567891011121314151617181920[root@zutuanxue ~]# docker exec centos7_6 ls /bindevetchomeliblib64lost+foundmediamntoptprocrootrunsbinsrvsystmpusrvar 1.6、容器信息输出-attach命令将一个运行容器的标准输出、错误输出、标准输入调入前台默认容器都会在后台运行，如果你想进入容器内，就可以使用该命令。这样你就可以交互式的在容器中执行命令了。 用法:docker attach [容器名称或者ID] 123[root@zutuanxue ~]# docker attach centos7_6[root@128dc0ffc489 /]# 1.7、容器启动-start命令启动一个容器 用法:docker start [容器名称或者ID] 12[root@zutuanxue ~]# docker start centos7_6centos7_6 1.8、停止一个容器-stop命令关闭一个容器 用法:docker stop [容器名称或者ID] 12[root@zutuanxue ~]# docker stop centos7_6centos7_6 1.9、重启一个容器-restart命令重启一个容器 用法:docker restart [容器名称或者ID] 12[root@zutuanxue ~]# docker restart centos7_6centos7_6 1.10、容器挂起-pause命令挂起运行中的容器 用法：docker pause [容器名称或者ID] 12345678[root@zutuanxue ~]# docker pause centos7_6centos7_6[root@zutuanxue ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES128dc0ffc489 centos &quot;/bin/bash&quot; 19 minutes ago Up 14 minutes (Paused) centos7_6 1.11、容器恢复-unpause命令恢复挂起容器 用法:docker unpause [容器名称或者ID] 12[root@zutuanxue ~]# docker unpause centos7_6centos7_6 1.12、容器重命名-rename命令重命名容器 用法:docker rename 容器名称 容器新名称 1[root@zutuanxue ~]# docker rename centos7_6 centos76 1.13、容器端口映射信息-port命令显示容器与宿主机的端口隐射信息 用法:docker port [容器名称或者ID] 1234[root@zutuanxue ~]# docker port 32fd02f054465000/tcp -&gt; 0.0.0.0:5000容器的TCP 5000端口与宿主机的所有IP的5000端口绑定 1.14、杀死一个或多个容器-kill命令杀死运行的容器 用法:docker kill [镜像名称或者ID] 12[root@zutuanxue ~]# docker kill centos76centos76 1.15、容器导出-export命令将一个容器导出一个镜像为压缩文件 用法:docker export -o 导出后镜像文件名 [容器名称或者ID] 12345[root@zutuanxue ~]# docker export -o zutuanxue_centos.tar centos76[root@zutuanxue ~]# lsanaconda-ks.cfg centos_base.tar Docker zutuanxue_centos.tar 1.16、容器镜像导入到镜像库-import命令将容器镜像导入到镜像库 用法:docker import 镜像文件名 镜像名:tag 12[root@zutuanxue ~]# docker import zutuanxue_centos.tar zutuanxue/centos7_6:latestsha256:659fb2fca656430822627685ba4f29d09ae619cd9f2b42ef52d47003c8af8d11 1.17、将容器生成镜像-commit命令将改变后的容器直接变成镜像，一般指的是封装好业务的容器，直接封装成镜像 用法:docker commit [容器名称或者ID] 导出后镜像的名字:tag 123[root@zutuanxue ~]# docker commit centos76 zutuanxue/centos_7_6:v1sha256:1f078c1d94dd641c65495bd91d3e471593c5ec60ecbb4492cfa18a161448dd3a"},{"path":"/2023/07/11/Docker容器实战部署/Docker安装/","content":"一、docker安装Docker 是管理容器的工具， Docker 不等于 容器。 1.1、docker yum源设置123456789101112131415161718#step 1 download docker-ce.repo file[root@zutuanxue ~]# wget https://download.docker.com/linux/centos/docker-ce.repo -P /etc/yum.repos.d/--2019-11-14 20:46:09-- https://download.docker.com/linux/centos/docker-ce.repo正在解析主机 download.docker.com (download.docker.com)... 13.35.50.117, 13.35.50.10, 13.35.50.93, ...正在连接 download.docker.com (download.docker.com)|13.35.50.117|:443... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：2424 (2.4K) [binary/octet-stream]正在保存至: “/etc/yum.repos.d/docker-ce.repo.1”100%[==================================================&gt;] 2,424 --.-K/s 用时 0s 2019-11-14 20:46:09 (210 MB/s) - 已保存 “/etc/yum.repos.d/docker-ce.repo.1” [2424/2424])#step 2 change docker yum repo from tsinghua web[root@zutuanxue ~]# sed -i &#x27;s#download.docker.com#mirrors.tuna.tsinghua.edu.cn/docker-ce#g&#x27; /etc/yum.repos.d/docker-ce.repo 1.2、docker 安装1.2.1、卸载旧版本1[root@zutuanxue ~]# yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine 1.2.2、安装docker123[root@zutuanxue ~]# yum -y install https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.2.6-3.3.el7.x86_64.rpm[root@zutuanxue ~]# yum -y install docker-ce 1.2.3、启动docker12345[root@zutuanxue ~]# systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.[root@zutuanxue ~]# systemctl start docker 1.3、验证启动12345678910111213141516171819202122[root@zutuanxue ~]# systemctl status docker● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since 四 2019-11-14 20:53:12 EST; 14s ago Docs: https://docs.docker.com Main PID: 1584 (dockerd) Tasks: 12 Memory: 60.7M CGroup: /system.slice/docker.service └─1584 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock11月 14 20:53:12 zutuanxue dockerd[1584]: time=&quot;2019-11-14T20:53:12.366007531-05:00&quot; level=info msg=&quot;scheme \\&quot;unix\\&quot; not registered, fallback to defau...odule=grpc11月 14 20:53:12 zutuanxue dockerd[1584]: time=&quot;2019-11-14T20:53:12.366028377-05:00&quot; level=info msg=&quot;ccResolverWrapper: sending update to cc: &#123;[&#123;unix:...odule=grpc11月 14 20:53:12 zutuanxue dockerd[1584]: time=&quot;2019-11-14T20:53:12.366036593-05:00&quot; level=info msg=&quot;ClientConn switching balancer to \\&quot;pick_first\\&quot;&quot; module=grpc11月 14 20:53:12 zutuanxue dockerd[1584]: time=&quot;2019-11-14T20:53:12.404043665-05:00&quot; level=info msg=&quot;Loading containers: start.&quot;11月 14 20:53:12 zutuanxue dockerd[1584]: time=&quot;2019-11-14T20:53:12.547472878-05:00&quot; level=info msg=&quot;Default bridge (docker0) is assigned with an IP a...P address&quot;11月 14 20:53:12 zutuanxue dockerd[1584]: time=&quot;2019-11-14T20:53:12.588359436-05:00&quot; level=info msg=&quot;Loading containers: done.&quot;11月 14 20:53:12 zutuanxue dockerd[1584]: time=&quot;2019-11-14T20:53:12.733704268-05:00&quot; level=info msg=&quot;Docker daemon&quot; commit=a872fc2f86 graphdriver(s)=o...on=19.03.311月 14 20:53:12 zutuanxue dockerd[1584]: time=&quot;2019-11-14T20:53:12.733826656-05:00&quot; level=info msg=&quot;Daemon has completed initialization&quot;11月 14 20:53:12 zutuanxue systemd[1]: Started Docker Application Container Engine.11月 14 20:53:12 zutuanxue dockerd[1584]: time=&quot;2019-11-14T20:53:12.753929596-05:00&quot; level=info msg=&quot;API listen on /var/run/docker.sock&quot;Hint: Some lines were ellipsized, use -l to show in full. 1.4、验证版本123[root@zutuanxue ~]# docker -vDocker version 19.03.1, build 74b1e89 二、docker client 和 daemon分离docker client 与 daemon分离123456789101112131415161718192021222324252627282930313233341、关闭docker[root@zutuanxue ~]# systemctl stop docker2、修改docker启动方式，要求加载配置文件启动[root@zutuanxue ~]# sed -i.bak &#x27;/^ExecStart=/c\\ExecStart=\\/usr\\/bin\\/dockerd&#x27; /usr/lib/systemd/system/docker.service3、设置docker配置文件,默认没有设置允许监听地址和端口，以及sock文件连接默认是使用sock方式连接，加tcp：//0.0.0.0:2375可实现远程管理[root@zutuanxue ~]# cat /etc/docker/daemon.json &#123; &quot;hosts&quot;: [&quot;tcp://0.0.0.0:2375&quot;,&quot;unix:///var/run/docker.sock&quot;]&#125;4、重载docker服务、重启docker生效配置[root@zutuanxue ~]# systemctl daemon-reload[root@zutuanxue ~]# systemctl restart docker5、查看docker的监听地址和端口[root@zutuanxue ~]# netstat -ntpl |grep 2375tcp6 0 0 :::2375 :::* LISTEN 21219/dockerd 6、客户端连接docker daemon，执行命令[root@zutuanxue ~]# docker -H 192.168.98.240 images"},{"path":"/2023/07/11/Docker容器实战部署/Dockerfile/","content":"一、什么是镜像？镜像可以看成是由多个镜像层叠加起来的一个文件系统（通过UnionFS与AUFS文件联合系统实现），镜像层也可以简单理解为一个基本的镜像，而每个镜像层之间通过指针的形式进行叠加。 1.png 2.png 根据上图，镜像层的主要组成部分包括镜像层 ID、镜像层指针 「指向父层」、元数据「 Layer Metadata，包含了 Docker 构建和运行的信息和父层的层次信息」。只读层和读写层「Top Layer」的组成部分基本一致，同时读写层可以转换成只读层「 通过docker commit 操作实现」。 元数据（metadata）就是关于这个层的额外信息，它不仅能够让Docker获取运行和构建时的信息，还包括父层的层次信息。需要注意，只读层和读写层都包含元数据。 3.png 每一层都包括了一个指向父层的指针。如果一个层没有这个指针，说明它处于最底层。 4.png 在docker主机中镜像层（image layer）的元数据被保存在名为”json”的文件中，一个容器的元数据好像是被分成了很多文件，但或多或少能够在&#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F;目录下找到，就是一个可读层的id。这个目录下的文件大多是运行时的数据，比如说网络，日志等等。 镜像是一堆只读层的统一视角，除了最底层没有指向外，每一层都指向它的父层。统一文件系统（ Union File System）技术能够将不同的层整合成一个文件系统，为这些层提供了一个统一的视角，这样就隐藏了多层的存在。在用户的角度看来，只存在一个文件系统。镜像每一层都是不可写的，都是只读层。 5.png 我们可以看到镜像包含多个只读层，它们重叠在一起。除了最下面一层，其它层都会有一个指针指向下一层。这些层是Docker内部的实现细节，并且能够在docker主机的文件系统上访问到。统一文件系统（union file system，升级版为AUFS）技术能够将不同的层整合成一个文件系统，为这些层提供了一个统一的视角，这样就隐藏了多层的存在，在用户的角度看来，只存在一个文件系统。 二、什么是DockerfileDockerfile 是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。它们简化了从头到尾的流程并极大的简化了部署工作。Dockerfile 从 FROM 命令开始，紧接着跟随着各种方法，命令和参数。其产出为一个新的可以用于创建容器的镜像。 Dockerfile 语法由两部分构成，注释和命令+参数，注释是不能少的,因为明天可能就忘记写的是什么了。说白了, Dockerfile 是告诉 docker 怎么样制作一个镜像,就像我们写代码告诉应用怎么执行一条逻辑,这样应该好理解了，所以可以在 Dockerfile 中写明,我们需要怎么个执行方式的某个镜像,最后执行 docker build 命令构建写好的Dockerfile 成镜像。 三、 Dockerfile基础命令3.1、 FROM：功能为指定基础镜像，并且必须是第一条指令。 如果不以任何镜像为基础，写法为：FROM scratch。 同时意味着接下来所写的指令将作为镜像的第一层开始 语法： FROM FROM : 其中 是可选项，如果没有选择，那么默认值为latest 3.2、 MAINTAINER指定作者 语法： MAINTAINER 3.3、 LABEL功能是为镜像指定标签 语法： LABEL &#x3D; &#x3D; &#x3D; … 一个Dockerfile种可以有多个LABEL，如下： 123456789101112131415161718LABEL &quot;com.example.vendor&quot;=&quot;ACME Incorporated&quot;LABEL com.example.label-with-value=&quot;foo&quot;LABEL version=&quot;1.0&quot;LABEL description=&quot;This text illustrates \\that label-values can span multiple lines.&quot;但是并不建议这样写，最好就写成一行，如太长需要换行的话则使用\\符号如下：LABEL multi.label1=&quot;value1&quot; \\multi.label2=&quot;value2&quot; \\other=&quot;value3&quot;注意：LABEL会继承基础镜像种的LABEL，如遇到key相同，则值覆盖 3.4、 RUN功能为运行指定的命令 RUN命令有两种格式 RUN RUN [“executable”, “param1”, “param2”] 第一种后边直接跟shell命令 在linux操作系统上默认 &#x2F;bin&#x2F;sh -c 第二种是类似于函数调用。 可将executable理解成为可执行文件，后面就是两个参数。 两种写法比对： RUN &#x2F;bin&#x2F;bash -c ‘source $HOME&#x2F;.bashrc; echo $HOME RUN [“&#x2F;bin&#x2F;bash”, “-c”, “echo hello”] 注意：多行命令不要写多个RUN，原因是Dockerfile中每一个指令都会建立一层. RUN书写时的换行符是 \\ 多少个RUN就构建了多少层镜像，会造成镜像的臃肿、多层，不仅仅增加了构件部署的时间，还容易出错。 3.5、 ADD一个复制命令，把文件复制到镜像中 如果把虚拟机与容器想象成两台linux服务器的话，那么这个命令就类似于scp，只是scp需要加用户名和密码的权限验证，而ADD不用 1234567891011121314151617181920212223242526272829303132语法如下：ADD &lt;src&gt;... &lt;dest&gt;&lt;src&gt;可以是一个本地文件或者是一个本地压缩文件，还可以是一个url&lt;dest&gt;路径的填写可以是容器内的绝对路径，也可以是相对于工作目录的相对路径ADD test1.txt test1.txtADD test1.txt test1.txt.bakADD test1.txt /mydir/ADD data1 data1ADD zip.tar /myzip有如下注意事项：1、如果源路径是个文件，且目标路径是以 / 结尾， 则docker会把目标路径当作一个目录，会把源文件拷贝到该目录下。如果目标路径不存在，则会自动创建目标路径。2、如果源路径是个文件，且目标路径不是以 / 结尾，则docker会把目标路径当作一个文件。3、如果目标路径不存在，会以目标路径为名创建一个文件，内容同源文件；4、如果目标文件是个存在的文件，会用源文件覆盖它，当然只是内容覆盖，文件名还是目标文件名。5、如果目标文件实际是个存在的目录，则会源文件拷贝到该目录下。 注意，这种情况下，最好显示的以 / 结尾，以避免混淆。6、如果源路径是个目录，且目标路径不存在，则docker会自动以目标路径创建一个目录，把源路径目录下的文件拷贝进来。如果目标路径是个已经存在的目录，则docker会把源路径目录下的文件拷贝到该目录下。7、如果源文件是个归档文件（压缩文件），则docker会自动帮解压。尽量不要把&lt;scr&gt;写成一个文件夹，如果&lt;src&gt;是一个文件夹了，复制整个目录的内容,包括文件系统元数据 3.6、COPY复制命令 语法如下： COPY … COPY [“”,… “”] 与ADD的区别, COPY的只能是本地文件，其他用法一致 3.7、 VOLUME可实现挂载功能，可以将内地文件夹或者其他容器种得文件夹挂在到这个容器种 语法为： VOLUME [“&#x2F;data”] 说明： [“&#x2F;data”]可以是一个JsonArray ，也可以是多个值。所以如下几种写法都是正确的 VOLUME [“&#x2F;var&#x2F;log&#x2F;“] VOLUME &#x2F;var&#x2F;log VOLUME &#x2F;var&#x2F;log &#x2F;var&#x2F;db 一般的使用场景为需要持久化存储数据时, 容器使用的是AUFS，这种文件系统不能持久化数据，当容器关闭后，所有的更改都会丢失，所以当数据需要持久化时用这个命令。 3.8、 EXPOSE功能为暴漏容器运行时的监听端口给外部 但是EXPOSE并不会使容器访问主机的端口 如果想使得容器与主机的端口有映射关系，必须在容器启动的时候加上 -P参数 3.9、 WORKDIR设置工作目录 语法： WORKDIR &#x2F;usr&#x2F;bin&#x2F; 3.10、 ENV功能为设置环境变量 语法有两种 ENV ENV &#x3D; … 两者的区别就是第一种是一次设置一个，第二种是一次设置多个 3.11、 CMD功能为容器启动时要运行的命令 语法有三种写法 CMD [“executable”,“param1”,“param2”] CMD [“param1”,“param2”] CMD command param1 param2 第三种比较好理解了，就时shell这种执行方式和写法 第一种和第二种其实都是可执行文件加上参数的形式 举例说明两种写法： CMD [ “sh”, “-c”, “echo $HOME” CMD [ “echo”, “$HOME” ] 注意： 1、这里边包括参数的一定要用双引号，就是 “ 不能是单引号, 原因是参数传递后，docker解析的是一个JSON Array 2、不要把RUN和CMD搞混了。 RUN：是构件容器时就运行的命令以及提交运行结果 CMD：是容器启动时执行的命令，在构件时并不运行 3.12、 ENTRYPOINT功能是启动时的默认命令 语法如下： ENTRYPOINT [“executable”, “param1”, “param2”] ENTRYPOINT command param1 param2 如果从上到下看到这里的话，那么你应该对这两种语法很熟悉啦。 第一种就是可执行文件加参数 第二种就是写shell 1234567891011121314151617181920212223242526与 CMD 比较说明：相同点：只能写一条，如果写了多条，那么只有最后一条生效，容器启动时才运行，运行时机相同不同点：ENTRYPOINT 不会被运行的 command 覆盖，而 CMD 则会被覆盖如果我们在 Dockerfile 时同时写了 ENTRYPOINT 和 CMD ，并且 CMD 指令不是一个完整的可执行命令，那么CMD 指定的内容将会作为 ENTRYPOINT 的参数, 如下：FROM centosENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]CMD [&quot;-c&quot;]如果我们在 Dockerfile 种同时写了 ENTRYPOINT 和 CMD ，并且 CMD 是一个完整的指令，那么它们两个会互相覆盖，谁在最后谁生效, 如下：FROM centosENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]CMD ls -al那么将执行 ls -al , top -b 不会执行 四、 Dockerfile 案例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485861、创建目录，用于存放 dockerfile 所使用的文件2、在此目录中创建 dockerfile 文件3、在此目录中使用 docker build 创建镜像4、使用创建的镜像启动容器准备启动文件：vim httpd-run.sh#!/bashrm -rf /run/httpd/*exec /usr/sbin/httpd -D FOREGROUND准备网页测试文件vim index.htmlhello welcome to zutuanxue!!!准备 dockerfile 文件FROM centos:latestMAINTAINER &quot;zutuanxue admin@163.com&quot; ADD httpd-run.sh /httpd-run.shADD index.html /var/www/html/index.htmlRUN yum -y install httpd &amp;&amp; chmod -v +x /httpd-run.shEXPOSE 80WORKDIR /CMD [&quot;/bin/bash&quot;,&quot;/httpd-run.sh&quot;]创建镜像：docker build -t centos-httpd:v1 . -t: 镜像的名字及标签，通常 name:tag 或者 name 格式#定义基础镜像 FROMFROM centos#定义作者 MAINTAINERMAINTAINER BaiShuming#上传文件到容器 COPY or ADD#COPY 从当前目录复制文件到容器. 只是单纯地复制文件. 格式为 COPY &lt;src&gt; &lt;dest&gt;。#ADD 从当前目录复制文件到容器. 会自动处理目录, 压缩包等情况.格式为 ADD &lt;src&gt; &lt;dest&gt;。ADD nginx-1.17.6.tar.gz /root#生成镜像时运行的命令 RUN#shell 写法RUN yum -y install pcre-devel zlib-devel openssl lsof iproute net-tools gcc make#exec写法#[&quot;命令&quot;,&quot;命令选项&quot;,&quot;参数&quot;]#解压压缩文件#RUN [&quot;tar&quot;,&quot;xf&quot;,&quot;nginx-1.17.6.tar.gz&quot;]#创建管理用户wwwRUN useradd -r -s/sbin/nologin -M www#进入nginx源码文件WORKDIRWORKDIR /root/nginx-1.17.6#安装nginxRUN ./configure --prefix=/usr/local/nginx --user=www --group=www &amp;&amp; make &amp;&amp; make install#定义变量 ENVENV PATH /usr/local/nginx/sbin:$PATH#业务初始化#COPY 从当前目录复制文件到容器. 只是单纯地复制文件. 格式为 COPY &lt;src&gt; &lt;dest&gt;。COPY nginx.conf /usr/local/nginx/confCOPY index.html /usr/local/nginx/html#输出端口 EXPOSEEXPOSE 80#挂载本地目录VOLUME#创建一个可以从本地主机或其他容器挂载的挂载点#一般用来存放数据库和需要保持同步的数据VOLUME [&quot;/data&quot;]#容器启动后执行的命令 CMD#只能执行一个，如果有多个，同一时间只有最后一个生效CMD [&quot;nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;]"},{"path":"/2023/07/11/Docker容器实战部署/Docker Swarm主机编排/","content":"一、 什么是Docker SwarmSwarm 是 Docker 公司推出的用来管理 docker 集群的平台，几乎全部用GO语言来完成的开发的，代码开源在https://github.com/docker/swarm， 它是将一群 Docker 宿主机变成一个单一的虚拟主机，Swarm 使用标准的 Docker API 接口作为其前端的访问入口，换言之，各种形式的Docker Client (compose,docker-py等) 均可以直接与 Swarm 通信，甚至 Docker 本身都可以很容易的与 Swarm 集成，这大大方便了用户将原本基于单节点的系统移植到 Swarm 上，同时 Swarm 内置了对 Docker 网络插件的支持，用户也很容易的部署跨主机的容器集群服务。 Docker Swarm 和 Docker Compose 一样，都是 Docker 官方容器编排项目，但不同的是，Docker Compose 是一个在单个服务器或主机上创建多个容器的工具，而 Docker Swarm 则可以在多个服务器或主机上创建容器集群服务，对于微服务的部署，显然 Docker Swarm 会更加适合。 从 Docker 1.12.0 版本开始，Docker Swarm 已经包含在 Docker 引擎中（docker swarm），并且已经内置了服务发现工具，我们就不需要像之前一样，再配置 Etcd 或者 Consul 来进行服务发现配置了。 Swarm deamon 只是一个调度器(Scheduler)加路由器(router), Swarm 自己不运行容器，它只是接受 Docker 客户端发来的请求，调度适合的节点来运行容器，这就意味着，即使 Swarm 由于某些原因挂掉了，集群中的节点也会照常运行，当 Swarm 重新恢复运行之后，他会收集重建集群信息。 二、 Swarm的几个关键概念Swarm集群的管理和编排是使用嵌入docker引擎的SwarmKit，可以在docker初始化时启动swarm模式或者加入已存在的swarm Node一个节点是docker引擎集群的一个实例。您还可以将其视为Docker节点。您可以在单个物理计算机或云服务器上运行一个或多个节点，但生产群集部署通常包括分布在多个物理和云计算机上的Docker节点。要将应用程序部署到swarm，请将服务定义提交给 管理器节点。管理器节点将称为任务的工作单元分派 给工作节点。Manager节点还执行维护所需群集状态所需的编排和集群管理功能，Manager节点选择单个领导者来执行编排任务，工作节点接收并执行从管理器节点分派的任务。默认情况下，管理器节点还将服务作为工作节点运行，但您可以将它们配置为仅运行管理器任务并且是仅管理器节点。代理程序在每个工作程序节点上运行，并报告分配给它的任务。工作节点向管理器节点通知其分配的任务的当前状态，以便管理器可以维持每个工作者的期望状态。 Service一个服务是任务的定义，管理机或工作节点上执行。它是群体系统的中心结构，是用户与群体交互的主要根源。创建服务时，你需要指定要使用的容器镜像。 Task任务是在docekr容器中执行的命令，Manager节点根据指定数量的任务副本分配任务给worker节点 三、相关命令123456789docker swarm：\t集群管理，子命令有init, ``join``, leave, update。（docker swarm --help查看帮助）docker service：\t服务创建，子命令有create, inspect, update, remove, tasks。（docker service--help查看帮助）docker node：\t节点管理，子命令有accept, promote, demote, inspect, update, tasks, ``ls``, ``rm``。（docker node --help查看帮助） 四、swarm集群部署4.1、 部署前准备1234567891011121314151617181920212223242526以下操作在所有节点上进行：| IP地址 | 计算机名 | 角色 || ------------- | ----------- ---- | ------------ || 192.168.1.150 | zutuanxue-manage01 | swarm_manager || 192.168.1.151 | zutuanxue-node-1 | swarm_node || 192.168.1.152 | zutuanxue-node-2 | swarm_node |安装 dockerhosts 解析[root@zutuanxue-manage01 ~]# cat /etc/hosts192.168.1.150 zutuanxue-manage01192.168.1.151 zutuanxue-node-1192.168.1.152 zutuanxue-node-2[root@zutuanxue-manage01 ~]# systemctl disable firewalld[root@zutuanxue-manage01 ~]# systemctl stop firewalld[root@zutuanxue-manage01 ~]# iptables -F关闭 selinux#设置为 disabled 后需要重启计算机生效SELINUX=disabled 4.2、 创建swarm集群1234567891011121314初始化集群-init[root@zutuanxue-manage01 ~]# docker swarm init --advertise-addr 192.168.1.150#--advertise-addr参数表示其它swarm中的worker节点使用此ip地址与manager联系Swarm initialized: current node (dh6qthwwctbrl0y3hx1k41icl) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-0vdbyxq80uk8sf9nlnahsnkv6w3gaf5necl992ia0g8dmc5x8c-bkenoigc7kwizoch08r3fc4wq 192.168.1.150:2377To add a manager to this swarm, run &#x27;docker swarm join-token manager&#x27; and follow the instructions. 4.3、添加worker（node工作节点）到swarm12345[root@zutuanxue-node-1 ~]# docker swarm join --token SWMTKN-1-0vdbyxq80uk8sf9nlnahsnkv6w3gaf5necl992ia0g8dmc5x8c-bkenoigc7kwizoch08r3fc4wq 192.168.1.150:2377This node joined a swarm as a worker.[root@zutuanxue-node-2 ~]# docker swarm join --token SWMTKN-1-0vdbyxq80uk8sf9nlnahsnkv6w3gaf5necl992ia0g8dmc5x8c-bkenoigc7kwizoch08r3fc4wq 192.168.1.150:2377This node joined a swarm as a worker. 4.4、 验证加入情况1[root@zutuanxue-manage01 ~]# docker node ls 4.5、 在Swarm中部署服务(nginx为例)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283创建网络在部署服务# 创建网络[root@zutuanxue-manage01 ~]# docker network create -d overlay nginx_neta52jy33asc5o0ts0rq823bf0m[root@zutuanxue-manage01 ~]# docker network ls | grep nginx_neta52jy33asc5o nginx_net overlay swarm # 部署服务[root@zutuanxue-manage01 ~]# docker service create --replicas 1 --network nginx_net --name my_nginx -p 80:80 nginx # 就创建了一个具有一个副本（--replicas 1 ）的nginx服务，使用镜像nginxolexfmtdf94sxyeetkchwhehgoverall progress: 1 out of 1 tasks1/1: running [==================================================&gt;]verify: Service converged在 manager与node 节点上使用上面这个覆盖网络创建 nginx 服务其中，--replicas 参数指定服务由几个实例组成注意：不需要提前在节点上下载 nginx 镜像，这个命令执行后会自动下载这个容器镜像# 使用 docker service ls 查看正在运行服务的列表[root@zutuanxue-manage01 ~]# docker service lsID NAME MODE REPLICAS IMAGE PORTSolexfmtdf94s my_nginx replicated 1/1 nginx:latest *:80-&gt;80/tcp 2) 查询Swarm中服务的信息 -pretty 使命令输出格式化为可读的格式，不加 --pretty 可以输出更详细的信息：[root@zutuanxue-manage01 ~]# docker service inspect --pretty my_nginxID: zs7fw4ereo5w7ohd4n9ii06ntName: my_nginxService Mode: Replicated Replicas: 1Placement:UpdateConfig: Parallelism: 1 On failure: pause Monitoring Period: 5s Max failure ratio: 0 Update order: stop-firstRollbackConfig: Parallelism: 1 On failure: pause Monitoring Period: 5s Max failure ratio: 0 Rollback order: stop-firstContainerSpec: Image: nginx:latest@sha256:b73f527d86e3461fd652f62cf47e7b375196063bbbd503e853af5be16597cb2e Init: falseResources:Networks: nginx_netEndpoint Mode: vipPorts: PublishedPort = 80 Protocol = tcp TargetPort = 80 PublishMode = ingress # 查询到哪个节点正在运行该服务[root@zutuanxue-manage01 ~]# docker service ps my_nginx在 Swarm 中动态扩展服务 (scale) 当然，如果只是通过 service 启动容器，swarm 也算不上什么新鲜东西了。Service 还提供了复制（类似 kubernetes 里的副本）功能。可以通过 docker service scale 命令来设置服务中容器的副本数，比如将上面的 my_nginx 容器动态扩展到 4 个[root@manager43 ~]# docker service scale my_nginx=4my_nginx scaled to 4overall progress: 4 out of 4 tasks1/4: running [==================================================&gt;]2/4: running [==================================================&gt;]3/4: running [==================================================&gt;]4/4: running [==================================================&gt;]verify: Service converged 和创建服务一样，增加 scale 数之后，将会创建新的容器，这些新启动的容器也会经历从准备到运行的过程，过一分钟左右，服务应该就会启动完成，这时候可以再来看一下 nginx 服务中的容器[root@manager43 ~]# docker service ps my_nginx升级镜像/升级业务/回滚业务docker service update --image nginx:new my_nginx删除服务[root@manager43 ~]# docker service rm my_nginx"},{"title":"Docker-Compose","path":"/2022/09/27/Docker容器实战部署/Docker Compose容器编排/","content":"一、 Docker-Compose1.1、 什么是Docker ComposeCompose 项目是 Docker 官方的开源项目，负责实现 Docker 容器集群的快速编排，开源代码在 https://github.com/docker/compose 上 我们知道使用 Dockerfile 模板文件可以让用户很方便的定义一个单独的应用容器，其实在工作中，经常会碰到需要多个容器相互配合来完成的某项任务情况，例如工作中的 web 服务容器本身，往往会在后端加上数据库容器，甚至会有负责均衡器，比如 LNMP 服务 Compose 就是来做这个事情的，它允许用户通过一个单独的 docker-compose.yml 模板文件 YAML格式 来定义一组相关联的应用容器为一个项目 project Compose 中有两个重要的概念： 服务 service :一个应用的容器，实际上可以包括若干运行相同镜像的容器实例项目 project :由一组关联的应用容器组成的一个完整业务单元，在docker-compose.yml中定义 1.2、 安装123# docker-compose版本选择:https://github.com/docker/compose/releases# curl -L https://github.com/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose# chmod +x /usr/local/bin/docker-compose 1.3、 命令12345678910111213141516171819202122232425262728293031323334353637383940Compose 大部分命令的对象即可以是项目的本身，也可以是指定为项目中的服务或者容器执行docker-compose [COMMAND] --help 或者docker-compose help [COMMAND]可以查看命令的帮助信息具体的使用格式docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS]参数选项-f,--file file指定模板文件，默认是docker-compose.yml模板文件,可以多次指定-p,--project-name name指定项目名称，默认使用所在目录名称作为项目名称--x-networking 使用Docker的后端可插拔网络特性--x-networking-driver driver指定网络的后端驱动，默认使用bridge--verbose 输入更多的调试信息-v,--version 输出版本信息Compose所支持的命令：build 构建项目中的服务容器 bundle 从Compose文件生成分布式应用程序包 config 验证并查看Compose文件 create 为服务创建容器 down 停止容器并删除由其创建的容器，网络，卷和图像up events 为项目中的每个容器流式传输容器事件 exec 这相当于docker exec。 help 获得一个命令的帮助 kill 通过发送SIGKILL信号来强制停止服务容器 logs 查看服务容器的输出 pause 暂停一个容器 port 打印某个容器端口所映射的公共端口 ps 列出项目中目前所有的容器 pull 拉取服务依赖镜像 push 推送服务镜像 restart 重启项目中的服务 rm 删除所有停止状态的服务容器 run 在指定服务上执行一个命令 scale 设置指定服务执行的容器个数 start 启动已存在的服务容器 stop 停止已存在的服务容器 top 显示容器正在运行的进程 unpause 恢复处于暂停状态的容器 up 自动完成包括构建镜像、创建服务、启动服务并关联服务相关容器的一系列操作 version 输出版本 1.4、模板文件排版问题，请看单独的文件。官网链接：https://docs.docker.com/compose/compose-file/#compose-file-structure-and-examples 1.5、 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687举个简单的例子来具有的说明一下 Compose 的使用1. 创建一个目录(里面包含需要的文件)[root@zutuanxue] mkdir compose-py2. 创建一个 Python 应用， 使用 Flask ，将数值记入 Redis[root@zutuanxue compose-py] cat app.pyimport time import redisfrom flask import Flask app = Flask(__name__)cache = redis.Redis(host=&#x27;redis&#x27;, port=6379) def get_hit_count(): retries = 5 while True: try: return cache.incr(&#x27;hits&#x27;) except redis.exceptions.ConnectionError as exc: if retries == 0: raise exc retries -= 1 time.sleep(0.5) @app.route(&#x27;/&#x27;)def hello(): count = get_hit_count() return &#x27;Hello World! I have been seen &#123;&#125; times. &#x27;.format(count) if __name__ == &quot;__main__&quot;: app.run(host=&quot;0.0.0.0&quot;, debug=True)3. 创建 requirements.txt 文件，里面是需要安装的 Python 包[root@zutuanxue compose-py] cat requirements.txtflaskredis4. 创建 Dockerfile 文件[root@zutuanxue compose-py] cat DockerfileFROM pythonADD . /codeWORKDIR /codeRUN pip install -r requirements.txtCMD [&quot;python&quot;, &quot;app.py&quot;] # 这告诉Docker： 从 Python 开始构建镜像 将当前目录 . 添加到 /code 镜像中的路径 将工作目录设置为 /code 安装 Python 依赖项 将容器的默认命令设置为 python app.py 5. 创建 docker-compose.yml 文件[root@zutuanxue compose-py] cat docker-compose.ymlversion: &#x27;3&#x27;services: web: build: . ports: - &quot;5000:5000&quot; volumes: - .:/code redis: image: &quot;redis&quot; 此 Compose 文件定义了两个服务，web 和 redis 该web服务：\t使用从 Dockerfile 当前目录中构建的镜像\t将容器上的公开端口 5000 转发到主机上的端口 5000 我们使用 Flask Web 服务器的默认端口 5000\t该 redis 服务使用从 Docker Hub 中提取的公共 Redis 映像\t6. 使用 Compose 构建并运行您的应用程序[root@zutuanxue compose-py] docker-compose up7. 测试访问，在浏览器访问 IP:5000 每刷新一次就会加一","categories":["Linux云计算","Docker"]},{"title":"Docker 网络","path":"/2022/09/27/Docker容器实战部署/Docker 网络/","content":"一、Docker 网络docker网络主要是解决容器联网问题，也是我们使用容器中最重要的一个环节，如果容器没有网络则无法向网络中提供服务。 网络管理命令：docker network12345678910111213141516[root@zutuanxue ~]# docker network --helpUsage:\tdocker network COMMANDManage networksCommands: connect Connect a container to a network create Create a network disconnect Disconnect a container from a network inspect Display detailed information on one or more networks ls List networks prune Remove all unused networks rm Remove one or more networksRun &#x27;docker network COMMAND --help&#x27; for more information on a command. 二、docker网络类型创建容器的时候可以通过—network命令来指定容器的网络，网络类型有以下四种 bridge host none 容器网络或联盟网络 bridge桥接网络是指容器通过桥接的方式将容器网卡桥接到宿主机的docker0网桥，然后在通过宿主机防火墙的NAT表实现与外网的联系。 宿主机docker0网桥123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[root@zutuanxue ~]# ifconfig #docker0网桥docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:c7ff:fe37:8e8 prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:c7:37:08:e8 txqueuelen 0 (Ethernet) RX packets 6618 bytes 277975 (271.4 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 8152 bytes 24675021 (23.5 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0.....省略了本机的网卡信息#容器网卡，每创建一个桥接网络的容器就会生成一个对应的网卡vethf75a942: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::9085:f5ff:fe34:77b5 prefixlen 64 scopeid 0x20&lt;link&gt; ether 92:85:f5:34:77:b5 txqueuelen 0 (Ethernet) RX packets 2850 bytes 158484 (154.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 3397 bytes 11613136 (11.0 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 如果想看更清楚一下 可以使用 ip add show命令[root@zutuanxue ~]# ip add show4: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:c7:37:08:e8 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:c7ff:fe37:8e8/64 scope link valid_lft forever preferred_lft forever容器网卡14: vethf75a942@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 92:85:f5:34:77:b5 brd ff:ff:ff:ff:ff:ff link-netnsid 1 inet6 fe80::9085:f5ff:fe34:77b5/64 scope link valid_lft forever preferred_lft forever注意：这里的vethf75a942@if13指的就是容器网卡，V代表虚拟网卡的意思，eth 以太网卡，f75a942网卡编号，if13指的是宿主机网桥(docekr0)的一个端口，对应容器的网卡编号加一。所以容器内的网卡编号应该是 eth0@if14通过在容器中执行命令 ip add show 也可以看到[root@zutuanxue ~]# docker exec centos1 ip add show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever13: eth0@if14: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 防火墙的NAT表内容12345678910111213141516171819[root@zutuanxue ~]# iptables -t nat -LChain PREROUTING (policy ACCEPT)target prot opt source destination DOCKER all -- anywhere anywhere ADDRTYPE match dst-type LOCALChain INPUT (policy ACCEPT)target prot opt source destination Chain OUTPUT (policy ACCEPT)target prot opt source destination DOCKER all -- anywhere !loopback/8 ADDRTYPE match dst-type LOCALChain POSTROUTING (policy ACCEPT)target prot opt source destination MASQUERADE all -- 172.17.0.0/16 anywhere Chain DOCKER (2 references)target prot opt source destination RETURN all -- anywhere anywhere docker0 与容器网卡桥接1234通过brctl show命令可以看到容器网卡和docker0网卡的桥接信息[root@zutuanxue ~]# brctl showbridge name\tbridge id STP enabled\tinterfacesdocker0 8000.0242c73708e8\tno vethf75a942 创建一个网络为bridge类型的容器，不指定默认也是这个类型 1[root@zutuanxue ~]# docker run -d --network bridge --name centos1 baishuming2020/centos_nginx host容器和真机共用网卡及对应的端口，缺点就是同一个端口只能宿主机或者某个容器使用，其他容器不能用。 12创建一个网络类型host的容器[root@zutuanxue ~]# docker run -d --network host --name centos2 baishuming2020/centos_nginx none容器仅有lo网卡，是一个不能联网的本地容器 12创建一个网络类型为lo的容器[root@zutuanxue ~]# docker run -d --network none --name centos3 baishuming2020/centos_nginx 2.1、实现网桥网络目的：不同的服务容器组应用不同的网桥，避免同一网络内容器太多，保持容器网络独立性。 关于新网桥联网问题：创建网桥后，宿主机会自动帮你做NAT，所以不用担心联网问题 查看网络-ls123456789101112[root@zutuanxue ~]# docker network lsNETWORK ID NAME DRIVER SCOPE80982d2613cd bridge bridge local40c179ab420a docker1 bridge local04aadb7475c0 docker100 bridge localce79e9d7525a host host local8f0358469e57 none null localNETWORK ID 网桥ID NAME 名称DRIVER 网络类型 SCOPE 作用范围 创建网桥-create1234567891011121314151617181920[root@zutuanxue ~]# docker network create -d bridge --subnet 192.168.1.0/24 --gateway 192.168.1.1 mydocker06a410e27b66ea587142d967f7dff6f36c04ced3c27116a79831412f3743aba56[root@zutuanxue ~]# docker network lsNETWORK ID NAME DRIVER SCOPE6ee1e928b710 bridge bridge localce79e9d7525a host host local6a410e27b66e mydocker0 bridge local8f0358469e57 none null local修改docker网桥名字1、关闭新建网桥[root@zutuanxue ~]# ip link set dev br-6a410e27b66e down2、修改名字[root@zutuanxue ~]# ip link set dev br-6a410e27b66e name mydocker03、启动网桥[root@zutuanxue ~]# ip link set dev mydocker0 up4、重启docker服务[root@zutuanxue ~]# systemctl restart docker 删除未使用的网桥-prune12345[root@zutuanxue ~]# docker network prune WARNING! This will remove all networks not used by at least one container.Are you sure you want to continue? [y/N] yDeleted Networks:docker1 删除某个网桥-rm12345[root@zutuanxue ~]# docker network rm docker100docker100注意：不能被活动容器占用 容器连接到网桥前提是该容器是桥接网络 12345678910111213141516171819202122232425[root@zutuanxue ~]# docker network connect docker1 centos1[root@zutuanxue ~]# docker exec centos1 ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:02 txqueuelen 0 (Ethernet) RX packets 8 bytes 656 (656.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0发现centos1容器多了一块网卡，使用的正是docker1的网段eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.1.2 netmask 255.255.255.0 broadcast 192.168.1.255 ether 02:42:c0:a8:01:02 txqueuelen 0 (Ethernet) RX packets 16 bytes 1312 (1.2 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 容器断开网桥12将centos1容器的网络从docker1网桥断开[root@zutuanxue ~]# docker network disconnect docker1 centos1 常见故障FAQ1：使用改名后的新网桥的容器可能无法解析域名原因：没有配置新网桥的DNS 解决方法：为容器手动配置一个DNS地址即可 FAQ2：Networking will not work12345678910[root@zutuanxue ~]# docker run -d --network docker100 --name centos4 baishuming2020/centos_nginxWARNING: IPv4 forwarding is disabled. Networking will not work.67f2c276123c993cd66b9d7a99ba22402331a13f9ea8817e57324a934896b805解决方案1、打开转发[root@zutuanxue ~]# echo &quot;net.ipv4.ip_forward=1&quot; &gt;&gt; /usr/lib/sysctl.d/00-system.conf2、重启网络[root@zutuanxue ~]# systemctl restart network 三、不同主机间的容器通信3.1、 macvlan在 Docker 中，macvlan 是众多 Docker 网络模型中的一种，并且是一种跨主机的网络模型，作为一种驱动启用，Docker macvlan 只支持 bridge 模式 123456789#macvlan 需要一块独立的网卡来进行使用，所以我们需要新添加一块网卡docker network create -d macvlan --subnet=172.16.10.0/24 --gateway=172.16.10.1 -o parent=ens224 mtacvlan-1-o parent=网卡名称 指定用来给 macvlan 网络使用的物理网卡注意，要在所有需要运行 macvlan 的主机上执行这条命令，但是要记得更改网关的地址，避免造成IP冲突docker run -itd --network macvlan-1 centos /bin/bash 3.2、 overlay在 Docker 中，overlay 是众多 Docker 网络模型中的一种，并且是一种跨主机的全局网络模型，有一个数据库专门的来存储网络分配信息，避免 IP 冲突，同时内部还有一个小型的 DNS 我们可以直接通过主机名进行访问 1234567891011121314151617181920212223242526272829303132consul 服务端：docker run -itd -h consul --name consul --restart=always -p 8500:8500 progrium/consul -server -bootstrap-h 主机名–name 容器名–restart=always 重启策略progrium/consul 镜像名称-server 以服务节点启动-bootstrap 预期的启动节点数：自举在浏览器内输入 IP地址+端口号 可以看到 web 页面在所有主机上编辑 daemon.json 文件：&#123;&quot;hosts&quot;: [&quot;tcp://0.0.0.0:2375&quot;,&quot;unix:///var/run/docker.sock&quot;]， 监听相关端口&quot;cluster-store&quot;:&quot;consul://192.168.1.150:8500&quot;, 集群的主机地址&quot;cluster-advertise&quot;:&quot;192.168.1.150:2375” 宣告自己的地址 &#125;重启 docker 服务创建 overlay 网络（全局网络）：一台主机上创建自动同步\tdocker network create -d overlay overlay-1启动容器测试：\tdocker run -it --name docker-1 --network=overlay-1 centos /bin/bash docker run -it --name docker-2 --network=overlay-1 centos /bin/bash\t验证：ping docker-1 常见故障如发现各容器内分配的ip之间相互ping不通 12345678910111213141516原因：可能由于防火墙问题引起的,默认forward链是drop状态，需要打开才可以解决方案:执行下面操作，保证INPUT FORWARD链都是ACCEPT状态清除其他规则[root@zutuanxue_node1 ~]# iptables -P INPUT ACCEPT[root@zutuanxue_node1 ~]# iptables -P FORWARD ACCEPT[root@zutuanxue_node1 ~]# iptables -F[root@zutuanxue_node1 ~]# iptables -L -n[root@zutuanxue_node2 ~]# iptables -P INPUT ACCEPT[root@zutuanxue_node2 ~]# iptables -P FORWARD ACCEPT[root@zutuanxue_node2 ~]# iptables -F[root@zutuanxue_node2 ~]# iptables -L -n","categories":["Linux云计算","Docker"]},{"title":"日常","path":"/more/index.html","content":"第一步：打开 GitHub打开 Stellar 的 GitHub 页面。第二步：点击 Star如果发现右上角的 Star 还没点亮，就点亮它！"},{"title":"公众号原点独白","path":"/wiki/stellar/index.html","content":"原点独白是我从2020年开始运营的账号。 转眼间，它就要4岁啦，然后悄悄告诉你们，聊天界面发消息我都可以看的见，快来和我一起聊聊天呗～ 如果你喜欢原点独白的话，希望能把它分享给你的朋友们。 有你们的帮助和支持，原点独白才会走得更远。 期待能够在这里认识更多新面孔。"}]